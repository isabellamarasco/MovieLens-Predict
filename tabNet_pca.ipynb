{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import copy\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "df = pd.read_csv('dataset-ml-25m/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train set:  9946\n",
      "Numebr of test set:  2764\n",
      "Number of validation set:  1106\n"
     ]
    }
   ],
   "source": [
    "# Dividi il dataset in feature e target\n",
    "X = df.drop(['rating'], axis=1).to_numpy()\n",
    "y = df['rating'].to_numpy()\n",
    "\n",
    "# Dividi il dataset in training, validation e test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1, random_state=42)\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "#count the numebr of x_train \n",
    "print(\"Number of train set: \", X_train.shape[0])\n",
    "print(\"Numebr of test set: \", X_test.shape[0])\n",
    "print(\"Number of validation set: \", X_val.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applica la riduzione della dimensionalit√† con PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_val = pca.transform(X_val)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations:  162\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [8, 16, 32]\n",
    "n_epochs = [200]\n",
    "# Dimension of the prediction  layer\n",
    "n_d = [8, 16, 32]\n",
    "#Dimension of the attention  layer\n",
    "n_a = [8, 16, 32]\n",
    "#Number of successive steps in the network\n",
    "n_steps = [3, 5, 7]\n",
    "# Number of independent GLU layer in each GLU block\n",
    "n_indipendent = [2, 3]\n",
    "\n",
    "params = list(product(batch_sizes, n_epochs, n_d, n_a, n_steps, n_indipendent))\n",
    "comb = len(batch_sizes)*len(n_d)*len(n_a) *len(n_steps) *len(n_indipendent)\n",
    "print(\"Number of combinations: \", comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(batch_size, n_epochs, n_d, n_a, n_steps, n_indipendent):\n",
    "    model = TabNetRegressor(\n",
    "        n_d=n_d,\n",
    "        n_a=n_a,\n",
    "        n_steps=n_steps,\n",
    "        n_independent=n_indipendent\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 2/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 3/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 4/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 5/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 7 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 6/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 7 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 7/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 8/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 9/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 10/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 11/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 7 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 12/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 7 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 13/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 14/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 15/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 16/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 17/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 7 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 18/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 7 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 19/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 20/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 21/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 22/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 23/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 7 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 24/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 7 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 25/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 26/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 27/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 28/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 29/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 7 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 30/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 7 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 31/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 32/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 33/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 34/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 35/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 7 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 36/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 7 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 37/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 38/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 39/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 40/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 41/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 7 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 42/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 7 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 43/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 44/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 45/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 46/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 47/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 7 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 48/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 7 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 49/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 50/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 51/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 52/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 53/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 7 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 54/162\n",
      "Configuration batch size: 8 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 7 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 55/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 56/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 57/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 58/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 59/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 7 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 60/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 7 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 61/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 62/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 63/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 64/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 65/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 7 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 66/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 7 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 67/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 68/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 69/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 70/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 71/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 7 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 72/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 7 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 73/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 74/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 75/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 76/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 77/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 7 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 78/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 7 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 79/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 80/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 81/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 82/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 83/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 7 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 84/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 7 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 85/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 86/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 87/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 88/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 89/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 7 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 90/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 7 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 91/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 92/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 93/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 94/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 95/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 7 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 96/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 7 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 97/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 98/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 99/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 100/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 101/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 7 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 102/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 7 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 103/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 104/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 105/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 106/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 107/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 7 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 108/162\n",
      "Configuration batch size: 16 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 7 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 109/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 110/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 111/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 112/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 113/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 7 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 114/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 7 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 115/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 116/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 117/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 118/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 119/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 7 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 120/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 7 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 121/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 3 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 122/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 3 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 123/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 5 - n_indipendent: 2\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 124/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 5 - n_indipendent: 3\n",
      "Model already trained. Skipping...\n",
      "\n",
      "Iteration 125/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.79384 | mse_mse: 0.24436 |  0:00:14s\n",
      "epoch 1  | loss: 0.28454 | mse_mse: 0.23164 |  0:00:30s\n",
      "epoch 2  | loss: 0.26362 | mse_mse: 0.23012 |  0:00:51s\n",
      "epoch 3  | loss: 0.25912 | mse_mse: 0.24612 |  0:01:32s\n",
      "epoch 4  | loss: 0.24846 | mse_mse: 0.22886 |  0:01:51s\n",
      "epoch 5  | loss: 0.24583 | mse_mse: 0.21812 |  0:02:08s\n",
      "epoch 6  | loss: 0.23901 | mse_mse: 0.22911 |  0:02:25s\n",
      "epoch 7  | loss: 0.17796 | mse_mse: 0.10796 |  0:02:42s\n",
      "epoch 8  | loss: 0.11928 | mse_mse: 0.07136 |  0:02:59s\n",
      "epoch 9  | loss: 0.07523 | mse_mse: 0.0356  |  0:03:17s\n",
      "epoch 10 | loss: 0.04812 | mse_mse: 0.03651 |  0:03:34s\n",
      "epoch 11 | loss: 0.03895 | mse_mse: 0.01936 |  0:03:52s\n",
      "epoch 12 | loss: 0.04461 | mse_mse: 0.01927 |  0:04:09s\n",
      "epoch 13 | loss: 0.0358  | mse_mse: 0.02157 |  0:04:23s\n",
      "epoch 14 | loss: 0.03574 | mse_mse: 0.01514 |  0:04:41s\n",
      "epoch 15 | loss: 0.03203 | mse_mse: 0.03801 |  0:04:57s\n",
      "epoch 16 | loss: 0.03513 | mse_mse: 0.01637 |  0:05:14s\n",
      "epoch 17 | loss: 0.03107 | mse_mse: 0.01946 |  0:05:27s\n",
      "epoch 18 | loss: 0.03234 | mse_mse: 0.02012 |  0:05:41s\n",
      "epoch 19 | loss: 0.03202 | mse_mse: 0.01437 |  0:05:57s\n",
      "epoch 20 | loss: 0.02626 | mse_mse: 0.00929 |  0:06:12s\n",
      "epoch 21 | loss: 0.02651 | mse_mse: 0.03177 |  0:06:28s\n",
      "epoch 22 | loss: 0.02616 | mse_mse: 0.01278 |  0:06:42s\n",
      "epoch 23 | loss: 0.02645 | mse_mse: 0.07345 |  0:06:57s\n",
      "epoch 24 | loss: 0.03088 | mse_mse: 0.01485 |  0:07:12s\n",
      "epoch 25 | loss: 0.0268  | mse_mse: 0.02503 |  0:07:26s\n",
      "epoch 26 | loss: 0.02658 | mse_mse: 0.01689 |  0:07:41s\n",
      "epoch 27 | loss: 0.02682 | mse_mse: 0.01541 |  0:07:56s\n",
      "epoch 28 | loss: 0.02576 | mse_mse: 0.01141 |  0:08:11s\n",
      "epoch 29 | loss: 0.02775 | mse_mse: 0.00781 |  0:08:26s\n",
      "epoch 30 | loss: 0.02315 | mse_mse: 0.01665 |  0:08:40s\n",
      "epoch 31 | loss: 0.0266  | mse_mse: 0.0275  |  0:08:55s\n",
      "epoch 32 | loss: 0.02573 | mse_mse: 0.01224 |  0:09:09s\n",
      "epoch 33 | loss: 0.02417 | mse_mse: 0.01024 |  0:09:24s\n",
      "epoch 34 | loss: 0.02336 | mse_mse: 0.0182  |  0:09:39s\n",
      "epoch 35 | loss: 0.0194  | mse_mse: 0.04859 |  0:09:54s\n",
      "epoch 36 | loss: 0.0247  | mse_mse: 0.01368 |  0:10:09s\n",
      "epoch 37 | loss: 0.02305 | mse_mse: 0.0109  |  0:10:24s\n",
      "epoch 38 | loss: 0.02106 | mse_mse: 0.01595 |  0:10:38s\n",
      "epoch 39 | loss: 0.02288 | mse_mse: 0.01043 |  0:10:54s\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_mse_mse = 0.00781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008039436009024499\n",
      "R2 Score: 0.9637317738903414\n",
      "Best model updated\n",
      "\n",
      "Iteration 126/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.60805 | mse_mse: 0.29565 |  0:00:15s\n",
      "epoch 1  | loss: 0.27357 | mse_mse: 0.25562 |  0:00:31s\n",
      "epoch 2  | loss: 0.27099 | mse_mse: 0.23454 |  0:00:46s\n",
      "epoch 3  | loss: 0.26773 | mse_mse: 0.24401 |  0:01:03s\n",
      "epoch 4  | loss: 0.26505 | mse_mse: 0.34917 |  0:01:18s\n",
      "epoch 5  | loss: 0.24574 | mse_mse: 0.22867 |  0:01:34s\n",
      "epoch 6  | loss: 0.23473 | mse_mse: 0.2165  |  0:01:50s\n",
      "epoch 7  | loss: 0.22227 | mse_mse: 0.16691 |  0:02:05s\n",
      "epoch 8  | loss: 0.12271 | mse_mse: 0.1766  |  0:02:20s\n",
      "epoch 9  | loss: 0.08266 | mse_mse: 0.06097 |  0:02:38s\n",
      "epoch 10 | loss: 0.07026 | mse_mse: 0.03722 |  0:02:55s\n",
      "epoch 11 | loss: 0.06102 | mse_mse: 0.03054 |  0:03:10s\n",
      "epoch 12 | loss: 0.05479 | mse_mse: 0.03323 |  0:03:25s\n",
      "epoch 13 | loss: 0.03999 | mse_mse: 0.02443 |  0:03:43s\n",
      "epoch 14 | loss: 0.03398 | mse_mse: 0.02369 |  0:04:00s\n",
      "epoch 15 | loss: 0.0335  | mse_mse: 0.02126 |  0:04:16s\n",
      "epoch 16 | loss: 0.02698 | mse_mse: 0.01565 |  0:04:33s\n",
      "epoch 17 | loss: 0.03236 | mse_mse: 0.01112 |  0:04:51s\n",
      "epoch 18 | loss: 0.02922 | mse_mse: 0.02071 |  0:05:06s\n",
      "epoch 19 | loss: 0.02972 | mse_mse: 0.04288 |  0:05:23s\n",
      "epoch 20 | loss: 0.02755 | mse_mse: 0.0163  |  0:05:41s\n",
      "epoch 21 | loss: 0.02887 | mse_mse: 0.01391 |  0:06:03s\n",
      "epoch 22 | loss: 0.02853 | mse_mse: 0.03053 |  0:06:25s\n",
      "epoch 23 | loss: 0.02653 | mse_mse: 0.01462 |  0:06:45s\n",
      "epoch 24 | loss: 0.02761 | mse_mse: 0.01418 |  0:07:07s\n",
      "epoch 25 | loss: 0.02542 | mse_mse: 0.01806 |  0:07:26s\n",
      "epoch 26 | loss: 0.02448 | mse_mse: 0.0092  |  0:07:43s\n",
      "epoch 27 | loss: 0.02417 | mse_mse: 0.0277  |  0:07:59s\n",
      "epoch 28 | loss: 0.02551 | mse_mse: 0.0273  |  0:08:18s\n",
      "epoch 29 | loss: 0.02329 | mse_mse: 0.02565 |  0:08:35s\n",
      "epoch 30 | loss: 0.02485 | mse_mse: 0.01406 |  0:08:52s\n",
      "epoch 31 | loss: 0.02462 | mse_mse: 0.01317 |  0:09:09s\n",
      "epoch 32 | loss: 0.02328 | mse_mse: 0.03306 |  0:09:26s\n",
      "epoch 33 | loss: 0.02218 | mse_mse: 0.032   |  0:09:42s\n",
      "epoch 34 | loss: 0.02243 | mse_mse: 0.02635 |  0:09:57s\n",
      "epoch 35 | loss: 0.02444 | mse_mse: 0.01846 |  0:10:13s\n",
      "epoch 36 | loss: 0.02235 | mse_mse: 0.01411 |  0:10:30s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_mse_mse = 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009459902437599461\n",
      "R2 Score: 0.9573236381013499\n",
      "\n",
      "Iteration 127/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.56637 | mse_mse: 0.24086 |  0:00:05s\n",
      "epoch 1  | loss: 0.26442 | mse_mse: 0.22721 |  0:00:11s\n",
      "epoch 2  | loss: 0.22356 | mse_mse: 0.17751 |  0:00:18s\n",
      "epoch 3  | loss: 0.1037  | mse_mse: 0.04745 |  0:00:24s\n",
      "epoch 4  | loss: 0.0565  | mse_mse: 0.03006 |  0:00:30s\n",
      "epoch 5  | loss: 0.04251 | mse_mse: 0.01766 |  0:00:37s\n",
      "epoch 6  | loss: 0.03506 | mse_mse: 0.01827 |  0:00:43s\n",
      "epoch 7  | loss: 0.03617 | mse_mse: 0.00875 |  0:00:50s\n",
      "epoch 8  | loss: 0.03306 | mse_mse: 0.02851 |  0:00:56s\n",
      "epoch 9  | loss: 0.03846 | mse_mse: 0.01264 |  0:01:03s\n",
      "epoch 10 | loss: 0.02934 | mse_mse: 0.02303 |  0:01:10s\n",
      "epoch 11 | loss: 0.03626 | mse_mse: 0.0441  |  0:01:16s\n",
      "epoch 12 | loss: 0.03068 | mse_mse: 0.0157  |  0:01:22s\n",
      "epoch 13 | loss: 0.02775 | mse_mse: 0.02577 |  0:01:28s\n",
      "epoch 14 | loss: 0.02878 | mse_mse: 0.01643 |  0:01:35s\n",
      "epoch 15 | loss: 0.02938 | mse_mse: 0.01073 |  0:01:41s\n",
      "epoch 16 | loss: 0.02716 | mse_mse: 0.02118 |  0:01:47s\n",
      "epoch 17 | loss: 0.02495 | mse_mse: 0.00798 |  0:01:53s\n",
      "epoch 18 | loss: 0.02473 | mse_mse: 0.01155 |  0:02:00s\n",
      "epoch 19 | loss: 0.02576 | mse_mse: 0.01131 |  0:02:05s\n",
      "epoch 20 | loss: 0.02432 | mse_mse: 0.03638 |  0:02:11s\n",
      "epoch 21 | loss: 0.02791 | mse_mse: 0.02911 |  0:02:18s\n",
      "epoch 22 | loss: 0.02676 | mse_mse: 0.02049 |  0:02:24s\n",
      "epoch 23 | loss: 0.02716 | mse_mse: 0.00882 |  0:02:30s\n",
      "epoch 24 | loss: 0.02411 | mse_mse: 0.01169 |  0:02:36s\n",
      "epoch 25 | loss: 0.02551 | mse_mse: 0.0936  |  0:02:43s\n",
      "epoch 26 | loss: 0.0267  | mse_mse: 0.03327 |  0:02:49s\n",
      "epoch 27 | loss: 0.02209 | mse_mse: 0.02254 |  0:02:55s\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_mse_mse = 0.00798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008012445175409173\n",
      "R2 Score: 0.9638535373642156\n",
      "Best model updated\n",
      "\n",
      "Iteration 128/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.36973 | mse_mse: 0.10861 |  0:00:07s\n",
      "epoch 1  | loss: 0.15027 | mse_mse: 0.10259 |  0:00:14s\n",
      "epoch 2  | loss: 0.13571 | mse_mse: 0.12476 |  0:00:21s\n",
      "epoch 3  | loss: 0.12475 | mse_mse: 0.07994 |  0:00:29s\n",
      "epoch 4  | loss: 0.09921 | mse_mse: 0.06494 |  0:00:36s\n",
      "epoch 5  | loss: 0.07536 | mse_mse: 0.03779 |  0:00:43s\n",
      "epoch 6  | loss: 0.05279 | mse_mse: 0.02751 |  0:00:51s\n",
      "epoch 7  | loss: 0.03453 | mse_mse: 0.0122  |  0:01:00s\n",
      "epoch 8  | loss: 0.03317 | mse_mse: 0.01086 |  0:01:07s\n",
      "epoch 9  | loss: 0.03268 | mse_mse: 0.02055 |  0:01:14s\n",
      "epoch 10 | loss: 0.02584 | mse_mse: 0.01993 |  0:01:22s\n",
      "epoch 11 | loss: 0.02914 | mse_mse: 0.01464 |  0:01:32s\n",
      "epoch 12 | loss: 0.02695 | mse_mse: 0.05339 |  0:01:40s\n",
      "epoch 13 | loss: 0.02748 | mse_mse: 0.05468 |  0:01:48s\n",
      "epoch 14 | loss: 0.02787 | mse_mse: 0.0189  |  0:01:55s\n",
      "epoch 15 | loss: 0.02584 | mse_mse: 0.04041 |  0:02:02s\n",
      "epoch 16 | loss: 0.02866 | mse_mse: 0.03682 |  0:02:10s\n",
      "epoch 17 | loss: 0.02472 | mse_mse: 0.04875 |  0:02:18s\n",
      "epoch 18 | loss: 0.02696 | mse_mse: 0.01151 |  0:02:25s\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_mse_mse = 0.01086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010997814226593313\n",
      "R2 Score: 0.9503856722493514\n",
      "\n",
      "Iteration 129/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.71771 | mse_mse: 0.23262 |  0:00:12s\n",
      "epoch 1  | loss: 0.29053 | mse_mse: 0.24602 |  0:00:24s\n",
      "epoch 2  | loss: 0.26325 | mse_mse: 0.21866 |  0:00:37s\n",
      "epoch 3  | loss: 0.24895 | mse_mse: 0.21673 |  0:00:48s\n",
      "epoch 4  | loss: 0.19531 | mse_mse: 0.10706 |  0:00:59s\n",
      "epoch 5  | loss: 0.11337 | mse_mse: 0.06146 |  0:01:09s\n",
      "epoch 6  | loss: 0.0708  | mse_mse: 0.07553 |  0:01:19s\n",
      "epoch 7  | loss: 0.05765 | mse_mse: 0.04613 |  0:01:29s\n",
      "epoch 8  | loss: 0.04025 | mse_mse: 0.02711 |  0:01:39s\n",
      "epoch 9  | loss: 0.03797 | mse_mse: 0.05854 |  0:01:49s\n",
      "epoch 10 | loss: 0.03291 | mse_mse: 0.05425 |  0:01:59s\n",
      "epoch 11 | loss: 0.0319  | mse_mse: 0.01117 |  0:02:11s\n",
      "epoch 12 | loss: 0.03251 | mse_mse: 0.01131 |  0:02:21s\n",
      "epoch 13 | loss: 0.02816 | mse_mse: 0.02401 |  0:02:32s\n",
      "epoch 14 | loss: 0.0281  | mse_mse: 0.01493 |  0:02:42s\n",
      "epoch 15 | loss: 0.03055 | mse_mse: 0.02399 |  0:02:52s\n",
      "epoch 16 | loss: 0.03077 | mse_mse: 0.02061 |  0:03:02s\n",
      "epoch 17 | loss: 0.02982 | mse_mse: 0.00972 |  0:03:11s\n",
      "epoch 18 | loss: 0.02786 | mse_mse: 0.02818 |  0:03:21s\n",
      "epoch 19 | loss: 0.02738 | mse_mse: 0.01554 |  0:03:33s\n",
      "epoch 20 | loss: 0.02508 | mse_mse: 0.02225 |  0:03:43s\n",
      "epoch 21 | loss: 0.02652 | mse_mse: 0.02722 |  0:03:53s\n",
      "epoch 22 | loss: 0.03356 | mse_mse: 0.04591 |  0:04:03s\n",
      "epoch 23 | loss: 0.02912 | mse_mse: 0.04729 |  0:04:13s\n",
      "epoch 24 | loss: 0.02586 | mse_mse: 0.01184 |  0:04:22s\n",
      "epoch 25 | loss: 0.02934 | mse_mse: 0.01869 |  0:04:31s\n",
      "epoch 26 | loss: 0.02794 | mse_mse: 0.04248 |  0:04:41s\n",
      "epoch 27 | loss: 0.02811 | mse_mse: 0.0401  |  0:04:51s\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_mse_mse = 0.00972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009805537675728474\n",
      "R2 Score: 0.9557643773579524\n",
      "\n",
      "Iteration 130/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.5602  | mse_mse: 0.27572 |  0:00:10s\n",
      "epoch 1  | loss: 0.28476 | mse_mse: 0.24912 |  0:00:20s\n",
      "epoch 2  | loss: 0.1978  | mse_mse: 0.12268 |  0:00:32s\n",
      "epoch 3  | loss: 0.15143 | mse_mse: 0.09351 |  0:00:43s\n",
      "epoch 4  | loss: 0.13434 | mse_mse: 0.1387  |  0:00:54s\n",
      "epoch 5  | loss: 0.13376 | mse_mse: 0.09022 |  0:01:05s\n",
      "epoch 6  | loss: 0.12714 | mse_mse: 0.11033 |  0:01:15s\n",
      "epoch 7  | loss: 0.12663 | mse_mse: 0.09547 |  0:01:27s\n",
      "epoch 8  | loss: 0.11977 | mse_mse: 0.0902  |  0:01:38s\n",
      "epoch 9  | loss: 0.11777 | mse_mse: 0.08617 |  0:01:49s\n",
      "epoch 10 | loss: 0.10269 | mse_mse: 0.04995 |  0:02:00s\n",
      "epoch 11 | loss: 0.05686 | mse_mse: 0.04048 |  0:02:11s\n",
      "epoch 12 | loss: 0.0421  | mse_mse: 0.0278  |  0:02:21s\n",
      "epoch 13 | loss: 0.03629 | mse_mse: 0.01465 |  0:02:32s\n",
      "epoch 14 | loss: 0.03557 | mse_mse: 0.0276  |  0:02:43s\n",
      "epoch 15 | loss: 0.02853 | mse_mse: 0.02696 |  0:02:53s\n",
      "epoch 16 | loss: 0.02997 | mse_mse: 0.01363 |  0:03:04s\n",
      "epoch 17 | loss: 0.03048 | mse_mse: 0.03027 |  0:03:14s\n",
      "epoch 18 | loss: 0.02764 | mse_mse: 0.06083 |  0:03:25s\n",
      "epoch 19 | loss: 0.02547 | mse_mse: 0.03141 |  0:03:37s\n",
      "epoch 20 | loss: 0.03085 | mse_mse: 0.01023 |  0:03:48s\n",
      "epoch 21 | loss: 0.02875 | mse_mse: 0.01573 |  0:03:59s\n",
      "epoch 22 | loss: 0.02461 | mse_mse: 0.02525 |  0:04:11s\n",
      "epoch 23 | loss: 0.02605 | mse_mse: 0.0464  |  0:04:24s\n",
      "epoch 24 | loss: 0.02534 | mse_mse: 0.02003 |  0:04:36s\n",
      "epoch 25 | loss: 0.0271  | mse_mse: 0.10626 |  0:04:49s\n",
      "epoch 26 | loss: 0.02902 | mse_mse: 0.01449 |  0:05:01s\n",
      "epoch 27 | loss: 0.0228  | mse_mse: 0.07356 |  0:05:13s\n",
      "epoch 28 | loss: 0.02047 | mse_mse: 0.0302  |  0:05:24s\n",
      "epoch 29 | loss: 0.02461 | mse_mse: 0.01832 |  0:05:35s\n",
      "epoch 30 | loss: 0.02383 | mse_mse: 0.02651 |  0:05:45s\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_mse_mse = 0.01023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.01132110463204017\n",
      "R2 Score: 0.9489272155229508\n",
      "\n",
      "Iteration 131/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.6965  | mse_mse: 0.27565 |  0:00:16s\n",
      "epoch 1  | loss: 0.23982 | mse_mse: 0.16581 |  0:00:31s\n",
      "epoch 2  | loss: 0.16714 | mse_mse: 0.12705 |  0:00:47s\n",
      "epoch 3  | loss: 0.14451 | mse_mse: 0.11122 |  0:01:02s\n",
      "epoch 4  | loss: 0.12931 | mse_mse: 0.10256 |  0:01:17s\n",
      "epoch 5  | loss: 0.13007 | mse_mse: 0.09518 |  0:01:33s\n",
      "epoch 6  | loss: 0.1222  | mse_mse: 0.08807 |  0:01:53s\n",
      "epoch 7  | loss: 0.11477 | mse_mse: 0.07878 |  0:02:15s\n",
      "epoch 8  | loss: 0.08522 | mse_mse: 0.0548  |  0:02:29s\n",
      "epoch 9  | loss: 0.05285 | mse_mse: 0.07685 |  0:02:43s\n",
      "epoch 10 | loss: 0.0383  | mse_mse: 0.02329 |  0:02:56s\n",
      "epoch 11 | loss: 0.02991 | mse_mse: 0.02415 |  0:03:10s\n",
      "epoch 12 | loss: 0.03486 | mse_mse: 0.01172 |  0:03:23s\n",
      "epoch 13 | loss: 0.03087 | mse_mse: 0.01623 |  0:03:38s\n",
      "epoch 14 | loss: 0.02692 | mse_mse: 0.00927 |  0:03:51s\n",
      "epoch 15 | loss: 0.02661 | mse_mse: 0.01217 |  0:04:05s\n",
      "epoch 16 | loss: 0.02349 | mse_mse: 0.00756 |  0:04:17s\n",
      "epoch 17 | loss: 0.02583 | mse_mse: 0.02651 |  0:04:30s\n",
      "epoch 18 | loss: 0.02661 | mse_mse: 0.01424 |  0:04:44s\n",
      "epoch 19 | loss: 0.02437 | mse_mse: 0.0189  |  0:05:01s\n",
      "epoch 20 | loss: 0.0249  | mse_mse: 0.00804 |  0:05:17s\n",
      "epoch 21 | loss: 0.02513 | mse_mse: 0.01036 |  0:05:31s\n",
      "epoch 22 | loss: 0.02516 | mse_mse: 0.01163 |  0:05:44s\n",
      "epoch 23 | loss: 0.02388 | mse_mse: 0.01543 |  0:05:58s\n",
      "epoch 24 | loss: 0.02197 | mse_mse: 0.01193 |  0:06:13s\n",
      "epoch 25 | loss: 0.02295 | mse_mse: 0.01389 |  0:06:27s\n",
      "epoch 26 | loss: 0.02538 | mse_mse: 0.00976 |  0:06:40s\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_mse_mse = 0.00756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008529512668892205\n",
      "R2 Score: 0.9615208960263723\n",
      "\n",
      "Iteration 132/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.12013 | mse_mse: 0.26145 |  0:00:15s\n",
      "epoch 1  | loss: 0.2848  | mse_mse: 0.3335  |  0:00:31s\n",
      "epoch 2  | loss: 0.26635 | mse_mse: 0.30212 |  0:00:46s\n",
      "epoch 3  | loss: 0.23785 | mse_mse: 0.14553 |  0:01:01s\n",
      "epoch 4  | loss: 0.14889 | mse_mse: 0.15012 |  0:01:18s\n",
      "epoch 5  | loss: 0.13508 | mse_mse: 0.13029 |  0:01:32s\n",
      "epoch 6  | loss: 0.1276  | mse_mse: 0.09803 |  0:01:46s\n",
      "epoch 7  | loss: 0.12836 | mse_mse: 0.11696 |  0:02:00s\n",
      "epoch 8  | loss: 0.12493 | mse_mse: 0.09233 |  0:02:18s\n",
      "epoch 9  | loss: 0.1102  | mse_mse: 0.11434 |  0:02:34s\n",
      "epoch 10 | loss: 0.07669 | mse_mse: 0.05433 |  0:02:51s\n",
      "epoch 11 | loss: 0.04797 | mse_mse: 0.04022 |  0:03:06s\n",
      "epoch 12 | loss: 0.03309 | mse_mse: 0.02551 |  0:03:23s\n",
      "epoch 13 | loss: 0.0308  | mse_mse: 0.02639 |  0:03:39s\n",
      "epoch 14 | loss: 0.02854 | mse_mse: 0.01392 |  0:03:55s\n",
      "epoch 15 | loss: 0.02625 | mse_mse: 0.01426 |  0:04:10s\n",
      "epoch 16 | loss: 0.02933 | mse_mse: 0.0155  |  0:04:25s\n",
      "epoch 17 | loss: 0.03176 | mse_mse: 0.02603 |  0:04:41s\n",
      "epoch 18 | loss: 0.02732 | mse_mse: 0.01926 |  0:04:58s\n",
      "epoch 19 | loss: 0.02796 | mse_mse: 0.00906 |  0:05:15s\n",
      "epoch 20 | loss: 0.02332 | mse_mse: 0.01746 |  0:05:31s\n",
      "epoch 21 | loss: 0.02833 | mse_mse: 0.0145  |  0:05:47s\n",
      "epoch 22 | loss: 0.02493 | mse_mse: 0.01608 |  0:06:03s\n",
      "epoch 23 | loss: 0.02171 | mse_mse: 0.01215 |  0:06:19s\n",
      "epoch 24 | loss: 0.02141 | mse_mse: 0.0137  |  0:06:35s\n",
      "epoch 25 | loss: 0.01983 | mse_mse: 0.01954 |  0:06:49s\n",
      "epoch 26 | loss: 0.02125 | mse_mse: 0.01585 |  0:07:04s\n",
      "epoch 27 | loss: 0.01852 | mse_mse: 0.01585 |  0:07:19s\n",
      "epoch 28 | loss: 0.02232 | mse_mse: 0.01585 |  0:07:36s\n",
      "epoch 29 | loss: 0.02    | mse_mse: 0.02228 |  0:07:52s\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_mse_mse = 0.00906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010688619516454435\n",
      "R2 Score: 0.9517805392085062\n",
      "\n",
      "Iteration 133/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.57661 | mse_mse: 0.27957 |  0:00:06s\n",
      "epoch 1  | loss: 0.26312 | mse_mse: 0.26036 |  0:00:13s\n",
      "epoch 2  | loss: 0.25237 | mse_mse: 0.22296 |  0:00:19s\n",
      "epoch 3  | loss: 0.24091 | mse_mse: 0.20374 |  0:00:26s\n",
      "epoch 4  | loss: 0.2263  | mse_mse: 0.2072  |  0:00:32s\n",
      "epoch 5  | loss: 0.21362 | mse_mse: 0.16138 |  0:00:40s\n",
      "epoch 6  | loss: 0.11018 | mse_mse: 0.06554 |  0:00:46s\n",
      "epoch 7  | loss: 0.04767 | mse_mse: 0.02027 |  0:00:53s\n",
      "epoch 8  | loss: 0.04405 | mse_mse: 0.01788 |  0:00:59s\n",
      "epoch 9  | loss: 0.03751 | mse_mse: 0.01787 |  0:01:06s\n",
      "epoch 10 | loss: 0.02931 | mse_mse: 0.01243 |  0:01:13s\n",
      "epoch 11 | loss: 0.03098 | mse_mse: 0.02098 |  0:01:20s\n",
      "epoch 12 | loss: 0.03158 | mse_mse: 0.01636 |  0:01:26s\n",
      "epoch 13 | loss: 0.02844 | mse_mse: 0.01017 |  0:01:35s\n",
      "epoch 14 | loss: 0.0254  | mse_mse: 0.01248 |  0:01:44s\n",
      "epoch 15 | loss: 0.02891 | mse_mse: 0.014   |  0:01:50s\n",
      "epoch 16 | loss: 0.02377 | mse_mse: 0.02056 |  0:01:57s\n",
      "epoch 17 | loss: 0.02356 | mse_mse: 0.00903 |  0:02:05s\n",
      "epoch 18 | loss: 0.02641 | mse_mse: 0.01718 |  0:02:13s\n",
      "epoch 19 | loss: 0.02268 | mse_mse: 0.00795 |  0:02:19s\n",
      "epoch 20 | loss: 0.02518 | mse_mse: 0.01189 |  0:02:27s\n",
      "epoch 21 | loss: 0.02318 | mse_mse: 0.01106 |  0:02:34s\n",
      "epoch 22 | loss: 0.02357 | mse_mse: 0.01306 |  0:02:41s\n",
      "epoch 23 | loss: 0.02112 | mse_mse: 0.01095 |  0:02:48s\n",
      "epoch 24 | loss: 0.02423 | mse_mse: 0.01661 |  0:02:54s\n",
      "epoch 25 | loss: 0.02079 | mse_mse: 0.00907 |  0:03:01s\n",
      "epoch 26 | loss: 0.02074 | mse_mse: 0.11064 |  0:03:07s\n",
      "epoch 27 | loss: 0.02298 | mse_mse: 0.01041 |  0:03:14s\n",
      "epoch 28 | loss: 0.0223  | mse_mse: 0.01846 |  0:03:20s\n",
      "epoch 29 | loss: 0.02282 | mse_mse: 0.03399 |  0:03:27s\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_mse_mse = 0.00795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007858162286700854\n",
      "R2 Score: 0.9645495521948882\n",
      "Best model updated\n",
      "\n",
      "Iteration 134/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.49173 | mse_mse: 0.25739 |  0:00:07s\n",
      "epoch 1  | loss: 0.26476 | mse_mse: 0.22707 |  0:00:15s\n",
      "epoch 2  | loss: 0.17208 | mse_mse: 0.11016 |  0:00:23s\n",
      "epoch 3  | loss: 0.07618 | mse_mse: 0.03848 |  0:00:31s\n",
      "epoch 4  | loss: 0.04746 | mse_mse: 0.02489 |  0:00:38s\n",
      "epoch 5  | loss: 0.04411 | mse_mse: 0.01945 |  0:00:46s\n",
      "epoch 6  | loss: 0.04197 | mse_mse: 0.01591 |  0:00:53s\n",
      "epoch 7  | loss: 0.0358  | mse_mse: 0.03797 |  0:01:01s\n",
      "epoch 8  | loss: 0.03692 | mse_mse: 0.01891 |  0:01:09s\n",
      "epoch 9  | loss: 0.03053 | mse_mse: 0.03363 |  0:01:16s\n",
      "epoch 10 | loss: 0.03225 | mse_mse: 0.04069 |  0:01:24s\n",
      "epoch 11 | loss: 0.03702 | mse_mse: 0.02744 |  0:01:31s\n",
      "epoch 12 | loss: 0.03116 | mse_mse: 0.02931 |  0:01:38s\n",
      "epoch 13 | loss: 0.03114 | mse_mse: 0.01549 |  0:01:45s\n",
      "epoch 14 | loss: 0.03386 | mse_mse: 0.02347 |  0:01:52s\n",
      "epoch 15 | loss: 0.02928 | mse_mse: 0.01715 |  0:01:59s\n",
      "epoch 16 | loss: 0.03275 | mse_mse: 0.06388 |  0:02:07s\n",
      "epoch 17 | loss: 0.03098 | mse_mse: 0.01728 |  0:02:14s\n",
      "epoch 18 | loss: 0.02493 | mse_mse: 0.01422 |  0:02:21s\n",
      "epoch 19 | loss: 0.0292  | mse_mse: 0.0378  |  0:02:28s\n",
      "epoch 20 | loss: 0.02525 | mse_mse: 0.00999 |  0:02:36s\n",
      "epoch 21 | loss: 0.02608 | mse_mse: 0.02408 |  0:02:43s\n",
      "epoch 22 | loss: 0.02308 | mse_mse: 0.0157  |  0:02:52s\n",
      "epoch 23 | loss: 0.0246  | mse_mse: 0.01372 |  0:02:58s\n",
      "epoch 24 | loss: 0.025   | mse_mse: 0.02202 |  0:03:05s\n",
      "epoch 25 | loss: 0.0286  | mse_mse: 0.01327 |  0:03:13s\n",
      "epoch 26 | loss: 0.02375 | mse_mse: 0.01235 |  0:03:20s\n",
      "epoch 27 | loss: 0.02863 | mse_mse: 0.01366 |  0:03:27s\n",
      "epoch 28 | loss: 0.02348 | mse_mse: 0.02333 |  0:03:35s\n",
      "epoch 29 | loss: 0.02276 | mse_mse: 0.00969 |  0:03:43s\n",
      "epoch 30 | loss: 0.0208  | mse_mse: 0.01016 |  0:03:51s\n",
      "epoch 31 | loss: 0.02293 | mse_mse: 0.03872 |  0:03:58s\n",
      "epoch 32 | loss: 0.02399 | mse_mse: 0.01873 |  0:04:05s\n",
      "epoch 33 | loss: 0.02061 | mse_mse: 0.00877 |  0:04:13s\n",
      "epoch 34 | loss: 0.02232 | mse_mse: 0.03328 |  0:04:20s\n",
      "epoch 35 | loss: 0.0204  | mse_mse: 0.0275  |  0:04:28s\n",
      "epoch 36 | loss: 0.01876 | mse_mse: 0.01717 |  0:04:35s\n",
      "epoch 37 | loss: 0.027   | mse_mse: 0.0334  |  0:04:43s\n",
      "epoch 38 | loss: 0.02213 | mse_mse: 0.0394  |  0:04:50s\n",
      "epoch 39 | loss: 0.01974 | mse_mse: 0.01623 |  0:04:57s\n",
      "epoch 40 | loss: 0.02022 | mse_mse: 0.01258 |  0:05:04s\n",
      "epoch 41 | loss: 0.02059 | mse_mse: 0.04043 |  0:05:12s\n",
      "epoch 42 | loss: 0.02142 | mse_mse: 0.02044 |  0:05:19s\n",
      "epoch 43 | loss: 0.0217  | mse_mse: 0.01391 |  0:05:28s\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_mse_mse = 0.00877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008392389933552616\n",
      "R2 Score: 0.9621394964312375\n",
      "\n",
      "Iteration 135/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.785   | mse_mse: 0.22563 |  0:00:10s\n",
      "epoch 1  | loss: 0.2678  | mse_mse: 0.2437  |  0:00:21s\n",
      "epoch 2  | loss: 0.27156 | mse_mse: 0.23405 |  0:00:32s\n",
      "epoch 3  | loss: 0.25451 | mse_mse: 0.25359 |  0:00:43s\n",
      "epoch 4  | loss: 0.21299 | mse_mse: 0.13721 |  0:00:53s\n",
      "epoch 5  | loss: 0.14092 | mse_mse: 0.10461 |  0:01:04s\n",
      "epoch 6  | loss: 0.10615 | mse_mse: 0.0787  |  0:01:14s\n",
      "epoch 7  | loss: 0.0699  | mse_mse: 0.04627 |  0:01:25s\n",
      "epoch 8  | loss: 0.047   | mse_mse: 0.0439  |  0:01:35s\n",
      "epoch 9  | loss: 0.04156 | mse_mse: 0.0299  |  0:01:46s\n",
      "epoch 10 | loss: 0.04037 | mse_mse: 0.02097 |  0:01:56s\n",
      "epoch 11 | loss: 0.03279 | mse_mse: 0.01488 |  0:02:07s\n",
      "epoch 12 | loss: 0.03785 | mse_mse: 0.03067 |  0:02:17s\n",
      "epoch 13 | loss: 0.0367  | mse_mse: 0.01868 |  0:02:30s\n",
      "epoch 14 | loss: 0.02743 | mse_mse: 0.01177 |  0:02:43s\n",
      "epoch 15 | loss: 0.03184 | mse_mse: 0.01812 |  0:02:55s\n",
      "epoch 16 | loss: 0.03146 | mse_mse: 0.01118 |  0:03:07s\n",
      "epoch 17 | loss: 0.02988 | mse_mse: 0.01431 |  0:03:18s\n",
      "epoch 18 | loss: 0.02619 | mse_mse: 0.01142 |  0:03:28s\n",
      "epoch 19 | loss: 0.02625 | mse_mse: 0.04212 |  0:03:38s\n",
      "epoch 20 | loss: 0.02957 | mse_mse: 0.0433  |  0:03:49s\n",
      "epoch 21 | loss: 0.02919 | mse_mse: 0.01586 |  0:03:59s\n",
      "epoch 22 | loss: 0.02799 | mse_mse: 0.04334 |  0:04:10s\n",
      "epoch 23 | loss: 0.02693 | mse_mse: 0.01486 |  0:04:20s\n",
      "epoch 24 | loss: 0.02775 | mse_mse: 0.01618 |  0:04:30s\n",
      "epoch 25 | loss: 0.02207 | mse_mse: 0.00814 |  0:04:40s\n",
      "epoch 26 | loss: 0.02411 | mse_mse: 0.0251  |  0:04:50s\n",
      "epoch 27 | loss: 0.02628 | mse_mse: 0.01839 |  0:05:00s\n",
      "epoch 28 | loss: 0.02684 | mse_mse: 0.02074 |  0:05:10s\n",
      "epoch 29 | loss: 0.02375 | mse_mse: 0.01366 |  0:05:20s\n",
      "epoch 30 | loss: 0.02349 | mse_mse: 0.02166 |  0:05:30s\n",
      "epoch 31 | loss: 0.02189 | mse_mse: 0.03044 |  0:05:39s\n",
      "epoch 32 | loss: 0.02475 | mse_mse: 0.03578 |  0:05:49s\n",
      "epoch 33 | loss: 0.02197 | mse_mse: 0.0283  |  0:05:59s\n",
      "epoch 34 | loss: 0.02579 | mse_mse: 0.05461 |  0:06:09s\n",
      "epoch 35 | loss: 0.02133 | mse_mse: 0.0126  |  0:06:19s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_mse_mse = 0.00814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008001095524742416\n",
      "R2 Score: 0.9639047389281294\n",
      "\n",
      "Iteration 136/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.59222 | mse_mse: 0.26898 |  0:00:10s\n",
      "epoch 1  | loss: 0.27229 | mse_mse: 0.23854 |  0:00:21s\n",
      "epoch 2  | loss: 0.26607 | mse_mse: 0.26686 |  0:00:31s\n",
      "epoch 3  | loss: 0.25675 | mse_mse: 0.21918 |  0:00:42s\n",
      "epoch 4  | loss: 0.25222 | mse_mse: 0.21676 |  0:00:54s\n",
      "epoch 5  | loss: 0.25289 | mse_mse: 0.21479 |  0:01:06s\n",
      "epoch 6  | loss: 0.24408 | mse_mse: 0.18197 |  0:01:17s\n",
      "epoch 7  | loss: 0.16125 | mse_mse: 0.09814 |  0:01:27s\n",
      "epoch 8  | loss: 0.0894  | mse_mse: 0.04497 |  0:01:38s\n",
      "epoch 9  | loss: 0.04928 | mse_mse: 0.0628  |  0:01:49s\n",
      "epoch 10 | loss: 0.05243 | mse_mse: 0.0301  |  0:02:00s\n",
      "epoch 11 | loss: 0.04429 | mse_mse: 0.05896 |  0:02:11s\n",
      "epoch 12 | loss: 0.041   | mse_mse: 0.02241 |  0:02:22s\n",
      "epoch 13 | loss: 0.02853 | mse_mse: 0.02289 |  0:02:32s\n",
      "epoch 14 | loss: 0.03645 | mse_mse: 0.02146 |  0:02:43s\n",
      "epoch 15 | loss: 0.02989 | mse_mse: 0.01778 |  0:02:54s\n",
      "epoch 16 | loss: 0.02808 | mse_mse: 0.06333 |  0:03:05s\n",
      "epoch 17 | loss: 0.02838 | mse_mse: 0.0113  |  0:03:16s\n",
      "epoch 18 | loss: 0.02763 | mse_mse: 0.06876 |  0:03:30s\n",
      "epoch 19 | loss: 0.03782 | mse_mse: 0.0164  |  0:03:42s\n",
      "epoch 20 | loss: 0.02617 | mse_mse: 0.0093  |  0:03:55s\n",
      "epoch 21 | loss: 0.02737 | mse_mse: 0.0209  |  0:04:08s\n",
      "epoch 22 | loss: 0.02748 | mse_mse: 0.02378 |  0:04:19s\n",
      "epoch 23 | loss: 0.02616 | mse_mse: 0.01425 |  0:04:31s\n",
      "epoch 24 | loss: 0.02997 | mse_mse: 0.05388 |  0:04:42s\n",
      "epoch 25 | loss: 0.02443 | mse_mse: 0.016   |  0:04:54s\n",
      "epoch 26 | loss: 0.02811 | mse_mse: 0.01824 |  0:05:06s\n",
      "epoch 27 | loss: 0.02572 | mse_mse: 0.00774 |  0:05:18s\n",
      "epoch 28 | loss: 0.02693 | mse_mse: 0.01265 |  0:05:29s\n",
      "epoch 29 | loss: 0.02636 | mse_mse: 0.02555 |  0:05:39s\n",
      "epoch 30 | loss: 0.02806 | mse_mse: 0.03431 |  0:05:50s\n",
      "epoch 31 | loss: 0.0227  | mse_mse: 0.01323 |  0:06:00s\n",
      "epoch 32 | loss: 0.02123 | mse_mse: 0.01516 |  0:06:10s\n",
      "epoch 33 | loss: 0.02782 | mse_mse: 0.02133 |  0:06:21s\n",
      "epoch 34 | loss: 0.02687 | mse_mse: 0.0122  |  0:06:31s\n",
      "epoch 35 | loss: 0.02204 | mse_mse: 0.01315 |  0:06:42s\n",
      "epoch 36 | loss: 0.02305 | mse_mse: 0.02057 |  0:06:52s\n",
      "epoch 37 | loss: 0.02036 | mse_mse: 0.0207  |  0:07:02s\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_mse_mse = 0.00774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00793163445977246\n",
      "R2 Score: 0.9642180979258652\n",
      "\n",
      "Iteration 137/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.15315 | mse_mse: 0.45508 |  0:00:14s\n",
      "epoch 1  | loss: 0.28529 | mse_mse: 0.32236 |  0:00:28s\n",
      "epoch 2  | loss: 0.27231 | mse_mse: 0.23791 |  0:00:42s\n",
      "epoch 3  | loss: 0.25187 | mse_mse: 0.22447 |  0:00:55s\n",
      "epoch 4  | loss: 0.25096 | mse_mse: 0.2221  |  0:01:09s\n",
      "epoch 5  | loss: 0.24619 | mse_mse: 0.19114 |  0:01:22s\n",
      "epoch 6  | loss: 0.16957 | mse_mse: 0.12616 |  0:01:36s\n",
      "epoch 7  | loss: 0.13627 | mse_mse: 0.11772 |  0:01:49s\n",
      "epoch 8  | loss: 0.12137 | mse_mse: 0.08969 |  0:02:03s\n",
      "epoch 9  | loss: 0.12388 | mse_mse: 0.10919 |  0:02:16s\n",
      "epoch 10 | loss: 0.1197  | mse_mse: 0.10281 |  0:02:31s\n",
      "epoch 11 | loss: 0.12235 | mse_mse: 0.09742 |  0:02:44s\n",
      "epoch 12 | loss: 0.11676 | mse_mse: 0.09566 |  0:03:00s\n",
      "epoch 13 | loss: 0.11616 | mse_mse: 0.09592 |  0:03:15s\n",
      "epoch 14 | loss: 0.11235 | mse_mse: 0.16712 |  0:03:29s\n",
      "epoch 15 | loss: 0.09744 | mse_mse: 0.05969 |  0:03:43s\n",
      "epoch 16 | loss: 0.07557 | mse_mse: 0.04785 |  0:03:57s\n",
      "epoch 17 | loss: 0.05689 | mse_mse: 0.02795 |  0:04:11s\n",
      "epoch 18 | loss: 0.03892 | mse_mse: 0.02422 |  0:04:26s\n",
      "epoch 19 | loss: 0.02848 | mse_mse: 0.01551 |  0:04:41s\n",
      "epoch 20 | loss: 0.02753 | mse_mse: 0.0212  |  0:04:56s\n",
      "epoch 21 | loss: 0.02619 | mse_mse: 0.09123 |  0:05:12s\n",
      "epoch 22 | loss: 0.02243 | mse_mse: 0.01287 |  0:05:25s\n",
      "epoch 23 | loss: 0.02975 | mse_mse: 0.0095  |  0:05:39s\n",
      "epoch 24 | loss: 0.02451 | mse_mse: 0.01538 |  0:05:53s\n",
      "epoch 25 | loss: 0.02502 | mse_mse: 0.01998 |  0:06:08s\n",
      "epoch 26 | loss: 0.02447 | mse_mse: 0.00877 |  0:06:24s\n",
      "epoch 27 | loss: 0.02339 | mse_mse: 0.01783 |  0:06:38s\n",
      "epoch 28 | loss: 0.02352 | mse_mse: 0.0204  |  0:06:52s\n",
      "epoch 29 | loss: 0.02309 | mse_mse: 0.01891 |  0:07:05s\n",
      "epoch 30 | loss: 0.02468 | mse_mse: 0.02426 |  0:07:19s\n",
      "epoch 31 | loss: 0.02483 | mse_mse: 0.01764 |  0:07:32s\n",
      "epoch 32 | loss: 0.02248 | mse_mse: 0.0159  |  0:07:46s\n",
      "epoch 33 | loss: 0.01938 | mse_mse: 0.01122 |  0:07:59s\n",
      "epoch 34 | loss: 0.02093 | mse_mse: 0.01606 |  0:08:13s\n",
      "epoch 35 | loss: 0.01803 | mse_mse: 0.01038 |  0:08:33s\n",
      "epoch 36 | loss: 0.01922 | mse_mse: 0.01497 |  0:08:50s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_mse_mse = 0.00877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009800147333689231\n",
      "R2 Score: 0.9557886947533105\n",
      "\n",
      "Iteration 138/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.61344 | mse_mse: 0.37516 |  0:00:21s\n",
      "epoch 1  | loss: 0.29241 | mse_mse: 0.23216 |  0:00:36s\n",
      "epoch 2  | loss: 0.26267 | mse_mse: 0.24281 |  0:00:52s\n",
      "epoch 3  | loss: 0.25894 | mse_mse: 0.24375 |  0:01:07s\n",
      "epoch 4  | loss: 0.25172 | mse_mse: 0.23513 |  0:01:22s\n",
      "epoch 5  | loss: 0.24467 | mse_mse: 0.18388 |  0:01:37s\n",
      "epoch 6  | loss: 0.1518  | mse_mse: 0.08135 |  0:01:52s\n",
      "epoch 7  | loss: 0.07472 | mse_mse: 0.03964 |  0:02:07s\n",
      "epoch 8  | loss: 0.05252 | mse_mse: 0.22226 |  0:02:22s\n",
      "epoch 9  | loss: 0.05002 | mse_mse: 0.05661 |  0:02:36s\n",
      "epoch 10 | loss: 0.04324 | mse_mse: 0.0194  |  0:02:51s\n",
      "epoch 11 | loss: 0.03932 | mse_mse: 0.08515 |  0:03:06s\n",
      "epoch 12 | loss: 0.03836 | mse_mse: 0.012   |  0:03:21s\n",
      "epoch 13 | loss: 0.03578 | mse_mse: 0.01737 |  0:03:36s\n",
      "epoch 14 | loss: 0.03558 | mse_mse: 0.02453 |  0:03:51s\n",
      "epoch 15 | loss: 0.04134 | mse_mse: 0.02357 |  0:04:06s\n",
      "epoch 16 | loss: 0.03945 | mse_mse: 0.03828 |  0:04:21s\n",
      "epoch 17 | loss: 0.0328  | mse_mse: 0.0161  |  0:04:35s\n",
      "epoch 18 | loss: 0.02968 | mse_mse: 0.01359 |  0:04:50s\n",
      "epoch 19 | loss: 0.03454 | mse_mse: 0.06364 |  0:05:05s\n",
      "epoch 20 | loss: 0.03403 | mse_mse: 0.05249 |  0:05:20s\n",
      "epoch 21 | loss: 0.03967 | mse_mse: 0.02703 |  0:05:35s\n",
      "epoch 22 | loss: 0.03263 | mse_mse: 0.01991 |  0:05:49s\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_mse_mse = 0.012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.012662470836271394\n",
      "R2 Score: 0.9428759237735914\n",
      "\n",
      "Iteration 139/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.77296 | mse_mse: 0.30191 |  0:00:06s\n",
      "epoch 1  | loss: 0.24982 | mse_mse: 0.22041 |  0:00:12s\n",
      "epoch 2  | loss: 0.19804 | mse_mse: 0.11995 |  0:00:18s\n",
      "epoch 3  | loss: 0.09025 | mse_mse: 0.06914 |  0:00:25s\n",
      "epoch 4  | loss: 0.05501 | mse_mse: 0.02799 |  0:00:31s\n",
      "epoch 5  | loss: 0.04725 | mse_mse: 0.01917 |  0:00:38s\n",
      "epoch 6  | loss: 0.03646 | mse_mse: 0.02468 |  0:00:44s\n",
      "epoch 7  | loss: 0.0308  | mse_mse: 0.01747 |  0:00:51s\n",
      "epoch 8  | loss: 0.03693 | mse_mse: 0.01324 |  0:00:57s\n",
      "epoch 9  | loss: 0.02995 | mse_mse: 0.01331 |  0:01:04s\n",
      "epoch 10 | loss: 0.02694 | mse_mse: 0.0163  |  0:01:10s\n",
      "epoch 11 | loss: 0.03142 | mse_mse: 0.01119 |  0:01:17s\n",
      "epoch 12 | loss: 0.03092 | mse_mse: 0.02091 |  0:01:23s\n",
      "epoch 13 | loss: 0.0344  | mse_mse: 0.01324 |  0:01:29s\n",
      "epoch 14 | loss: 0.02887 | mse_mse: 0.01807 |  0:01:36s\n",
      "epoch 15 | loss: 0.02848 | mse_mse: 0.00965 |  0:01:43s\n",
      "epoch 16 | loss: 0.02681 | mse_mse: 0.01726 |  0:01:49s\n",
      "epoch 17 | loss: 0.02616 | mse_mse: 0.00891 |  0:01:56s\n",
      "epoch 18 | loss: 0.02388 | mse_mse: 0.00934 |  0:02:02s\n",
      "epoch 19 | loss: 0.02509 | mse_mse: 0.01117 |  0:02:09s\n",
      "epoch 20 | loss: 0.02398 | mse_mse: 0.01316 |  0:02:15s\n",
      "epoch 21 | loss: 0.02361 | mse_mse: 0.01283 |  0:02:22s\n",
      "epoch 22 | loss: 0.02616 | mse_mse: 0.01116 |  0:02:28s\n",
      "epoch 23 | loss: 0.0225  | mse_mse: 0.01493 |  0:02:35s\n",
      "epoch 24 | loss: 0.02499 | mse_mse: 0.03828 |  0:02:41s\n",
      "epoch 25 | loss: 0.02329 | mse_mse: 0.02085 |  0:02:48s\n",
      "epoch 26 | loss: 0.02556 | mse_mse: 0.01886 |  0:02:54s\n",
      "epoch 27 | loss: 0.02287 | mse_mse: 0.01495 |  0:03:01s\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_mse_mse = 0.00891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008918834932487378\n",
      "R2 Score: 0.959764550448182\n",
      "\n",
      "Iteration 140/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.53745 | mse_mse: 0.23171 |  0:00:06s\n",
      "epoch 1  | loss: 0.25668 | mse_mse: 0.22738 |  0:00:13s\n",
      "epoch 2  | loss: 0.247   | mse_mse: 0.21259 |  0:00:20s\n",
      "epoch 3  | loss: 0.17032 | mse_mse: 0.09685 |  0:00:27s\n",
      "epoch 4  | loss: 0.06744 | mse_mse: 0.03425 |  0:00:35s\n",
      "epoch 5  | loss: 0.04839 | mse_mse: 0.0233  |  0:00:42s\n",
      "epoch 6  | loss: 0.04096 | mse_mse: 0.03896 |  0:00:49s\n",
      "epoch 7  | loss: 0.0368  | mse_mse: 0.0161  |  0:00:56s\n",
      "epoch 8  | loss: 0.04047 | mse_mse: 0.04306 |  0:01:03s\n",
      "epoch 9  | loss: 0.0349  | mse_mse: 0.03714 |  0:01:10s\n",
      "epoch 10 | loss: 0.03293 | mse_mse: 0.01171 |  0:01:18s\n",
      "epoch 11 | loss: 0.03367 | mse_mse: 0.01686 |  0:01:25s\n",
      "epoch 12 | loss: 0.03143 | mse_mse: 0.04429 |  0:01:32s\n",
      "epoch 13 | loss: 0.03068 | mse_mse: 0.01223 |  0:01:39s\n",
      "epoch 14 | loss: 0.02694 | mse_mse: 0.00923 |  0:01:46s\n",
      "epoch 15 | loss: 0.02855 | mse_mse: 0.04696 |  0:01:54s\n",
      "epoch 16 | loss: 0.02931 | mse_mse: 0.03549 |  0:02:01s\n",
      "epoch 17 | loss: 0.02993 | mse_mse: 0.02558 |  0:02:08s\n",
      "epoch 18 | loss: 0.02789 | mse_mse: 0.01394 |  0:02:15s\n",
      "epoch 19 | loss: 0.02887 | mse_mse: 0.01034 |  0:02:22s\n",
      "epoch 20 | loss: 0.02592 | mse_mse: 0.01554 |  0:02:29s\n",
      "epoch 21 | loss: 0.02991 | mse_mse: 0.07714 |  0:02:37s\n",
      "epoch 22 | loss: 0.02972 | mse_mse: 0.01749 |  0:02:44s\n",
      "epoch 23 | loss: 0.02613 | mse_mse: 0.14388 |  0:02:51s\n",
      "epoch 24 | loss: 0.02618 | mse_mse: 0.0702  |  0:02:58s\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_mse_mse = 0.00923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009718981470910713\n",
      "R2 Score: 0.956154857486658\n",
      "\n",
      "Iteration 141/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.61244 | mse_mse: 0.26526 |  0:00:09s\n",
      "epoch 1  | loss: 0.29155 | mse_mse: 0.27544 |  0:00:19s\n",
      "epoch 2  | loss: 0.2624  | mse_mse: 0.216   |  0:00:29s\n",
      "epoch 3  | loss: 0.25577 | mse_mse: 0.21969 |  0:00:39s\n",
      "epoch 4  | loss: 0.23961 | mse_mse: 0.21777 |  0:00:49s\n",
      "epoch 5  | loss: 0.21652 | mse_mse: 0.17218 |  0:00:59s\n",
      "epoch 6  | loss: 0.12124 | mse_mse: 0.08199 |  0:01:10s\n",
      "epoch 7  | loss: 0.06805 | mse_mse: 0.03052 |  0:01:20s\n",
      "epoch 8  | loss: 0.04561 | mse_mse: 0.01637 |  0:01:30s\n",
      "epoch 9  | loss: 0.04088 | mse_mse: 0.01193 |  0:01:40s\n",
      "epoch 10 | loss: 0.03991 | mse_mse: 0.01278 |  0:01:51s\n",
      "epoch 11 | loss: 0.02879 | mse_mse: 0.01001 |  0:02:01s\n",
      "epoch 12 | loss: 0.03142 | mse_mse: 0.01469 |  0:02:11s\n",
      "epoch 13 | loss: 0.03823 | mse_mse: 0.0382  |  0:02:21s\n",
      "epoch 14 | loss: 0.03376 | mse_mse: 0.01096 |  0:02:32s\n",
      "epoch 15 | loss: 0.02963 | mse_mse: 0.02984 |  0:02:42s\n",
      "epoch 16 | loss: 0.02815 | mse_mse: 0.02139 |  0:02:52s\n",
      "epoch 17 | loss: 0.03017 | mse_mse: 0.01613 |  0:03:02s\n",
      "epoch 18 | loss: 0.0291  | mse_mse: 0.03706 |  0:03:12s\n",
      "epoch 19 | loss: 0.02555 | mse_mse: 0.02084 |  0:03:23s\n",
      "epoch 20 | loss: 0.02689 | mse_mse: 0.02801 |  0:03:33s\n",
      "epoch 21 | loss: 0.02644 | mse_mse: 0.04022 |  0:03:43s\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_mse_mse = 0.01001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010479567718993875\n",
      "R2 Score: 0.9527236324616174\n",
      "\n",
      "Iteration 142/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.67617 | mse_mse: 0.37629 |  0:00:10s\n",
      "epoch 1  | loss: 0.26805 | mse_mse: 0.21197 |  0:00:21s\n",
      "epoch 2  | loss: 0.24361 | mse_mse: 0.21536 |  0:00:32s\n",
      "epoch 3  | loss: 0.24377 | mse_mse: 0.21185 |  0:00:43s\n",
      "epoch 4  | loss: 0.24133 | mse_mse: 0.2239  |  0:00:54s\n",
      "epoch 5  | loss: 0.23573 | mse_mse: 0.25616 |  0:01:06s\n",
      "epoch 6  | loss: 0.23536 | mse_mse: 0.2091  |  0:01:17s\n",
      "epoch 7  | loss: 0.23107 | mse_mse: 0.2093  |  0:01:28s\n",
      "epoch 8  | loss: 0.22415 | mse_mse: 0.20985 |  0:01:39s\n",
      "epoch 9  | loss: 0.22745 | mse_mse: 0.20885 |  0:01:51s\n",
      "epoch 10 | loss: 0.17912 | mse_mse: 0.1099  |  0:02:02s\n",
      "epoch 11 | loss: 0.06851 | mse_mse: 0.0684  |  0:02:13s\n",
      "epoch 12 | loss: 0.04421 | mse_mse: 0.02236 |  0:02:24s\n",
      "epoch 13 | loss: 0.03599 | mse_mse: 0.02846 |  0:02:36s\n",
      "epoch 14 | loss: 0.03283 | mse_mse: 0.0266  |  0:02:47s\n",
      "epoch 15 | loss: 0.03365 | mse_mse: 0.04479 |  0:02:58s\n",
      "epoch 16 | loss: 0.02764 | mse_mse: 0.02    |  0:03:10s\n",
      "epoch 17 | loss: 0.02598 | mse_mse: 0.03257 |  0:03:21s\n",
      "epoch 18 | loss: 0.02591 | mse_mse: 0.01415 |  0:03:32s\n",
      "epoch 19 | loss: 0.03003 | mse_mse: 0.01222 |  0:03:43s\n",
      "epoch 20 | loss: 0.02628 | mse_mse: 0.01942 |  0:03:55s\n",
      "epoch 21 | loss: 0.02866 | mse_mse: 0.01814 |  0:04:06s\n",
      "epoch 22 | loss: 0.02476 | mse_mse: 0.01614 |  0:04:17s\n",
      "epoch 23 | loss: 0.02788 | mse_mse: 0.02168 |  0:04:28s\n",
      "epoch 24 | loss: 0.0262  | mse_mse: 0.01641 |  0:04:40s\n",
      "epoch 25 | loss: 0.02354 | mse_mse: 0.01332 |  0:04:51s\n",
      "epoch 26 | loss: 0.02601 | mse_mse: 0.01108 |  0:05:02s\n",
      "epoch 27 | loss: 0.02341 | mse_mse: 0.0139  |  0:05:14s\n",
      "epoch 28 | loss: 0.02538 | mse_mse: 0.01436 |  0:05:25s\n",
      "epoch 29 | loss: 0.02488 | mse_mse: 0.01097 |  0:05:36s\n",
      "epoch 30 | loss: 0.0258  | mse_mse: 0.01237 |  0:05:47s\n",
      "epoch 31 | loss: 0.0195  | mse_mse: 0.01198 |  0:05:59s\n",
      "epoch 32 | loss: 0.0205  | mse_mse: 0.01352 |  0:06:10s\n",
      "epoch 33 | loss: 0.02596 | mse_mse: 0.01113 |  0:06:21s\n",
      "epoch 34 | loss: 0.02543 | mse_mse: 0.0116  |  0:06:33s\n",
      "epoch 35 | loss: 0.02138 | mse_mse: 0.01542 |  0:06:44s\n",
      "epoch 36 | loss: 0.0234  | mse_mse: 0.01442 |  0:06:55s\n",
      "epoch 37 | loss: 0.01982 | mse_mse: 0.01035 |  0:07:07s\n",
      "epoch 38 | loss: 0.02449 | mse_mse: 0.07272 |  0:07:18s\n",
      "epoch 39 | loss: 0.02457 | mse_mse: 0.01533 |  0:07:29s\n",
      "epoch 40 | loss: 0.02213 | mse_mse: 0.0107  |  0:07:40s\n",
      "epoch 41 | loss: 0.02116 | mse_mse: 0.01984 |  0:07:52s\n",
      "epoch 42 | loss: 0.01904 | mse_mse: 0.01628 |  0:08:03s\n",
      "epoch 43 | loss: 0.0222  | mse_mse: 0.01686 |  0:08:14s\n",
      "epoch 44 | loss: 0.01899 | mse_mse: 0.01377 |  0:08:26s\n",
      "epoch 45 | loss: 0.01875 | mse_mse: 0.02082 |  0:08:37s\n",
      "epoch 46 | loss: 0.02213 | mse_mse: 0.01502 |  0:08:48s\n",
      "epoch 47 | loss: 0.01625 | mse_mse: 0.00958 |  0:09:00s\n",
      "epoch 48 | loss: 0.02112 | mse_mse: 0.02217 |  0:09:11s\n",
      "epoch 49 | loss: 0.01973 | mse_mse: 0.01562 |  0:09:22s\n",
      "epoch 50 | loss: 0.02013 | mse_mse: 0.03579 |  0:09:33s\n",
      "epoch 51 | loss: 0.01888 | mse_mse: 0.01149 |  0:09:45s\n",
      "epoch 52 | loss: 0.01709 | mse_mse: 0.01399 |  0:09:56s\n",
      "epoch 53 | loss: 0.01661 | mse_mse: 0.03694 |  0:10:08s\n",
      "epoch 54 | loss: 0.01825 | mse_mse: 0.02447 |  0:10:19s\n",
      "epoch 55 | loss: 0.01544 | mse_mse: 0.02381 |  0:10:30s\n",
      "epoch 56 | loss: 0.01745 | mse_mse: 0.02337 |  0:10:41s\n",
      "epoch 57 | loss: 0.01807 | mse_mse: 0.02153 |  0:10:53s\n",
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 47 and best_mse_mse = 0.00958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009120061660110666\n",
      "R2 Score: 0.9588567583532445\n",
      "\n",
      "Iteration 143/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.23297 | mse_mse: 0.50958 |  0:00:13s\n",
      "epoch 1  | loss: 0.27785 | mse_mse: 0.2353  |  0:00:26s\n",
      "epoch 2  | loss: 0.26259 | mse_mse: 0.26285 |  0:00:40s\n",
      "epoch 3  | loss: 0.25923 | mse_mse: 0.25097 |  0:00:54s\n",
      "epoch 4  | loss: 0.24925 | mse_mse: 0.20341 |  0:01:07s\n",
      "epoch 5  | loss: 0.18295 | mse_mse: 0.12182 |  0:01:21s\n",
      "epoch 6  | loss: 0.10727 | mse_mse: 0.07319 |  0:01:35s\n",
      "epoch 7  | loss: 0.07093 | mse_mse: 0.06628 |  0:01:49s\n",
      "epoch 8  | loss: 0.05914 | mse_mse: 0.02751 |  0:02:03s\n",
      "epoch 9  | loss: 0.04644 | mse_mse: 0.04696 |  0:02:17s\n",
      "epoch 10 | loss: 0.05091 | mse_mse: 0.02668 |  0:02:31s\n",
      "epoch 11 | loss: 0.03705 | mse_mse: 0.01764 |  0:02:45s\n",
      "epoch 12 | loss: 0.04094 | mse_mse: 0.02489 |  0:02:59s\n",
      "epoch 13 | loss: 0.04345 | mse_mse: 0.02754 |  0:03:13s\n",
      "epoch 14 | loss: 0.04214 | mse_mse: 0.03176 |  0:03:27s\n",
      "epoch 15 | loss: 0.03392 | mse_mse: 0.01836 |  0:03:42s\n",
      "epoch 16 | loss: 0.03483 | mse_mse: 0.01864 |  0:03:57s\n",
      "epoch 17 | loss: 0.03105 | mse_mse: 0.0184  |  0:04:12s\n",
      "epoch 18 | loss: 0.03752 | mse_mse: 0.03183 |  0:04:34s\n",
      "epoch 19 | loss: 0.03253 | mse_mse: 0.00883 |  0:04:54s\n",
      "epoch 20 | loss: 0.02851 | mse_mse: 0.02893 |  0:05:10s\n",
      "epoch 21 | loss: 0.03192 | mse_mse: 0.03577 |  0:05:25s\n",
      "epoch 22 | loss: 0.03286 | mse_mse: 0.04178 |  0:05:41s\n",
      "epoch 23 | loss: 0.02913 | mse_mse: 0.02271 |  0:05:56s\n",
      "epoch 24 | loss: 0.02889 | mse_mse: 0.01493 |  0:06:11s\n",
      "epoch 25 | loss: 0.03419 | mse_mse: 0.02734 |  0:06:26s\n",
      "epoch 26 | loss: 0.03378 | mse_mse: 0.02002 |  0:06:41s\n",
      "epoch 27 | loss: 0.0297  | mse_mse: 0.04051 |  0:06:56s\n",
      "epoch 28 | loss: 0.03105 | mse_mse: 0.03218 |  0:07:11s\n",
      "epoch 29 | loss: 0.02827 | mse_mse: 0.03245 |  0:07:26s\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_mse_mse = 0.00883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009208270985733139\n",
      "R2 Score: 0.958458820517423\n",
      "\n",
      "Iteration 144/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.05803 | mse_mse: 0.39652 |  0:00:15s\n",
      "epoch 1  | loss: 0.28359 | mse_mse: 0.22756 |  0:00:30s\n",
      "epoch 2  | loss: 0.26216 | mse_mse: 0.22576 |  0:00:47s\n",
      "epoch 3  | loss: 0.25418 | mse_mse: 0.29801 |  0:01:03s\n",
      "epoch 4  | loss: 0.25095 | mse_mse: 0.22784 |  0:01:19s\n",
      "epoch 5  | loss: 0.25977 | mse_mse: 0.2345  |  0:01:36s\n",
      "epoch 6  | loss: 0.2461  | mse_mse: 0.23506 |  0:01:52s\n",
      "epoch 7  | loss: 0.21647 | mse_mse: 0.12184 |  0:02:08s\n",
      "epoch 8  | loss: 0.09387 | mse_mse: 0.04715 |  0:02:25s\n",
      "epoch 9  | loss: 0.05171 | mse_mse: 0.05077 |  0:02:41s\n",
      "epoch 10 | loss: 0.04204 | mse_mse: 0.05823 |  0:02:57s\n",
      "epoch 11 | loss: 0.04099 | mse_mse: 0.03572 |  0:03:13s\n",
      "epoch 12 | loss: 0.05138 | mse_mse: 0.01889 |  0:03:30s\n",
      "epoch 13 | loss: 0.02997 | mse_mse: 0.01035 |  0:03:46s\n",
      "epoch 14 | loss: 0.0384  | mse_mse: 0.0242  |  0:04:02s\n",
      "epoch 15 | loss: 0.03169 | mse_mse: 0.03071 |  0:04:18s\n",
      "epoch 16 | loss: 0.04053 | mse_mse: 0.01753 |  0:04:35s\n",
      "epoch 17 | loss: 0.031   | mse_mse: 0.0194  |  0:04:51s\n",
      "epoch 18 | loss: 0.02878 | mse_mse: 0.05088 |  0:05:07s\n",
      "epoch 19 | loss: 0.03773 | mse_mse: 0.0212  |  0:05:23s\n",
      "epoch 20 | loss: 0.03062 | mse_mse: 0.01571 |  0:05:40s\n",
      "epoch 21 | loss: 0.032   | mse_mse: 0.02348 |  0:05:56s\n",
      "epoch 22 | loss: 0.03254 | mse_mse: 0.0241  |  0:06:12s\n",
      "epoch 23 | loss: 0.02882 | mse_mse: 0.01738 |  0:06:28s\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_mse_mse = 0.01035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.01035387835409369\n",
      "R2 Score: 0.9532906536184078\n",
      "\n",
      "Iteration 145/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.70289 | mse_mse: 0.23295 |  0:00:06s\n",
      "epoch 1  | loss: 0.26754 | mse_mse: 0.27221 |  0:00:12s\n",
      "epoch 2  | loss: 0.25703 | mse_mse: 0.22187 |  0:00:19s\n",
      "epoch 3  | loss: 0.20021 | mse_mse: 0.10495 |  0:00:26s\n",
      "epoch 4  | loss: 0.0751  | mse_mse: 0.0498  |  0:00:32s\n",
      "epoch 5  | loss: 0.04886 | mse_mse: 0.02033 |  0:00:39s\n",
      "epoch 6  | loss: 0.03721 | mse_mse: 0.01919 |  0:00:45s\n",
      "epoch 7  | loss: 0.03998 | mse_mse: 0.01581 |  0:00:52s\n",
      "epoch 8  | loss: 0.0331  | mse_mse: 0.04315 |  0:00:59s\n",
      "epoch 9  | loss: 0.0299  | mse_mse: 0.03847 |  0:01:05s\n",
      "epoch 10 | loss: 0.03408 | mse_mse: 0.02031 |  0:01:12s\n",
      "epoch 11 | loss: 0.02654 | mse_mse: 0.00828 |  0:01:18s\n",
      "epoch 12 | loss: 0.0325  | mse_mse: 0.01079 |  0:01:25s\n",
      "epoch 13 | loss: 0.02489 | mse_mse: 0.01032 |  0:01:31s\n",
      "epoch 14 | loss: 0.02808 | mse_mse: 0.04576 |  0:01:38s\n",
      "epoch 15 | loss: 0.02552 | mse_mse: 0.01043 |  0:01:45s\n",
      "epoch 16 | loss: 0.03107 | mse_mse: 0.02608 |  0:01:51s\n",
      "epoch 17 | loss: 0.02745 | mse_mse: 0.01197 |  0:01:58s\n",
      "epoch 18 | loss: 0.02856 | mse_mse: 0.01297 |  0:02:04s\n",
      "epoch 19 | loss: 0.02806 | mse_mse: 0.03289 |  0:02:11s\n",
      "epoch 20 | loss: 0.02622 | mse_mse: 0.01892 |  0:02:17s\n",
      "epoch 21 | loss: 0.0336  | mse_mse: 0.01472 |  0:02:24s\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_mse_mse = 0.00828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008585588939002247\n",
      "R2 Score: 0.961267919717903\n",
      "\n",
      "Iteration 146/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.57701 | mse_mse: 0.23361 |  0:00:07s\n",
      "epoch 1  | loss: 0.27267 | mse_mse: 0.24336 |  0:00:14s\n",
      "epoch 2  | loss: 0.26254 | mse_mse: 0.23057 |  0:00:21s\n",
      "epoch 3  | loss: 0.20164 | mse_mse: 0.11849 |  0:00:28s\n",
      "epoch 4  | loss: 0.08235 | mse_mse: 0.05818 |  0:00:36s\n",
      "epoch 5  | loss: 0.04816 | mse_mse: 0.02814 |  0:00:43s\n",
      "epoch 6  | loss: 0.0413  | mse_mse: 0.08702 |  0:00:50s\n",
      "epoch 7  | loss: 0.03099 | mse_mse: 0.01809 |  0:00:57s\n",
      "epoch 8  | loss: 0.03131 | mse_mse: 0.00867 |  0:01:05s\n",
      "epoch 9  | loss: 0.03354 | mse_mse: 0.02054 |  0:01:12s\n",
      "epoch 10 | loss: 0.0276  | mse_mse: 0.01652 |  0:01:19s\n",
      "epoch 11 | loss: 0.02757 | mse_mse: 0.02562 |  0:01:27s\n",
      "epoch 12 | loss: 0.02567 | mse_mse: 0.01999 |  0:01:34s\n",
      "epoch 13 | loss: 0.02664 | mse_mse: 0.0154  |  0:01:41s\n",
      "epoch 14 | loss: 0.02546 | mse_mse: 0.01793 |  0:01:49s\n",
      "epoch 15 | loss: 0.02787 | mse_mse: 0.01083 |  0:01:56s\n",
      "epoch 16 | loss: 0.02538 | mse_mse: 0.01173 |  0:02:03s\n",
      "epoch 17 | loss: 0.02952 | mse_mse: 0.02018 |  0:02:10s\n",
      "epoch 18 | loss: 0.02431 | mse_mse: 0.00849 |  0:02:18s\n",
      "epoch 19 | loss: 0.02318 | mse_mse: 0.01609 |  0:02:25s\n",
      "epoch 20 | loss: 0.02536 | mse_mse: 0.02364 |  0:02:32s\n",
      "epoch 21 | loss: 0.02435 | mse_mse: 0.02312 |  0:02:39s\n",
      "epoch 22 | loss: 0.02473 | mse_mse: 0.00838 |  0:02:47s\n",
      "epoch 23 | loss: 0.0226  | mse_mse: 0.01929 |  0:02:54s\n",
      "epoch 24 | loss: 0.02283 | mse_mse: 0.01357 |  0:03:02s\n",
      "epoch 25 | loss: 0.0235  | mse_mse: 0.01669 |  0:03:09s\n",
      "epoch 26 | loss: 0.02304 | mse_mse: 0.02132 |  0:03:16s\n",
      "epoch 27 | loss: 0.02302 | mse_mse: 0.02332 |  0:03:23s\n",
      "epoch 28 | loss: 0.0238  | mse_mse: 0.17344 |  0:03:31s\n",
      "epoch 29 | loss: 0.02144 | mse_mse: 0.02699 |  0:03:38s\n",
      "epoch 30 | loss: 0.02396 | mse_mse: 0.03191 |  0:03:45s\n",
      "epoch 31 | loss: 0.02239 | mse_mse: 0.01986 |  0:03:53s\n",
      "epoch 32 | loss: 0.02204 | mse_mse: 0.06125 |  0:04:00s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_mse_mse = 0.00838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008074953131863781\n",
      "R2 Score: 0.9635715458543879\n",
      "\n",
      "Iteration 147/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.12408 | mse_mse: 0.25419 |  0:00:10s\n",
      "epoch 1  | loss: 0.28555 | mse_mse: 0.24156 |  0:00:20s\n",
      "epoch 2  | loss: 0.26702 | mse_mse: 0.33973 |  0:00:30s\n",
      "epoch 3  | loss: 0.25537 | mse_mse: 0.31278 |  0:00:40s\n",
      "epoch 4  | loss: 0.19884 | mse_mse: 0.1848  |  0:00:50s\n",
      "epoch 5  | loss: 0.15454 | mse_mse: 0.12828 |  0:01:01s\n",
      "epoch 6  | loss: 0.11443 | mse_mse: 0.06681 |  0:01:11s\n",
      "epoch 7  | loss: 0.08337 | mse_mse: 0.0466  |  0:01:21s\n",
      "epoch 8  | loss: 0.05567 | mse_mse: 0.03098 |  0:01:31s\n",
      "epoch 9  | loss: 0.0429  | mse_mse: 0.01603 |  0:01:42s\n",
      "epoch 10 | loss: 0.03528 | mse_mse: 0.01551 |  0:01:52s\n",
      "epoch 11 | loss: 0.03121 | mse_mse: 0.0131  |  0:02:02s\n",
      "epoch 12 | loss: 0.02852 | mse_mse: 0.02719 |  0:02:13s\n",
      "epoch 13 | loss: 0.03204 | mse_mse: 0.02808 |  0:02:23s\n",
      "epoch 14 | loss: 0.03137 | mse_mse: 0.01169 |  0:02:33s\n",
      "epoch 15 | loss: 0.03223 | mse_mse: 0.03757 |  0:02:43s\n",
      "epoch 16 | loss: 0.03128 | mse_mse: 0.01671 |  0:02:54s\n",
      "epoch 17 | loss: 0.02977 | mse_mse: 0.01127 |  0:03:04s\n",
      "epoch 18 | loss: 0.02594 | mse_mse: 0.01049 |  0:03:14s\n",
      "epoch 19 | loss: 0.02815 | mse_mse: 0.01345 |  0:03:25s\n",
      "epoch 20 | loss: 0.02981 | mse_mse: 0.01135 |  0:03:35s\n",
      "epoch 21 | loss: 0.0274  | mse_mse: 0.01487 |  0:03:45s\n",
      "epoch 22 | loss: 0.02529 | mse_mse: 0.01564 |  0:03:55s\n",
      "epoch 23 | loss: 0.02829 | mse_mse: 0.01606 |  0:04:06s\n",
      "epoch 24 | loss: 0.0258  | mse_mse: 0.03309 |  0:04:16s\n",
      "epoch 25 | loss: 0.02418 | mse_mse: 0.01855 |  0:04:26s\n",
      "epoch 26 | loss: 0.02303 | mse_mse: 0.01102 |  0:04:36s\n",
      "epoch 27 | loss: 0.02209 | mse_mse: 0.03015 |  0:04:47s\n",
      "epoch 28 | loss: 0.02612 | mse_mse: 0.04112 |  0:04:57s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_mse_mse = 0.01049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010364501069338252\n",
      "R2 Score: 0.9532427314708896\n",
      "\n",
      "Iteration 148/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.76186 | mse_mse: 0.23817 |  0:00:11s\n",
      "epoch 1  | loss: 0.27868 | mse_mse: 0.27333 |  0:00:22s\n",
      "epoch 2  | loss: 0.23769 | mse_mse: 0.14229 |  0:00:33s\n",
      "epoch 3  | loss: 0.13931 | mse_mse: 0.13815 |  0:00:44s\n",
      "epoch 4  | loss: 0.13413 | mse_mse: 0.10769 |  0:00:56s\n",
      "epoch 5  | loss: 0.12771 | mse_mse: 0.12553 |  0:01:07s\n",
      "epoch 6  | loss: 0.12983 | mse_mse: 0.08797 |  0:01:18s\n",
      "epoch 7  | loss: 0.11284 | mse_mse: 0.08545 |  0:01:30s\n",
      "epoch 8  | loss: 0.10956 | mse_mse: 0.08551 |  0:01:41s\n",
      "epoch 9  | loss: 0.10285 | mse_mse: 0.08358 |  0:01:52s\n",
      "epoch 10 | loss: 0.09792 | mse_mse: 0.09678 |  0:02:04s\n",
      "epoch 11 | loss: 0.08314 | mse_mse: 0.05048 |  0:02:15s\n",
      "epoch 12 | loss: 0.06223 | mse_mse: 0.05162 |  0:02:26s\n",
      "epoch 13 | loss: 0.0494  | mse_mse: 0.04823 |  0:02:38s\n",
      "epoch 14 | loss: 0.04001 | mse_mse: 0.01882 |  0:02:49s\n",
      "epoch 15 | loss: 0.03199 | mse_mse: 0.03275 |  0:03:00s\n",
      "epoch 16 | loss: 0.03724 | mse_mse: 0.03201 |  0:03:12s\n",
      "epoch 17 | loss: 0.03185 | mse_mse: 0.02896 |  0:03:23s\n",
      "epoch 18 | loss: 0.03817 | mse_mse: 0.02745 |  0:03:34s\n",
      "epoch 19 | loss: 0.03409 | mse_mse: 0.01753 |  0:03:46s\n",
      "epoch 20 | loss: 0.03129 | mse_mse: 0.07827 |  0:03:57s\n",
      "epoch 21 | loss: 0.03127 | mse_mse: 0.0424  |  0:04:08s\n",
      "epoch 22 | loss: 0.03242 | mse_mse: 0.01784 |  0:04:20s\n",
      "epoch 23 | loss: 0.02966 | mse_mse: 0.01305 |  0:04:31s\n",
      "epoch 24 | loss: 0.02773 | mse_mse: 0.02193 |  0:04:43s\n",
      "epoch 25 | loss: 0.02866 | mse_mse: 0.01485 |  0:04:54s\n",
      "epoch 26 | loss: 0.03255 | mse_mse: 0.03048 |  0:05:05s\n",
      "epoch 27 | loss: 0.0276  | mse_mse: 0.01532 |  0:05:17s\n",
      "epoch 28 | loss: 0.02548 | mse_mse: 0.01587 |  0:05:28s\n",
      "epoch 29 | loss: 0.02544 | mse_mse: 0.01177 |  0:05:39s\n",
      "epoch 30 | loss: 0.02638 | mse_mse: 0.21754 |  0:05:50s\n",
      "epoch 31 | loss: 0.02492 | mse_mse: 0.04844 |  0:06:02s\n",
      "epoch 32 | loss: 0.02813 | mse_mse: 0.03512 |  0:06:13s\n",
      "epoch 33 | loss: 0.02688 | mse_mse: 0.01669 |  0:06:24s\n",
      "epoch 34 | loss: 0.02637 | mse_mse: 0.02195 |  0:06:36s\n",
      "epoch 35 | loss: 0.02744 | mse_mse: 0.02171 |  0:06:47s\n",
      "epoch 36 | loss: 0.02474 | mse_mse: 0.01303 |  0:06:58s\n",
      "epoch 37 | loss: 0.02303 | mse_mse: 0.02357 |  0:07:10s\n",
      "epoch 38 | loss: 0.02259 | mse_mse: 0.01271 |  0:07:21s\n",
      "epoch 39 | loss: 0.0226  | mse_mse: 0.01867 |  0:07:33s\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_mse_mse = 0.01177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.011719478169496278\n",
      "R2 Score: 0.9471300370248144\n",
      "\n",
      "Iteration 149/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.18543 | mse_mse: 0.16819 |  0:00:13s\n",
      "epoch 1  | loss: 0.19871 | mse_mse: 0.13158 |  0:00:27s\n",
      "epoch 2  | loss: 0.16201 | mse_mse: 0.15306 |  0:00:41s\n",
      "epoch 3  | loss: 0.13891 | mse_mse: 0.09966 |  0:00:55s\n",
      "epoch 4  | loss: 0.13063 | mse_mse: 0.0906  |  0:01:09s\n",
      "epoch 5  | loss: 0.12697 | mse_mse: 0.11105 |  0:01:23s\n",
      "epoch 6  | loss: 0.12234 | mse_mse: 0.12439 |  0:01:36s\n",
      "epoch 7  | loss: 0.12665 | mse_mse: 0.10637 |  0:01:50s\n",
      "epoch 8  | loss: 0.12043 | mse_mse: 0.12804 |  0:02:04s\n",
      "epoch 9  | loss: 0.11961 | mse_mse: 0.0881  |  0:02:18s\n",
      "epoch 10 | loss: 0.1165  | mse_mse: 0.10177 |  0:02:33s\n",
      "epoch 11 | loss: 0.11445 | mse_mse: 0.09794 |  0:02:47s\n",
      "epoch 12 | loss: 0.11492 | mse_mse: 0.10452 |  0:03:00s\n",
      "epoch 13 | loss: 0.11312 | mse_mse: 0.09543 |  0:03:14s\n",
      "epoch 14 | loss: 0.10647 | mse_mse: 0.09756 |  0:03:28s\n",
      "epoch 15 | loss: 0.08473 | mse_mse: 0.07071 |  0:03:42s\n",
      "epoch 16 | loss: 0.06114 | mse_mse: 0.04791 |  0:03:55s\n",
      "epoch 17 | loss: 0.04962 | mse_mse: 0.02615 |  0:04:09s\n",
      "epoch 18 | loss: 0.04066 | mse_mse: 0.05704 |  0:04:23s\n",
      "epoch 19 | loss: 0.03616 | mse_mse: 0.02422 |  0:04:37s\n",
      "epoch 20 | loss: 0.03663 | mse_mse: 0.01251 |  0:04:51s\n",
      "epoch 21 | loss: 0.03095 | mse_mse: 0.02175 |  0:05:04s\n",
      "epoch 22 | loss: 0.02881 | mse_mse: 0.01086 |  0:05:18s\n",
      "epoch 23 | loss: 0.02877 | mse_mse: 0.02887 |  0:05:32s\n",
      "epoch 24 | loss: 0.03336 | mse_mse: 0.01716 |  0:05:46s\n",
      "epoch 25 | loss: 0.0278  | mse_mse: 0.01242 |  0:06:00s\n",
      "epoch 26 | loss: 0.02625 | mse_mse: 0.02144 |  0:06:14s\n",
      "epoch 27 | loss: 0.02854 | mse_mse: 0.01641 |  0:06:28s\n",
      "epoch 28 | loss: 0.02577 | mse_mse: 0.09347 |  0:06:41s\n",
      "epoch 29 | loss: 0.02586 | mse_mse: 0.01509 |  0:06:55s\n",
      "epoch 30 | loss: 0.02655 | mse_mse: 0.01288 |  0:07:09s\n",
      "epoch 31 | loss: 0.02343 | mse_mse: 0.01519 |  0:07:23s\n",
      "epoch 32 | loss: 0.02338 | mse_mse: 0.01353 |  0:07:37s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_mse_mse = 0.01086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.012192023040066296\n",
      "R2 Score: 0.9449982501440488\n",
      "\n",
      "Iteration 150/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.08203 | mse_mse: 0.21369 |  0:00:14s\n",
      "epoch 1  | loss: 0.28291 | mse_mse: 0.2675  |  0:00:30s\n",
      "epoch 2  | loss: 0.24937 | mse_mse: 0.20922 |  0:00:45s\n",
      "epoch 3  | loss: 0.21953 | mse_mse: 0.14219 |  0:01:00s\n",
      "epoch 4  | loss: 0.1207  | mse_mse: 0.07919 |  0:01:15s\n",
      "epoch 5  | loss: 0.07079 | mse_mse: 0.04781 |  0:01:30s\n",
      "epoch 6  | loss: 0.05152 | mse_mse: 0.04446 |  0:01:45s\n",
      "epoch 7  | loss: 0.04322 | mse_mse: 0.08806 |  0:02:01s\n",
      "epoch 8  | loss: 0.03451 | mse_mse: 0.01614 |  0:02:16s\n",
      "epoch 9  | loss: 0.03414 | mse_mse: 0.01448 |  0:02:31s\n",
      "epoch 10 | loss: 0.03194 | mse_mse: 0.01211 |  0:02:46s\n",
      "epoch 11 | loss: 0.0279  | mse_mse: 0.02202 |  0:03:02s\n",
      "epoch 12 | loss: 0.02985 | mse_mse: 0.0198  |  0:03:17s\n",
      "epoch 13 | loss: 0.02888 | mse_mse: 0.02375 |  0:03:32s\n",
      "epoch 14 | loss: 0.02706 | mse_mse: 0.05891 |  0:03:48s\n",
      "epoch 15 | loss: 0.02704 | mse_mse: 0.01852 |  0:04:03s\n",
      "epoch 16 | loss: 0.02453 | mse_mse: 0.0123  |  0:04:18s\n",
      "epoch 17 | loss: 0.02566 | mse_mse: 0.05634 |  0:04:33s\n",
      "epoch 18 | loss: 0.02678 | mse_mse: 0.01307 |  0:04:49s\n",
      "epoch 19 | loss: 0.02818 | mse_mse: 0.01488 |  0:05:04s\n",
      "epoch 20 | loss: 0.02609 | mse_mse: 0.01128 |  0:05:19s\n",
      "epoch 21 | loss: 0.03324 | mse_mse: 0.01313 |  0:05:34s\n",
      "epoch 22 | loss: 0.02806 | mse_mse: 0.01633 |  0:05:50s\n",
      "epoch 23 | loss: 0.02422 | mse_mse: 0.02431 |  0:06:05s\n",
      "epoch 24 | loss: 0.02985 | mse_mse: 0.02878 |  0:06:20s\n",
      "epoch 25 | loss: 0.02888 | mse_mse: 0.01527 |  0:06:35s\n",
      "epoch 26 | loss: 0.02335 | mse_mse: 0.02009 |  0:06:51s\n",
      "epoch 27 | loss: 0.02438 | mse_mse: 0.01522 |  0:07:06s\n",
      "epoch 28 | loss: 0.02447 | mse_mse: 0.01509 |  0:07:21s\n",
      "epoch 29 | loss: 0.02086 | mse_mse: 0.01417 |  0:07:37s\n",
      "epoch 30 | loss: 0.02355 | mse_mse: 0.01866 |  0:07:52s\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_mse_mse = 0.01128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.011545229658951002\n",
      "R2 Score: 0.9479161225627344\n",
      "\n",
      "Iteration 151/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.6357  | mse_mse: 0.21782 |  0:00:06s\n",
      "epoch 1  | loss: 0.25593 | mse_mse: 0.22984 |  0:00:13s\n",
      "epoch 2  | loss: 0.25769 | mse_mse: 0.21032 |  0:00:20s\n",
      "epoch 3  | loss: 0.21813 | mse_mse: 0.13939 |  0:00:27s\n",
      "epoch 4  | loss: 0.10674 | mse_mse: 0.0549  |  0:00:34s\n",
      "epoch 5  | loss: 0.05068 | mse_mse: 0.01778 |  0:00:41s\n",
      "epoch 6  | loss: 0.04218 | mse_mse: 0.03122 |  0:00:48s\n",
      "epoch 7  | loss: 0.02793 | mse_mse: 0.01686 |  0:00:55s\n",
      "epoch 8  | loss: 0.03238 | mse_mse: 0.01444 |  0:01:01s\n",
      "epoch 9  | loss: 0.02932 | mse_mse: 0.01015 |  0:01:08s\n",
      "epoch 10 | loss: 0.02818 | mse_mse: 0.04214 |  0:01:15s\n",
      "epoch 11 | loss: 0.02897 | mse_mse: 0.01477 |  0:01:22s\n",
      "epoch 12 | loss: 0.02555 | mse_mse: 0.01479 |  0:01:29s\n",
      "epoch 13 | loss: 0.02701 | mse_mse: 0.00754 |  0:01:36s\n",
      "epoch 14 | loss: 0.02585 | mse_mse: 0.0166  |  0:01:43s\n",
      "epoch 15 | loss: 0.02671 | mse_mse: 0.02214 |  0:01:50s\n",
      "epoch 16 | loss: 0.02941 | mse_mse: 0.01268 |  0:01:57s\n",
      "epoch 17 | loss: 0.02377 | mse_mse: 0.01328 |  0:02:03s\n",
      "epoch 18 | loss: 0.02517 | mse_mse: 0.00956 |  0:02:11s\n",
      "epoch 19 | loss: 0.02393 | mse_mse: 0.01269 |  0:02:17s\n",
      "epoch 20 | loss: 0.02419 | mse_mse: 0.01158 |  0:02:25s\n",
      "epoch 21 | loss: 0.02408 | mse_mse: 0.01002 |  0:02:31s\n",
      "epoch 22 | loss: 0.02264 | mse_mse: 0.01369 |  0:02:38s\n",
      "epoch 23 | loss: 0.02387 | mse_mse: 0.0212  |  0:02:45s\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_mse_mse = 0.00754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007387734314121369\n",
      "R2 Score: 0.9666717891352244\n",
      "Best model updated\n",
      "\n",
      "Iteration 152/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.76218 | mse_mse: 0.32097 |  0:00:07s\n",
      "epoch 1  | loss: 0.27955 | mse_mse: 0.271   |  0:00:15s\n",
      "epoch 2  | loss: 0.26829 | mse_mse: 0.23759 |  0:00:22s\n",
      "epoch 3  | loss: 0.25662 | mse_mse: 0.19902 |  0:00:30s\n",
      "epoch 4  | loss: 0.14724 | mse_mse: 0.0713  |  0:00:37s\n",
      "epoch 5  | loss: 0.06251 | mse_mse: 0.03872 |  0:00:45s\n",
      "epoch 6  | loss: 0.04327 | mse_mse: 0.02667 |  0:00:53s\n",
      "epoch 7  | loss: 0.04207 | mse_mse: 0.05224 |  0:01:00s\n",
      "epoch 8  | loss: 0.0385  | mse_mse: 0.02529 |  0:01:08s\n",
      "epoch 9  | loss: 0.03701 | mse_mse: 0.0224  |  0:01:16s\n",
      "epoch 10 | loss: 0.03094 | mse_mse: 0.0299  |  0:01:23s\n",
      "epoch 11 | loss: 0.03141 | mse_mse: 0.01391 |  0:01:31s\n",
      "epoch 12 | loss: 0.03791 | mse_mse: 0.01327 |  0:01:39s\n",
      "epoch 13 | loss: 0.03375 | mse_mse: 0.01136 |  0:01:46s\n",
      "epoch 14 | loss: 0.03143 | mse_mse: 0.03052 |  0:01:54s\n",
      "epoch 15 | loss: 0.0295  | mse_mse: 0.03012 |  0:02:02s\n",
      "epoch 16 | loss: 0.02845 | mse_mse: 0.01783 |  0:02:09s\n",
      "epoch 17 | loss: 0.03137 | mse_mse: 0.01084 |  0:02:17s\n",
      "epoch 18 | loss: 0.02504 | mse_mse: 0.00713 |  0:02:25s\n",
      "epoch 19 | loss: 0.02639 | mse_mse: 0.05269 |  0:02:32s\n",
      "epoch 20 | loss: 0.02556 | mse_mse: 0.02017 |  0:02:40s\n",
      "epoch 21 | loss: 0.02649 | mse_mse: 0.01298 |  0:02:48s\n",
      "epoch 22 | loss: 0.03254 | mse_mse: 0.0574  |  0:02:56s\n",
      "epoch 23 | loss: 0.02701 | mse_mse: 0.03297 |  0:03:03s\n",
      "epoch 24 | loss: 0.0282  | mse_mse: 0.01281 |  0:03:11s\n",
      "epoch 25 | loss: 0.02345 | mse_mse: 0.01773 |  0:03:18s\n",
      "epoch 26 | loss: 0.02153 | mse_mse: 0.01006 |  0:03:26s\n",
      "epoch 27 | loss: 0.02318 | mse_mse: 0.02324 |  0:03:34s\n",
      "epoch 28 | loss: 0.02121 | mse_mse: 0.0105  |  0:03:42s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_mse_mse = 0.00713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00727536348501948\n",
      "R2 Score: 0.9671787265165809\n",
      "Best model updated\n",
      "\n",
      "Iteration 153/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.83778 | mse_mse: 0.31169 |  0:00:10s\n",
      "epoch 1  | loss: 0.29652 | mse_mse: 0.27467 |  0:00:21s\n",
      "epoch 2  | loss: 0.24288 | mse_mse: 0.19807 |  0:00:31s\n",
      "epoch 3  | loss: 0.16757 | mse_mse: 0.13198 |  0:00:42s\n",
      "epoch 4  | loss: 0.11708 | mse_mse: 0.07801 |  0:00:53s\n",
      "epoch 5  | loss: 0.07907 | mse_mse: 0.03562 |  0:01:03s\n",
      "epoch 6  | loss: 0.04911 | mse_mse: 0.03108 |  0:01:14s\n",
      "epoch 7  | loss: 0.04524 | mse_mse: 0.02992 |  0:01:25s\n",
      "epoch 8  | loss: 0.03391 | mse_mse: 0.01422 |  0:01:36s\n",
      "epoch 9  | loss: 0.03119 | mse_mse: 0.01543 |  0:01:46s\n",
      "epoch 10 | loss: 0.03045 | mse_mse: 0.01494 |  0:01:57s\n",
      "epoch 11 | loss: 0.02959 | mse_mse: 0.01331 |  0:02:08s\n",
      "epoch 12 | loss: 0.02933 | mse_mse: 0.01969 |  0:02:19s\n",
      "epoch 13 | loss: 0.03099 | mse_mse: 0.031   |  0:02:29s\n",
      "epoch 14 | loss: 0.02491 | mse_mse: 0.01137 |  0:02:40s\n",
      "epoch 15 | loss: 0.02571 | mse_mse: 0.02782 |  0:02:51s\n",
      "epoch 16 | loss: 0.02824 | mse_mse: 0.01901 |  0:03:02s\n",
      "epoch 17 | loss: 0.0236  | mse_mse: 0.01251 |  0:03:13s\n",
      "epoch 18 | loss: 0.02437 | mse_mse: 0.01871 |  0:03:23s\n",
      "epoch 19 | loss: 0.02785 | mse_mse: 0.01997 |  0:03:34s\n",
      "epoch 20 | loss: 0.03083 | mse_mse: 0.03314 |  0:03:45s\n",
      "epoch 21 | loss: 0.02921 | mse_mse: 0.15856 |  0:03:56s\n",
      "epoch 22 | loss: 0.02698 | mse_mse: 0.0152  |  0:04:07s\n",
      "epoch 23 | loss: 0.02755 | mse_mse: 0.05145 |  0:04:17s\n",
      "epoch 24 | loss: 0.02652 | mse_mse: 0.011   |  0:04:28s\n",
      "epoch 25 | loss: 0.03187 | mse_mse: 0.01278 |  0:04:39s\n",
      "epoch 26 | loss: 0.02999 | mse_mse: 0.01389 |  0:04:50s\n",
      "epoch 27 | loss: 0.02597 | mse_mse: 0.00772 |  0:05:01s\n",
      "epoch 28 | loss: 0.02987 | mse_mse: 0.02216 |  0:05:11s\n",
      "epoch 29 | loss: 0.03003 | mse_mse: 0.01779 |  0:05:22s\n",
      "epoch 30 | loss: 0.02456 | mse_mse: 0.02778 |  0:05:33s\n",
      "epoch 31 | loss: 0.02427 | mse_mse: 0.03139 |  0:05:44s\n",
      "epoch 32 | loss: 0.02425 | mse_mse: 0.02322 |  0:05:55s\n",
      "epoch 33 | loss: 0.02416 | mse_mse: 0.00966 |  0:06:05s\n",
      "epoch 34 | loss: 0.02355 | mse_mse: 0.01199 |  0:06:16s\n",
      "epoch 35 | loss: 0.02473 | mse_mse: 0.05333 |  0:06:27s\n",
      "epoch 36 | loss: 0.02281 | mse_mse: 0.00857 |  0:06:38s\n",
      "epoch 37 | loss: 0.01912 | mse_mse: 0.0205  |  0:06:49s\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_mse_mse = 0.00772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007948859381408989\n",
      "R2 Score: 0.9641403913116283\n",
      "\n",
      "Iteration 154/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.6257  | mse_mse: 0.33443 |  0:00:11s\n",
      "epoch 1  | loss: 0.28993 | mse_mse: 0.23581 |  0:00:23s\n",
      "epoch 2  | loss: 0.26994 | mse_mse: 0.24929 |  0:00:34s\n",
      "epoch 3  | loss: 0.2637  | mse_mse: 0.25808 |  0:00:46s\n",
      "epoch 4  | loss: 0.25704 | mse_mse: 0.21741 |  0:00:58s\n",
      "epoch 5  | loss: 0.22248 | mse_mse: 0.13353 |  0:01:10s\n",
      "epoch 6  | loss: 0.15383 | mse_mse: 0.08842 |  0:01:22s\n",
      "epoch 7  | loss: 0.07416 | mse_mse: 0.03166 |  0:01:34s\n",
      "epoch 8  | loss: 0.04327 | mse_mse: 0.02762 |  0:01:45s\n",
      "epoch 9  | loss: 0.03856 | mse_mse: 0.02135 |  0:01:57s\n",
      "epoch 10 | loss: 0.03916 | mse_mse: 0.01622 |  0:02:09s\n",
      "epoch 11 | loss: 0.03158 | mse_mse: 0.01318 |  0:02:21s\n",
      "epoch 12 | loss: 0.03986 | mse_mse: 0.03866 |  0:02:33s\n",
      "epoch 13 | loss: 0.035   | mse_mse: 0.02038 |  0:02:45s\n",
      "epoch 14 | loss: 0.03095 | mse_mse: 0.01581 |  0:02:57s\n",
      "epoch 15 | loss: 0.03571 | mse_mse: 0.02114 |  0:03:09s\n",
      "epoch 16 | loss: 0.02704 | mse_mse: 0.01352 |  0:03:20s\n",
      "epoch 17 | loss: 0.0269  | mse_mse: 0.08338 |  0:03:32s\n",
      "epoch 18 | loss: 0.03022 | mse_mse: 0.02472 |  0:03:44s\n",
      "epoch 19 | loss: 0.02726 | mse_mse: 0.00969 |  0:03:56s\n",
      "epoch 20 | loss: 0.02191 | mse_mse: 0.0551  |  0:04:08s\n",
      "epoch 21 | loss: 0.02786 | mse_mse: 0.56081 |  0:04:20s\n",
      "epoch 22 | loss: 0.02756 | mse_mse: 0.03148 |  0:04:32s\n",
      "epoch 23 | loss: 0.02499 | mse_mse: 0.01066 |  0:04:44s\n",
      "epoch 24 | loss: 0.02543 | mse_mse: 0.03423 |  0:04:56s\n",
      "epoch 25 | loss: 0.02443 | mse_mse: 0.01311 |  0:05:07s\n",
      "epoch 26 | loss: 0.0245  | mse_mse: 0.00921 |  0:05:19s\n",
      "epoch 27 | loss: 0.02307 | mse_mse: 0.01857 |  0:05:31s\n",
      "epoch 28 | loss: 0.02021 | mse_mse: 0.01018 |  0:05:43s\n",
      "epoch 29 | loss: 0.01999 | mse_mse: 0.04865 |  0:05:55s\n",
      "epoch 30 | loss: 0.01935 | mse_mse: 0.01211 |  0:06:07s\n",
      "epoch 31 | loss: 0.01894 | mse_mse: 0.01325 |  0:06:19s\n",
      "epoch 32 | loss: 0.01977 | mse_mse: 0.01365 |  0:06:31s\n",
      "epoch 33 | loss: 0.01995 | mse_mse: 0.02281 |  0:06:42s\n",
      "epoch 34 | loss: 0.01911 | mse_mse: 0.0277  |  0:06:54s\n",
      "epoch 35 | loss: 0.01935 | mse_mse: 0.02293 |  0:07:06s\n",
      "epoch 36 | loss: 0.01801 | mse_mse: 0.0215  |  0:07:18s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_mse_mse = 0.00921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008314160942515716\n",
      "R2 Score: 0.9624924100848908\n",
      "\n",
      "Iteration 155/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.72248 | mse_mse: 0.30355 |  0:00:14s\n",
      "epoch 1  | loss: 0.2994  | mse_mse: 0.24031 |  0:00:28s\n",
      "epoch 2  | loss: 0.27652 | mse_mse: 0.22455 |  0:00:42s\n",
      "epoch 3  | loss: 0.26064 | mse_mse: 0.24999 |  0:00:57s\n",
      "epoch 4  | loss: 0.25837 | mse_mse: 0.23088 |  0:01:11s\n",
      "epoch 5  | loss: 0.25867 | mse_mse: 0.22522 |  0:01:26s\n",
      "epoch 6  | loss: 0.24879 | mse_mse: 0.22879 |  0:01:40s\n",
      "epoch 7  | loss: 0.24707 | mse_mse: 0.2102  |  0:01:55s\n",
      "epoch 8  | loss: 0.1974  | mse_mse: 0.12739 |  0:02:09s\n",
      "epoch 9  | loss: 0.124   | mse_mse: 0.10507 |  0:02:24s\n",
      "epoch 10 | loss: 0.06183 | mse_mse: 0.10299 |  0:02:39s\n",
      "epoch 11 | loss: 0.05362 | mse_mse: 0.027   |  0:02:53s\n",
      "epoch 12 | loss: 0.04428 | mse_mse: 0.02624 |  0:03:08s\n",
      "epoch 13 | loss: 0.03714 | mse_mse: 0.02894 |  0:03:23s\n",
      "epoch 14 | loss: 0.03859 | mse_mse: 0.01388 |  0:03:37s\n",
      "epoch 15 | loss: 0.03244 | mse_mse: 0.02392 |  0:03:52s\n",
      "epoch 16 | loss: 0.03039 | mse_mse: 0.01317 |  0:04:07s\n",
      "epoch 17 | loss: 0.02938 | mse_mse: 0.01872 |  0:04:21s\n",
      "epoch 18 | loss: 0.02753 | mse_mse: 0.02311 |  0:04:36s\n",
      "epoch 19 | loss: 0.02634 | mse_mse: 0.01051 |  0:04:51s\n",
      "epoch 20 | loss: 0.02585 | mse_mse: 0.04941 |  0:05:06s\n",
      "epoch 21 | loss: 0.02789 | mse_mse: 0.02376 |  0:05:20s\n",
      "epoch 22 | loss: 0.02542 | mse_mse: 0.00987 |  0:05:35s\n",
      "epoch 23 | loss: 0.02808 | mse_mse: 0.03286 |  0:05:50s\n",
      "epoch 24 | loss: 0.02936 | mse_mse: 0.02371 |  0:06:04s\n",
      "epoch 25 | loss: 0.02648 | mse_mse: 0.01893 |  0:06:19s\n",
      "epoch 26 | loss: 0.02893 | mse_mse: 0.0258  |  0:06:34s\n",
      "epoch 27 | loss: 0.02543 | mse_mse: 0.00873 |  0:06:48s\n",
      "epoch 28 | loss: 0.02411 | mse_mse: 0.02167 |  0:07:03s\n",
      "epoch 29 | loss: 0.025   | mse_mse: 0.01575 |  0:07:18s\n",
      "epoch 30 | loss: 0.02585 | mse_mse: 0.01921 |  0:07:32s\n",
      "epoch 31 | loss: 0.03012 | mse_mse: 0.06927 |  0:07:47s\n",
      "epoch 32 | loss: 0.02303 | mse_mse: 0.01377 |  0:08:02s\n",
      "epoch 33 | loss: 0.02312 | mse_mse: 0.09486 |  0:08:16s\n",
      "epoch 34 | loss: 0.02527 | mse_mse: 0.07171 |  0:08:31s\n",
      "epoch 35 | loss: 0.02506 | mse_mse: 0.01574 |  0:08:46s\n",
      "epoch 36 | loss: 0.02157 | mse_mse: 0.00821 |  0:09:00s\n",
      "epoch 37 | loss: 0.02139 | mse_mse: 0.04719 |  0:09:15s\n",
      "epoch 38 | loss: 0.02286 | mse_mse: 0.04385 |  0:09:30s\n",
      "epoch 39 | loss: 0.0219  | mse_mse: 0.02736 |  0:09:44s\n",
      "epoch 40 | loss: 0.02265 | mse_mse: 0.01163 |  0:09:59s\n",
      "epoch 41 | loss: 0.02308 | mse_mse: 0.04068 |  0:10:14s\n",
      "epoch 42 | loss: 0.02099 | mse_mse: 0.0275  |  0:10:28s\n",
      "epoch 43 | loss: 0.02417 | mse_mse: 0.03763 |  0:10:43s\n",
      "epoch 44 | loss: 0.02215 | mse_mse: 0.00987 |  0:10:58s\n",
      "epoch 45 | loss: 0.02198 | mse_mse: 0.0156  |  0:11:13s\n",
      "epoch 46 | loss: 0.02348 | mse_mse: 0.01909 |  0:11:27s\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_mse_mse = 0.00821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00823413865361632\n",
      "R2 Score: 0.9628534138249987\n",
      "\n",
      "Iteration 156/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.97469 | mse_mse: 0.49947 |  0:00:15s\n",
      "epoch 1  | loss: 0.28929 | mse_mse: 0.24548 |  0:00:31s\n",
      "epoch 2  | loss: 0.26886 | mse_mse: 0.2421  |  0:00:47s\n",
      "epoch 3  | loss: 0.27071 | mse_mse: 0.25236 |  0:01:03s\n",
      "epoch 4  | loss: 0.26273 | mse_mse: 0.24235 |  0:01:19s\n",
      "epoch 5  | loss: 0.25636 | mse_mse: 0.26639 |  0:01:36s\n",
      "epoch 6  | loss: 0.25196 | mse_mse: 0.23015 |  0:01:52s\n",
      "epoch 7  | loss: 0.25674 | mse_mse: 0.22987 |  0:02:08s\n",
      "epoch 8  | loss: 0.24519 | mse_mse: 0.22402 |  0:02:24s\n",
      "epoch 9  | loss: 0.23404 | mse_mse: 0.18965 |  0:02:40s\n",
      "epoch 10 | loss: 0.15527 | mse_mse: 0.07704 |  0:02:57s\n",
      "epoch 11 | loss: 0.06993 | mse_mse: 0.03629 |  0:03:13s\n",
      "epoch 12 | loss: 0.04055 | mse_mse: 0.02259 |  0:03:29s\n",
      "epoch 13 | loss: 0.04261 | mse_mse: 0.01907 |  0:03:45s\n",
      "epoch 14 | loss: 0.0345  | mse_mse: 0.01198 |  0:04:02s\n",
      "epoch 15 | loss: 0.03652 | mse_mse: 0.0094  |  0:04:18s\n",
      "epoch 16 | loss: 0.03064 | mse_mse: 0.01544 |  0:04:34s\n",
      "epoch 17 | loss: 0.03145 | mse_mse: 0.01135 |  0:04:50s\n",
      "epoch 18 | loss: 0.03154 | mse_mse: 0.01061 |  0:05:07s\n",
      "epoch 19 | loss: 0.03017 | mse_mse: 0.02696 |  0:05:23s\n",
      "epoch 20 | loss: 0.02791 | mse_mse: 0.07673 |  0:05:39s\n",
      "epoch 21 | loss: 0.04139 | mse_mse: 0.01133 |  0:05:55s\n",
      "epoch 22 | loss: 0.02739 | mse_mse: 0.01703 |  0:06:11s\n",
      "epoch 23 | loss: 0.03207 | mse_mse: 0.13424 |  0:06:28s\n",
      "epoch 24 | loss: 0.0275  | mse_mse: 0.03397 |  0:06:44s\n",
      "epoch 25 | loss: 0.02669 | mse_mse: 0.03582 |  0:07:00s\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_mse_mse = 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009817373001533562\n",
      "R2 Score: 0.955710984772714\n",
      "\n",
      "Iteration 157/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.50665 | mse_mse: 0.22433 |  0:00:06s\n",
      "epoch 1  | loss: 0.2818  | mse_mse: 0.25081 |  0:00:13s\n",
      "epoch 2  | loss: 0.24483 | mse_mse: 0.19153 |  0:00:20s\n",
      "epoch 3  | loss: 0.15682 | mse_mse: 0.09718 |  0:00:27s\n",
      "epoch 4  | loss: 0.08142 | mse_mse: 0.07911 |  0:00:34s\n",
      "epoch 5  | loss: 0.04564 | mse_mse: 0.06527 |  0:00:41s\n",
      "epoch 6  | loss: 0.03915 | mse_mse: 0.04255 |  0:00:49s\n",
      "epoch 7  | loss: 0.03491 | mse_mse: 0.03497 |  0:00:56s\n",
      "epoch 8  | loss: 0.03605 | mse_mse: 0.00801 |  0:01:03s\n",
      "epoch 9  | loss: 0.03277 | mse_mse: 0.01064 |  0:01:10s\n",
      "epoch 10 | loss: 0.0302  | mse_mse: 0.00833 |  0:01:17s\n",
      "epoch 11 | loss: 0.03052 | mse_mse: 0.01322 |  0:01:25s\n",
      "epoch 12 | loss: 0.02718 | mse_mse: 0.01082 |  0:01:32s\n",
      "epoch 13 | loss: 0.03081 | mse_mse: 0.01947 |  0:01:39s\n",
      "epoch 14 | loss: 0.02534 | mse_mse: 0.05404 |  0:01:46s\n",
      "epoch 15 | loss: 0.02888 | mse_mse: 0.02169 |  0:01:53s\n",
      "epoch 16 | loss: 0.03581 | mse_mse: 0.0299  |  0:02:01s\n",
      "epoch 17 | loss: 0.0246  | mse_mse: 0.04716 |  0:02:08s\n",
      "epoch 18 | loss: 0.02896 | mse_mse: 0.00945 |  0:02:15s\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_mse_mse = 0.00801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008320087352897309\n",
      "R2 Score: 0.9624656743298582\n",
      "\n",
      "Iteration 158/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.65795 | mse_mse: 0.24044 |  0:00:07s\n",
      "epoch 1  | loss: 0.26534 | mse_mse: 0.27187 |  0:00:15s\n",
      "epoch 2  | loss: 0.21792 | mse_mse: 0.1066  |  0:00:23s\n",
      "epoch 3  | loss: 0.08365 | mse_mse: 0.03871 |  0:00:31s\n",
      "epoch 4  | loss: 0.04511 | mse_mse: 0.05879 |  0:00:39s\n",
      "epoch 5  | loss: 0.03911 | mse_mse: 0.02271 |  0:00:47s\n",
      "epoch 6  | loss: 0.03521 | mse_mse: 0.02488 |  0:00:55s\n",
      "epoch 7  | loss: 0.03078 | mse_mse: 0.03787 |  0:01:03s\n",
      "epoch 8  | loss: 0.03187 | mse_mse: 0.0276  |  0:01:11s\n",
      "epoch 9  | loss: 0.02714 | mse_mse: 0.03754 |  0:01:19s\n",
      "epoch 10 | loss: 0.02507 | mse_mse: 0.01647 |  0:01:27s\n",
      "epoch 11 | loss: 0.0305  | mse_mse: 0.02488 |  0:01:35s\n",
      "epoch 12 | loss: 0.02797 | mse_mse: 0.02057 |  0:01:43s\n",
      "epoch 13 | loss: 0.02785 | mse_mse: 0.0293  |  0:01:50s\n",
      "epoch 14 | loss: 0.02729 | mse_mse: 0.01    |  0:01:59s\n",
      "epoch 15 | loss: 0.02659 | mse_mse: 0.0107  |  0:02:07s\n",
      "epoch 16 | loss: 0.02735 | mse_mse: 0.02365 |  0:02:15s\n",
      "epoch 17 | loss: 0.02371 | mse_mse: 0.01894 |  0:02:23s\n",
      "epoch 18 | loss: 0.02335 | mse_mse: 0.01329 |  0:02:31s\n",
      "epoch 19 | loss: 0.0229  | mse_mse: 0.01537 |  0:02:39s\n",
      "epoch 20 | loss: 0.02389 | mse_mse: 0.01038 |  0:02:47s\n",
      "epoch 21 | loss: 0.02206 | mse_mse: 0.01617 |  0:02:55s\n",
      "epoch 22 | loss: 0.02461 | mse_mse: 0.00953 |  0:03:03s\n",
      "epoch 23 | loss: 0.02139 | mse_mse: 0.00914 |  0:03:11s\n",
      "epoch 24 | loss: 0.022   | mse_mse: 0.01752 |  0:03:19s\n",
      "epoch 25 | loss: 0.02181 | mse_mse: 0.03835 |  0:03:27s\n",
      "epoch 26 | loss: 0.02241 | mse_mse: 0.01204 |  0:03:35s\n",
      "epoch 27 | loss: 0.02109 | mse_mse: 0.04842 |  0:03:43s\n",
      "epoch 28 | loss: 0.02215 | mse_mse: 0.05025 |  0:03:51s\n",
      "epoch 29 | loss: 0.01957 | mse_mse: 0.02658 |  0:03:59s\n",
      "epoch 30 | loss: 0.0205  | mse_mse: 0.0124  |  0:04:07s\n",
      "epoch 31 | loss: 0.01949 | mse_mse: 0.01951 |  0:04:15s\n",
      "epoch 32 | loss: 0.02149 | mse_mse: 0.03525 |  0:04:23s\n",
      "epoch 33 | loss: 0.02058 | mse_mse: 0.01784 |  0:04:31s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_mse_mse = 0.00914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008654131390899013\n",
      "R2 Score: 0.9609587048500053\n",
      "\n",
      "Iteration 159/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.80247 | mse_mse: 0.2922  |  0:00:10s\n",
      "epoch 1  | loss: 0.17134 | mse_mse: 0.12424 |  0:00:21s\n",
      "epoch 2  | loss: 0.13721 | mse_mse: 0.11143 |  0:00:32s\n",
      "epoch 3  | loss: 0.12317 | mse_mse: 0.09264 |  0:00:43s\n",
      "epoch 4  | loss: 0.10947 | mse_mse: 0.07836 |  0:00:54s\n",
      "epoch 5  | loss: 0.09256 | mse_mse: 0.04938 |  0:01:05s\n",
      "epoch 6  | loss: 0.06813 | mse_mse: 0.05467 |  0:01:16s\n",
      "epoch 7  | loss: 0.0654  | mse_mse: 0.05719 |  0:01:27s\n",
      "epoch 8  | loss: 0.0506  | mse_mse: 0.10341 |  0:01:39s\n",
      "epoch 9  | loss: 0.04125 | mse_mse: 0.02973 |  0:01:50s\n",
      "epoch 10 | loss: 0.0353  | mse_mse: 0.02532 |  0:02:01s\n",
      "epoch 11 | loss: 0.02936 | mse_mse: 0.0127  |  0:02:12s\n",
      "epoch 12 | loss: 0.03134 | mse_mse: 0.04904 |  0:02:24s\n",
      "epoch 13 | loss: 0.02435 | mse_mse: 0.01248 |  0:02:35s\n",
      "epoch 14 | loss: 0.02565 | mse_mse: 0.01048 |  0:02:46s\n",
      "epoch 15 | loss: 0.02902 | mse_mse: 0.01895 |  0:02:58s\n",
      "epoch 16 | loss: 0.02523 | mse_mse: 0.02136 |  0:03:09s\n",
      "epoch 17 | loss: 0.02509 | mse_mse: 0.01867 |  0:03:20s\n",
      "epoch 18 | loss: 0.02862 | mse_mse: 0.01219 |  0:03:31s\n",
      "epoch 19 | loss: 0.0238  | mse_mse: 0.01154 |  0:03:43s\n",
      "epoch 20 | loss: 0.02043 | mse_mse: 0.01997 |  0:03:54s\n",
      "epoch 21 | loss: 0.02546 | mse_mse: 0.02468 |  0:04:05s\n",
      "epoch 22 | loss: 0.01863 | mse_mse: 0.01771 |  0:04:16s\n",
      "epoch 23 | loss: 0.02167 | mse_mse: 0.01805 |  0:04:28s\n",
      "epoch 24 | loss: 0.02009 | mse_mse: 0.03571 |  0:04:39s\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_mse_mse = 0.01048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010573620655010134\n",
      "R2 Score: 0.9522993324055082\n",
      "\n",
      "Iteration 160/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.60093 | mse_mse: 0.25414 |  0:00:11s\n",
      "epoch 1  | loss: 0.27216 | mse_mse: 0.24562 |  0:00:23s\n",
      "epoch 2  | loss: 0.27233 | mse_mse: 0.21737 |  0:00:35s\n",
      "epoch 3  | loss: 0.21763 | mse_mse: 0.14057 |  0:00:47s\n",
      "epoch 4  | loss: 0.1463  | mse_mse: 0.08339 |  0:01:00s\n",
      "epoch 5  | loss: 0.09224 | mse_mse: 0.0895  |  0:01:12s\n",
      "epoch 6  | loss: 0.06208 | mse_mse: 0.03579 |  0:01:24s\n",
      "epoch 7  | loss: 0.04685 | mse_mse: 0.07134 |  0:01:37s\n",
      "epoch 8  | loss: 0.04006 | mse_mse: 0.02302 |  0:01:49s\n",
      "epoch 9  | loss: 0.03909 | mse_mse: 0.02636 |  0:02:01s\n",
      "epoch 10 | loss: 0.03359 | mse_mse: 0.01746 |  0:02:14s\n",
      "epoch 11 | loss: 0.03164 | mse_mse: 0.02203 |  0:02:26s\n",
      "epoch 12 | loss: 0.03294 | mse_mse: 0.02711 |  0:02:38s\n",
      "epoch 13 | loss: 0.02892 | mse_mse: 0.01837 |  0:02:51s\n",
      "epoch 14 | loss: 0.03125 | mse_mse: 0.01389 |  0:03:03s\n",
      "epoch 15 | loss: 0.02794 | mse_mse: 0.02441 |  0:03:15s\n",
      "epoch 16 | loss: 0.03462 | mse_mse: 0.02138 |  0:03:28s\n",
      "epoch 17 | loss: 0.02494 | mse_mse: 0.01807 |  0:03:40s\n",
      "epoch 18 | loss: 0.03172 | mse_mse: 0.02756 |  0:03:53s\n",
      "epoch 19 | loss: 0.02489 | mse_mse: 0.01441 |  0:04:05s\n",
      "epoch 20 | loss: 0.02621 | mse_mse: 0.01252 |  0:04:17s\n",
      "epoch 21 | loss: 0.02618 | mse_mse: 0.01547 |  0:04:30s\n",
      "epoch 22 | loss: 0.02294 | mse_mse: 0.00828 |  0:04:42s\n",
      "epoch 23 | loss: 0.02621 | mse_mse: 0.01432 |  0:04:55s\n",
      "epoch 24 | loss: 0.02687 | mse_mse: 0.06612 |  0:05:07s\n",
      "epoch 25 | loss: 0.02465 | mse_mse: 0.02786 |  0:05:19s\n",
      "epoch 26 | loss: 0.02313 | mse_mse: 0.01134 |  0:05:32s\n",
      "epoch 27 | loss: 0.02446 | mse_mse: 0.02775 |  0:05:44s\n",
      "epoch 28 | loss: 0.02292 | mse_mse: 0.01985 |  0:05:56s\n",
      "epoch 29 | loss: 0.02558 | mse_mse: 0.0148  |  0:06:09s\n",
      "epoch 30 | loss: 0.02293 | mse_mse: 0.01753 |  0:06:21s\n",
      "epoch 31 | loss: 0.024   | mse_mse: 0.019   |  0:06:33s\n",
      "epoch 32 | loss: 0.02813 | mse_mse: 0.01271 |  0:06:46s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_mse_mse = 0.00828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007938523759027524\n",
      "R2 Score: 0.9641870183000258\n",
      "\n",
      "Iteration 161/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.63431 | mse_mse: 0.28552 |  0:00:14s\n",
      "epoch 1  | loss: 0.32368 | mse_mse: 0.23583 |  0:00:29s\n",
      "epoch 2  | loss: 0.27931 | mse_mse: 0.23464 |  0:00:43s\n",
      "epoch 3  | loss: 0.25623 | mse_mse: 0.24879 |  0:00:58s\n",
      "epoch 4  | loss: 0.25827 | mse_mse: 0.23876 |  0:01:14s\n",
      "epoch 5  | loss: 0.21754 | mse_mse: 0.14882 |  0:01:29s\n",
      "epoch 6  | loss: 0.12769 | mse_mse: 0.07628 |  0:01:44s\n",
      "epoch 7  | loss: 0.07423 | mse_mse: 0.14106 |  0:01:59s\n",
      "epoch 8  | loss: 0.04934 | mse_mse: 0.02263 |  0:02:14s\n",
      "epoch 9  | loss: 0.04262 | mse_mse: 0.16309 |  0:02:29s\n",
      "epoch 10 | loss: 0.04194 | mse_mse: 0.05328 |  0:02:45s\n",
      "epoch 11 | loss: 0.04322 | mse_mse: 0.01269 |  0:03:00s\n",
      "epoch 12 | loss: 0.03503 | mse_mse: 0.03414 |  0:03:15s\n",
      "epoch 13 | loss: 0.03348 | mse_mse: 0.01735 |  0:03:30s\n",
      "epoch 14 | loss: 0.03027 | mse_mse: 0.01208 |  0:03:45s\n",
      "epoch 15 | loss: 0.03163 | mse_mse: 0.02354 |  0:04:01s\n",
      "epoch 16 | loss: 0.03142 | mse_mse: 0.01498 |  0:04:16s\n",
      "epoch 17 | loss: 0.04096 | mse_mse: 0.02542 |  0:04:31s\n",
      "epoch 18 | loss: 0.03557 | mse_mse: 0.02463 |  0:04:46s\n",
      "epoch 19 | loss: 0.02984 | mse_mse: 0.04526 |  0:05:02s\n",
      "epoch 20 | loss: 0.03024 | mse_mse: 0.01339 |  0:05:17s\n",
      "epoch 21 | loss: 0.02854 | mse_mse: 0.00994 |  0:05:32s\n",
      "epoch 22 | loss: 0.02627 | mse_mse: 0.00827 |  0:05:47s\n",
      "epoch 23 | loss: 0.02492 | mse_mse: 0.01659 |  0:06:03s\n",
      "epoch 24 | loss: 0.03425 | mse_mse: 0.01582 |  0:06:18s\n",
      "epoch 25 | loss: 0.02825 | mse_mse: 0.01503 |  0:06:33s\n",
      "epoch 26 | loss: 0.02756 | mse_mse: 0.03749 |  0:06:48s\n",
      "epoch 27 | loss: 0.02724 | mse_mse: 0.0099  |  0:07:04s\n",
      "epoch 28 | loss: 0.02353 | mse_mse: 0.00993 |  0:07:19s\n",
      "epoch 29 | loss: 0.02403 | mse_mse: 0.0106  |  0:07:34s\n",
      "epoch 30 | loss: 0.02258 | mse_mse: 0.08322 |  0:07:49s\n",
      "epoch 31 | loss: 0.02332 | mse_mse: 0.01206 |  0:08:05s\n",
      "epoch 32 | loss: 0.02622 | mse_mse: 0.05445 |  0:08:20s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_mse_mse = 0.00827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008882590708238332\n",
      "R2 Score: 0.959928058649349\n",
      "\n",
      "Iteration 162/162\n",
      "Configuration batch size: 32 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.0339  | mse_mse: 0.2507  |  0:00:15s\n",
      "epoch 1  | loss: 0.28588 | mse_mse: 0.22611 |  0:00:31s\n",
      "epoch 2  | loss: 0.25186 | mse_mse: 0.29915 |  0:00:48s\n",
      "epoch 3  | loss: 0.19435 | mse_mse: 0.12115 |  0:01:05s\n",
      "epoch 4  | loss: 0.12441 | mse_mse: 0.12056 |  0:01:21s\n",
      "epoch 5  | loss: 0.10885 | mse_mse: 0.08292 |  0:01:38s\n",
      "epoch 6  | loss: 0.10242 | mse_mse: 0.08825 |  0:01:55s\n",
      "epoch 7  | loss: 0.10641 | mse_mse: 0.08532 |  0:02:12s\n",
      "epoch 8  | loss: 0.10254 | mse_mse: 0.07656 |  0:02:28s\n",
      "epoch 9  | loss: 0.0978  | mse_mse: 0.1192  |  0:02:45s\n",
      "epoch 10 | loss: 0.09648 | mse_mse: 0.07826 |  0:03:02s\n",
      "epoch 11 | loss: 0.09355 | mse_mse: 0.07616 |  0:03:19s\n",
      "epoch 12 | loss: 0.0949  | mse_mse: 0.10214 |  0:03:36s\n",
      "epoch 13 | loss: 0.08558 | mse_mse: 0.06609 |  0:03:52s\n",
      "epoch 14 | loss: 0.08423 | mse_mse: 0.06691 |  0:04:09s\n",
      "epoch 15 | loss: 0.07519 | mse_mse: 0.08354 |  0:04:26s\n",
      "epoch 16 | loss: 0.06156 | mse_mse: 0.04374 |  0:04:43s\n",
      "epoch 17 | loss: 0.04862 | mse_mse: 0.06675 |  0:05:00s\n",
      "epoch 18 | loss: 0.03635 | mse_mse: 0.08524 |  0:05:16s\n",
      "epoch 19 | loss: 0.03263 | mse_mse: 0.01814 |  0:05:33s\n",
      "epoch 20 | loss: 0.03046 | mse_mse: 0.02373 |  0:05:50s\n",
      "epoch 21 | loss: 0.03122 | mse_mse: 0.04197 |  0:06:07s\n",
      "epoch 22 | loss: 0.02868 | mse_mse: 0.01128 |  0:06:24s\n",
      "epoch 23 | loss: 0.02685 | mse_mse: 0.02477 |  0:06:41s\n",
      "epoch 24 | loss: 0.03284 | mse_mse: 0.06037 |  0:06:58s\n",
      "epoch 25 | loss: 0.02618 | mse_mse: 0.02908 |  0:07:15s\n",
      "epoch 26 | loss: 0.02154 | mse_mse: 0.03105 |  0:07:32s\n",
      "epoch 27 | loss: 0.02447 | mse_mse: 0.02225 |  0:07:48s\n",
      "epoch 28 | loss: 0.02377 | mse_mse: 0.01893 |  0:08:05s\n",
      "epoch 29 | loss: 0.02296 | mse_mse: 0.026   |  0:08:22s\n",
      "epoch 30 | loss: 0.02155 | mse_mse: 0.02017 |  0:08:39s\n",
      "epoch 31 | loss: 0.01916 | mse_mse: 0.02251 |  0:08:56s\n",
      "epoch 32 | loss: 0.02126 | mse_mse: 0.02981 |  0:09:13s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_mse_mse = 0.01128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.012078978372291535\n",
      "R2 Score: 0.9455082274069742\n"
     ]
    }
   ],
   "source": [
    "best_mse = float('inf')\n",
    "best_model = None\n",
    "best_params = None\n",
    "iter = 0\n",
    "for b, n_e, n_d, n_a, n_s, n_i in params:\n",
    "    iter += 1\n",
    "    print(f'\\nIteration {iter}/{comb}')\n",
    "    print(f\"Configuration batch size: {b} - epochs: {n_e} - n_d: {n_d} - n_a: {n_a} - steps: {n_s} - n_indipendent: {n_i}\")\n",
    "    \n",
    "    model = get_model(b, n_e, n_d, n_a, n_s, n_i)\n",
    "    #save results for each iteration with tensorboard\n",
    "    log = f'bach_size_{b}_nEpochs_{n_e}_nd_{n_d}_na_{n_a}_nSteps_{n_s}_nIndipendent_{n_i}'\n",
    "\n",
    "    if os.path.exists(\"./results/TabNet/pca/\"+log):\n",
    "        print(\"Model already trained. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    writer = SummaryWriter(f'results/TabNet/pca/bach_size_{b}_nEpochs_{n_e}_nd_{n_d}_na_{n_a}_nSteps_{n_s}_nIndipendent_{n_i}')\n",
    "    #fit model\n",
    "    model.fit(\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_name=['mse'],\n",
    "        patience=10,\n",
    "        batch_size=b\n",
    "    )\n",
    "\n",
    "    # evaluate model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "   #save hparams for each iteration with tensorboard\n",
    "    writer.add_hparams(\n",
    "        {'batch_size': b, 'n_epochs': n_e, 'n_d': n_d, 'n_a': n_a, 'n_steps': n_s, 'n_indipendent': n_i},\n",
    "        {'hparam/mse': mse, 'hparam/r2': r2}\n",
    "    )\n",
    "    print('MSE:', mse)\n",
    "    print('R2 Score:', r2)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_params = (b, n_e, n_d, n_a, n_s, n_i)\n",
    "        print('Best model updated')\n",
    "    writer.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabNetRegressor(n_d=32, n_a=16, n_steps=3, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=3, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=1, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=552, output_dim=1, device_name='auto', n_shared_decoder=1, n_indep_decoder=1)\n",
      "Best MSE:  0.00727536348501948\n",
      "R2 score 0.9671787265165809\n"
     ]
    }
   ],
   "source": [
    "#pint the best model\n",
    "print(best_model)\n",
    "print(\"Best MSE: \", best_mse)\n",
    "print(\"R2 score\", r2_score(y_test, best_model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at best_model_tabnet_pca.csv.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'best_model_tabnet_pca.csv.zip'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the best model in a file csv\n",
    "best_model.save_model('best_model_tabnet_pca.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
