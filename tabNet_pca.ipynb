{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product\n",
    "from sklearn.metrics import r2_score\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def fix_random(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "fix_random(42)\n",
    "\n",
    "pca_t = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "df = pd.read_csv('dataset-ml-25m/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train set:  9946\n",
      "Numebr of test set:  2764\n",
      "Number of validation set:  1106\n"
     ]
    }
   ],
   "source": [
    "# Dividi il dataset in feature e target\n",
    "X = df.drop(['rating'], axis=1).to_numpy()\n",
    "y = df['rating'].to_numpy()\n",
    "\n",
    "# Dividi il dataset in training, validation e test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1, random_state=42)\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "#count the numebr of x_train \n",
    "print(\"Number of train set: \", X_train.shape[0])\n",
    "print(\"Numebr of test set: \", X_test.shape[0])\n",
    "print(\"Number of validation set: \", X_val.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applica la riduzione della dimensionalit√† con PCA\n",
    "if pca_t == True:\n",
    "    pca = PCA(n_components=0.95)\n",
    "    pca.fit(X_train)\n",
    "    X_train = pca.transform(X_train)\n",
    "    X_val = pca.transform(X_val)\n",
    "    X_test = pca.transform(X_test)\n",
    "else:\n",
    "    print (\"PCA is not applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations:  54\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [256]\n",
    "n_epochs = [200]\n",
    "# Dimension of the prediction  layer\n",
    "n_d = [8, 16, 32]\n",
    "#Dimension of the attention  layer\n",
    "n_a = [8, 16, 32]\n",
    "#Number of successive steps in the network\n",
    "n_steps = [3, 5, 7]\n",
    "# Number of independent GLU layer in each GLU block\n",
    "n_indipendent = [2, 3]\n",
    "\n",
    "params = list(product(batch_sizes, n_epochs, n_d, n_a, n_steps, n_indipendent))\n",
    "comb = len(batch_sizes)*len(n_d)*len(n_a) *len(n_steps) *len(n_indipendent)\n",
    "print(\"Number of combinations: \", comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(batch_size, n_epochs, n_d, n_a, n_steps, n_indipendent):\n",
    "    model = TabNetRegressor(\n",
    "        n_d=n_d,\n",
    "        n_a=n_a,\n",
    "        n_steps=n_steps,\n",
    "        n_independent=n_indipendent\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.4431  | mse_mse: 0.55601 |  0:00:02s\n",
      "epoch 1  | loss: 0.27711 | mse_mse: 0.30228 |  0:00:04s\n",
      "epoch 2  | loss: 0.25628 | mse_mse: 0.27185 |  0:00:07s\n",
      "epoch 3  | loss: 0.24273 | mse_mse: 0.25033 |  0:00:09s\n",
      "epoch 4  | loss: 0.24211 | mse_mse: 0.25804 |  0:00:12s\n",
      "epoch 5  | loss: 0.24092 | mse_mse: 0.24931 |  0:00:15s\n",
      "epoch 6  | loss: 0.22846 | mse_mse: 0.22774 |  0:00:18s\n",
      "epoch 7  | loss: 0.21858 | mse_mse: 0.20714 |  0:00:21s\n",
      "epoch 8  | loss: 0.18961 | mse_mse: 0.15768 |  0:00:23s\n",
      "epoch 9  | loss: 0.14221 | mse_mse: 0.17193 |  0:00:26s\n",
      "epoch 10 | loss: 0.10433 | mse_mse: 0.08337 |  0:00:29s\n",
      "epoch 11 | loss: 0.0792  | mse_mse: 0.05475 |  0:00:32s\n",
      "epoch 12 | loss: 0.06385 | mse_mse: 0.04705 |  0:00:36s\n",
      "epoch 13 | loss: 0.05083 | mse_mse: 0.04002 |  0:00:38s\n",
      "epoch 14 | loss: 0.04332 | mse_mse: 0.04124 |  0:00:40s\n",
      "epoch 15 | loss: 0.04216 | mse_mse: 0.04099 |  0:00:43s\n",
      "epoch 16 | loss: 0.03664 | mse_mse: 0.02717 |  0:00:45s\n",
      "epoch 17 | loss: 0.02981 | mse_mse: 0.02608 |  0:00:47s\n",
      "epoch 18 | loss: 0.02754 | mse_mse: 0.02149 |  0:00:49s\n",
      "epoch 19 | loss: 0.02463 | mse_mse: 0.02448 |  0:00:52s\n",
      "epoch 20 | loss: 0.02306 | mse_mse: 0.01672 |  0:00:54s\n",
      "epoch 21 | loss: 0.01976 | mse_mse: 0.01929 |  0:00:56s\n",
      "epoch 22 | loss: 0.0192  | mse_mse: 0.01658 |  0:00:58s\n",
      "epoch 23 | loss: 0.02082 | mse_mse: 0.01594 |  0:01:00s\n",
      "epoch 24 | loss: 0.01818 | mse_mse: 0.01287 |  0:01:03s\n",
      "epoch 25 | loss: 0.01539 | mse_mse: 0.01294 |  0:01:05s\n",
      "epoch 26 | loss: 0.01757 | mse_mse: 0.01605 |  0:01:08s\n",
      "epoch 27 | loss: 0.01771 | mse_mse: 0.01129 |  0:01:10s\n",
      "epoch 28 | loss: 0.01832 | mse_mse: 0.01088 |  0:01:13s\n",
      "epoch 29 | loss: 0.01537 | mse_mse: 0.011   |  0:01:15s\n",
      "epoch 30 | loss: 0.0157  | mse_mse: 0.02037 |  0:01:17s\n",
      "epoch 31 | loss: 0.01652 | mse_mse: 0.01418 |  0:01:19s\n",
      "epoch 32 | loss: 0.01623 | mse_mse: 0.0239  |  0:01:22s\n",
      "epoch 33 | loss: 0.01578 | mse_mse: 0.01185 |  0:01:24s\n",
      "epoch 34 | loss: 0.01532 | mse_mse: 0.0095  |  0:01:26s\n",
      "epoch 35 | loss: 0.01452 | mse_mse: 0.01    |  0:01:28s\n",
      "epoch 36 | loss: 0.01541 | mse_mse: 0.01032 |  0:01:30s\n",
      "epoch 37 | loss: 0.01299 | mse_mse: 0.00959 |  0:01:32s\n",
      "epoch 38 | loss: 0.0115  | mse_mse: 0.00886 |  0:01:34s\n",
      "epoch 39 | loss: 0.01244 | mse_mse: 0.00944 |  0:01:36s\n",
      "epoch 40 | loss: 0.01177 | mse_mse: 0.00807 |  0:01:38s\n",
      "epoch 41 | loss: 0.01274 | mse_mse: 0.00912 |  0:01:40s\n",
      "epoch 42 | loss: 0.01125 | mse_mse: 0.00815 |  0:01:42s\n",
      "epoch 43 | loss: 0.01153 | mse_mse: 0.00849 |  0:01:45s\n",
      "epoch 44 | loss: 0.01202 | mse_mse: 0.01083 |  0:01:47s\n",
      "epoch 45 | loss: 0.01001 | mse_mse: 0.00791 |  0:01:49s\n",
      "epoch 46 | loss: 0.01328 | mse_mse: 0.00806 |  0:01:51s\n",
      "epoch 47 | loss: 0.01311 | mse_mse: 0.00974 |  0:01:53s\n",
      "epoch 48 | loss: 0.0116  | mse_mse: 0.0072  |  0:01:55s\n",
      "epoch 49 | loss: 0.01062 | mse_mse: 0.0167  |  0:01:57s\n",
      "epoch 50 | loss: 0.01059 | mse_mse: 0.00853 |  0:01:59s\n",
      "epoch 51 | loss: 0.01603 | mse_mse: 0.01055 |  0:02:01s\n",
      "epoch 52 | loss: 0.00969 | mse_mse: 0.00765 |  0:02:02s\n",
      "epoch 53 | loss: 0.01044 | mse_mse: 0.01687 |  0:02:04s\n",
      "epoch 54 | loss: 0.01003 | mse_mse: 0.00681 |  0:02:06s\n",
      "epoch 55 | loss: 0.00974 | mse_mse: 0.01366 |  0:02:07s\n",
      "epoch 56 | loss: 0.01123 | mse_mse: 0.00866 |  0:02:09s\n",
      "epoch 57 | loss: 0.01069 | mse_mse: 0.01255 |  0:02:10s\n",
      "epoch 58 | loss: 0.01129 | mse_mse: 0.01284 |  0:02:12s\n",
      "epoch 59 | loss: 0.01458 | mse_mse: 0.0076  |  0:02:14s\n",
      "epoch 60 | loss: 0.01086 | mse_mse: 0.01223 |  0:02:15s\n",
      "epoch 61 | loss: 0.01634 | mse_mse: 0.00899 |  0:02:17s\n",
      "epoch 62 | loss: 0.01463 | mse_mse: 0.00903 |  0:02:18s\n",
      "epoch 63 | loss: 0.011   | mse_mse: 0.00654 |  0:02:20s\n",
      "epoch 64 | loss: 0.00835 | mse_mse: 0.00894 |  0:02:21s\n",
      "epoch 65 | loss: 0.00931 | mse_mse: 0.01093 |  0:02:23s\n",
      "epoch 66 | loss: 0.00983 | mse_mse: 0.00679 |  0:02:24s\n",
      "epoch 67 | loss: 0.00991 | mse_mse: 0.00948 |  0:02:26s\n",
      "epoch 68 | loss: 0.01031 | mse_mse: 0.01015 |  0:02:28s\n",
      "epoch 69 | loss: 0.01226 | mse_mse: 0.00898 |  0:02:29s\n",
      "epoch 70 | loss: 0.00885 | mse_mse: 0.0112  |  0:02:31s\n",
      "epoch 71 | loss: 0.01148 | mse_mse: 0.00756 |  0:02:32s\n",
      "epoch 72 | loss: 0.01453 | mse_mse: 0.01609 |  0:02:34s\n",
      "epoch 73 | loss: 0.01142 | mse_mse: 0.00726 |  0:02:35s\n",
      "\n",
      "Early stopping occurred at epoch 73 with best_epoch = 63 and best_mse_mse = 0.00654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.006771515136360431\n",
      "R2 Score: 0.9694517324604843\n",
      "Best model updated\n",
      "\n",
      "Iteration 2/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.3774  | mse_mse: 0.93021 |  0:00:01s\n",
      "epoch 1  | loss: 0.27581 | mse_mse: 0.36664 |  0:00:03s\n",
      "epoch 2  | loss: 0.24918 | mse_mse: 0.2684  |  0:00:05s\n",
      "epoch 3  | loss: 0.23737 | mse_mse: 0.22004 |  0:00:06s\n",
      "epoch 4  | loss: 0.21728 | mse_mse: 0.12965 |  0:00:08s\n",
      "epoch 5  | loss: 0.15356 | mse_mse: 0.13874 |  0:00:10s\n",
      "epoch 6  | loss: 0.12247 | mse_mse: 0.08911 |  0:00:11s\n",
      "epoch 7  | loss: 0.10422 | mse_mse: 0.08297 |  0:00:13s\n",
      "epoch 8  | loss: 0.09717 | mse_mse: 0.08228 |  0:00:15s\n",
      "epoch 9  | loss: 0.09409 | mse_mse: 0.08214 |  0:00:16s\n",
      "epoch 10 | loss: 0.08817 | mse_mse: 0.08416 |  0:00:18s\n",
      "epoch 11 | loss: 0.08488 | mse_mse: 0.07654 |  0:00:20s\n",
      "epoch 12 | loss: 0.07718 | mse_mse: 0.05996 |  0:00:21s\n",
      "epoch 13 | loss: 0.06599 | mse_mse: 0.04921 |  0:00:23s\n",
      "epoch 14 | loss: 0.06009 | mse_mse: 0.0457  |  0:00:25s\n",
      "epoch 15 | loss: 0.05351 | mse_mse: 0.03634 |  0:00:26s\n",
      "epoch 16 | loss: 0.04458 | mse_mse: 0.03526 |  0:00:28s\n",
      "epoch 17 | loss: 0.03747 | mse_mse: 0.0423  |  0:00:30s\n",
      "epoch 18 | loss: 0.03773 | mse_mse: 0.03073 |  0:00:31s\n",
      "epoch 19 | loss: 0.03192 | mse_mse: 0.02992 |  0:00:33s\n",
      "epoch 20 | loss: 0.02785 | mse_mse: 0.02497 |  0:00:35s\n",
      "epoch 21 | loss: 0.02519 | mse_mse: 0.01892 |  0:00:37s\n",
      "epoch 22 | loss: 0.02471 | mse_mse: 0.0206  |  0:00:38s\n",
      "epoch 23 | loss: 0.02203 | mse_mse: 0.02408 |  0:00:40s\n",
      "epoch 24 | loss: 0.023   | mse_mse: 0.01833 |  0:00:42s\n",
      "epoch 25 | loss: 0.02338 | mse_mse: 0.02608 |  0:00:43s\n",
      "epoch 26 | loss: 0.02044 | mse_mse: 0.01493 |  0:00:45s\n",
      "epoch 27 | loss: 0.01607 | mse_mse: 0.01304 |  0:00:47s\n",
      "epoch 28 | loss: 0.01644 | mse_mse: 0.01211 |  0:00:48s\n",
      "epoch 29 | loss: 0.01569 | mse_mse: 0.01496 |  0:00:50s\n",
      "epoch 30 | loss: 0.01526 | mse_mse: 0.0215  |  0:00:52s\n",
      "epoch 31 | loss: 0.01644 | mse_mse: 0.01036 |  0:00:53s\n",
      "epoch 32 | loss: 0.01433 | mse_mse: 0.01098 |  0:00:55s\n",
      "epoch 33 | loss: 0.01504 | mse_mse: 0.01173 |  0:00:57s\n",
      "epoch 34 | loss: 0.01531 | mse_mse: 0.02083 |  0:00:58s\n",
      "epoch 35 | loss: 0.01559 | mse_mse: 0.01242 |  0:01:00s\n",
      "epoch 36 | loss: 0.01369 | mse_mse: 0.00999 |  0:01:02s\n",
      "epoch 37 | loss: 0.01425 | mse_mse: 0.01446 |  0:01:03s\n",
      "epoch 38 | loss: 0.01236 | mse_mse: 0.01257 |  0:01:05s\n",
      "epoch 39 | loss: 0.01286 | mse_mse: 0.0098  |  0:01:07s\n",
      "epoch 40 | loss: 0.01284 | mse_mse: 0.00899 |  0:01:08s\n",
      "epoch 41 | loss: 0.01321 | mse_mse: 0.01031 |  0:01:10s\n",
      "epoch 42 | loss: 0.01228 | mse_mse: 0.01388 |  0:01:12s\n",
      "epoch 43 | loss: 0.01186 | mse_mse: 0.00903 |  0:01:13s\n",
      "epoch 44 | loss: 0.01177 | mse_mse: 0.00906 |  0:01:15s\n",
      "epoch 45 | loss: 0.01111 | mse_mse: 0.01647 |  0:01:17s\n",
      "epoch 46 | loss: 0.0119  | mse_mse: 0.01486 |  0:01:18s\n",
      "epoch 47 | loss: 0.01175 | mse_mse: 0.00821 |  0:01:20s\n",
      "epoch 48 | loss: 0.0133  | mse_mse: 0.01164 |  0:01:22s\n",
      "epoch 49 | loss: 0.01119 | mse_mse: 0.01329 |  0:01:23s\n",
      "epoch 50 | loss: 0.01123 | mse_mse: 0.00822 |  0:01:25s\n",
      "epoch 51 | loss: 0.01306 | mse_mse: 0.01237 |  0:01:27s\n",
      "epoch 52 | loss: 0.01218 | mse_mse: 0.01527 |  0:01:28s\n",
      "epoch 53 | loss: 0.01111 | mse_mse: 0.01039 |  0:01:30s\n",
      "epoch 54 | loss: 0.01111 | mse_mse: 0.0088  |  0:01:32s\n",
      "epoch 55 | loss: 0.01078 | mse_mse: 0.0082  |  0:01:33s\n",
      "epoch 56 | loss: 0.01188 | mse_mse: 0.00796 |  0:01:35s\n",
      "epoch 57 | loss: 0.01158 | mse_mse: 0.01079 |  0:01:37s\n",
      "epoch 58 | loss: 0.01517 | mse_mse: 0.00889 |  0:01:38s\n",
      "epoch 59 | loss: 0.01449 | mse_mse: 0.00877 |  0:01:40s\n",
      "epoch 60 | loss: 0.01322 | mse_mse: 0.00978 |  0:01:42s\n",
      "epoch 61 | loss: 0.01196 | mse_mse: 0.00994 |  0:01:43s\n",
      "epoch 62 | loss: 0.0132  | mse_mse: 0.0079  |  0:01:45s\n",
      "epoch 63 | loss: 0.01155 | mse_mse: 0.01478 |  0:01:47s\n",
      "epoch 64 | loss: 0.0121  | mse_mse: 0.0087  |  0:01:48s\n",
      "epoch 65 | loss: 0.01199 | mse_mse: 0.00885 |  0:01:50s\n",
      "epoch 66 | loss: 0.01118 | mse_mse: 0.00968 |  0:01:52s\n",
      "epoch 67 | loss: 0.01087 | mse_mse: 0.00733 |  0:01:53s\n",
      "epoch 68 | loss: 0.00888 | mse_mse: 0.01133 |  0:01:55s\n",
      "epoch 69 | loss: 0.00977 | mse_mse: 0.01914 |  0:01:57s\n",
      "epoch 70 | loss: 0.01228 | mse_mse: 0.01279 |  0:01:58s\n",
      "epoch 71 | loss: 0.01243 | mse_mse: 0.00783 |  0:02:00s\n",
      "epoch 72 | loss: 0.01121 | mse_mse: 0.01089 |  0:02:02s\n",
      "epoch 73 | loss: 0.01153 | mse_mse: 0.01689 |  0:02:04s\n",
      "epoch 74 | loss: 0.01119 | mse_mse: 0.01465 |  0:02:05s\n",
      "epoch 75 | loss: 0.0104  | mse_mse: 0.00954 |  0:02:07s\n",
      "epoch 76 | loss: 0.01006 | mse_mse: 0.00769 |  0:02:09s\n",
      "epoch 77 | loss: 0.01116 | mse_mse: 0.00875 |  0:02:10s\n",
      "\n",
      "Early stopping occurred at epoch 77 with best_epoch = 67 and best_mse_mse = 0.00733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0076932412188899\n",
      "R2 Score: 0.9652935589350252\n",
      "\n",
      "Iteration 3/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.3653  | mse_mse: 0.41277 |  0:00:02s\n",
      "epoch 1  | loss: 0.33816 | mse_mse: 0.4186  |  0:00:04s\n",
      "epoch 2  | loss: 0.28204 | mse_mse: 0.29882 |  0:00:07s\n",
      "epoch 3  | loss: 0.27009 | mse_mse: 0.3749  |  0:00:09s\n",
      "epoch 4  | loss: 0.24477 | mse_mse: 0.23377 |  0:00:12s\n",
      "epoch 5  | loss: 0.24383 | mse_mse: 0.24872 |  0:00:14s\n",
      "epoch 6  | loss: 0.24254 | mse_mse: 0.23071 |  0:00:17s\n",
      "epoch 7  | loss: 0.23909 | mse_mse: 0.23684 |  0:00:19s\n",
      "epoch 8  | loss: 0.23834 | mse_mse: 0.24294 |  0:00:22s\n",
      "epoch 9  | loss: 0.23968 | mse_mse: 0.25169 |  0:00:24s\n",
      "epoch 10 | loss: 0.23102 | mse_mse: 0.21459 |  0:00:26s\n",
      "epoch 11 | loss: 0.24082 | mse_mse: 0.21927 |  0:00:29s\n",
      "epoch 12 | loss: 0.23194 | mse_mse: 0.22464 |  0:00:31s\n",
      "epoch 13 | loss: 0.23303 | mse_mse: 0.21701 |  0:00:34s\n",
      "epoch 14 | loss: 0.23086 | mse_mse: 0.21519 |  0:00:36s\n",
      "epoch 15 | loss: 0.22861 | mse_mse: 0.2108  |  0:00:39s\n",
      "epoch 16 | loss: 0.22675 | mse_mse: 0.21272 |  0:00:41s\n",
      "epoch 17 | loss: 0.22788 | mse_mse: 0.21703 |  0:00:44s\n",
      "epoch 18 | loss: 0.22822 | mse_mse: 0.21947 |  0:00:46s\n",
      "epoch 19 | loss: 0.23285 | mse_mse: 0.20914 |  0:00:49s\n",
      "epoch 20 | loss: 0.22717 | mse_mse: 0.21479 |  0:00:51s\n",
      "epoch 21 | loss: 0.22338 | mse_mse: 0.21101 |  0:00:54s\n",
      "epoch 22 | loss: 0.2253  | mse_mse: 0.20807 |  0:00:56s\n",
      "epoch 23 | loss: 0.22225 | mse_mse: 0.20871 |  0:00:59s\n",
      "epoch 24 | loss: 0.22084 | mse_mse: 0.2055  |  0:01:01s\n",
      "epoch 25 | loss: 0.21522 | mse_mse: 0.19567 |  0:01:04s\n",
      "epoch 26 | loss: 0.20354 | mse_mse: 0.18502 |  0:01:06s\n",
      "epoch 27 | loss: 0.18717 | mse_mse: 0.16837 |  0:01:09s\n",
      "epoch 28 | loss: 0.16162 | mse_mse: 0.15816 |  0:01:11s\n",
      "epoch 29 | loss: 0.14298 | mse_mse: 0.12599 |  0:01:13s\n",
      "epoch 30 | loss: 0.1327  | mse_mse: 0.12064 |  0:01:16s\n",
      "epoch 31 | loss: 0.1272  | mse_mse: 0.10434 |  0:01:18s\n",
      "epoch 32 | loss: 0.11158 | mse_mse: 0.0893  |  0:01:21s\n",
      "epoch 33 | loss: 0.09721 | mse_mse: 0.08539 |  0:01:24s\n",
      "epoch 34 | loss: 0.08906 | mse_mse: 0.08316 |  0:01:26s\n",
      "epoch 35 | loss: 0.08387 | mse_mse: 0.0716  |  0:01:29s\n",
      "epoch 36 | loss: 0.07034 | mse_mse: 0.05419 |  0:01:31s\n",
      "epoch 37 | loss: 0.05832 | mse_mse: 0.05562 |  0:01:33s\n",
      "epoch 38 | loss: 0.05316 | mse_mse: 0.04359 |  0:01:36s\n",
      "epoch 39 | loss: 0.05136 | mse_mse: 0.04024 |  0:01:38s\n",
      "epoch 40 | loss: 0.04212 | mse_mse: 0.05707 |  0:01:41s\n",
      "epoch 41 | loss: 0.03726 | mse_mse: 0.03311 |  0:01:43s\n",
      "epoch 42 | loss: 0.0385  | mse_mse: 0.03171 |  0:01:46s\n",
      "epoch 43 | loss: 0.03309 | mse_mse: 0.02427 |  0:01:48s\n",
      "epoch 44 | loss: 0.03619 | mse_mse: 0.03006 |  0:01:51s\n",
      "epoch 45 | loss: 0.02672 | mse_mse: 0.01993 |  0:01:53s\n",
      "epoch 46 | loss: 0.02846 | mse_mse: 0.02352 |  0:01:56s\n",
      "epoch 47 | loss: 0.02456 | mse_mse: 0.02615 |  0:01:58s\n",
      "epoch 48 | loss: 0.02371 | mse_mse: 0.01956 |  0:02:01s\n",
      "epoch 49 | loss: 0.02237 | mse_mse: 0.01779 |  0:02:03s\n",
      "epoch 50 | loss: 0.02156 | mse_mse: 0.02342 |  0:02:06s\n",
      "epoch 51 | loss: 0.02221 | mse_mse: 0.01713 |  0:02:08s\n",
      "epoch 52 | loss: 0.02331 | mse_mse: 0.03883 |  0:02:10s\n",
      "epoch 53 | loss: 0.02242 | mse_mse: 0.01708 |  0:02:13s\n",
      "epoch 54 | loss: 0.01966 | mse_mse: 0.01537 |  0:02:15s\n",
      "epoch 55 | loss: 0.01608 | mse_mse: 0.01398 |  0:02:18s\n",
      "epoch 56 | loss: 0.01679 | mse_mse: 0.01519 |  0:02:20s\n",
      "epoch 57 | loss: 0.0171  | mse_mse: 0.01928 |  0:02:23s\n",
      "epoch 58 | loss: 0.01432 | mse_mse: 0.01201 |  0:02:25s\n",
      "epoch 59 | loss: 0.01802 | mse_mse: 0.01696 |  0:02:28s\n",
      "epoch 60 | loss: 0.01921 | mse_mse: 0.01937 |  0:02:30s\n",
      "epoch 61 | loss: 0.01633 | mse_mse: 0.01137 |  0:02:33s\n",
      "epoch 62 | loss: 0.01359 | mse_mse: 0.01572 |  0:02:35s\n",
      "epoch 63 | loss: 0.01544 | mse_mse: 0.01003 |  0:02:38s\n",
      "epoch 64 | loss: 0.0162  | mse_mse: 0.00889 |  0:02:40s\n",
      "epoch 65 | loss: 0.01329 | mse_mse: 0.00879 |  0:02:42s\n",
      "epoch 66 | loss: 0.01245 | mse_mse: 0.01153 |  0:02:45s\n",
      "epoch 67 | loss: 0.01498 | mse_mse: 0.01459 |  0:02:47s\n",
      "epoch 68 | loss: 0.0156  | mse_mse: 0.00824 |  0:02:50s\n",
      "epoch 69 | loss: 0.01285 | mse_mse: 0.01786 |  0:02:53s\n",
      "epoch 70 | loss: 0.01313 | mse_mse: 0.01898 |  0:02:55s\n",
      "epoch 71 | loss: 0.01255 | mse_mse: 0.00943 |  0:02:58s\n",
      "epoch 72 | loss: 0.01355 | mse_mse: 0.0095  |  0:03:00s\n",
      "epoch 73 | loss: 0.01434 | mse_mse: 0.01172 |  0:03:03s\n",
      "epoch 74 | loss: 0.01112 | mse_mse: 0.00838 |  0:03:05s\n",
      "epoch 75 | loss: 0.01354 | mse_mse: 0.00942 |  0:03:07s\n",
      "epoch 76 | loss: 0.01157 | mse_mse: 0.01269 |  0:03:10s\n",
      "epoch 77 | loss: 0.01395 | mse_mse: 0.01355 |  0:03:12s\n",
      "epoch 78 | loss: 0.0129  | mse_mse: 0.01767 |  0:03:15s\n",
      "\n",
      "Early stopping occurred at epoch 78 with best_epoch = 68 and best_mse_mse = 0.00824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00833500477664977\n",
      "R2 Score: 0.9623983775074167\n",
      "\n",
      "Iteration 4/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.68756 | mse_mse: 0.49262 |  0:00:02s\n",
      "epoch 1  | loss: 0.35584 | mse_mse: 0.24281 |  0:00:05s\n",
      "epoch 2  | loss: 0.28611 | mse_mse: 0.32523 |  0:00:07s\n",
      "epoch 3  | loss: 0.25788 | mse_mse: 0.27594 |  0:00:10s\n",
      "epoch 4  | loss: 0.24503 | mse_mse: 0.2527  |  0:00:13s\n",
      "epoch 5  | loss: 0.24352 | mse_mse: 0.25462 |  0:00:15s\n",
      "epoch 6  | loss: 0.23675 | mse_mse: 0.23376 |  0:00:18s\n",
      "epoch 7  | loss: 0.23167 | mse_mse: 0.2721  |  0:00:20s\n",
      "epoch 8  | loss: 0.23291 | mse_mse: 0.25551 |  0:00:23s\n",
      "epoch 9  | loss: 0.23355 | mse_mse: 0.22871 |  0:00:26s\n",
      "epoch 10 | loss: 0.23138 | mse_mse: 0.22835 |  0:00:28s\n",
      "epoch 11 | loss: 0.22593 | mse_mse: 0.2181  |  0:00:31s\n",
      "epoch 12 | loss: 0.21847 | mse_mse: 0.21907 |  0:00:34s\n",
      "epoch 13 | loss: 0.21536 | mse_mse: 0.19523 |  0:00:36s\n",
      "epoch 14 | loss: 0.20574 | mse_mse: 0.17323 |  0:00:39s\n",
      "epoch 15 | loss: 0.19394 | mse_mse: 0.15916 |  0:00:41s\n",
      "epoch 16 | loss: 0.17893 | mse_mse: 0.14519 |  0:00:44s\n",
      "epoch 17 | loss: 0.15921 | mse_mse: 0.12681 |  0:00:47s\n",
      "epoch 18 | loss: 0.1329  | mse_mse: 0.1159  |  0:00:49s\n",
      "epoch 19 | loss: 0.11375 | mse_mse: 0.08509 |  0:00:52s\n",
      "epoch 20 | loss: 0.08624 | mse_mse: 0.07022 |  0:00:55s\n",
      "epoch 21 | loss: 0.0678  | mse_mse: 0.06195 |  0:00:57s\n",
      "epoch 22 | loss: 0.0582  | mse_mse: 0.04937 |  0:01:00s\n",
      "epoch 23 | loss: 0.05205 | mse_mse: 0.04313 |  0:01:03s\n",
      "epoch 24 | loss: 0.04299 | mse_mse: 0.03649 |  0:01:05s\n",
      "epoch 25 | loss: 0.03728 | mse_mse: 0.04307 |  0:01:08s\n",
      "epoch 26 | loss: 0.03414 | mse_mse: 0.02769 |  0:01:11s\n",
      "epoch 27 | loss: 0.02875 | mse_mse: 0.02672 |  0:01:13s\n",
      "epoch 28 | loss: 0.02694 | mse_mse: 0.02077 |  0:01:16s\n",
      "epoch 29 | loss: 0.02374 | mse_mse: 0.01849 |  0:01:18s\n",
      "epoch 30 | loss: 0.0302  | mse_mse: 0.01772 |  0:01:21s\n",
      "epoch 31 | loss: 0.02193 | mse_mse: 0.01638 |  0:01:24s\n",
      "epoch 32 | loss: 0.01956 | mse_mse: 0.01753 |  0:01:26s\n",
      "epoch 33 | loss: 0.01903 | mse_mse: 0.02239 |  0:01:29s\n",
      "epoch 34 | loss: 0.0206  | mse_mse: 0.01498 |  0:01:32s\n",
      "epoch 35 | loss: 0.01669 | mse_mse: 0.01477 |  0:01:34s\n",
      "epoch 36 | loss: 0.01846 | mse_mse: 0.02216 |  0:01:37s\n",
      "epoch 37 | loss: 0.01733 | mse_mse: 0.01136 |  0:01:39s\n",
      "epoch 38 | loss: 0.01471 | mse_mse: 0.0131  |  0:01:42s\n",
      "epoch 39 | loss: 0.02156 | mse_mse: 0.01446 |  0:01:45s\n",
      "epoch 40 | loss: 0.02813 | mse_mse: 0.0219  |  0:01:47s\n",
      "epoch 41 | loss: 0.02139 | mse_mse: 0.01501 |  0:01:50s\n",
      "epoch 42 | loss: 0.02126 | mse_mse: 0.02084 |  0:01:52s\n",
      "epoch 43 | loss: 0.02326 | mse_mse: 0.06532 |  0:01:55s\n",
      "epoch 44 | loss: 0.01872 | mse_mse: 0.01322 |  0:01:58s\n",
      "epoch 45 | loss: 0.01812 | mse_mse: 0.02946 |  0:02:00s\n",
      "epoch 46 | loss: 0.017   | mse_mse: 0.01631 |  0:02:03s\n",
      "epoch 47 | loss: 0.01575 | mse_mse: 0.01158 |  0:02:05s\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 37 and best_mse_mse = 0.01136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.011748884304374997\n",
      "R2 Score: 0.9469973774268531\n",
      "\n",
      "Iteration 5/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.84151 | mse_mse: 0.64703 |  0:00:03s\n",
      "epoch 1  | loss: 0.39329 | mse_mse: 0.37367 |  0:00:06s\n",
      "epoch 2  | loss: 0.32088 | mse_mse: 0.41621 |  0:00:10s\n",
      "epoch 3  | loss: 0.3508  | mse_mse: 0.22397 |  0:00:13s\n",
      "epoch 4  | loss: 0.27118 | mse_mse: 0.23577 |  0:00:16s\n",
      "epoch 5  | loss: 0.28777 | mse_mse: 0.27565 |  0:00:20s\n",
      "epoch 6  | loss: 0.21489 | mse_mse: 0.15379 |  0:00:23s\n",
      "epoch 7  | loss: 0.14579 | mse_mse: 0.12621 |  0:00:26s\n",
      "epoch 8  | loss: 0.13254 | mse_mse: 0.10984 |  0:00:30s\n",
      "epoch 9  | loss: 0.12919 | mse_mse: 0.11127 |  0:00:33s\n",
      "epoch 10 | loss: 0.11862 | mse_mse: 0.09701 |  0:00:36s\n",
      "epoch 11 | loss: 0.11745 | mse_mse: 0.10784 |  0:00:40s\n",
      "epoch 12 | loss: 0.11581 | mse_mse: 0.09257 |  0:00:43s\n",
      "epoch 13 | loss: 0.11128 | mse_mse: 0.0958  |  0:00:46s\n",
      "epoch 14 | loss: 0.10955 | mse_mse: 0.0896  |  0:00:50s\n",
      "epoch 15 | loss: 0.10954 | mse_mse: 0.10972 |  0:00:54s\n",
      "epoch 16 | loss: 0.1153  | mse_mse: 0.08802 |  0:00:58s\n",
      "epoch 17 | loss: 0.10817 | mse_mse: 0.08656 |  0:01:02s\n",
      "epoch 18 | loss: 0.11051 | mse_mse: 0.08731 |  0:01:07s\n",
      "epoch 19 | loss: 0.10604 | mse_mse: 0.08905 |  0:01:11s\n",
      "epoch 20 | loss: 0.10697 | mse_mse: 0.08608 |  0:01:15s\n",
      "epoch 21 | loss: 0.10772 | mse_mse: 0.09389 |  0:01:20s\n",
      "epoch 22 | loss: 0.10589 | mse_mse: 0.08702 |  0:01:24s\n",
      "epoch 23 | loss: 0.10571 | mse_mse: 0.08894 |  0:01:28s\n",
      "epoch 24 | loss: 0.11128 | mse_mse: 0.09515 |  0:01:32s\n",
      "epoch 25 | loss: 0.11768 | mse_mse: 0.09638 |  0:01:37s\n",
      "epoch 26 | loss: 0.10542 | mse_mse: 0.08784 |  0:01:41s\n",
      "epoch 27 | loss: 0.10813 | mse_mse: 0.08484 |  0:01:45s\n",
      "epoch 28 | loss: 0.10699 | mse_mse: 0.08816 |  0:01:49s\n",
      "epoch 29 | loss: 0.107   | mse_mse: 0.08763 |  0:01:54s\n",
      "epoch 30 | loss: 0.10391 | mse_mse: 0.09772 |  0:01:58s\n",
      "epoch 31 | loss: 0.10805 | mse_mse: 0.08826 |  0:02:03s\n",
      "epoch 32 | loss: 0.10524 | mse_mse: 0.08922 |  0:02:07s\n",
      "epoch 33 | loss: 0.10543 | mse_mse: 0.08701 |  0:02:11s\n",
      "epoch 34 | loss: 0.10353 | mse_mse: 0.08601 |  0:02:15s\n",
      "epoch 35 | loss: 0.10478 | mse_mse: 0.08443 |  0:02:19s\n",
      "epoch 36 | loss: 0.10535 | mse_mse: 0.08166 |  0:02:24s\n",
      "epoch 37 | loss: 0.1044  | mse_mse: 0.08723 |  0:02:28s\n",
      "epoch 38 | loss: 0.10238 | mse_mse: 0.10957 |  0:02:32s\n",
      "epoch 39 | loss: 0.10306 | mse_mse: 0.08857 |  0:02:36s\n",
      "epoch 40 | loss: 0.10473 | mse_mse: 0.08771 |  0:02:41s\n",
      "epoch 41 | loss: 0.10441 | mse_mse: 0.08342 |  0:02:45s\n",
      "epoch 42 | loss: 0.10164 | mse_mse: 0.08484 |  0:02:51s\n",
      "epoch 43 | loss: 0.10244 | mse_mse: 0.08578 |  0:02:56s\n",
      "epoch 44 | loss: 0.10211 | mse_mse: 0.08423 |  0:03:04s\n",
      "epoch 45 | loss: 0.10785 | mse_mse: 0.10152 |  0:03:08s\n",
      "epoch 46 | loss: 0.10558 | mse_mse: 0.08879 |  0:03:11s\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_mse_mse = 0.08166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.08988147962925677\n",
      "R2 Score: 0.5945185927712718\n",
      "\n",
      "Iteration 6/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.84121 | mse_mse: 1.96808 |  0:00:03s\n",
      "epoch 1  | loss: 0.36666 | mse_mse: 0.39113 |  0:00:07s\n",
      "epoch 2  | loss: 0.28822 | mse_mse: 0.22799 |  0:00:11s\n",
      "epoch 3  | loss: 0.31845 | mse_mse: 0.22721 |  0:00:14s\n",
      "epoch 4  | loss: 0.27659 | mse_mse: 0.23067 |  0:00:18s\n",
      "epoch 5  | loss: 0.28025 | mse_mse: 0.38331 |  0:00:22s\n",
      "epoch 6  | loss: 0.27161 | mse_mse: 0.28456 |  0:00:25s\n",
      "epoch 7  | loss: 0.25513 | mse_mse: 0.2384  |  0:00:29s\n",
      "epoch 8  | loss: 0.24594 | mse_mse: 0.25222 |  0:00:33s\n",
      "epoch 9  | loss: 0.2411  | mse_mse: 0.22868 |  0:00:36s\n",
      "epoch 10 | loss: 0.24344 | mse_mse: 0.22248 |  0:00:40s\n",
      "epoch 11 | loss: 0.23725 | mse_mse: 0.23067 |  0:00:44s\n",
      "epoch 12 | loss: 0.23567 | mse_mse: 0.23546 |  0:00:47s\n",
      "epoch 13 | loss: 0.23167 | mse_mse: 0.21693 |  0:00:51s\n",
      "epoch 14 | loss: 0.23354 | mse_mse: 0.24141 |  0:00:55s\n",
      "epoch 15 | loss: 0.24424 | mse_mse: 0.21626 |  0:00:58s\n",
      "epoch 16 | loss: 0.23825 | mse_mse: 0.21787 |  0:01:02s\n",
      "epoch 17 | loss: 0.23814 | mse_mse: 0.22473 |  0:01:06s\n",
      "epoch 18 | loss: 0.23223 | mse_mse: 0.22364 |  0:01:09s\n",
      "epoch 19 | loss: 0.23049 | mse_mse: 0.22311 |  0:01:13s\n",
      "epoch 20 | loss: 0.24667 | mse_mse: 0.22406 |  0:01:17s\n",
      "epoch 21 | loss: 0.25442 | mse_mse: 0.22733 |  0:01:21s\n",
      "epoch 22 | loss: 0.22709 | mse_mse: 0.21506 |  0:01:24s\n",
      "epoch 23 | loss: 0.22343 | mse_mse: 0.20842 |  0:01:28s\n",
      "epoch 24 | loss: 0.2186  | mse_mse: 0.19461 |  0:01:32s\n",
      "epoch 25 | loss: 0.19748 | mse_mse: 0.17332 |  0:01:36s\n",
      "epoch 26 | loss: 0.17107 | mse_mse: 0.16285 |  0:01:39s\n",
      "epoch 27 | loss: 0.15018 | mse_mse: 0.1252  |  0:01:43s\n",
      "epoch 28 | loss: 0.13005 | mse_mse: 0.10804 |  0:01:47s\n",
      "epoch 29 | loss: 0.11437 | mse_mse: 0.0941  |  0:01:50s\n",
      "epoch 30 | loss: 0.09943 | mse_mse: 0.08208 |  0:01:54s\n",
      "epoch 31 | loss: 0.08423 | mse_mse: 0.07524 |  0:01:58s\n",
      "epoch 32 | loss: 0.07175 | mse_mse: 0.06009 |  0:02:01s\n",
      "epoch 33 | loss: 0.06624 | mse_mse: 0.05191 |  0:02:05s\n",
      "epoch 34 | loss: 0.05469 | mse_mse: 0.04808 |  0:02:09s\n",
      "epoch 35 | loss: 0.05304 | mse_mse: 0.03811 |  0:02:13s\n",
      "epoch 36 | loss: 0.04311 | mse_mse: 0.04105 |  0:02:16s\n",
      "epoch 37 | loss: 0.0417  | mse_mse: 0.03147 |  0:02:20s\n",
      "epoch 38 | loss: 0.03663 | mse_mse: 0.02953 |  0:02:24s\n",
      "epoch 39 | loss: 0.03363 | mse_mse: 0.02514 |  0:02:27s\n",
      "epoch 40 | loss: 0.04    | mse_mse: 0.02825 |  0:02:31s\n",
      "epoch 41 | loss: 0.03321 | mse_mse: 0.02953 |  0:02:35s\n",
      "epoch 42 | loss: 0.0322  | mse_mse: 0.02587 |  0:02:39s\n",
      "epoch 43 | loss: 0.02752 | mse_mse: 0.02412 |  0:02:42s\n",
      "epoch 44 | loss: 0.02519 | mse_mse: 0.01924 |  0:02:46s\n",
      "epoch 45 | loss: 0.02542 | mse_mse: 0.01818 |  0:02:49s\n",
      "epoch 46 | loss: 0.02331 | mse_mse: 0.0327  |  0:02:53s\n",
      "epoch 47 | loss: 0.0226  | mse_mse: 0.0221  |  0:02:56s\n",
      "epoch 48 | loss: 0.01963 | mse_mse: 0.0189  |  0:03:00s\n",
      "epoch 49 | loss: 0.02467 | mse_mse: 0.01701 |  0:03:04s\n",
      "epoch 50 | loss: 0.02249 | mse_mse: 0.02031 |  0:03:07s\n",
      "epoch 51 | loss: 0.02138 | mse_mse: 0.02716 |  0:03:11s\n",
      "epoch 52 | loss: 0.02067 | mse_mse: 0.02203 |  0:03:14s\n",
      "epoch 53 | loss: 0.01793 | mse_mse: 0.01431 |  0:03:18s\n",
      "epoch 54 | loss: 0.02516 | mse_mse: 0.01612 |  0:03:22s\n",
      "epoch 55 | loss: 0.01786 | mse_mse: 0.015   |  0:03:25s\n",
      "epoch 56 | loss: 0.01743 | mse_mse: 0.01648 |  0:03:29s\n",
      "epoch 57 | loss: 0.01561 | mse_mse: 0.01018 |  0:03:33s\n",
      "epoch 58 | loss: 0.01375 | mse_mse: 0.01415 |  0:03:36s\n",
      "epoch 59 | loss: 0.01568 | mse_mse: 0.01023 |  0:03:40s\n",
      "epoch 60 | loss: 0.01665 | mse_mse: 0.01292 |  0:03:43s\n",
      "epoch 61 | loss: 0.0275  | mse_mse: 0.0129  |  0:03:47s\n",
      "epoch 62 | loss: 0.01512 | mse_mse: 0.01877 |  0:03:51s\n",
      "epoch 63 | loss: 0.01295 | mse_mse: 0.0139  |  0:03:54s\n",
      "epoch 64 | loss: 0.01507 | mse_mse: 0.00912 |  0:03:58s\n",
      "epoch 65 | loss: 0.01332 | mse_mse: 0.00806 |  0:04:01s\n",
      "epoch 66 | loss: 0.01281 | mse_mse: 0.01451 |  0:04:05s\n",
      "epoch 67 | loss: 0.0157  | mse_mse: 0.00929 |  0:04:09s\n",
      "epoch 68 | loss: 0.01474 | mse_mse: 0.03291 |  0:04:12s\n",
      "epoch 69 | loss: 0.02205 | mse_mse: 0.01576 |  0:04:16s\n",
      "epoch 70 | loss: 0.02002 | mse_mse: 0.01466 |  0:04:20s\n",
      "epoch 71 | loss: 0.02388 | mse_mse: 0.02672 |  0:04:23s\n",
      "epoch 72 | loss: 0.0192  | mse_mse: 0.01683 |  0:04:27s\n",
      "epoch 73 | loss: 0.02473 | mse_mse: 0.02911 |  0:04:31s\n",
      "epoch 74 | loss: 0.02191 | mse_mse: 0.01818 |  0:04:34s\n",
      "epoch 75 | loss: 0.01709 | mse_mse: 0.02237 |  0:04:38s\n",
      "\n",
      "Early stopping occurred at epoch 75 with best_epoch = 65 and best_mse_mse = 0.00806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008025043851761065\n",
      "R2 Score: 0.9637967010833994\n",
      "\n",
      "Iteration 7/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.96836 | mse_mse: 1.08126 |  0:00:01s\n",
      "epoch 1  | loss: 0.29789 | mse_mse: 0.416   |  0:00:03s\n",
      "epoch 2  | loss: 0.25904 | mse_mse: 0.28831 |  0:00:05s\n",
      "epoch 3  | loss: 0.24693 | mse_mse: 0.24897 |  0:00:07s\n",
      "epoch 4  | loss: 0.24685 | mse_mse: 0.24639 |  0:00:09s\n",
      "epoch 5  | loss: 0.23952 | mse_mse: 0.25117 |  0:00:11s\n",
      "epoch 6  | loss: 0.24171 | mse_mse: 0.2254  |  0:00:13s\n",
      "epoch 7  | loss: 0.23255 | mse_mse: 0.23167 |  0:00:15s\n",
      "epoch 8  | loss: 0.18584 | mse_mse: 0.17763 |  0:00:16s\n",
      "epoch 9  | loss: 0.13007 | mse_mse: 0.12669 |  0:00:18s\n",
      "epoch 10 | loss: 0.10016 | mse_mse: 0.08998 |  0:00:20s\n",
      "epoch 11 | loss: 0.08352 | mse_mse: 0.05593 |  0:00:22s\n",
      "epoch 12 | loss: 0.06508 | mse_mse: 0.05006 |  0:00:24s\n",
      "epoch 13 | loss: 0.05381 | mse_mse: 0.03922 |  0:00:26s\n",
      "epoch 14 | loss: 0.05112 | mse_mse: 0.03729 |  0:00:28s\n",
      "epoch 15 | loss: 0.03876 | mse_mse: 0.03207 |  0:00:30s\n",
      "epoch 16 | loss: 0.0364  | mse_mse: 0.03028 |  0:00:32s\n",
      "epoch 17 | loss: 0.03377 | mse_mse: 0.0282  |  0:00:33s\n",
      "epoch 18 | loss: 0.03225 | mse_mse: 0.03003 |  0:00:35s\n",
      "epoch 19 | loss: 0.03123 | mse_mse: 0.03189 |  0:00:37s\n",
      "epoch 20 | loss: 0.02729 | mse_mse: 0.02218 |  0:00:39s\n",
      "epoch 21 | loss: 0.02081 | mse_mse: 0.01825 |  0:00:41s\n",
      "epoch 22 | loss: 0.0203  | mse_mse: 0.01867 |  0:00:43s\n",
      "epoch 23 | loss: 0.01909 | mse_mse: 0.0204  |  0:00:45s\n",
      "epoch 24 | loss: 0.02035 | mse_mse: 0.01503 |  0:00:47s\n",
      "epoch 25 | loss: 0.01945 | mse_mse: 0.02181 |  0:00:49s\n",
      "epoch 26 | loss: 0.01875 | mse_mse: 0.01658 |  0:00:51s\n",
      "epoch 27 | loss: 0.018   | mse_mse: 0.012   |  0:00:53s\n",
      "epoch 28 | loss: 0.0142  | mse_mse: 0.01195 |  0:00:54s\n",
      "epoch 29 | loss: 0.01498 | mse_mse: 0.01536 |  0:00:56s\n",
      "epoch 30 | loss: 0.01423 | mse_mse: 0.01722 |  0:00:58s\n",
      "epoch 31 | loss: 0.01409 | mse_mse: 0.02542 |  0:01:00s\n",
      "epoch 32 | loss: 0.01559 | mse_mse: 0.01403 |  0:01:02s\n",
      "epoch 33 | loss: 0.0191  | mse_mse: 0.02567 |  0:01:04s\n",
      "epoch 34 | loss: 0.01758 | mse_mse: 0.01254 |  0:01:06s\n",
      "epoch 35 | loss: 0.01244 | mse_mse: 0.00913 |  0:01:08s\n",
      "epoch 36 | loss: 0.01289 | mse_mse: 0.01089 |  0:01:10s\n",
      "epoch 37 | loss: 0.01186 | mse_mse: 0.01156 |  0:01:12s\n",
      "epoch 38 | loss: 0.01308 | mse_mse: 0.0089  |  0:01:13s\n",
      "epoch 39 | loss: 0.01103 | mse_mse: 0.00848 |  0:01:15s\n",
      "epoch 40 | loss: 0.01258 | mse_mse: 0.00793 |  0:01:17s\n",
      "epoch 41 | loss: 0.01143 | mse_mse: 0.00991 |  0:01:19s\n",
      "epoch 42 | loss: 0.01104 | mse_mse: 0.00821 |  0:01:21s\n",
      "epoch 43 | loss: 0.01263 | mse_mse: 0.00894 |  0:01:23s\n",
      "epoch 44 | loss: 0.01239 | mse_mse: 0.00888 |  0:01:25s\n",
      "epoch 45 | loss: 0.01153 | mse_mse: 0.00788 |  0:01:27s\n",
      "epoch 46 | loss: 0.01405 | mse_mse: 0.01221 |  0:01:29s\n",
      "epoch 47 | loss: 0.01164 | mse_mse: 0.01228 |  0:01:30s\n",
      "epoch 48 | loss: 0.01066 | mse_mse: 0.01186 |  0:01:32s\n",
      "epoch 49 | loss: 0.01273 | mse_mse: 0.00788 |  0:01:34s\n",
      "epoch 50 | loss: 0.01289 | mse_mse: 0.00895 |  0:01:36s\n",
      "epoch 51 | loss: 0.0095  | mse_mse: 0.01341 |  0:01:38s\n",
      "epoch 52 | loss: 0.01379 | mse_mse: 0.00909 |  0:01:40s\n",
      "epoch 53 | loss: 0.01199 | mse_mse: 0.00676 |  0:01:42s\n",
      "epoch 54 | loss: 0.01004 | mse_mse: 0.00671 |  0:01:44s\n",
      "epoch 55 | loss: 0.01148 | mse_mse: 0.00772 |  0:01:46s\n",
      "epoch 56 | loss: 0.00992 | mse_mse: 0.00715 |  0:01:48s\n",
      "epoch 57 | loss: 0.01159 | mse_mse: 0.01085 |  0:01:49s\n",
      "epoch 58 | loss: 0.01005 | mse_mse: 0.0071  |  0:01:51s\n",
      "epoch 59 | loss: 0.01271 | mse_mse: 0.02106 |  0:01:53s\n",
      "epoch 60 | loss: 0.01278 | mse_mse: 0.013   |  0:01:55s\n",
      "epoch 61 | loss: 0.01058 | mse_mse: 0.01058 |  0:01:57s\n",
      "epoch 62 | loss: 0.00895 | mse_mse: 0.00764 |  0:01:59s\n",
      "epoch 63 | loss: 0.00999 | mse_mse: 0.00694 |  0:02:01s\n",
      "epoch 64 | loss: 0.00956 | mse_mse: 0.01729 |  0:02:03s\n",
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 54 and best_mse_mse = 0.00671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.006645834471059633\n",
      "R2 Score: 0.9700187143708603\n",
      "Best model updated\n",
      "\n",
      "Iteration 8/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.43197 | mse_mse: 0.58448 |  0:00:02s\n",
      "epoch 1  | loss: 0.28462 | mse_mse: 0.28109 |  0:00:04s\n",
      "epoch 2  | loss: 0.17398 | mse_mse: 0.09859 |  0:00:06s\n",
      "epoch 3  | loss: 0.13013 | mse_mse: 0.08772 |  0:00:08s\n",
      "epoch 4  | loss: 0.11938 | mse_mse: 0.08445 |  0:00:10s\n",
      "epoch 5  | loss: 0.11034 | mse_mse: 0.0879  |  0:00:12s\n",
      "epoch 6  | loss: 0.10225 | mse_mse: 0.08798 |  0:00:14s\n",
      "epoch 7  | loss: 0.09538 | mse_mse: 0.07651 |  0:00:16s\n",
      "epoch 8  | loss: 0.09292 | mse_mse: 0.07094 |  0:00:18s\n",
      "epoch 9  | loss: 0.08546 | mse_mse: 0.06407 |  0:00:20s\n",
      "epoch 10 | loss: 0.0783  | mse_mse: 0.06694 |  0:00:22s\n",
      "epoch 11 | loss: 0.0815  | mse_mse: 0.06112 |  0:00:24s\n",
      "epoch 12 | loss: 0.07573 | mse_mse: 0.06258 |  0:00:26s\n",
      "epoch 13 | loss: 0.07144 | mse_mse: 0.06589 |  0:00:28s\n",
      "epoch 14 | loss: 0.07502 | mse_mse: 0.06902 |  0:00:30s\n",
      "epoch 15 | loss: 0.07559 | mse_mse: 0.05988 |  0:00:32s\n",
      "epoch 16 | loss: 0.07184 | mse_mse: 0.05695 |  0:00:34s\n",
      "epoch 17 | loss: 0.07603 | mse_mse: 0.06507 |  0:00:36s\n",
      "epoch 18 | loss: 0.07383 | mse_mse: 0.05664 |  0:00:38s\n",
      "epoch 19 | loss: 0.07092 | mse_mse: 0.06107 |  0:00:40s\n",
      "epoch 20 | loss: 0.07244 | mse_mse: 0.05867 |  0:00:42s\n",
      "epoch 21 | loss: 0.07649 | mse_mse: 0.0608  |  0:00:44s\n",
      "epoch 22 | loss: 0.0735  | mse_mse: 0.06522 |  0:00:46s\n",
      "epoch 23 | loss: 0.06997 | mse_mse: 0.07394 |  0:00:48s\n",
      "epoch 24 | loss: 0.07004 | mse_mse: 0.05673 |  0:00:51s\n",
      "epoch 25 | loss: 0.06812 | mse_mse: 0.05806 |  0:00:53s\n",
      "epoch 26 | loss: 0.0666  | mse_mse: 0.05994 |  0:00:55s\n",
      "epoch 27 | loss: 0.07108 | mse_mse: 0.06795 |  0:00:57s\n",
      "epoch 28 | loss: 0.07031 | mse_mse: 0.05777 |  0:00:59s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_mse_mse = 0.05664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.05884712427280064\n",
      "R2 Score: 0.7345235652559055\n",
      "\n",
      "Iteration 9/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.88242 | mse_mse: 0.61859 |  0:00:02s\n",
      "epoch 1  | loss: 0.3304  | mse_mse: 0.38781 |  0:00:05s\n",
      "epoch 2  | loss: 0.29778 | mse_mse: 0.24112 |  0:00:08s\n",
      "epoch 3  | loss: 0.25496 | mse_mse: 0.30282 |  0:00:11s\n",
      "epoch 4  | loss: 0.26057 | mse_mse: 0.27552 |  0:00:14s\n",
      "epoch 5  | loss: 0.25649 | mse_mse: 0.32974 |  0:00:17s\n",
      "epoch 6  | loss: 0.24776 | mse_mse: 0.23674 |  0:00:20s\n",
      "epoch 7  | loss: 0.24189 | mse_mse: 0.23399 |  0:00:23s\n",
      "epoch 8  | loss: 0.23855 | mse_mse: 0.22411 |  0:00:26s\n",
      "epoch 9  | loss: 0.23927 | mse_mse: 0.21728 |  0:00:29s\n",
      "epoch 10 | loss: 0.2359  | mse_mse: 0.22973 |  0:00:32s\n",
      "epoch 11 | loss: 0.23268 | mse_mse: 0.22422 |  0:00:35s\n",
      "epoch 12 | loss: 0.23751 | mse_mse: 0.23843 |  0:00:38s\n",
      "epoch 13 | loss: 0.23536 | mse_mse: 0.21585 |  0:00:41s\n",
      "epoch 14 | loss: 0.24524 | mse_mse: 0.20259 |  0:00:44s\n",
      "epoch 15 | loss: 0.23298 | mse_mse: 0.2085  |  0:00:46s\n",
      "epoch 16 | loss: 0.2231  | mse_mse: 0.21235 |  0:00:49s\n",
      "epoch 17 | loss: 0.21669 | mse_mse: 0.19275 |  0:00:52s\n",
      "epoch 18 | loss: 0.20966 | mse_mse: 0.18101 |  0:00:55s\n",
      "epoch 19 | loss: 0.18505 | mse_mse: 0.15487 |  0:00:58s\n",
      "epoch 20 | loss: 0.15194 | mse_mse: 0.15021 |  0:01:01s\n",
      "epoch 21 | loss: 0.12659 | mse_mse: 0.12379 |  0:01:04s\n",
      "epoch 22 | loss: 0.11094 | mse_mse: 0.09622 |  0:01:07s\n",
      "epoch 23 | loss: 0.09808 | mse_mse: 0.08359 |  0:01:10s\n",
      "epoch 24 | loss: 0.08417 | mse_mse: 0.07858 |  0:01:13s\n",
      "epoch 25 | loss: 0.07958 | mse_mse: 0.06698 |  0:01:16s\n",
      "epoch 26 | loss: 0.07127 | mse_mse: 0.05998 |  0:01:19s\n",
      "epoch 27 | loss: 0.05883 | mse_mse: 0.05395 |  0:01:22s\n",
      "epoch 28 | loss: 0.05299 | mse_mse: 0.05684 |  0:01:25s\n",
      "epoch 29 | loss: 0.05319 | mse_mse: 0.04514 |  0:01:28s\n",
      "epoch 30 | loss: 0.04816 | mse_mse: 0.04122 |  0:01:31s\n",
      "epoch 31 | loss: 0.04161 | mse_mse: 0.04261 |  0:01:34s\n",
      "epoch 32 | loss: 0.04059 | mse_mse: 0.03569 |  0:01:37s\n",
      "epoch 33 | loss: 0.03723 | mse_mse: 0.03469 |  0:01:40s\n",
      "epoch 34 | loss: 0.03884 | mse_mse: 0.0341  |  0:01:43s\n",
      "epoch 35 | loss: 0.03897 | mse_mse: 0.03307 |  0:01:46s\n",
      "epoch 36 | loss: 0.03118 | mse_mse: 0.02877 |  0:01:49s\n",
      "epoch 37 | loss: 0.03051 | mse_mse: 0.02941 |  0:01:52s\n",
      "epoch 38 | loss: 0.03351 | mse_mse: 0.02357 |  0:01:55s\n",
      "epoch 39 | loss: 0.02613 | mse_mse: 0.02315 |  0:01:57s\n",
      "epoch 40 | loss: 0.02343 | mse_mse: 0.01894 |  0:02:00s\n",
      "epoch 41 | loss: 0.02842 | mse_mse: 0.0263  |  0:02:03s\n",
      "epoch 42 | loss: 0.02356 | mse_mse: 0.01699 |  0:02:06s\n",
      "epoch 43 | loss: 0.02334 | mse_mse: 0.01609 |  0:02:09s\n",
      "epoch 44 | loss: 0.02193 | mse_mse: 0.02054 |  0:02:12s\n",
      "epoch 45 | loss: 0.02065 | mse_mse: 0.02125 |  0:02:15s\n",
      "epoch 46 | loss: 0.02302 | mse_mse: 0.01448 |  0:02:18s\n",
      "epoch 47 | loss: 0.02085 | mse_mse: 0.01705 |  0:02:21s\n",
      "epoch 48 | loss: 0.01812 | mse_mse: 0.02075 |  0:02:24s\n",
      "epoch 49 | loss: 0.01748 | mse_mse: 0.01811 |  0:02:27s\n",
      "epoch 50 | loss: 0.0206  | mse_mse: 0.01738 |  0:02:30s\n",
      "epoch 51 | loss: 0.01885 | mse_mse: 0.01356 |  0:02:33s\n",
      "epoch 52 | loss: 0.01852 | mse_mse: 0.01233 |  0:02:36s\n",
      "epoch 53 | loss: 0.01634 | mse_mse: 0.02193 |  0:02:39s\n",
      "epoch 54 | loss: 0.01338 | mse_mse: 0.01464 |  0:02:42s\n",
      "epoch 55 | loss: 0.01646 | mse_mse: 0.01667 |  0:02:45s\n",
      "epoch 56 | loss: 0.01481 | mse_mse: 0.01058 |  0:02:48s\n",
      "epoch 57 | loss: 0.01393 | mse_mse: 0.00988 |  0:02:51s\n",
      "epoch 58 | loss: 0.01572 | mse_mse: 0.01178 |  0:02:54s\n",
      "epoch 59 | loss: 0.015   | mse_mse: 0.0134  |  0:02:57s\n",
      "epoch 60 | loss: 0.01393 | mse_mse: 0.01215 |  0:02:59s\n",
      "epoch 61 | loss: 0.01994 | mse_mse: 0.01945 |  0:03:02s\n",
      "epoch 62 | loss: 0.02198 | mse_mse: 0.01526 |  0:03:05s\n",
      "epoch 63 | loss: 0.01407 | mse_mse: 0.01095 |  0:03:08s\n",
      "epoch 64 | loss: 0.01308 | mse_mse: 0.01234 |  0:03:11s\n",
      "epoch 65 | loss: 0.01473 | mse_mse: 0.01157 |  0:03:14s\n",
      "epoch 66 | loss: 0.01934 | mse_mse: 0.01249 |  0:03:17s\n",
      "epoch 67 | loss: 0.01323 | mse_mse: 0.01027 |  0:03:20s\n",
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 57 and best_mse_mse = 0.00988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010717709956058015\n",
      "R2 Score: 0.951649303803437\n",
      "\n",
      "Iteration 10/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.56886 | mse_mse: 0.95671 |  0:00:03s\n",
      "epoch 1  | loss: 0.35418 | mse_mse: 0.33067 |  0:00:06s\n",
      "epoch 2  | loss: 0.28901 | mse_mse: 0.24814 |  0:00:09s\n",
      "epoch 3  | loss: 0.27061 | mse_mse: 0.22249 |  0:00:12s\n",
      "epoch 4  | loss: 0.26058 | mse_mse: 0.23122 |  0:00:15s\n",
      "epoch 5  | loss: 0.24781 | mse_mse: 0.23456 |  0:00:18s\n",
      "epoch 6  | loss: 0.24814 | mse_mse: 0.27853 |  0:00:21s\n",
      "epoch 7  | loss: 0.2469  | mse_mse: 0.22458 |  0:00:25s\n",
      "epoch 8  | loss: 0.23543 | mse_mse: 0.2288  |  0:00:28s\n",
      "epoch 9  | loss: 0.23591 | mse_mse: 0.21496 |  0:00:31s\n",
      "epoch 10 | loss: 0.23419 | mse_mse: 0.21832 |  0:00:34s\n",
      "epoch 11 | loss: 0.22827 | mse_mse: 0.2327  |  0:00:37s\n",
      "epoch 12 | loss: 0.2312  | mse_mse: 0.21342 |  0:00:40s\n",
      "epoch 13 | loss: 0.22433 | mse_mse: 0.20733 |  0:00:44s\n",
      "epoch 14 | loss: 0.21734 | mse_mse: 0.19746 |  0:00:47s\n",
      "epoch 15 | loss: 0.20702 | mse_mse: 0.17731 |  0:00:50s\n",
      "epoch 16 | loss: 0.1841  | mse_mse: 0.1453  |  0:00:53s\n",
      "epoch 17 | loss: 0.16229 | mse_mse: 0.13574 |  0:00:56s\n",
      "epoch 18 | loss: 0.13523 | mse_mse: 0.12053 |  0:00:59s\n",
      "epoch 19 | loss: 0.11773 | mse_mse: 0.10058 |  0:01:03s\n",
      "epoch 20 | loss: 0.10852 | mse_mse: 0.087   |  0:01:06s\n",
      "epoch 21 | loss: 0.09015 | mse_mse: 0.07551 |  0:01:09s\n",
      "epoch 22 | loss: 0.07581 | mse_mse: 0.08653 |  0:01:12s\n",
      "epoch 23 | loss: 0.06979 | mse_mse: 0.06026 |  0:01:16s\n",
      "epoch 24 | loss: 0.07048 | mse_mse: 0.05123 |  0:01:19s\n",
      "epoch 25 | loss: 0.05322 | mse_mse: 0.05187 |  0:01:22s\n",
      "epoch 26 | loss: 0.05153 | mse_mse: 0.04275 |  0:01:25s\n",
      "epoch 27 | loss: 0.04286 | mse_mse: 0.04705 |  0:01:28s\n",
      "epoch 28 | loss: 0.03933 | mse_mse: 0.03564 |  0:01:31s\n",
      "epoch 29 | loss: 0.03855 | mse_mse: 0.03245 |  0:01:35s\n",
      "epoch 30 | loss: 0.03484 | mse_mse: 0.02969 |  0:01:38s\n",
      "epoch 31 | loss: 0.02985 | mse_mse: 0.02742 |  0:01:41s\n",
      "epoch 32 | loss: 0.02999 | mse_mse: 0.02361 |  0:01:44s\n",
      "epoch 33 | loss: 0.02635 | mse_mse: 0.02526 |  0:01:48s\n",
      "epoch 34 | loss: 0.02513 | mse_mse: 0.02708 |  0:01:51s\n",
      "epoch 35 | loss: 0.02475 | mse_mse: 0.02495 |  0:01:54s\n",
      "epoch 36 | loss: 0.024   | mse_mse: 0.01992 |  0:01:57s\n",
      "epoch 37 | loss: 0.02361 | mse_mse: 0.02887 |  0:02:00s\n",
      "epoch 38 | loss: 0.02488 | mse_mse: 0.06257 |  0:02:04s\n",
      "epoch 39 | loss: 0.0263  | mse_mse: 0.02121 |  0:02:07s\n",
      "epoch 40 | loss: 0.02087 | mse_mse: 0.0161  |  0:02:10s\n",
      "epoch 41 | loss: 0.01963 | mse_mse: 0.01413 |  0:02:13s\n",
      "epoch 42 | loss: 0.01734 | mse_mse: 0.01345 |  0:02:16s\n",
      "epoch 43 | loss: 0.01736 | mse_mse: 0.01459 |  0:02:19s\n",
      "epoch 44 | loss: 0.01643 | mse_mse: 0.01162 |  0:02:23s\n",
      "epoch 45 | loss: 0.016   | mse_mse: 0.02511 |  0:02:26s\n",
      "epoch 46 | loss: 0.02138 | mse_mse: 0.01425 |  0:02:29s\n",
      "epoch 47 | loss: 0.01717 | mse_mse: 0.01199 |  0:02:32s\n",
      "epoch 48 | loss: 0.01497 | mse_mse: 0.01287 |  0:02:35s\n",
      "epoch 49 | loss: 0.01568 | mse_mse: 0.01371 |  0:02:39s\n",
      "epoch 50 | loss: 0.01434 | mse_mse: 0.01074 |  0:02:42s\n",
      "epoch 51 | loss: 0.01999 | mse_mse: 0.00909 |  0:02:45s\n",
      "epoch 52 | loss: 0.01395 | mse_mse: 0.01259 |  0:02:48s\n",
      "epoch 53 | loss: 0.01423 | mse_mse: 0.01086 |  0:02:51s\n",
      "epoch 54 | loss: 0.014   | mse_mse: 0.01501 |  0:02:55s\n",
      "epoch 55 | loss: 0.01216 | mse_mse: 0.00866 |  0:02:58s\n",
      "epoch 56 | loss: 0.01209 | mse_mse: 0.01328 |  0:03:01s\n",
      "epoch 57 | loss: 0.0118  | mse_mse: 0.01087 |  0:03:04s\n",
      "epoch 58 | loss: 0.01233 | mse_mse: 0.00804 |  0:03:07s\n",
      "epoch 59 | loss: 0.01258 | mse_mse: 0.01476 |  0:03:11s\n",
      "epoch 60 | loss: 0.01221 | mse_mse: 0.00946 |  0:03:14s\n",
      "epoch 61 | loss: 0.01595 | mse_mse: 0.03086 |  0:03:17s\n",
      "epoch 62 | loss: 0.01354 | mse_mse: 0.01222 |  0:03:20s\n",
      "epoch 63 | loss: 0.01251 | mse_mse: 0.01343 |  0:03:23s\n",
      "epoch 64 | loss: 0.01223 | mse_mse: 0.01117 |  0:03:27s\n",
      "epoch 65 | loss: 0.01429 | mse_mse: 0.01219 |  0:03:30s\n",
      "epoch 66 | loss: 0.01291 | mse_mse: 0.0168  |  0:03:33s\n",
      "epoch 67 | loss: 0.01011 | mse_mse: 0.01192 |  0:03:36s\n",
      "epoch 68 | loss: 0.01052 | mse_mse: 0.02532 |  0:03:40s\n",
      "\n",
      "Early stopping occurred at epoch 68 with best_epoch = 58 and best_mse_mse = 0.00804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008842321471641143\n",
      "R2 Score: 0.9601097248478897\n",
      "\n",
      "Iteration 11/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.61536 | mse_mse: 0.98409 |  0:00:03s\n",
      "epoch 1  | loss: 0.3325  | mse_mse: 0.29521 |  0:00:07s\n",
      "epoch 2  | loss: 0.26626 | mse_mse: 0.29515 |  0:00:11s\n",
      "epoch 3  | loss: 0.35486 | mse_mse: 0.21847 |  0:00:15s\n",
      "epoch 4  | loss: 0.27956 | mse_mse: 0.21443 |  0:00:19s\n",
      "epoch 5  | loss: 0.2519  | mse_mse: 0.24192 |  0:00:23s\n",
      "epoch 6  | loss: 0.2459  | mse_mse: 0.23647 |  0:00:27s\n",
      "epoch 7  | loss: 0.2339  | mse_mse: 0.24114 |  0:00:31s\n",
      "epoch 8  | loss: 0.23339 | mse_mse: 0.22321 |  0:00:35s\n",
      "epoch 9  | loss: 0.2313  | mse_mse: 0.23127 |  0:00:39s\n",
      "epoch 10 | loss: 0.24558 | mse_mse: 0.21816 |  0:00:43s\n",
      "epoch 11 | loss: 0.23831 | mse_mse: 0.20685 |  0:00:47s\n",
      "epoch 12 | loss: 0.23363 | mse_mse: 0.21293 |  0:00:51s\n",
      "epoch 13 | loss: 0.22928 | mse_mse: 0.2116  |  0:00:55s\n",
      "epoch 14 | loss: 0.22146 | mse_mse: 0.1928  |  0:00:59s\n",
      "epoch 15 | loss: 0.21122 | mse_mse: 0.2096  |  0:01:03s\n",
      "epoch 16 | loss: 0.21144 | mse_mse: 0.1884  |  0:01:07s\n",
      "epoch 17 | loss: 0.21057 | mse_mse: 0.18678 |  0:01:11s\n",
      "epoch 18 | loss: 0.21432 | mse_mse: 0.21493 |  0:01:15s\n",
      "epoch 19 | loss: 0.20645 | mse_mse: 0.19745 |  0:01:19s\n",
      "epoch 20 | loss: 0.20645 | mse_mse: 0.18164 |  0:01:23s\n",
      "epoch 21 | loss: 0.20862 | mse_mse: 0.18461 |  0:01:27s\n",
      "epoch 22 | loss: 0.20557 | mse_mse: 0.18025 |  0:01:31s\n",
      "epoch 23 | loss: 0.2044  | mse_mse: 0.18029 |  0:01:35s\n",
      "epoch 24 | loss: 0.21635 | mse_mse: 0.1813  |  0:01:39s\n",
      "epoch 25 | loss: 0.20721 | mse_mse: 0.18037 |  0:01:43s\n",
      "epoch 26 | loss: 0.20649 | mse_mse: 0.18152 |  0:01:47s\n",
      "epoch 27 | loss: 0.20927 | mse_mse: 0.18215 |  0:01:51s\n",
      "epoch 28 | loss: 0.20708 | mse_mse: 0.17871 |  0:01:55s\n",
      "epoch 29 | loss: 0.20068 | mse_mse: 0.18322 |  0:01:59s\n",
      "epoch 30 | loss: 0.20047 | mse_mse: 0.18605 |  0:02:03s\n",
      "epoch 31 | loss: 0.20297 | mse_mse: 0.1867  |  0:02:07s\n",
      "epoch 32 | loss: 0.20277 | mse_mse: 0.18341 |  0:02:11s\n",
      "epoch 33 | loss: 0.20017 | mse_mse: 0.18756 |  0:02:15s\n",
      "epoch 34 | loss: 0.20485 | mse_mse: 0.21023 |  0:02:19s\n",
      "epoch 35 | loss: 0.20204 | mse_mse: 0.18261 |  0:02:23s\n",
      "epoch 36 | loss: 0.20207 | mse_mse: 0.17712 |  0:02:27s\n",
      "epoch 37 | loss: 0.19737 | mse_mse: 0.17857 |  0:02:32s\n",
      "epoch 38 | loss: 0.19909 | mse_mse: 0.1842  |  0:02:36s\n",
      "epoch 39 | loss: 0.19877 | mse_mse: 0.17885 |  0:02:40s\n",
      "epoch 40 | loss: 0.19836 | mse_mse: 0.17826 |  0:02:43s\n",
      "epoch 41 | loss: 0.19768 | mse_mse: 0.17989 |  0:02:47s\n",
      "epoch 42 | loss: 0.199   | mse_mse: 0.18035 |  0:02:51s\n",
      "epoch 43 | loss: 0.19406 | mse_mse: 0.17238 |  0:02:56s\n",
      "epoch 44 | loss: 0.19384 | mse_mse: 0.17749 |  0:03:00s\n",
      "epoch 45 | loss: 0.19457 | mse_mse: 0.18268 |  0:03:04s\n",
      "epoch 46 | loss: 0.19567 | mse_mse: 0.17698 |  0:03:08s\n",
      "epoch 47 | loss: 0.20432 | mse_mse: 0.185   |  0:03:12s\n",
      "epoch 48 | loss: 0.20427 | mse_mse: 0.18715 |  0:03:16s\n",
      "epoch 49 | loss: 0.19545 | mse_mse: 0.17349 |  0:03:20s\n",
      "epoch 50 | loss: 0.19282 | mse_mse: 0.18939 |  0:03:24s\n",
      "epoch 51 | loss: 0.19838 | mse_mse: 0.17798 |  0:03:28s\n",
      "epoch 52 | loss: 0.19498 | mse_mse: 0.17328 |  0:03:32s\n",
      "epoch 53 | loss: 0.19283 | mse_mse: 0.18484 |  0:03:36s\n",
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 43 and best_mse_mse = 0.17238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.1774404984504877\n",
      "R2 Score: 0.1995144794250686\n",
      "\n",
      "Iteration 12/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.18981 | mse_mse: 0.68903 |  0:00:04s\n",
      "epoch 1  | loss: 0.45695 | mse_mse: 0.59391 |  0:00:08s\n",
      "epoch 2  | loss: 0.28    | mse_mse: 0.23204 |  0:00:13s\n",
      "epoch 3  | loss: 0.25571 | mse_mse: 0.1606  |  0:00:17s\n",
      "epoch 4  | loss: 0.1678  | mse_mse: 0.14693 |  0:00:21s\n",
      "epoch 5  | loss: 0.16873 | mse_mse: 0.11202 |  0:00:25s\n",
      "epoch 6  | loss: 0.16117 | mse_mse: 0.10981 |  0:00:30s\n",
      "epoch 7  | loss: 0.12924 | mse_mse: 0.10849 |  0:00:34s\n",
      "epoch 8  | loss: 0.12654 | mse_mse: 0.11384 |  0:00:38s\n",
      "epoch 9  | loss: 0.12446 | mse_mse: 0.10634 |  0:00:43s\n",
      "epoch 10 | loss: 0.11594 | mse_mse: 0.09311 |  0:00:47s\n",
      "epoch 11 | loss: 0.11069 | mse_mse: 0.09883 |  0:00:51s\n",
      "epoch 12 | loss: 0.11097 | mse_mse: 0.0891  |  0:00:56s\n",
      "epoch 13 | loss: 0.11338 | mse_mse: 0.09589 |  0:01:00s\n",
      "epoch 14 | loss: 0.10803 | mse_mse: 0.09759 |  0:01:04s\n",
      "epoch 15 | loss: 0.11481 | mse_mse: 0.08454 |  0:01:08s\n",
      "epoch 16 | loss: 0.1066  | mse_mse: 0.08583 |  0:01:13s\n",
      "epoch 17 | loss: 0.10856 | mse_mse: 0.08579 |  0:01:17s\n",
      "epoch 18 | loss: 0.10251 | mse_mse: 0.08613 |  0:01:21s\n",
      "epoch 19 | loss: 0.10127 | mse_mse: 0.09081 |  0:01:26s\n",
      "epoch 20 | loss: 0.10536 | mse_mse: 0.08567 |  0:01:30s\n",
      "epoch 21 | loss: 0.10124 | mse_mse: 0.07938 |  0:01:34s\n",
      "epoch 22 | loss: 0.10267 | mse_mse: 0.08044 |  0:01:39s\n",
      "epoch 23 | loss: 0.0991  | mse_mse: 0.08323 |  0:01:43s\n",
      "epoch 24 | loss: 0.09597 | mse_mse: 0.07784 |  0:01:47s\n",
      "epoch 25 | loss: 0.09842 | mse_mse: 0.07743 |  0:01:52s\n",
      "epoch 26 | loss: 0.09828 | mse_mse: 0.07728 |  0:01:56s\n",
      "epoch 27 | loss: 0.09343 | mse_mse: 0.08042 |  0:02:01s\n",
      "epoch 28 | loss: 0.09822 | mse_mse: 0.09994 |  0:02:05s\n",
      "epoch 29 | loss: 0.1006  | mse_mse: 0.07842 |  0:02:09s\n",
      "epoch 30 | loss: 0.09147 | mse_mse: 0.07475 |  0:02:14s\n",
      "epoch 31 | loss: 0.08954 | mse_mse: 0.07816 |  0:02:18s\n",
      "epoch 32 | loss: 0.08992 | mse_mse: 0.07916 |  0:02:22s\n",
      "epoch 33 | loss: 0.08913 | mse_mse: 0.07711 |  0:02:27s\n",
      "epoch 34 | loss: 0.09219 | mse_mse: 0.07617 |  0:02:31s\n",
      "epoch 35 | loss: 0.09109 | mse_mse: 0.07344 |  0:02:35s\n",
      "epoch 36 | loss: 0.08685 | mse_mse: 0.08449 |  0:02:40s\n",
      "epoch 37 | loss: 0.08704 | mse_mse: 0.08239 |  0:02:44s\n",
      "epoch 38 | loss: 0.09178 | mse_mse: 0.09593 |  0:02:49s\n",
      "epoch 39 | loss: 0.08921 | mse_mse: 0.10156 |  0:02:53s\n",
      "epoch 40 | loss: 0.0907  | mse_mse: 0.07216 |  0:02:57s\n",
      "epoch 41 | loss: 0.08535 | mse_mse: 0.07188 |  0:03:02s\n",
      "epoch 42 | loss: 0.08841 | mse_mse: 0.07771 |  0:03:06s\n",
      "epoch 43 | loss: 0.08635 | mse_mse: 0.07201 |  0:03:10s\n",
      "epoch 44 | loss: 0.0809  | mse_mse: 0.07164 |  0:03:15s\n",
      "epoch 45 | loss: 0.08207 | mse_mse: 0.07161 |  0:03:19s\n",
      "epoch 46 | loss: 0.08286 | mse_mse: 0.0878  |  0:03:23s\n",
      "epoch 47 | loss: 0.0834  | mse_mse: 0.08144 |  0:03:28s\n",
      "epoch 48 | loss: 0.08542 | mse_mse: 0.0724  |  0:03:32s\n",
      "epoch 49 | loss: 0.08082 | mse_mse: 0.07218 |  0:03:36s\n",
      "epoch 50 | loss: 0.08068 | mse_mse: 0.07538 |  0:03:41s\n",
      "epoch 51 | loss: 0.08149 | mse_mse: 0.08947 |  0:03:45s\n",
      "epoch 52 | loss: 0.0829  | mse_mse: 0.08076 |  0:03:49s\n",
      "epoch 53 | loss: 0.07964 | mse_mse: 0.07321 |  0:03:54s\n",
      "epoch 54 | loss: 0.08304 | mse_mse: 0.07234 |  0:03:58s\n",
      "epoch 55 | loss: 0.08191 | mse_mse: 0.08649 |  0:04:02s\n",
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 45 and best_mse_mse = 0.07161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.07525443466078587\n",
      "R2 Score: 0.6605054323502113\n",
      "\n",
      "Iteration 13/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.91087 | mse_mse: 1.1496  |  0:00:02s\n",
      "epoch 1  | loss: 0.3012  | mse_mse: 0.25202 |  0:00:04s\n",
      "epoch 2  | loss: 0.16694 | mse_mse: 0.13727 |  0:00:06s\n",
      "epoch 3  | loss: 0.12346 | mse_mse: 0.09019 |  0:00:08s\n",
      "epoch 4  | loss: 0.1155  | mse_mse: 0.08916 |  0:00:11s\n",
      "epoch 5  | loss: 0.11154 | mse_mse: 0.08986 |  0:00:13s\n",
      "epoch 6  | loss: 0.10974 | mse_mse: 0.086   |  0:00:15s\n",
      "epoch 7  | loss: 0.10636 | mse_mse: 0.09258 |  0:00:17s\n",
      "epoch 8  | loss: 0.10672 | mse_mse: 0.09849 |  0:00:19s\n",
      "epoch 9  | loss: 0.10616 | mse_mse: 0.08671 |  0:00:21s\n",
      "epoch 10 | loss: 0.10467 | mse_mse: 0.08505 |  0:00:24s\n",
      "epoch 11 | loss: 0.10628 | mse_mse: 0.0854  |  0:00:26s\n",
      "epoch 12 | loss: 0.10025 | mse_mse: 0.08308 |  0:00:28s\n",
      "epoch 13 | loss: 0.10267 | mse_mse: 0.08891 |  0:00:30s\n",
      "epoch 14 | loss: 0.09921 | mse_mse: 0.08114 |  0:00:32s\n",
      "epoch 15 | loss: 0.09725 | mse_mse: 0.08348 |  0:00:35s\n",
      "epoch 16 | loss: 0.09374 | mse_mse: 0.08492 |  0:00:37s\n",
      "epoch 17 | loss: 0.08801 | mse_mse: 0.0747  |  0:00:39s\n",
      "epoch 18 | loss: 0.08525 | mse_mse: 0.07337 |  0:00:41s\n",
      "epoch 19 | loss: 0.08358 | mse_mse: 0.07129 |  0:00:43s\n",
      "epoch 20 | loss: 0.07457 | mse_mse: 0.06406 |  0:00:46s\n",
      "epoch 21 | loss: 0.06743 | mse_mse: 0.05883 |  0:00:48s\n",
      "epoch 22 | loss: 0.06073 | mse_mse: 0.05085 |  0:00:50s\n",
      "epoch 23 | loss: 0.05239 | mse_mse: 0.04697 |  0:00:52s\n",
      "epoch 24 | loss: 0.04708 | mse_mse: 0.03804 |  0:00:55s\n",
      "epoch 25 | loss: 0.04138 | mse_mse: 0.03952 |  0:00:57s\n",
      "epoch 26 | loss: 0.03778 | mse_mse: 0.03908 |  0:00:59s\n",
      "epoch 27 | loss: 0.03534 | mse_mse: 0.02761 |  0:01:02s\n",
      "epoch 28 | loss: 0.03053 | mse_mse: 0.02583 |  0:01:04s\n",
      "epoch 29 | loss: 0.02807 | mse_mse: 0.02342 |  0:01:06s\n",
      "epoch 30 | loss: 0.02545 | mse_mse: 0.02345 |  0:01:08s\n",
      "epoch 31 | loss: 0.0243  | mse_mse: 0.01954 |  0:01:10s\n",
      "epoch 32 | loss: 0.02524 | mse_mse: 0.01911 |  0:01:13s\n",
      "epoch 33 | loss: 0.02385 | mse_mse: 0.01755 |  0:01:15s\n",
      "epoch 34 | loss: 0.02215 | mse_mse: 0.01833 |  0:01:17s\n",
      "epoch 35 | loss: 0.01937 | mse_mse: 0.0188  |  0:01:19s\n",
      "epoch 36 | loss: 0.02151 | mse_mse: 0.03323 |  0:01:22s\n",
      "epoch 37 | loss: 0.03494 | mse_mse: 0.02237 |  0:01:24s\n",
      "epoch 38 | loss: 0.0216  | mse_mse: 0.02209 |  0:01:26s\n",
      "epoch 39 | loss: 0.01813 | mse_mse: 0.01381 |  0:01:28s\n",
      "epoch 40 | loss: 0.01845 | mse_mse: 0.01845 |  0:01:31s\n",
      "epoch 41 | loss: 0.01941 | mse_mse: 0.01901 |  0:01:33s\n",
      "epoch 42 | loss: 0.01689 | mse_mse: 0.01847 |  0:01:35s\n",
      "epoch 43 | loss: 0.01516 | mse_mse: 0.01301 |  0:01:37s\n",
      "epoch 44 | loss: 0.01525 | mse_mse: 0.01586 |  0:01:39s\n",
      "epoch 45 | loss: 0.01724 | mse_mse: 0.01494 |  0:01:42s\n",
      "epoch 46 | loss: 0.02026 | mse_mse: 0.0165  |  0:01:44s\n",
      "epoch 47 | loss: 0.01497 | mse_mse: 0.01158 |  0:01:46s\n",
      "epoch 48 | loss: 0.01389 | mse_mse: 0.01574 |  0:01:48s\n",
      "epoch 49 | loss: 0.01293 | mse_mse: 0.0125  |  0:01:51s\n",
      "epoch 50 | loss: 0.01211 | mse_mse: 0.01078 |  0:01:53s\n",
      "epoch 51 | loss: 0.01725 | mse_mse: 0.03166 |  0:01:55s\n",
      "epoch 52 | loss: 0.01964 | mse_mse: 0.02009 |  0:01:57s\n",
      "epoch 53 | loss: 0.0184  | mse_mse: 0.0135  |  0:02:00s\n",
      "epoch 54 | loss: 0.01513 | mse_mse: 0.02085 |  0:02:02s\n",
      "epoch 55 | loss: 0.01826 | mse_mse: 0.01291 |  0:02:04s\n",
      "epoch 56 | loss: 0.01374 | mse_mse: 0.01915 |  0:02:06s\n",
      "epoch 57 | loss: 0.02034 | mse_mse: 0.02878 |  0:02:08s\n",
      "epoch 58 | loss: 0.01762 | mse_mse: 0.0128  |  0:02:11s\n",
      "epoch 59 | loss: 0.01552 | mse_mse: 0.01317 |  0:02:13s\n",
      "epoch 60 | loss: 0.01376 | mse_mse: 0.01063 |  0:02:15s\n",
      "epoch 61 | loss: 0.01468 | mse_mse: 0.01078 |  0:02:17s\n",
      "epoch 62 | loss: 0.01188 | mse_mse: 0.01116 |  0:02:19s\n",
      "epoch 63 | loss: 0.01444 | mse_mse: 0.01366 |  0:02:22s\n",
      "epoch 64 | loss: 0.01342 | mse_mse: 0.00945 |  0:02:24s\n",
      "epoch 65 | loss: 0.01173 | mse_mse: 0.01265 |  0:02:26s\n",
      "epoch 66 | loss: 0.01217 | mse_mse: 0.00991 |  0:02:29s\n",
      "epoch 67 | loss: 0.01255 | mse_mse: 0.0126  |  0:02:31s\n",
      "epoch 68 | loss: 0.01224 | mse_mse: 0.009   |  0:02:33s\n",
      "epoch 69 | loss: 0.01588 | mse_mse: 0.01998 |  0:02:35s\n",
      "epoch 70 | loss: 0.02076 | mse_mse: 0.01304 |  0:02:37s\n",
      "epoch 71 | loss: 0.01488 | mse_mse: 0.01486 |  0:02:39s\n",
      "epoch 72 | loss: 0.0111  | mse_mse: 0.0201  |  0:02:42s\n",
      "epoch 73 | loss: 0.0129  | mse_mse: 0.01387 |  0:02:44s\n",
      "epoch 74 | loss: 0.01003 | mse_mse: 0.00866 |  0:02:46s\n",
      "epoch 75 | loss: 0.01152 | mse_mse: 0.009   |  0:02:48s\n",
      "epoch 76 | loss: 0.01074 | mse_mse: 0.00813 |  0:02:51s\n",
      "epoch 77 | loss: 0.01454 | mse_mse: 0.01127 |  0:02:53s\n",
      "epoch 78 | loss: 0.01012 | mse_mse: 0.01301 |  0:02:55s\n",
      "epoch 79 | loss: 0.01078 | mse_mse: 0.01271 |  0:02:57s\n",
      "epoch 80 | loss: 0.012   | mse_mse: 0.00948 |  0:03:00s\n",
      "epoch 81 | loss: 0.01117 | mse_mse: 0.01848 |  0:03:02s\n",
      "epoch 82 | loss: 0.01282 | mse_mse: 0.00866 |  0:03:04s\n",
      "epoch 83 | loss: 0.01129 | mse_mse: 0.01649 |  0:03:06s\n",
      "epoch 84 | loss: 0.01065 | mse_mse: 0.01013 |  0:03:08s\n",
      "epoch 85 | loss: 0.01474 | mse_mse: 0.01103 |  0:03:11s\n",
      "epoch 86 | loss: 0.01311 | mse_mse: 0.01176 |  0:03:13s\n",
      "\n",
      "Early stopping occurred at epoch 86 with best_epoch = 76 and best_mse_mse = 0.00813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0081602751612984\n",
      "R2 Score: 0.9631866334485678\n",
      "\n",
      "Iteration 14/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.44525 | mse_mse: 0.99021 |  0:00:02s\n",
      "epoch 1  | loss: 0.30957 | mse_mse: 0.3857  |  0:00:04s\n",
      "epoch 2  | loss: 0.25827 | mse_mse: 0.26074 |  0:00:07s\n",
      "epoch 3  | loss: 0.24348 | mse_mse: 0.25129 |  0:00:09s\n",
      "epoch 4  | loss: 0.2399  | mse_mse: 0.2169  |  0:00:12s\n",
      "epoch 5  | loss: 0.22809 | mse_mse: 0.19186 |  0:00:14s\n",
      "epoch 6  | loss: 0.19093 | mse_mse: 0.15568 |  0:00:16s\n",
      "epoch 7  | loss: 0.13404 | mse_mse: 0.15417 |  0:00:19s\n",
      "epoch 8  | loss: 0.0998  | mse_mse: 0.075   |  0:00:21s\n",
      "epoch 9  | loss: 0.07615 | mse_mse: 0.06096 |  0:00:24s\n",
      "epoch 10 | loss: 0.06274 | mse_mse: 0.04744 |  0:00:26s\n",
      "epoch 11 | loss: 0.05216 | mse_mse: 0.0422  |  0:00:28s\n",
      "epoch 12 | loss: 0.04373 | mse_mse: 0.0306  |  0:00:31s\n",
      "epoch 13 | loss: 0.03525 | mse_mse: 0.02596 |  0:00:33s\n",
      "epoch 14 | loss: 0.03023 | mse_mse: 0.02607 |  0:00:35s\n",
      "epoch 15 | loss: 0.02732 | mse_mse: 0.02529 |  0:00:38s\n",
      "epoch 16 | loss: 0.02533 | mse_mse: 0.03708 |  0:00:40s\n",
      "epoch 17 | loss: 0.02713 | mse_mse: 0.02391 |  0:00:43s\n",
      "epoch 18 | loss: 0.02354 | mse_mse: 0.02164 |  0:00:45s\n",
      "epoch 19 | loss: 0.02175 | mse_mse: 0.01512 |  0:00:47s\n",
      "epoch 20 | loss: 0.0166  | mse_mse: 0.0156  |  0:00:50s\n",
      "epoch 21 | loss: 0.0153  | mse_mse: 0.01698 |  0:00:52s\n",
      "epoch 22 | loss: 0.01577 | mse_mse: 0.01526 |  0:00:55s\n",
      "epoch 23 | loss: 0.01744 | mse_mse: 0.01373 |  0:00:57s\n",
      "epoch 24 | loss: 0.01829 | mse_mse: 0.01543 |  0:00:59s\n",
      "epoch 25 | loss: 0.01458 | mse_mse: 0.01351 |  0:01:02s\n",
      "epoch 26 | loss: 0.01422 | mse_mse: 0.0144  |  0:01:04s\n",
      "epoch 27 | loss: 0.01445 | mse_mse: 0.0119  |  0:01:07s\n",
      "epoch 28 | loss: 0.01334 | mse_mse: 0.01188 |  0:01:09s\n",
      "epoch 29 | loss: 0.0124  | mse_mse: 0.00929 |  0:01:11s\n",
      "epoch 30 | loss: 0.01177 | mse_mse: 0.01019 |  0:01:14s\n",
      "epoch 31 | loss: 0.01185 | mse_mse: 0.02452 |  0:01:16s\n",
      "epoch 32 | loss: 0.01171 | mse_mse: 0.00857 |  0:01:19s\n",
      "epoch 33 | loss: 0.01407 | mse_mse: 0.0214  |  0:01:21s\n",
      "epoch 34 | loss: 0.01543 | mse_mse: 0.008   |  0:01:24s\n",
      "epoch 35 | loss: 0.01125 | mse_mse: 0.00797 |  0:01:26s\n",
      "epoch 36 | loss: 0.01059 | mse_mse: 0.0095  |  0:01:28s\n",
      "epoch 37 | loss: 0.01198 | mse_mse: 0.00825 |  0:01:31s\n",
      "epoch 38 | loss: 0.0106  | mse_mse: 0.01816 |  0:01:33s\n",
      "epoch 39 | loss: 0.01292 | mse_mse: 0.01952 |  0:01:35s\n",
      "epoch 40 | loss: 0.01319 | mse_mse: 0.00808 |  0:01:38s\n",
      "epoch 41 | loss: 0.01268 | mse_mse: 0.01784 |  0:01:40s\n",
      "epoch 42 | loss: 0.01133 | mse_mse: 0.00831 |  0:01:43s\n",
      "epoch 43 | loss: 0.01009 | mse_mse: 0.01259 |  0:01:45s\n",
      "epoch 44 | loss: 0.00941 | mse_mse: 0.00884 |  0:01:47s\n",
      "epoch 45 | loss: 0.01431 | mse_mse: 0.01271 |  0:01:50s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_mse_mse = 0.00797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00803641343338421\n",
      "R2 Score: 0.9637454096051642\n",
      "\n",
      "Iteration 15/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.82268 | mse_mse: 0.98812 |  0:00:03s\n",
      "epoch 1  | loss: 0.35738 | mse_mse: 0.32343 |  0:00:06s\n",
      "epoch 2  | loss: 0.28766 | mse_mse: 0.3128  |  0:00:10s\n",
      "epoch 3  | loss: 0.26285 | mse_mse: 0.29276 |  0:00:13s\n",
      "epoch 4  | loss: 0.24875 | mse_mse: 0.27572 |  0:00:17s\n",
      "epoch 5  | loss: 0.2423  | mse_mse: 0.25456 |  0:00:20s\n",
      "epoch 6  | loss: 0.23983 | mse_mse: 0.22746 |  0:00:23s\n",
      "epoch 7  | loss: 0.25278 | mse_mse: 0.25584 |  0:00:27s\n",
      "epoch 8  | loss: 0.24731 | mse_mse: 0.24525 |  0:00:30s\n",
      "epoch 9  | loss: 0.23453 | mse_mse: 0.21133 |  0:00:33s\n",
      "epoch 10 | loss: 0.23479 | mse_mse: 0.20489 |  0:00:37s\n",
      "epoch 11 | loss: 0.22513 | mse_mse: 0.20132 |  0:00:40s\n",
      "epoch 12 | loss: 0.21889 | mse_mse: 0.2041  |  0:00:44s\n",
      "epoch 13 | loss: 0.21378 | mse_mse: 0.17179 |  0:00:47s\n",
      "epoch 14 | loss: 0.18261 | mse_mse: 0.14913 |  0:00:51s\n",
      "epoch 15 | loss: 0.15403 | mse_mse: 0.11797 |  0:00:54s\n",
      "epoch 16 | loss: 0.13392 | mse_mse: 0.10086 |  0:00:57s\n",
      "epoch 17 | loss: 0.11885 | mse_mse: 0.11727 |  0:01:01s\n",
      "epoch 18 | loss: 0.10796 | mse_mse: 0.07611 |  0:01:04s\n",
      "epoch 19 | loss: 0.09307 | mse_mse: 0.07345 |  0:01:08s\n",
      "epoch 20 | loss: 0.07781 | mse_mse: 0.06326 |  0:01:11s\n",
      "epoch 21 | loss: 0.0689  | mse_mse: 0.06582 |  0:01:15s\n",
      "epoch 22 | loss: 0.06936 | mse_mse: 0.05499 |  0:01:18s\n",
      "epoch 23 | loss: 0.05794 | mse_mse: 0.05004 |  0:01:22s\n",
      "epoch 24 | loss: 0.05477 | mse_mse: 0.04728 |  0:01:25s\n",
      "epoch 25 | loss: 0.04699 | mse_mse: 0.03837 |  0:01:29s\n",
      "epoch 26 | loss: 0.04293 | mse_mse: 0.03293 |  0:01:32s\n",
      "epoch 27 | loss: 0.03995 | mse_mse: 0.03019 |  0:01:36s\n",
      "epoch 28 | loss: 0.03374 | mse_mse: 0.02594 |  0:01:39s\n",
      "epoch 29 | loss: 0.03115 | mse_mse: 0.04649 |  0:01:43s\n",
      "epoch 30 | loss: 0.02977 | mse_mse: 0.02411 |  0:01:46s\n",
      "epoch 31 | loss: 0.02526 | mse_mse: 0.02147 |  0:01:50s\n",
      "epoch 32 | loss: 0.02567 | mse_mse: 0.02496 |  0:01:53s\n",
      "epoch 33 | loss: 0.02408 | mse_mse: 0.02106 |  0:01:57s\n",
      "epoch 34 | loss: 0.02302 | mse_mse: 0.0265  |  0:02:00s\n",
      "epoch 35 | loss: 0.02196 | mse_mse: 0.01734 |  0:02:03s\n",
      "epoch 36 | loss: 0.01986 | mse_mse: 0.01799 |  0:02:07s\n",
      "epoch 37 | loss: 0.02328 | mse_mse: 0.02337 |  0:02:10s\n",
      "epoch 38 | loss: 0.02326 | mse_mse: 0.01495 |  0:02:14s\n",
      "epoch 39 | loss: 0.0193  | mse_mse: 0.02205 |  0:02:17s\n",
      "epoch 40 | loss: 0.0193  | mse_mse: 0.02678 |  0:02:21s\n",
      "epoch 41 | loss: 0.01994 | mse_mse: 0.0189  |  0:02:24s\n",
      "epoch 42 | loss: 0.01634 | mse_mse: 0.02186 |  0:02:28s\n",
      "epoch 43 | loss: 0.01805 | mse_mse: 0.01312 |  0:02:31s\n",
      "epoch 44 | loss: 0.01807 | mse_mse: 0.0253  |  0:02:35s\n",
      "epoch 45 | loss: 0.01623 | mse_mse: 0.01157 |  0:02:38s\n",
      "epoch 46 | loss: 0.01655 | mse_mse: 0.01195 |  0:02:42s\n",
      "epoch 47 | loss: 0.01445 | mse_mse: 0.01278 |  0:02:45s\n",
      "epoch 48 | loss: 0.01623 | mse_mse: 0.01368 |  0:02:49s\n",
      "epoch 49 | loss: 0.01856 | mse_mse: 0.0133  |  0:02:52s\n",
      "epoch 50 | loss: 0.01269 | mse_mse: 0.01097 |  0:02:55s\n",
      "epoch 51 | loss: 0.01445 | mse_mse: 0.01263 |  0:02:59s\n",
      "epoch 52 | loss: 0.01428 | mse_mse: 0.0144  |  0:03:02s\n",
      "epoch 53 | loss: 0.01605 | mse_mse: 0.01523 |  0:03:06s\n",
      "epoch 54 | loss: 0.01432 | mse_mse: 0.0107  |  0:03:09s\n",
      "epoch 55 | loss: 0.01584 | mse_mse: 0.016   |  0:03:13s\n",
      "epoch 56 | loss: 0.02004 | mse_mse: 0.01082 |  0:03:16s\n",
      "epoch 57 | loss: 0.01598 | mse_mse: 0.0117  |  0:03:20s\n",
      "epoch 58 | loss: 0.0174  | mse_mse: 0.01157 |  0:03:23s\n",
      "epoch 59 | loss: 0.02204 | mse_mse: 0.01127 |  0:03:27s\n",
      "epoch 60 | loss: 0.01407 | mse_mse: 0.00979 |  0:03:30s\n",
      "epoch 61 | loss: 0.01398 | mse_mse: 0.01681 |  0:03:34s\n",
      "epoch 62 | loss: 0.01227 | mse_mse: 0.01091 |  0:03:37s\n",
      "epoch 63 | loss: 0.01582 | mse_mse: 0.00896 |  0:03:41s\n",
      "epoch 64 | loss: 0.01367 | mse_mse: 0.01079 |  0:03:44s\n",
      "epoch 65 | loss: 0.01257 | mse_mse: 0.0137  |  0:03:48s\n",
      "epoch 66 | loss: 0.01318 | mse_mse: 0.01316 |  0:03:51s\n",
      "epoch 67 | loss: 0.01297 | mse_mse: 0.00825 |  0:03:55s\n",
      "epoch 68 | loss: 0.01231 | mse_mse: 0.01197 |  0:03:58s\n",
      "epoch 69 | loss: 0.0139  | mse_mse: 0.00962 |  0:04:02s\n",
      "epoch 70 | loss: 0.01318 | mse_mse: 0.01077 |  0:04:05s\n",
      "epoch 71 | loss: 0.01276 | mse_mse: 0.00815 |  0:04:08s\n",
      "epoch 72 | loss: 0.0191  | mse_mse: 0.01554 |  0:04:12s\n",
      "epoch 73 | loss: 0.01417 | mse_mse: 0.01289 |  0:04:15s\n",
      "epoch 74 | loss: 0.01067 | mse_mse: 0.0092  |  0:04:19s\n",
      "epoch 75 | loss: 0.01216 | mse_mse: 0.00949 |  0:04:22s\n",
      "epoch 76 | loss: 0.01327 | mse_mse: 0.01397 |  0:04:26s\n",
      "epoch 77 | loss: 0.01134 | mse_mse: 0.00863 |  0:04:29s\n",
      "epoch 78 | loss: 0.01085 | mse_mse: 0.00892 |  0:04:33s\n",
      "epoch 79 | loss: 0.01318 | mse_mse: 0.00955 |  0:04:36s\n",
      "epoch 80 | loss: 0.0096  | mse_mse: 0.00898 |  0:04:40s\n",
      "epoch 81 | loss: 0.01168 | mse_mse: 0.0086  |  0:04:43s\n",
      "\n",
      "Early stopping occurred at epoch 81 with best_epoch = 71 and best_mse_mse = 0.00815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008163474074527314\n",
      "R2 Score: 0.9631722022237703\n",
      "\n",
      "Iteration 16/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.03284 | mse_mse: 0.51008 |  0:00:03s\n",
      "epoch 1  | loss: 0.275   | mse_mse: 0.10623 |  0:00:07s\n",
      "epoch 2  | loss: 0.18999 | mse_mse: 0.14633 |  0:00:11s\n",
      "epoch 3  | loss: 0.15192 | mse_mse: 0.12409 |  0:00:14s\n",
      "epoch 4  | loss: 0.13794 | mse_mse: 0.14282 |  0:00:18s\n",
      "epoch 5  | loss: 0.11777 | mse_mse: 0.09262 |  0:00:22s\n",
      "epoch 6  | loss: 0.1102  | mse_mse: 0.08143 |  0:00:25s\n",
      "epoch 7  | loss: 0.10854 | mse_mse: 0.08129 |  0:00:29s\n",
      "epoch 8  | loss: 0.10554 | mse_mse: 0.08188 |  0:00:33s\n",
      "epoch 9  | loss: 0.10346 | mse_mse: 0.0808  |  0:00:37s\n",
      "epoch 10 | loss: 0.09972 | mse_mse: 0.09002 |  0:00:40s\n",
      "epoch 11 | loss: 0.09931 | mse_mse: 0.08061 |  0:00:44s\n",
      "epoch 12 | loss: 0.0972  | mse_mse: 0.08582 |  0:00:48s\n",
      "epoch 13 | loss: 0.09667 | mse_mse: 0.07721 |  0:00:51s\n",
      "epoch 14 | loss: 0.09193 | mse_mse: 0.07775 |  0:00:55s\n",
      "epoch 15 | loss: 0.08823 | mse_mse: 0.07827 |  0:00:59s\n",
      "epoch 16 | loss: 0.08547 | mse_mse: 0.07342 |  0:01:02s\n",
      "epoch 17 | loss: 0.08086 | mse_mse: 0.07484 |  0:01:06s\n",
      "epoch 18 | loss: 0.07924 | mse_mse: 0.07167 |  0:01:10s\n",
      "epoch 19 | loss: 0.07642 | mse_mse: 0.06735 |  0:01:14s\n",
      "epoch 20 | loss: 0.07646 | mse_mse: 0.0697  |  0:01:17s\n",
      "epoch 21 | loss: 0.08231 | mse_mse: 0.06588 |  0:01:21s\n",
      "epoch 22 | loss: 0.07085 | mse_mse: 0.06083 |  0:01:25s\n",
      "epoch 23 | loss: 0.0666  | mse_mse: 0.05783 |  0:01:29s\n",
      "epoch 24 | loss: 0.06311 | mse_mse: 0.05464 |  0:01:32s\n",
      "epoch 25 | loss: 0.06168 | mse_mse: 0.06127 |  0:01:36s\n",
      "epoch 26 | loss: 0.0584  | mse_mse: 0.0491  |  0:01:40s\n",
      "epoch 27 | loss: 0.05734 | mse_mse: 0.04565 |  0:01:44s\n",
      "epoch 28 | loss: 0.05451 | mse_mse: 0.04659 |  0:01:47s\n",
      "epoch 29 | loss: 0.05261 | mse_mse: 0.03948 |  0:01:51s\n",
      "epoch 30 | loss: 0.04757 | mse_mse: 0.04856 |  0:01:55s\n",
      "epoch 31 | loss: 0.04721 | mse_mse: 0.03604 |  0:01:59s\n",
      "epoch 32 | loss: 0.04367 | mse_mse: 0.03685 |  0:02:02s\n",
      "epoch 33 | loss: 0.04313 | mse_mse: 0.0326  |  0:02:06s\n",
      "epoch 34 | loss: 0.03365 | mse_mse: 0.03152 |  0:02:10s\n",
      "epoch 35 | loss: 0.03378 | mse_mse: 0.03598 |  0:02:14s\n",
      "epoch 36 | loss: 0.02867 | mse_mse: 0.02279 |  0:02:17s\n",
      "epoch 37 | loss: 0.02544 | mse_mse: 0.03349 |  0:02:21s\n",
      "epoch 38 | loss: 0.02692 | mse_mse: 0.02296 |  0:02:25s\n",
      "epoch 39 | loss: 0.02295 | mse_mse: 0.0157  |  0:02:29s\n",
      "epoch 40 | loss: 0.02241 | mse_mse: 0.01504 |  0:02:32s\n",
      "epoch 41 | loss: 0.01929 | mse_mse: 0.01715 |  0:02:36s\n",
      "epoch 42 | loss: 0.0202  | mse_mse: 0.01878 |  0:02:40s\n",
      "epoch 43 | loss: 0.01898 | mse_mse: 0.02231 |  0:02:43s\n",
      "epoch 44 | loss: 0.01993 | mse_mse: 0.02727 |  0:02:47s\n",
      "epoch 45 | loss: 0.03037 | mse_mse: 0.01902 |  0:02:51s\n",
      "epoch 46 | loss: 0.02331 | mse_mse: 0.0223  |  0:02:55s\n",
      "epoch 47 | loss: 0.02098 | mse_mse: 0.01297 |  0:02:58s\n",
      "epoch 48 | loss: 0.01684 | mse_mse: 0.01267 |  0:03:02s\n",
      "epoch 49 | loss: 0.01848 | mse_mse: 0.01256 |  0:03:06s\n",
      "epoch 50 | loss: 0.01711 | mse_mse: 0.01066 |  0:03:09s\n",
      "epoch 51 | loss: 0.01418 | mse_mse: 0.01213 |  0:03:13s\n",
      "epoch 52 | loss: 0.01371 | mse_mse: 0.01154 |  0:03:17s\n",
      "epoch 53 | loss: 0.01479 | mse_mse: 0.01119 |  0:03:21s\n",
      "epoch 54 | loss: 0.01296 | mse_mse: 0.00955 |  0:03:24s\n",
      "epoch 55 | loss: 0.01404 | mse_mse: 0.01538 |  0:03:28s\n",
      "epoch 56 | loss: 0.01366 | mse_mse: 0.00908 |  0:03:32s\n",
      "epoch 57 | loss: 0.01375 | mse_mse: 0.0087  |  0:03:35s\n",
      "epoch 58 | loss: 0.0152  | mse_mse: 0.00906 |  0:03:39s\n",
      "epoch 59 | loss: 0.01186 | mse_mse: 0.00776 |  0:03:43s\n",
      "epoch 60 | loss: 0.01359 | mse_mse: 0.02104 |  0:03:47s\n",
      "epoch 61 | loss: 0.01612 | mse_mse: 0.01242 |  0:03:50s\n",
      "epoch 62 | loss: 0.0118  | mse_mse: 0.00819 |  0:03:54s\n",
      "epoch 63 | loss: 0.01308 | mse_mse: 0.01112 |  0:03:58s\n",
      "epoch 64 | loss: 0.01616 | mse_mse: 0.01122 |  0:04:01s\n",
      "epoch 65 | loss: 0.0144  | mse_mse: 0.00818 |  0:04:05s\n",
      "epoch 66 | loss: 0.01081 | mse_mse: 0.00868 |  0:04:09s\n",
      "epoch 67 | loss: 0.0118  | mse_mse: 0.01189 |  0:04:12s\n",
      "epoch 68 | loss: 0.01296 | mse_mse: 0.00836 |  0:04:16s\n",
      "epoch 69 | loss: 0.01092 | mse_mse: 0.00841 |  0:04:20s\n",
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 59 and best_mse_mse = 0.00776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008916373398830637\n",
      "R2 Score: 0.9597756551399961\n",
      "\n",
      "Iteration 17/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.07322 | mse_mse: 0.96845 |  0:00:04s\n",
      "epoch 1  | loss: 0.42102 | mse_mse: 0.31067 |  0:00:09s\n",
      "epoch 2  | loss: 0.29623 | mse_mse: 0.55918 |  0:00:13s\n",
      "epoch 3  | loss: 0.34778 | mse_mse: 0.45719 |  0:00:18s\n",
      "epoch 4  | loss: 0.26558 | mse_mse: 0.28229 |  0:00:23s\n",
      "epoch 5  | loss: 0.26069 | mse_mse: 0.22294 |  0:00:27s\n",
      "epoch 6  | loss: 0.29487 | mse_mse: 0.27856 |  0:00:32s\n",
      "epoch 7  | loss: 0.24494 | mse_mse: 0.23644 |  0:00:36s\n",
      "epoch 8  | loss: 0.23937 | mse_mse: 0.22586 |  0:00:41s\n",
      "epoch 9  | loss: 0.25046 | mse_mse: 0.25606 |  0:00:46s\n",
      "epoch 10 | loss: 0.25554 | mse_mse: 0.21109 |  0:00:50s\n",
      "epoch 11 | loss: 0.23703 | mse_mse: 0.20756 |  0:00:55s\n",
      "epoch 12 | loss: 0.23014 | mse_mse: 0.22272 |  0:01:00s\n",
      "epoch 13 | loss: 0.22201 | mse_mse: 0.20551 |  0:01:04s\n",
      "epoch 14 | loss: 0.22748 | mse_mse: 0.18794 |  0:01:09s\n",
      "epoch 15 | loss: 0.21415 | mse_mse: 0.18872 |  0:01:14s\n",
      "epoch 16 | loss: 0.20073 | mse_mse: 0.1742  |  0:01:18s\n",
      "epoch 17 | loss: 0.19205 | mse_mse: 0.19016 |  0:01:23s\n",
      "epoch 18 | loss: 0.17243 | mse_mse: 0.15159 |  0:01:28s\n",
      "epoch 19 | loss: 0.14796 | mse_mse: 0.13    |  0:01:32s\n",
      "epoch 20 | loss: 0.13675 | mse_mse: 0.13273 |  0:01:37s\n",
      "epoch 21 | loss: 0.12038 | mse_mse: 0.10981 |  0:01:42s\n",
      "epoch 22 | loss: 0.11502 | mse_mse: 0.10463 |  0:01:47s\n",
      "epoch 23 | loss: 0.11257 | mse_mse: 0.10074 |  0:01:51s\n",
      "epoch 24 | loss: 0.09945 | mse_mse: 0.10056 |  0:01:56s\n",
      "epoch 25 | loss: 0.08763 | mse_mse: 0.08212 |  0:02:01s\n",
      "epoch 26 | loss: 0.08054 | mse_mse: 0.07244 |  0:02:05s\n",
      "epoch 27 | loss: 0.07114 | mse_mse: 0.06602 |  0:02:10s\n",
      "epoch 28 | loss: 0.0708  | mse_mse: 0.06431 |  0:02:15s\n",
      "epoch 29 | loss: 0.06789 | mse_mse: 0.06324 |  0:02:19s\n",
      "epoch 30 | loss: 0.06691 | mse_mse: 0.06384 |  0:02:24s\n",
      "epoch 31 | loss: 0.06549 | mse_mse: 0.05454 |  0:02:29s\n",
      "epoch 32 | loss: 0.05389 | mse_mse: 0.04878 |  0:02:34s\n",
      "epoch 33 | loss: 0.05145 | mse_mse: 0.0474  |  0:02:38s\n",
      "epoch 34 | loss: 0.04772 | mse_mse: 0.04151 |  0:02:43s\n",
      "epoch 35 | loss: 0.04412 | mse_mse: 0.04053 |  0:02:48s\n",
      "epoch 36 | loss: 0.04238 | mse_mse: 0.03537 |  0:02:52s\n",
      "epoch 37 | loss: 0.04222 | mse_mse: 0.03899 |  0:02:57s\n",
      "epoch 38 | loss: 0.04907 | mse_mse: 0.03662 |  0:03:02s\n",
      "epoch 39 | loss: 0.04104 | mse_mse: 0.03518 |  0:03:07s\n",
      "epoch 40 | loss: 0.0409  | mse_mse: 0.03318 |  0:03:11s\n",
      "epoch 41 | loss: 0.03381 | mse_mse: 0.03854 |  0:03:16s\n",
      "epoch 42 | loss: 0.03472 | mse_mse: 0.02871 |  0:03:21s\n",
      "epoch 43 | loss: 0.03292 | mse_mse: 0.04548 |  0:03:25s\n",
      "epoch 44 | loss: 0.03466 | mse_mse: 0.03002 |  0:03:30s\n",
      "epoch 45 | loss: 0.03758 | mse_mse: 0.03603 |  0:03:35s\n",
      "epoch 46 | loss: 0.02871 | mse_mse: 0.02642 |  0:03:40s\n",
      "epoch 47 | loss: 0.02728 | mse_mse: 0.03523 |  0:03:44s\n",
      "epoch 48 | loss: 0.03508 | mse_mse: 0.02659 |  0:03:49s\n",
      "epoch 49 | loss: 0.03007 | mse_mse: 0.03652 |  0:03:54s\n",
      "epoch 50 | loss: 0.02978 | mse_mse: 0.03279 |  0:03:59s\n",
      "epoch 51 | loss: 0.0318  | mse_mse: 0.02406 |  0:04:03s\n",
      "epoch 52 | loss: 0.02641 | mse_mse: 0.03692 |  0:04:08s\n",
      "epoch 53 | loss: 0.02277 | mse_mse: 0.01992 |  0:04:13s\n",
      "epoch 54 | loss: 0.01999 | mse_mse: 0.01853 |  0:04:17s\n",
      "epoch 55 | loss: 0.02446 | mse_mse: 0.02319 |  0:04:22s\n",
      "epoch 56 | loss: 0.01914 | mse_mse: 0.01843 |  0:04:27s\n",
      "epoch 57 | loss: 0.01832 | mse_mse: 0.02504 |  0:04:32s\n",
      "epoch 58 | loss: 0.02013 | mse_mse: 0.01956 |  0:04:36s\n",
      "epoch 59 | loss: 0.01929 | mse_mse: 0.01736 |  0:04:41s\n",
      "epoch 60 | loss: 0.01923 | mse_mse: 0.01709 |  0:04:46s\n",
      "epoch 61 | loss: 0.01918 | mse_mse: 0.05035 |  0:04:51s\n",
      "epoch 62 | loss: 0.02125 | mse_mse: 0.02194 |  0:04:55s\n",
      "epoch 63 | loss: 0.02337 | mse_mse: 0.02855 |  0:05:00s\n",
      "epoch 64 | loss: 0.02249 | mse_mse: 0.02114 |  0:05:05s\n",
      "epoch 65 | loss: 0.01805 | mse_mse: 0.01301 |  0:05:09s\n",
      "epoch 66 | loss: 0.01872 | mse_mse: 0.03405 |  0:05:14s\n",
      "epoch 67 | loss: 0.01823 | mse_mse: 0.01717 |  0:05:19s\n",
      "epoch 68 | loss: 0.01645 | mse_mse: 0.01511 |  0:05:23s\n",
      "epoch 69 | loss: 0.01491 | mse_mse: 0.01359 |  0:05:28s\n",
      "epoch 70 | loss: 0.01729 | mse_mse: 0.01489 |  0:05:33s\n",
      "epoch 71 | loss: 0.01641 | mse_mse: 0.01182 |  0:05:38s\n",
      "epoch 72 | loss: 0.01859 | mse_mse: 0.01812 |  0:05:42s\n",
      "epoch 73 | loss: 0.01789 | mse_mse: 0.01877 |  0:05:47s\n",
      "epoch 74 | loss: 0.01963 | mse_mse: 0.01629 |  0:05:52s\n",
      "epoch 75 | loss: 0.02062 | mse_mse: 0.02492 |  0:05:57s\n",
      "epoch 76 | loss: 0.01451 | mse_mse: 0.01161 |  0:06:02s\n",
      "epoch 77 | loss: 0.01446 | mse_mse: 0.01869 |  0:06:06s\n",
      "epoch 78 | loss: 0.01764 | mse_mse: 0.00998 |  0:06:11s\n",
      "epoch 79 | loss: 0.01564 | mse_mse: 0.02839 |  0:06:16s\n",
      "epoch 80 | loss: 0.01805 | mse_mse: 0.03206 |  0:06:20s\n",
      "epoch 81 | loss: 0.01271 | mse_mse: 0.01211 |  0:06:25s\n",
      "epoch 82 | loss: 0.01421 | mse_mse: 0.01478 |  0:06:30s\n",
      "epoch 83 | loss: 0.01203 | mse_mse: 0.01039 |  0:06:35s\n",
      "epoch 84 | loss: 0.0142  | mse_mse: 0.01836 |  0:06:40s\n",
      "epoch 85 | loss: 0.01284 | mse_mse: 0.01122 |  0:06:44s\n",
      "epoch 86 | loss: 0.01743 | mse_mse: 0.01514 |  0:06:49s\n",
      "epoch 87 | loss: 0.012   | mse_mse: 0.00925 |  0:06:54s\n",
      "epoch 88 | loss: 0.01357 | mse_mse: 0.00835 |  0:06:59s\n",
      "epoch 89 | loss: 0.01245 | mse_mse: 0.00734 |  0:07:03s\n",
      "epoch 90 | loss: 0.01552 | mse_mse: 0.01913 |  0:07:08s\n",
      "epoch 91 | loss: 0.01261 | mse_mse: 0.00719 |  0:07:13s\n",
      "epoch 92 | loss: 0.00986 | mse_mse: 0.00852 |  0:07:18s\n",
      "epoch 93 | loss: 0.01189 | mse_mse: 0.01182 |  0:07:23s\n",
      "epoch 94 | loss: 0.01209 | mse_mse: 0.00744 |  0:07:27s\n",
      "epoch 95 | loss: 0.00995 | mse_mse: 0.00726 |  0:07:32s\n",
      "epoch 96 | loss: 0.00923 | mse_mse: 0.00728 |  0:07:37s\n",
      "epoch 97 | loss: 0.01148 | mse_mse: 0.00982 |  0:07:42s\n",
      "epoch 98 | loss: 0.00962 | mse_mse: 0.00862 |  0:07:46s\n",
      "epoch 99 | loss: 0.00975 | mse_mse: 0.00788 |  0:07:51s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 91 and best_mse_mse = 0.00719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0074023798325676396\n",
      "R2 Score: 0.9666057189564325\n",
      "\n",
      "Iteration 18/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.21366 | mse_mse: 0.61658 |  0:00:05s\n",
      "epoch 1  | loss: 0.33362 | mse_mse: 0.33444 |  0:00:10s\n",
      "epoch 2  | loss: 0.27064 | mse_mse: 0.66791 |  0:00:15s\n",
      "epoch 3  | loss: 0.43856 | mse_mse: 0.1213  |  0:00:20s\n",
      "epoch 4  | loss: 0.19026 | mse_mse: 0.32702 |  0:00:25s\n",
      "epoch 5  | loss: 0.21935 | mse_mse: 0.09921 |  0:00:30s\n",
      "epoch 6  | loss: 0.16668 | mse_mse: 0.09258 |  0:00:35s\n",
      "epoch 7  | loss: 0.13227 | mse_mse: 0.10838 |  0:00:40s\n",
      "epoch 8  | loss: 0.12206 | mse_mse: 0.09112 |  0:00:45s\n",
      "epoch 9  | loss: 0.11299 | mse_mse: 0.09056 |  0:00:50s\n",
      "epoch 10 | loss: 0.11624 | mse_mse: 0.09769 |  0:00:55s\n",
      "epoch 11 | loss: 0.11018 | mse_mse: 0.08948 |  0:01:00s\n",
      "epoch 12 | loss: 0.11335 | mse_mse: 0.09887 |  0:01:05s\n",
      "epoch 13 | loss: 0.10891 | mse_mse: 0.08857 |  0:01:10s\n",
      "epoch 14 | loss: 0.10908 | mse_mse: 0.08845 |  0:01:15s\n",
      "epoch 15 | loss: 0.10958 | mse_mse: 0.09652 |  0:01:20s\n",
      "epoch 16 | loss: 0.10983 | mse_mse: 0.09603 |  0:01:25s\n",
      "epoch 17 | loss: 0.10622 | mse_mse: 0.08817 |  0:01:30s\n",
      "epoch 18 | loss: 0.10542 | mse_mse: 0.0923  |  0:01:36s\n",
      "epoch 19 | loss: 0.10662 | mse_mse: 0.08964 |  0:01:43s\n",
      "epoch 20 | loss: 0.10927 | mse_mse: 0.0903  |  0:01:48s\n",
      "epoch 21 | loss: 0.10783 | mse_mse: 0.10411 |  0:01:53s\n",
      "epoch 22 | loss: 0.10703 | mse_mse: 0.0937  |  0:01:58s\n",
      "epoch 23 | loss: 0.10676 | mse_mse: 0.09364 |  0:02:03s\n",
      "epoch 24 | loss: 0.1075  | mse_mse: 0.09267 |  0:02:08s\n",
      "epoch 25 | loss: 0.10959 | mse_mse: 0.08917 |  0:02:13s\n",
      "epoch 26 | loss: 0.10463 | mse_mse: 0.08952 |  0:02:18s\n",
      "epoch 27 | loss: 0.10562 | mse_mse: 0.08923 |  0:02:23s\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_mse_mse = 0.08817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0918562087762605\n",
      "R2 Score: 0.5856100172034747\n",
      "\n",
      "Iteration 19/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.19161 | mse_mse: 0.52701 |  0:00:01s\n",
      "epoch 1  | loss: 0.27138 | mse_mse: 0.37953 |  0:00:03s\n",
      "epoch 2  | loss: 0.16994 | mse_mse: 0.11801 |  0:00:05s\n",
      "epoch 3  | loss: 0.13317 | mse_mse: 0.09816 |  0:00:07s\n",
      "epoch 4  | loss: 0.12043 | mse_mse: 0.09246 |  0:00:09s\n",
      "epoch 5  | loss: 0.11125 | mse_mse: 0.08093 |  0:00:11s\n",
      "epoch 6  | loss: 0.10521 | mse_mse: 0.07614 |  0:00:13s\n",
      "epoch 7  | loss: 0.09519 | mse_mse: 0.08116 |  0:00:14s\n",
      "epoch 8  | loss: 0.09225 | mse_mse: 0.07533 |  0:00:16s\n",
      "epoch 9  | loss: 0.09252 | mse_mse: 0.07258 |  0:00:18s\n",
      "epoch 10 | loss: 0.09253 | mse_mse: 0.06673 |  0:00:20s\n",
      "epoch 11 | loss: 0.0872  | mse_mse: 0.06636 |  0:00:22s\n",
      "epoch 12 | loss: 0.08502 | mse_mse: 0.06814 |  0:00:24s\n",
      "epoch 13 | loss: 0.08676 | mse_mse: 0.06755 |  0:00:26s\n",
      "epoch 14 | loss: 0.08356 | mse_mse: 0.07257 |  0:00:28s\n",
      "epoch 15 | loss: 0.08436 | mse_mse: 0.06833 |  0:00:30s\n",
      "epoch 16 | loss: 0.08212 | mse_mse: 0.08479 |  0:00:31s\n",
      "epoch 17 | loss: 0.07969 | mse_mse: 0.06858 |  0:00:33s\n",
      "epoch 18 | loss: 0.08025 | mse_mse: 0.06831 |  0:00:35s\n",
      "epoch 19 | loss: 0.07811 | mse_mse: 0.06912 |  0:00:37s\n",
      "epoch 20 | loss: 0.07549 | mse_mse: 0.06962 |  0:00:39s\n",
      "epoch 21 | loss: 0.07271 | mse_mse: 0.06498 |  0:00:41s\n",
      "epoch 22 | loss: 0.06597 | mse_mse: 0.05645 |  0:00:43s\n",
      "epoch 23 | loss: 0.06267 | mse_mse: 0.05145 |  0:00:45s\n",
      "epoch 24 | loss: 0.05774 | mse_mse: 0.04768 |  0:00:46s\n",
      "epoch 25 | loss: 0.05178 | mse_mse: 0.05043 |  0:00:48s\n",
      "epoch 26 | loss: 0.04941 | mse_mse: 0.04262 |  0:00:50s\n",
      "epoch 27 | loss: 0.04438 | mse_mse: 0.04393 |  0:00:52s\n",
      "epoch 28 | loss: 0.04595 | mse_mse: 0.04579 |  0:00:54s\n",
      "epoch 29 | loss: 0.03861 | mse_mse: 0.0329  |  0:00:56s\n",
      "epoch 30 | loss: 0.03578 | mse_mse: 0.03118 |  0:00:58s\n",
      "epoch 31 | loss: 0.03363 | mse_mse: 0.02797 |  0:01:00s\n",
      "epoch 32 | loss: 0.03196 | mse_mse: 0.02734 |  0:01:01s\n",
      "epoch 33 | loss: 0.02951 | mse_mse: 0.02599 |  0:01:03s\n",
      "epoch 34 | loss: 0.02714 | mse_mse: 0.02442 |  0:01:05s\n",
      "epoch 35 | loss: 0.02527 | mse_mse: 0.02502 |  0:01:07s\n",
      "epoch 36 | loss: 0.02462 | mse_mse: 0.01947 |  0:01:09s\n",
      "epoch 37 | loss: 0.02428 | mse_mse: 0.01806 |  0:01:11s\n",
      "epoch 38 | loss: 0.02264 | mse_mse: 0.01956 |  0:01:13s\n",
      "epoch 39 | loss: 0.02228 | mse_mse: 0.01634 |  0:01:14s\n",
      "epoch 40 | loss: 0.02127 | mse_mse: 0.02167 |  0:01:16s\n",
      "epoch 41 | loss: 0.02127 | mse_mse: 0.01657 |  0:01:18s\n",
      "epoch 42 | loss: 0.02035 | mse_mse: 0.01493 |  0:01:20s\n",
      "epoch 43 | loss: 0.01753 | mse_mse: 0.01422 |  0:01:22s\n",
      "epoch 44 | loss: 0.01593 | mse_mse: 0.02268 |  0:01:24s\n",
      "epoch 45 | loss: 0.01858 | mse_mse: 0.01339 |  0:01:26s\n",
      "epoch 46 | loss: 0.0166  | mse_mse: 0.01403 |  0:01:28s\n",
      "epoch 47 | loss: 0.01589 | mse_mse: 0.0128  |  0:01:30s\n",
      "epoch 48 | loss: 0.01651 | mse_mse: 0.01552 |  0:01:32s\n",
      "epoch 49 | loss: 0.01537 | mse_mse: 0.01286 |  0:01:34s\n",
      "epoch 50 | loss: 0.01513 | mse_mse: 0.01384 |  0:01:35s\n",
      "epoch 51 | loss: 0.01315 | mse_mse: 0.01116 |  0:01:37s\n",
      "epoch 52 | loss: 0.01257 | mse_mse: 0.01172 |  0:01:39s\n",
      "epoch 53 | loss: 0.01352 | mse_mse: 0.01392 |  0:01:41s\n",
      "epoch 54 | loss: 0.01576 | mse_mse: 0.01085 |  0:01:43s\n",
      "epoch 55 | loss: 0.01546 | mse_mse: 0.01054 |  0:01:45s\n",
      "epoch 56 | loss: 0.01439 | mse_mse: 0.01181 |  0:01:47s\n",
      "epoch 57 | loss: 0.014   | mse_mse: 0.01035 |  0:01:49s\n",
      "epoch 58 | loss: 0.01252 | mse_mse: 0.01003 |  0:01:51s\n",
      "epoch 59 | loss: 0.01428 | mse_mse: 0.01108 |  0:01:52s\n",
      "epoch 60 | loss: 0.01177 | mse_mse: 0.01048 |  0:01:54s\n",
      "epoch 61 | loss: 0.0115  | mse_mse: 0.01892 |  0:01:56s\n",
      "epoch 62 | loss: 0.01233 | mse_mse: 0.00955 |  0:01:58s\n",
      "epoch 63 | loss: 0.01174 | mse_mse: 0.00962 |  0:02:00s\n",
      "epoch 64 | loss: 0.01086 | mse_mse: 0.02015 |  0:02:02s\n",
      "epoch 65 | loss: 0.01244 | mse_mse: 0.01182 |  0:02:04s\n",
      "epoch 66 | loss: 0.0121  | mse_mse: 0.00869 |  0:02:06s\n",
      "epoch 67 | loss: 0.01207 | mse_mse: 0.01049 |  0:02:07s\n",
      "epoch 68 | loss: 0.01363 | mse_mse: 0.01151 |  0:02:09s\n",
      "epoch 69 | loss: 0.01168 | mse_mse: 0.01435 |  0:02:11s\n",
      "epoch 70 | loss: 0.01414 | mse_mse: 0.00948 |  0:02:13s\n",
      "epoch 71 | loss: 0.01092 | mse_mse: 0.009   |  0:02:15s\n",
      "epoch 72 | loss: 0.01087 | mse_mse: 0.00851 |  0:02:17s\n",
      "epoch 73 | loss: 0.01156 | mse_mse: 0.01018 |  0:02:19s\n",
      "epoch 74 | loss: 0.01072 | mse_mse: 0.00953 |  0:02:20s\n",
      "epoch 75 | loss: 0.01036 | mse_mse: 0.00914 |  0:02:22s\n",
      "epoch 76 | loss: 0.01276 | mse_mse: 0.01949 |  0:02:24s\n",
      "epoch 77 | loss: 0.01293 | mse_mse: 0.00951 |  0:02:26s\n",
      "epoch 78 | loss: 0.00941 | mse_mse: 0.00881 |  0:02:28s\n",
      "epoch 79 | loss: 0.0104  | mse_mse: 0.01379 |  0:02:30s\n",
      "epoch 80 | loss: 0.01064 | mse_mse: 0.00986 |  0:02:32s\n",
      "epoch 81 | loss: 0.01419 | mse_mse: 0.01131 |  0:02:33s\n",
      "epoch 82 | loss: 0.01062 | mse_mse: 0.01141 |  0:02:35s\n",
      "\n",
      "Early stopping occurred at epoch 82 with best_epoch = 72 and best_mse_mse = 0.00851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008731949753689709\n",
      "R2 Score: 0.9606076436593934\n",
      "\n",
      "Iteration 20/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.23119 | mse_mse: 0.60179 |  0:00:01s\n",
      "epoch 1  | loss: 0.30343 | mse_mse: 0.18157 |  0:00:04s\n",
      "epoch 2  | loss: 0.17087 | mse_mse: 0.20587 |  0:00:06s\n",
      "epoch 3  | loss: 0.13553 | mse_mse: 0.10742 |  0:00:08s\n",
      "epoch 4  | loss: 0.12378 | mse_mse: 0.09747 |  0:00:10s\n",
      "epoch 5  | loss: 0.12242 | mse_mse: 0.12846 |  0:00:12s\n",
      "epoch 6  | loss: 0.11811 | mse_mse: 0.08668 |  0:00:14s\n",
      "epoch 7  | loss: 0.11352 | mse_mse: 0.08652 |  0:00:16s\n",
      "epoch 8  | loss: 0.11334 | mse_mse: 0.08821 |  0:00:18s\n",
      "epoch 9  | loss: 0.11121 | mse_mse: 0.08818 |  0:00:20s\n",
      "epoch 10 | loss: 0.10975 | mse_mse: 0.08897 |  0:00:22s\n",
      "epoch 11 | loss: 0.11506 | mse_mse: 0.09285 |  0:00:24s\n",
      "epoch 12 | loss: 0.11848 | mse_mse: 0.10621 |  0:00:26s\n",
      "epoch 13 | loss: 0.11862 | mse_mse: 0.08722 |  0:00:28s\n",
      "epoch 14 | loss: 0.10737 | mse_mse: 0.08454 |  0:00:30s\n",
      "epoch 15 | loss: 0.10715 | mse_mse: 0.08831 |  0:00:32s\n",
      "epoch 16 | loss: 0.10813 | mse_mse: 0.09102 |  0:00:34s\n",
      "epoch 17 | loss: 0.10408 | mse_mse: 0.08388 |  0:00:36s\n",
      "epoch 18 | loss: 0.10355 | mse_mse: 0.08403 |  0:00:38s\n",
      "epoch 19 | loss: 0.09867 | mse_mse: 0.08009 |  0:00:40s\n",
      "epoch 20 | loss: 0.09314 | mse_mse: 0.0732  |  0:00:42s\n",
      "epoch 21 | loss: 0.08469 | mse_mse: 0.06271 |  0:00:44s\n",
      "epoch 22 | loss: 0.07355 | mse_mse: 0.05984 |  0:00:47s\n",
      "epoch 23 | loss: 0.065   | mse_mse: 0.04979 |  0:00:49s\n",
      "epoch 24 | loss: 0.0541  | mse_mse: 0.0473  |  0:00:51s\n",
      "epoch 25 | loss: 0.04718 | mse_mse: 0.04569 |  0:00:53s\n",
      "epoch 26 | loss: 0.04016 | mse_mse: 0.03298 |  0:00:55s\n",
      "epoch 27 | loss: 0.03968 | mse_mse: 0.03083 |  0:00:57s\n",
      "epoch 28 | loss: 0.03215 | mse_mse: 0.02584 |  0:00:59s\n",
      "epoch 29 | loss: 0.02803 | mse_mse: 0.02666 |  0:01:01s\n",
      "epoch 30 | loss: 0.02394 | mse_mse: 0.02643 |  0:01:03s\n",
      "epoch 31 | loss: 0.02519 | mse_mse: 0.01669 |  0:01:05s\n",
      "epoch 32 | loss: 0.02243 | mse_mse: 0.01523 |  0:01:07s\n",
      "epoch 33 | loss: 0.01989 | mse_mse: 0.01516 |  0:01:09s\n",
      "epoch 34 | loss: 0.01673 | mse_mse: 0.01693 |  0:01:11s\n",
      "epoch 35 | loss: 0.01654 | mse_mse: 0.01334 |  0:01:13s\n",
      "epoch 36 | loss: 0.019   | mse_mse: 0.02112 |  0:01:15s\n",
      "epoch 37 | loss: 0.01898 | mse_mse: 0.01438 |  0:01:17s\n",
      "epoch 38 | loss: 0.01677 | mse_mse: 0.01056 |  0:01:19s\n",
      "epoch 39 | loss: 0.01464 | mse_mse: 0.01108 |  0:01:21s\n",
      "epoch 40 | loss: 0.0151  | mse_mse: 0.00982 |  0:01:23s\n",
      "epoch 41 | loss: 0.0144  | mse_mse: 0.01526 |  0:01:25s\n",
      "epoch 42 | loss: 0.01418 | mse_mse: 0.00867 |  0:01:27s\n",
      "epoch 43 | loss: 0.01637 | mse_mse: 0.00855 |  0:01:29s\n",
      "epoch 44 | loss: 0.01145 | mse_mse: 0.01134 |  0:01:31s\n",
      "epoch 45 | loss: 0.01445 | mse_mse: 0.01009 |  0:01:33s\n",
      "epoch 46 | loss: 0.01199 | mse_mse: 0.01292 |  0:01:35s\n",
      "epoch 47 | loss: 0.013   | mse_mse: 0.01173 |  0:01:37s\n",
      "epoch 48 | loss: 0.01365 | mse_mse: 0.00889 |  0:01:39s\n",
      "epoch 49 | loss: 0.01505 | mse_mse: 0.01171 |  0:01:41s\n",
      "epoch 50 | loss: 0.01321 | mse_mse: 0.0103  |  0:01:43s\n",
      "epoch 51 | loss: 0.014   | mse_mse: 0.01029 |  0:01:45s\n",
      "epoch 52 | loss: 0.0109  | mse_mse: 0.01031 |  0:01:47s\n",
      "epoch 53 | loss: 0.01231 | mse_mse: 0.00902 |  0:01:49s\n",
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 43 and best_mse_mse = 0.00855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008743512527228268\n",
      "R2 Score: 0.9605554806364301\n",
      "\n",
      "Iteration 21/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.36877 | mse_mse: 0.87106 |  0:00:02s\n",
      "epoch 1  | loss: 0.33137 | mse_mse: 0.3242  |  0:00:05s\n",
      "epoch 2  | loss: 0.2675  | mse_mse: 0.36582 |  0:00:08s\n",
      "epoch 3  | loss: 0.21977 | mse_mse: 0.18971 |  0:00:11s\n",
      "epoch 4  | loss: 0.16955 | mse_mse: 0.16273 |  0:00:14s\n",
      "epoch 5  | loss: 0.14889 | mse_mse: 0.11731 |  0:00:17s\n",
      "epoch 6  | loss: 0.13434 | mse_mse: 0.10719 |  0:00:20s\n",
      "epoch 7  | loss: 0.1335  | mse_mse: 0.10995 |  0:00:23s\n",
      "epoch 8  | loss: 0.12482 | mse_mse: 0.09408 |  0:00:26s\n",
      "epoch 9  | loss: 0.12094 | mse_mse: 0.09638 |  0:00:29s\n",
      "epoch 10 | loss: 0.12026 | mse_mse: 0.09312 |  0:00:31s\n",
      "epoch 11 | loss: 0.1145  | mse_mse: 0.09485 |  0:00:34s\n",
      "epoch 12 | loss: 0.11403 | mse_mse: 0.09442 |  0:00:37s\n",
      "epoch 13 | loss: 0.11818 | mse_mse: 0.09622 |  0:00:40s\n",
      "epoch 14 | loss: 0.12596 | mse_mse: 0.08762 |  0:00:43s\n",
      "epoch 15 | loss: 0.10652 | mse_mse: 0.09063 |  0:00:46s\n",
      "epoch 16 | loss: 0.10958 | mse_mse: 0.09728 |  0:00:49s\n",
      "epoch 17 | loss: 0.10558 | mse_mse: 0.08913 |  0:00:51s\n",
      "epoch 18 | loss: 0.10252 | mse_mse: 0.0882  |  0:00:54s\n",
      "epoch 19 | loss: 0.10195 | mse_mse: 0.08086 |  0:00:57s\n",
      "epoch 20 | loss: 0.09337 | mse_mse: 0.0785  |  0:01:00s\n",
      "epoch 21 | loss: 0.09173 | mse_mse: 0.07017 |  0:01:03s\n",
      "epoch 22 | loss: 0.08563 | mse_mse: 0.06728 |  0:01:06s\n",
      "epoch 23 | loss: 0.07476 | mse_mse: 0.06872 |  0:01:09s\n",
      "epoch 24 | loss: 0.06993 | mse_mse: 0.05553 |  0:01:12s\n",
      "epoch 25 | loss: 0.06124 | mse_mse: 0.04428 |  0:01:15s\n",
      "epoch 26 | loss: 0.05479 | mse_mse: 0.03937 |  0:01:18s\n",
      "epoch 27 | loss: 0.04276 | mse_mse: 0.03377 |  0:01:21s\n",
      "epoch 28 | loss: 0.03921 | mse_mse: 0.02787 |  0:01:24s\n",
      "epoch 29 | loss: 0.03012 | mse_mse: 0.0246  |  0:01:26s\n",
      "epoch 30 | loss: 0.02521 | mse_mse: 0.02358 |  0:01:29s\n",
      "epoch 31 | loss: 0.02387 | mse_mse: 0.01865 |  0:01:32s\n",
      "epoch 32 | loss: 0.02184 | mse_mse: 0.01722 |  0:01:35s\n",
      "epoch 33 | loss: 0.02245 | mse_mse: 0.01737 |  0:01:38s\n",
      "epoch 34 | loss: 0.01817 | mse_mse: 0.01863 |  0:01:41s\n",
      "epoch 35 | loss: 0.01821 | mse_mse: 0.01584 |  0:01:44s\n",
      "epoch 36 | loss: 0.01587 | mse_mse: 0.0107  |  0:01:47s\n",
      "epoch 37 | loss: 0.01343 | mse_mse: 0.00956 |  0:01:50s\n",
      "epoch 38 | loss: 0.01445 | mse_mse: 0.01894 |  0:01:53s\n",
      "epoch 39 | loss: 0.01497 | mse_mse: 0.00984 |  0:01:56s\n",
      "epoch 40 | loss: 0.01439 | mse_mse: 0.01158 |  0:01:58s\n",
      "epoch 41 | loss: 0.01195 | mse_mse: 0.00874 |  0:02:01s\n",
      "epoch 42 | loss: 0.01326 | mse_mse: 0.01787 |  0:02:04s\n",
      "epoch 43 | loss: 0.01415 | mse_mse: 0.01707 |  0:02:07s\n",
      "epoch 44 | loss: 0.01237 | mse_mse: 0.00776 |  0:02:10s\n",
      "epoch 45 | loss: 0.01017 | mse_mse: 0.00986 |  0:02:13s\n",
      "epoch 46 | loss: 0.011   | mse_mse: 0.00918 |  0:02:16s\n",
      "epoch 47 | loss: 0.01258 | mse_mse: 0.011   |  0:02:19s\n",
      "epoch 48 | loss: 0.01063 | mse_mse: 0.00944 |  0:02:22s\n",
      "epoch 49 | loss: 0.01108 | mse_mse: 0.00799 |  0:02:25s\n",
      "epoch 50 | loss: 0.01323 | mse_mse: 0.01503 |  0:02:27s\n",
      "epoch 51 | loss: 0.01228 | mse_mse: 0.00904 |  0:02:30s\n",
      "epoch 52 | loss: 0.01065 | mse_mse: 0.00792 |  0:02:33s\n",
      "epoch 53 | loss: 0.01018 | mse_mse: 0.00938 |  0:02:36s\n",
      "epoch 54 | loss: 0.0127  | mse_mse: 0.0071  |  0:02:39s\n",
      "epoch 55 | loss: 0.00958 | mse_mse: 0.00943 |  0:02:42s\n",
      "epoch 56 | loss: 0.01044 | mse_mse: 0.00734 |  0:02:45s\n",
      "epoch 57 | loss: 0.01023 | mse_mse: 0.00879 |  0:02:48s\n",
      "epoch 58 | loss: 0.01157 | mse_mse: 0.01331 |  0:02:51s\n",
      "epoch 59 | loss: 0.01027 | mse_mse: 0.01426 |  0:02:54s\n",
      "epoch 60 | loss: 0.0102  | mse_mse: 0.00729 |  0:02:56s\n",
      "epoch 61 | loss: 0.0124  | mse_mse: 0.01009 |  0:02:59s\n",
      "epoch 62 | loss: 0.00968 | mse_mse: 0.00915 |  0:03:02s\n",
      "epoch 63 | loss: 0.01028 | mse_mse: 0.00906 |  0:03:05s\n",
      "epoch 64 | loss: 0.00895 | mse_mse: 0.00776 |  0:03:08s\n",
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 54 and best_mse_mse = 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0072965562134163844\n",
      "R2 Score: 0.9670831199759583\n",
      "\n",
      "Iteration 22/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.60898 | mse_mse: 0.75709 |  0:00:03s\n",
      "epoch 1  | loss: 0.33436 | mse_mse: 0.32029 |  0:00:06s\n",
      "epoch 2  | loss: 0.29548 | mse_mse: 0.4094  |  0:00:09s\n",
      "epoch 3  | loss: 0.27277 | mse_mse: 0.28252 |  0:00:12s\n",
      "epoch 4  | loss: 0.25869 | mse_mse: 0.25142 |  0:00:15s\n",
      "epoch 5  | loss: 0.24334 | mse_mse: 0.26474 |  0:00:18s\n",
      "epoch 6  | loss: 0.23876 | mse_mse: 0.2361  |  0:00:21s\n",
      "epoch 7  | loss: 0.24635 | mse_mse: 0.21739 |  0:00:25s\n",
      "epoch 8  | loss: 0.24763 | mse_mse: 0.25043 |  0:00:28s\n",
      "epoch 9  | loss: 0.23327 | mse_mse: 0.21961 |  0:00:31s\n",
      "epoch 10 | loss: 0.2258  | mse_mse: 0.20314 |  0:00:34s\n",
      "epoch 11 | loss: 0.22884 | mse_mse: 0.21888 |  0:00:37s\n",
      "epoch 12 | loss: 0.2198  | mse_mse: 0.1999  |  0:00:40s\n",
      "epoch 13 | loss: 0.21741 | mse_mse: 0.20053 |  0:00:43s\n",
      "epoch 14 | loss: 0.22166 | mse_mse: 0.20486 |  0:00:46s\n",
      "epoch 15 | loss: 0.21528 | mse_mse: 0.20584 |  0:00:50s\n",
      "epoch 16 | loss: 0.21698 | mse_mse: 0.20345 |  0:00:53s\n",
      "epoch 17 | loss: 0.21985 | mse_mse: 0.2244  |  0:00:56s\n",
      "epoch 18 | loss: 0.21027 | mse_mse: 0.19482 |  0:00:59s\n",
      "epoch 19 | loss: 0.20661 | mse_mse: 0.18967 |  0:01:02s\n",
      "epoch 20 | loss: 0.20626 | mse_mse: 0.18512 |  0:01:05s\n",
      "epoch 21 | loss: 0.18877 | mse_mse: 0.16752 |  0:01:08s\n",
      "epoch 22 | loss: 0.16475 | mse_mse: 0.13949 |  0:01:12s\n",
      "epoch 23 | loss: 0.15927 | mse_mse: 0.10765 |  0:01:15s\n",
      "epoch 24 | loss: 0.11203 | mse_mse: 0.09234 |  0:01:18s\n",
      "epoch 25 | loss: 0.09139 | mse_mse: 0.07955 |  0:01:22s\n",
      "epoch 26 | loss: 0.07337 | mse_mse: 0.0618  |  0:01:25s\n",
      "epoch 27 | loss: 0.06007 | mse_mse: 0.05865 |  0:01:28s\n",
      "epoch 28 | loss: 0.06038 | mse_mse: 0.06016 |  0:01:31s\n",
      "epoch 29 | loss: 0.05265 | mse_mse: 0.03946 |  0:01:34s\n",
      "epoch 30 | loss: 0.03882 | mse_mse: 0.03888 |  0:01:37s\n",
      "epoch 31 | loss: 0.03736 | mse_mse: 0.03194 |  0:01:40s\n",
      "epoch 32 | loss: 0.0339  | mse_mse: 0.02962 |  0:01:44s\n",
      "epoch 33 | loss: 0.03287 | mse_mse: 0.02968 |  0:01:47s\n",
      "epoch 34 | loss: 0.02956 | mse_mse: 0.03669 |  0:01:50s\n",
      "epoch 35 | loss: 0.03267 | mse_mse: 0.02282 |  0:01:53s\n",
      "epoch 36 | loss: 0.0259  | mse_mse: 0.02354 |  0:01:56s\n",
      "epoch 37 | loss: 0.02855 | mse_mse: 0.04135 |  0:01:59s\n",
      "epoch 38 | loss: 0.03357 | mse_mse: 0.02394 |  0:02:02s\n",
      "epoch 39 | loss: 0.02439 | mse_mse: 0.01835 |  0:02:05s\n",
      "epoch 40 | loss: 0.02088 | mse_mse: 0.02709 |  0:02:09s\n",
      "epoch 41 | loss: 0.02239 | mse_mse: 0.03383 |  0:02:12s\n",
      "epoch 42 | loss: 0.02801 | mse_mse: 0.01422 |  0:02:15s\n",
      "epoch 43 | loss: 0.01907 | mse_mse: 0.01503 |  0:02:18s\n",
      "epoch 44 | loss: 0.01697 | mse_mse: 0.01457 |  0:02:21s\n",
      "epoch 45 | loss: 0.01486 | mse_mse: 0.01174 |  0:02:24s\n",
      "epoch 46 | loss: 0.01657 | mse_mse: 0.01123 |  0:02:27s\n",
      "epoch 47 | loss: 0.01473 | mse_mse: 0.01134 |  0:02:30s\n",
      "epoch 48 | loss: 0.01453 | mse_mse: 0.01122 |  0:02:33s\n",
      "epoch 49 | loss: 0.01428 | mse_mse: 0.02028 |  0:02:37s\n",
      "epoch 50 | loss: 0.01627 | mse_mse: 0.01004 |  0:02:40s\n",
      "epoch 51 | loss: 0.01366 | mse_mse: 0.00863 |  0:02:43s\n",
      "epoch 52 | loss: 0.01289 | mse_mse: 0.01206 |  0:02:46s\n",
      "epoch 53 | loss: 0.01615 | mse_mse: 0.02094 |  0:02:49s\n",
      "epoch 54 | loss: 0.01784 | mse_mse: 0.01145 |  0:02:52s\n",
      "epoch 55 | loss: 0.01199 | mse_mse: 0.00793 |  0:02:55s\n",
      "epoch 56 | loss: 0.0124  | mse_mse: 0.00862 |  0:02:58s\n",
      "epoch 57 | loss: 0.01486 | mse_mse: 0.01178 |  0:03:01s\n",
      "epoch 58 | loss: 0.01157 | mse_mse: 0.01217 |  0:03:04s\n",
      "epoch 59 | loss: 0.0122  | mse_mse: 0.00873 |  0:03:08s\n",
      "epoch 60 | loss: 0.01257 | mse_mse: 0.00949 |  0:03:11s\n",
      "epoch 61 | loss: 0.01291 | mse_mse: 0.01237 |  0:03:14s\n",
      "epoch 62 | loss: 0.01532 | mse_mse: 0.0158  |  0:03:17s\n",
      "epoch 63 | loss: 0.0121  | mse_mse: 0.01637 |  0:03:20s\n",
      "epoch 64 | loss: 0.01168 | mse_mse: 0.00829 |  0:03:23s\n",
      "epoch 65 | loss: 0.01168 | mse_mse: 0.00698 |  0:03:26s\n",
      "epoch 66 | loss: 0.01013 | mse_mse: 0.00811 |  0:03:30s\n",
      "epoch 67 | loss: 0.01548 | mse_mse: 0.01438 |  0:03:33s\n",
      "epoch 68 | loss: 0.01397 | mse_mse: 0.00937 |  0:03:36s\n",
      "epoch 69 | loss: 0.01151 | mse_mse: 0.01859 |  0:03:39s\n",
      "epoch 70 | loss: 0.01808 | mse_mse: 0.00703 |  0:03:42s\n",
      "epoch 71 | loss: 0.01198 | mse_mse: 0.01135 |  0:03:45s\n",
      "epoch 72 | loss: 0.00942 | mse_mse: 0.00752 |  0:03:48s\n",
      "epoch 73 | loss: 0.01065 | mse_mse: 0.01111 |  0:03:51s\n",
      "epoch 74 | loss: 0.00929 | mse_mse: 0.01397 |  0:03:54s\n",
      "epoch 75 | loss: 0.01251 | mse_mse: 0.01419 |  0:03:57s\n",
      "\n",
      "Early stopping occurred at epoch 75 with best_epoch = 65 and best_mse_mse = 0.00698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0072911721856763236\n",
      "R2 Score: 0.9671074088856826\n",
      "\n",
      "Iteration 23/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.92392 | mse_mse: 0.56532 |  0:00:03s\n",
      "epoch 1  | loss: 0.34563 | mse_mse: 0.40921 |  0:00:07s\n",
      "epoch 2  | loss: 0.34411 | mse_mse: 0.25725 |  0:00:11s\n",
      "epoch 3  | loss: 0.31674 | mse_mse: 0.27694 |  0:00:16s\n",
      "epoch 4  | loss: 0.27964 | mse_mse: 0.23777 |  0:00:21s\n",
      "epoch 5  | loss: 0.27678 | mse_mse: 0.28126 |  0:00:25s\n",
      "epoch 6  | loss: 0.24629 | mse_mse: 0.30768 |  0:00:30s\n",
      "epoch 7  | loss: 0.27052 | mse_mse: 0.22643 |  0:00:34s\n",
      "epoch 8  | loss: 0.25078 | mse_mse: 0.2497  |  0:00:39s\n",
      "epoch 9  | loss: 0.24644 | mse_mse: 0.22194 |  0:00:43s\n",
      "epoch 10 | loss: 0.23935 | mse_mse: 0.23396 |  0:00:48s\n",
      "epoch 11 | loss: 0.2368  | mse_mse: 0.2203  |  0:00:53s\n",
      "epoch 12 | loss: 0.23819 | mse_mse: 0.2356  |  0:00:57s\n",
      "epoch 13 | loss: 0.24022 | mse_mse: 0.22984 |  0:01:01s\n",
      "epoch 14 | loss: 0.24042 | mse_mse: 0.22959 |  0:01:05s\n",
      "epoch 15 | loss: 0.24356 | mse_mse: 0.2216  |  0:01:09s\n",
      "epoch 16 | loss: 0.25677 | mse_mse: 0.22349 |  0:01:13s\n",
      "epoch 17 | loss: 0.24146 | mse_mse: 0.22018 |  0:01:18s\n",
      "epoch 18 | loss: 0.24726 | mse_mse: 0.22298 |  0:01:22s\n",
      "epoch 19 | loss: 0.23893 | mse_mse: 0.23643 |  0:01:26s\n",
      "epoch 20 | loss: 0.23615 | mse_mse: 0.22582 |  0:01:31s\n",
      "epoch 21 | loss: 0.24001 | mse_mse: 0.22552 |  0:01:35s\n",
      "epoch 22 | loss: 0.23857 | mse_mse: 0.21662 |  0:01:47s\n",
      "epoch 23 | loss: 0.23673 | mse_mse: 0.21706 |  0:01:52s\n",
      "epoch 24 | loss: 0.23465 | mse_mse: 0.21588 |  0:01:56s\n",
      "epoch 25 | loss: 0.23646 | mse_mse: 0.21535 |  0:02:00s\n",
      "epoch 26 | loss: 0.23215 | mse_mse: 0.2207  |  0:02:04s\n",
      "epoch 27 | loss: 0.22175 | mse_mse: 0.20893 |  0:02:08s\n",
      "epoch 28 | loss: 0.21722 | mse_mse: 0.19261 |  0:02:13s\n",
      "epoch 29 | loss: 0.19426 | mse_mse: 0.16042 |  0:02:17s\n",
      "epoch 30 | loss: 0.15786 | mse_mse: 0.12994 |  0:02:21s\n",
      "epoch 31 | loss: 0.14007 | mse_mse: 0.13682 |  0:02:24s\n",
      "epoch 32 | loss: 0.13562 | mse_mse: 0.10788 |  0:02:28s\n",
      "epoch 33 | loss: 0.12885 | mse_mse: 0.10216 |  0:02:33s\n",
      "epoch 34 | loss: 0.12452 | mse_mse: 0.09433 |  0:02:38s\n",
      "epoch 35 | loss: 0.10141 | mse_mse: 0.08533 |  0:02:41s\n",
      "epoch 36 | loss: 0.10224 | mse_mse: 0.08268 |  0:02:46s\n",
      "epoch 37 | loss: 0.08718 | mse_mse: 0.07944 |  0:02:51s\n",
      "epoch 38 | loss: 0.08116 | mse_mse: 0.06867 |  0:02:55s\n",
      "epoch 39 | loss: 0.07433 | mse_mse: 0.05684 |  0:02:59s\n",
      "epoch 40 | loss: 0.07116 | mse_mse: 0.04784 |  0:03:03s\n",
      "epoch 41 | loss: 0.05551 | mse_mse: 0.07413 |  0:03:06s\n",
      "epoch 42 | loss: 0.05094 | mse_mse: 0.06682 |  0:03:10s\n",
      "epoch 43 | loss: 0.05082 | mse_mse: 0.03576 |  0:03:13s\n",
      "epoch 44 | loss: 0.04957 | mse_mse: 0.03564 |  0:03:17s\n",
      "epoch 45 | loss: 0.04351 | mse_mse: 0.05609 |  0:03:21s\n",
      "epoch 46 | loss: 0.03869 | mse_mse: 0.03303 |  0:03:24s\n",
      "epoch 47 | loss: 0.03777 | mse_mse: 0.05094 |  0:03:28s\n",
      "epoch 48 | loss: 0.03918 | mse_mse: 0.03573 |  0:03:31s\n",
      "epoch 49 | loss: 0.03904 | mse_mse: 0.02711 |  0:03:35s\n",
      "epoch 50 | loss: 0.03217 | mse_mse: 0.03735 |  0:03:38s\n",
      "epoch 51 | loss: 0.03406 | mse_mse: 0.05176 |  0:03:42s\n",
      "epoch 52 | loss: 0.03169 | mse_mse: 0.02404 |  0:03:45s\n",
      "epoch 53 | loss: 0.02712 | mse_mse: 0.02851 |  0:03:49s\n",
      "epoch 54 | loss: 0.026   | mse_mse: 0.02955 |  0:03:53s\n",
      "epoch 55 | loss: 0.02359 | mse_mse: 0.02254 |  0:03:56s\n",
      "epoch 56 | loss: 0.02884 | mse_mse: 0.03626 |  0:04:00s\n",
      "epoch 57 | loss: 0.02814 | mse_mse: 0.01906 |  0:04:04s\n",
      "epoch 58 | loss: 0.03195 | mse_mse: 0.05023 |  0:04:07s\n",
      "epoch 59 | loss: 0.02579 | mse_mse: 0.01656 |  0:04:11s\n",
      "epoch 60 | loss: 0.02182 | mse_mse: 0.01611 |  0:04:14s\n",
      "epoch 61 | loss: 0.02389 | mse_mse: 0.01514 |  0:04:18s\n",
      "epoch 62 | loss: 0.01923 | mse_mse: 0.0163  |  0:04:21s\n",
      "epoch 63 | loss: 0.02063 | mse_mse: 0.01224 |  0:04:25s\n",
      "epoch 64 | loss: 0.01697 | mse_mse: 0.01386 |  0:04:29s\n",
      "epoch 65 | loss: 0.01737 | mse_mse: 0.01606 |  0:04:32s\n",
      "epoch 66 | loss: 0.02009 | mse_mse: 0.01353 |  0:04:36s\n",
      "epoch 67 | loss: 0.02291 | mse_mse: 0.01898 |  0:04:40s\n",
      "epoch 68 | loss: 0.01851 | mse_mse: 0.01158 |  0:04:43s\n",
      "epoch 69 | loss: 0.01772 | mse_mse: 0.01207 |  0:04:47s\n",
      "epoch 70 | loss: 0.01873 | mse_mse: 0.01459 |  0:04:51s\n",
      "epoch 71 | loss: 0.01821 | mse_mse: 0.03586 |  0:04:55s\n",
      "epoch 72 | loss: 0.01878 | mse_mse: 0.01317 |  0:04:59s\n",
      "epoch 73 | loss: 0.02716 | mse_mse: 0.0202  |  0:05:03s\n",
      "epoch 74 | loss: 0.02111 | mse_mse: 0.01662 |  0:05:07s\n",
      "epoch 75 | loss: 0.01738 | mse_mse: 0.01171 |  0:05:11s\n",
      "epoch 76 | loss: 0.01511 | mse_mse: 0.01119 |  0:05:15s\n",
      "epoch 77 | loss: 0.01753 | mse_mse: 0.01515 |  0:05:19s\n",
      "epoch 78 | loss: 0.01714 | mse_mse: 0.00971 |  0:05:23s\n",
      "epoch 79 | loss: 0.01275 | mse_mse: 0.01622 |  0:05:27s\n",
      "epoch 80 | loss: 0.0149  | mse_mse: 0.01247 |  0:05:31s\n",
      "epoch 81 | loss: 0.01416 | mse_mse: 0.00938 |  0:05:34s\n",
      "epoch 82 | loss: 0.01337 | mse_mse: 0.01112 |  0:05:38s\n",
      "epoch 83 | loss: 0.01298 | mse_mse: 0.0095  |  0:05:42s\n",
      "epoch 84 | loss: 0.01232 | mse_mse: 0.00775 |  0:05:46s\n",
      "epoch 85 | loss: 0.01223 | mse_mse: 0.01168 |  0:05:50s\n",
      "epoch 86 | loss: 0.01391 | mse_mse: 0.01961 |  0:05:53s\n",
      "epoch 87 | loss: 0.01243 | mse_mse: 0.01131 |  0:05:57s\n",
      "epoch 88 | loss: 0.01339 | mse_mse: 0.01922 |  0:06:01s\n",
      "epoch 89 | loss: 0.0133  | mse_mse: 0.00853 |  0:06:05s\n",
      "epoch 90 | loss: 0.01736 | mse_mse: 0.00769 |  0:06:09s\n",
      "epoch 91 | loss: 0.01271 | mse_mse: 0.0076  |  0:06:13s\n",
      "epoch 92 | loss: 0.01041 | mse_mse: 0.0079  |  0:06:17s\n",
      "epoch 93 | loss: 0.01164 | mse_mse: 0.01016 |  0:06:21s\n",
      "epoch 94 | loss: 0.01275 | mse_mse: 0.02745 |  0:06:25s\n",
      "epoch 95 | loss: 0.01242 | mse_mse: 0.00753 |  0:06:29s\n",
      "epoch 96 | loss: 0.01196 | mse_mse: 0.0099  |  0:06:33s\n",
      "epoch 97 | loss: 0.01096 | mse_mse: 0.01368 |  0:06:37s\n",
      "epoch 98 | loss: 0.01364 | mse_mse: 0.01043 |  0:06:41s\n",
      "epoch 99 | loss: 0.01292 | mse_mse: 0.00793 |  0:06:45s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 95 and best_mse_mse = 0.00753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008428790060934844\n",
      "R2 Score: 0.9619752849058473\n",
      "\n",
      "Iteration 24/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.30371 | mse_mse: 0.50432 |  0:00:04s\n",
      "epoch 1  | loss: 0.41319 | mse_mse: 0.43114 |  0:00:08s\n",
      "epoch 2  | loss: 0.36507 | mse_mse: 0.49846 |  0:00:12s\n",
      "epoch 3  | loss: 0.33714 | mse_mse: 0.2801  |  0:00:16s\n",
      "epoch 4  | loss: 0.35656 | mse_mse: 0.27627 |  0:00:21s\n",
      "epoch 5  | loss: 0.38911 | mse_mse: 0.24991 |  0:00:25s\n",
      "epoch 6  | loss: 0.27234 | mse_mse: 0.24599 |  0:00:29s\n",
      "epoch 7  | loss: 0.23838 | mse_mse: 0.25097 |  0:00:33s\n",
      "epoch 8  | loss: 0.23835 | mse_mse: 0.25149 |  0:00:38s\n",
      "epoch 9  | loss: 0.23802 | mse_mse: 0.27065 |  0:00:42s\n",
      "epoch 10 | loss: 0.24115 | mse_mse: 0.26084 |  0:00:46s\n",
      "epoch 11 | loss: 0.23583 | mse_mse: 0.23474 |  0:00:50s\n",
      "epoch 12 | loss: 0.23051 | mse_mse: 0.24763 |  0:00:55s\n",
      "epoch 13 | loss: 0.23474 | mse_mse: 0.21517 |  0:00:59s\n",
      "epoch 14 | loss: 0.22797 | mse_mse: 0.20829 |  0:01:03s\n",
      "epoch 15 | loss: 0.22656 | mse_mse: 0.2091  |  0:01:07s\n",
      "epoch 16 | loss: 0.22642 | mse_mse: 0.214   |  0:01:11s\n",
      "epoch 17 | loss: 0.22968 | mse_mse: 0.22075 |  0:01:16s\n",
      "epoch 18 | loss: 0.23348 | mse_mse: 0.23101 |  0:01:20s\n",
      "epoch 19 | loss: 0.22489 | mse_mse: 0.21272 |  0:01:24s\n",
      "epoch 20 | loss: 0.22399 | mse_mse: 0.22641 |  0:01:28s\n",
      "epoch 21 | loss: 0.22447 | mse_mse: 0.20962 |  0:01:33s\n",
      "epoch 22 | loss: 0.21333 | mse_mse: 0.20041 |  0:01:37s\n",
      "epoch 23 | loss: 0.20017 | mse_mse: 0.17776 |  0:01:41s\n",
      "epoch 24 | loss: 0.18521 | mse_mse: 0.16061 |  0:01:45s\n",
      "epoch 25 | loss: 0.16984 | mse_mse: 0.15776 |  0:01:50s\n",
      "epoch 26 | loss: 0.15761 | mse_mse: 0.139   |  0:01:54s\n",
      "epoch 27 | loss: 0.14813 | mse_mse: 0.13149 |  0:01:58s\n",
      "epoch 28 | loss: 0.13336 | mse_mse: 0.1372  |  0:02:02s\n",
      "epoch 29 | loss: 0.11947 | mse_mse: 0.1221  |  0:02:07s\n",
      "epoch 30 | loss: 0.10363 | mse_mse: 0.10302 |  0:02:11s\n",
      "epoch 31 | loss: 0.08966 | mse_mse: 0.08406 |  0:02:15s\n",
      "epoch 32 | loss: 0.06615 | mse_mse: 0.06055 |  0:02:19s\n",
      "epoch 33 | loss: 0.05273 | mse_mse: 0.04536 |  0:02:24s\n",
      "epoch 34 | loss: 0.04342 | mse_mse: 0.03821 |  0:02:28s\n",
      "epoch 35 | loss: 0.04015 | mse_mse: 0.03205 |  0:02:32s\n",
      "epoch 36 | loss: 0.04192 | mse_mse: 0.03663 |  0:02:36s\n",
      "epoch 37 | loss: 0.03462 | mse_mse: 0.04859 |  0:02:41s\n",
      "epoch 38 | loss: 0.03312 | mse_mse: 0.03241 |  0:02:45s\n",
      "epoch 39 | loss: 0.02994 | mse_mse: 0.02421 |  0:02:49s\n",
      "epoch 40 | loss: 0.02859 | mse_mse: 0.02271 |  0:02:53s\n",
      "epoch 41 | loss: 0.03056 | mse_mse: 0.02875 |  0:02:57s\n",
      "epoch 42 | loss: 0.02734 | mse_mse: 0.0275  |  0:03:02s\n",
      "epoch 43 | loss: 0.02706 | mse_mse: 0.03296 |  0:03:06s\n",
      "epoch 44 | loss: 0.02814 | mse_mse: 0.02396 |  0:03:10s\n",
      "epoch 45 | loss: 0.0282  | mse_mse: 0.02326 |  0:03:14s\n",
      "epoch 46 | loss: 0.02359 | mse_mse: 0.01674 |  0:03:19s\n",
      "epoch 47 | loss: 0.01885 | mse_mse: 0.0154  |  0:03:23s\n",
      "epoch 48 | loss: 0.01912 | mse_mse: 0.0157  |  0:03:27s\n",
      "epoch 49 | loss: 0.01632 | mse_mse: 0.01544 |  0:03:31s\n",
      "epoch 50 | loss: 0.01916 | mse_mse: 0.02114 |  0:03:36s\n",
      "epoch 51 | loss: 0.02003 | mse_mse: 0.01395 |  0:03:40s\n",
      "epoch 52 | loss: 0.01887 | mse_mse: 0.01258 |  0:03:44s\n",
      "epoch 53 | loss: 0.01791 | mse_mse: 0.01419 |  0:03:48s\n",
      "epoch 54 | loss: 0.01964 | mse_mse: 0.01708 |  0:03:52s\n",
      "epoch 55 | loss: 0.01707 | mse_mse: 0.0173  |  0:03:57s\n",
      "epoch 56 | loss: 0.02047 | mse_mse: 0.01594 |  0:04:01s\n",
      "epoch 57 | loss: 0.01665 | mse_mse: 0.01126 |  0:04:05s\n",
      "epoch 58 | loss: 0.01475 | mse_mse: 0.01199 |  0:04:09s\n",
      "epoch 59 | loss: 0.01494 | mse_mse: 0.00976 |  0:04:14s\n",
      "epoch 60 | loss: 0.01477 | mse_mse: 0.009   |  0:04:18s\n",
      "epoch 61 | loss: 0.01345 | mse_mse: 0.01607 |  0:04:22s\n",
      "epoch 62 | loss: 0.01307 | mse_mse: 0.01217 |  0:04:26s\n",
      "epoch 63 | loss: 0.01627 | mse_mse: 0.18563 |  0:04:30s\n",
      "epoch 64 | loss: 0.01716 | mse_mse: 0.0174  |  0:04:35s\n",
      "epoch 65 | loss: 0.0134  | mse_mse: 0.01944 |  0:04:39s\n",
      "epoch 66 | loss: 0.01729 | mse_mse: 0.02267 |  0:04:43s\n",
      "epoch 67 | loss: 0.01487 | mse_mse: 0.01167 |  0:04:47s\n",
      "epoch 68 | loss: 0.01189 | mse_mse: 0.00736 |  0:04:52s\n",
      "epoch 69 | loss: 0.01149 | mse_mse: 0.00784 |  0:04:56s\n",
      "epoch 70 | loss: 0.01034 | mse_mse: 0.00696 |  0:05:00s\n",
      "epoch 71 | loss: 0.01614 | mse_mse: 0.00826 |  0:05:04s\n",
      "epoch 72 | loss: 0.01216 | mse_mse: 0.00854 |  0:05:09s\n",
      "epoch 73 | loss: 0.0137  | mse_mse: 0.01463 |  0:05:13s\n",
      "epoch 74 | loss: 0.01682 | mse_mse: 0.01196 |  0:05:17s\n",
      "epoch 75 | loss: 0.01084 | mse_mse: 0.00859 |  0:05:21s\n",
      "epoch 76 | loss: 0.01279 | mse_mse: 0.00998 |  0:05:26s\n",
      "epoch 77 | loss: 0.01117 | mse_mse: 0.00802 |  0:05:30s\n",
      "epoch 78 | loss: 0.00979 | mse_mse: 0.00803 |  0:05:34s\n",
      "epoch 79 | loss: 0.01195 | mse_mse: 0.0066  |  0:05:38s\n",
      "epoch 80 | loss: 0.02197 | mse_mse: 0.00688 |  0:05:43s\n",
      "epoch 81 | loss: 0.01417 | mse_mse: 0.00908 |  0:05:47s\n",
      "epoch 82 | loss: 0.00982 | mse_mse: 0.00735 |  0:05:51s\n",
      "epoch 83 | loss: 0.01233 | mse_mse: 0.00745 |  0:05:55s\n",
      "epoch 84 | loss: 0.0093  | mse_mse: 0.02387 |  0:05:59s\n",
      "epoch 85 | loss: 0.01146 | mse_mse: 0.00688 |  0:06:04s\n",
      "epoch 86 | loss: 0.01049 | mse_mse: 0.00959 |  0:06:08s\n",
      "epoch 87 | loss: 0.01022 | mse_mse: 0.00921 |  0:06:12s\n",
      "epoch 88 | loss: 0.01094 | mse_mse: 0.00831 |  0:06:16s\n",
      "epoch 89 | loss: 0.00941 | mse_mse: 0.00754 |  0:06:21s\n",
      "\n",
      "Early stopping occurred at epoch 89 with best_epoch = 79 and best_mse_mse = 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007040448049889833\n",
      "R2 Score: 0.9682384981359291\n",
      "\n",
      "Iteration 25/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.84667 | mse_mse: 0.80342 |  0:00:01s\n",
      "epoch 1  | loss: 0.31524 | mse_mse: 0.333   |  0:00:03s\n",
      "epoch 2  | loss: 0.25857 | mse_mse: 0.23704 |  0:00:05s\n",
      "epoch 3  | loss: 0.2377  | mse_mse: 0.21526 |  0:00:07s\n",
      "epoch 4  | loss: 0.213   | mse_mse: 0.17985 |  0:00:09s\n",
      "epoch 5  | loss: 0.17517 | mse_mse: 0.16808 |  0:00:11s\n",
      "epoch 6  | loss: 0.1332  | mse_mse: 0.15683 |  0:00:13s\n",
      "epoch 7  | loss: 0.10527 | mse_mse: 0.11308 |  0:00:15s\n",
      "epoch 8  | loss: 0.08809 | mse_mse: 0.07459 |  0:00:16s\n",
      "epoch 9  | loss: 0.07745 | mse_mse: 0.06657 |  0:00:19s\n",
      "epoch 10 | loss: 0.0712  | mse_mse: 0.05514 |  0:00:21s\n",
      "epoch 11 | loss: 0.06252 | mse_mse: 0.06596 |  0:00:22s\n",
      "epoch 12 | loss: 0.05073 | mse_mse: 0.03409 |  0:00:24s\n",
      "epoch 13 | loss: 0.0413  | mse_mse: 0.03063 |  0:00:26s\n",
      "epoch 14 | loss: 0.03505 | mse_mse: 0.02751 |  0:00:28s\n",
      "epoch 15 | loss: 0.0312  | mse_mse: 0.0277  |  0:00:30s\n",
      "epoch 16 | loss: 0.02944 | mse_mse: 0.02163 |  0:00:32s\n",
      "epoch 17 | loss: 0.02727 | mse_mse: 0.02378 |  0:00:34s\n",
      "epoch 18 | loss: 0.02276 | mse_mse: 0.01938 |  0:00:35s\n",
      "epoch 19 | loss: 0.02066 | mse_mse: 0.01815 |  0:00:37s\n",
      "epoch 20 | loss: 0.02619 | mse_mse: 0.01704 |  0:00:39s\n",
      "epoch 21 | loss: 0.02324 | mse_mse: 0.01577 |  0:00:41s\n",
      "epoch 22 | loss: 0.01958 | mse_mse: 0.01531 |  0:00:43s\n",
      "epoch 23 | loss: 0.01965 | mse_mse: 0.01466 |  0:00:45s\n",
      "epoch 24 | loss: 0.01778 | mse_mse: 0.01347 |  0:00:47s\n",
      "epoch 25 | loss: 0.01438 | mse_mse: 0.01645 |  0:00:49s\n",
      "epoch 26 | loss: 0.01586 | mse_mse: 0.0138  |  0:00:51s\n",
      "epoch 27 | loss: 0.01326 | mse_mse: 0.0124  |  0:00:52s\n",
      "epoch 28 | loss: 0.01432 | mse_mse: 0.00983 |  0:00:54s\n",
      "epoch 29 | loss: 0.01514 | mse_mse: 0.01185 |  0:00:56s\n",
      "epoch 30 | loss: 0.01378 | mse_mse: 0.01025 |  0:00:58s\n",
      "epoch 31 | loss: 0.01413 | mse_mse: 0.01083 |  0:01:00s\n",
      "epoch 32 | loss: 0.01359 | mse_mse: 0.01244 |  0:01:02s\n",
      "epoch 33 | loss: 0.01567 | mse_mse: 0.0105  |  0:01:04s\n",
      "epoch 34 | loss: 0.01924 | mse_mse: 0.01109 |  0:01:05s\n",
      "epoch 35 | loss: 0.01343 | mse_mse: 0.01114 |  0:01:07s\n",
      "epoch 36 | loss: 0.01594 | mse_mse: 0.00877 |  0:01:09s\n",
      "epoch 37 | loss: 0.01156 | mse_mse: 0.0087  |  0:01:11s\n",
      "epoch 38 | loss: 0.01417 | mse_mse: 0.0106  |  0:01:13s\n",
      "epoch 39 | loss: 0.01196 | mse_mse: 0.00828 |  0:01:15s\n",
      "epoch 40 | loss: 0.01159 | mse_mse: 0.01425 |  0:01:17s\n",
      "epoch 41 | loss: 0.01097 | mse_mse: 0.00826 |  0:01:19s\n",
      "epoch 42 | loss: 0.01227 | mse_mse: 0.01337 |  0:01:21s\n",
      "epoch 43 | loss: 0.01254 | mse_mse: 0.00971 |  0:01:22s\n",
      "epoch 44 | loss: 0.01292 | mse_mse: 0.00997 |  0:01:24s\n",
      "epoch 45 | loss: 0.01163 | mse_mse: 0.02339 |  0:01:26s\n",
      "epoch 46 | loss: 0.01175 | mse_mse: 0.01005 |  0:01:28s\n",
      "epoch 47 | loss: 0.01321 | mse_mse: 0.00761 |  0:01:30s\n",
      "epoch 48 | loss: 0.01183 | mse_mse: 0.01196 |  0:01:32s\n",
      "epoch 49 | loss: 0.01097 | mse_mse: 0.00954 |  0:01:34s\n",
      "epoch 50 | loss: 0.0093  | mse_mse: 0.00959 |  0:01:36s\n",
      "epoch 51 | loss: 0.01034 | mse_mse: 0.00977 |  0:01:37s\n",
      "epoch 52 | loss: 0.01195 | mse_mse: 0.0101  |  0:01:39s\n",
      "epoch 53 | loss: 0.00909 | mse_mse: 0.01048 |  0:01:41s\n",
      "epoch 54 | loss: 0.01038 | mse_mse: 0.00849 |  0:01:43s\n",
      "epoch 55 | loss: 0.01359 | mse_mse: 0.0153  |  0:01:45s\n",
      "epoch 56 | loss: 0.01208 | mse_mse: 0.00927 |  0:01:47s\n",
      "epoch 57 | loss: 0.00961 | mse_mse: 0.00803 |  0:01:49s\n",
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 47 and best_mse_mse = 0.00761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008436655718108546\n",
      "R2 Score: 0.9619398006464345\n",
      "\n",
      "Iteration 26/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.36598 | mse_mse: 0.74356 |  0:00:01s\n",
      "epoch 1  | loss: 0.29815 | mse_mse: 0.4978  |  0:00:03s\n",
      "epoch 2  | loss: 0.2459  | mse_mse: 0.21711 |  0:00:06s\n",
      "epoch 3  | loss: 0.18924 | mse_mse: 0.132   |  0:00:08s\n",
      "epoch 4  | loss: 0.14384 | mse_mse: 0.10471 |  0:00:10s\n",
      "epoch 5  | loss: 0.12116 | mse_mse: 0.09723 |  0:00:12s\n",
      "epoch 6  | loss: 0.10987 | mse_mse: 0.08485 |  0:00:13s\n",
      "epoch 7  | loss: 0.10549 | mse_mse: 0.08861 |  0:00:15s\n",
      "epoch 8  | loss: 0.09783 | mse_mse: 0.07981 |  0:00:18s\n",
      "epoch 9  | loss: 0.0948  | mse_mse: 0.07429 |  0:00:20s\n",
      "epoch 10 | loss: 0.09324 | mse_mse: 0.07588 |  0:00:22s\n",
      "epoch 11 | loss: 0.08474 | mse_mse: 0.07076 |  0:00:24s\n",
      "epoch 12 | loss: 0.08698 | mse_mse: 0.08251 |  0:00:26s\n",
      "epoch 13 | loss: 0.08363 | mse_mse: 0.07021 |  0:00:28s\n",
      "epoch 14 | loss: 0.07851 | mse_mse: 0.06738 |  0:00:30s\n",
      "epoch 15 | loss: 0.07558 | mse_mse: 0.06417 |  0:00:32s\n",
      "epoch 16 | loss: 0.07354 | mse_mse: 0.06621 |  0:00:34s\n",
      "epoch 17 | loss: 0.06969 | mse_mse: 0.06014 |  0:00:36s\n",
      "epoch 18 | loss: 0.0727  | mse_mse: 0.06237 |  0:00:38s\n",
      "epoch 19 | loss: 0.06323 | mse_mse: 0.06051 |  0:00:40s\n",
      "epoch 20 | loss: 0.06207 | mse_mse: 0.05064 |  0:00:42s\n",
      "epoch 21 | loss: 0.05725 | mse_mse: 0.0511  |  0:00:44s\n",
      "epoch 22 | loss: 0.05726 | mse_mse: 0.04821 |  0:00:46s\n",
      "epoch 23 | loss: 0.05045 | mse_mse: 0.04513 |  0:00:48s\n",
      "epoch 24 | loss: 0.04698 | mse_mse: 0.04632 |  0:00:50s\n",
      "epoch 25 | loss: 0.04434 | mse_mse: 0.04132 |  0:00:52s\n",
      "epoch 26 | loss: 0.04354 | mse_mse: 0.03701 |  0:00:54s\n",
      "epoch 27 | loss: 0.04625 | mse_mse: 0.03449 |  0:00:56s\n",
      "epoch 28 | loss: 0.03664 | mse_mse: 0.03229 |  0:00:58s\n",
      "epoch 29 | loss: 0.03463 | mse_mse: 0.0301  |  0:01:00s\n",
      "epoch 30 | loss: 0.03751 | mse_mse: 0.0296  |  0:01:02s\n",
      "epoch 31 | loss: 0.03175 | mse_mse: 0.02503 |  0:01:04s\n",
      "epoch 32 | loss: 0.03274 | mse_mse: 0.03916 |  0:01:06s\n",
      "epoch 33 | loss: 0.03012 | mse_mse: 0.03151 |  0:01:08s\n",
      "epoch 34 | loss: 0.02774 | mse_mse: 0.02994 |  0:01:10s\n",
      "epoch 35 | loss: 0.02609 | mse_mse: 0.02263 |  0:01:12s\n",
      "epoch 36 | loss: 0.02498 | mse_mse: 0.02282 |  0:01:14s\n",
      "epoch 37 | loss: 0.02376 | mse_mse: 0.02331 |  0:01:16s\n",
      "epoch 38 | loss: 0.02191 | mse_mse: 0.01683 |  0:01:18s\n",
      "epoch 39 | loss: 0.02358 | mse_mse: 0.01558 |  0:01:20s\n",
      "epoch 40 | loss: 0.0199  | mse_mse: 0.01612 |  0:01:22s\n",
      "epoch 41 | loss: 0.01801 | mse_mse: 0.03097 |  0:01:24s\n",
      "epoch 42 | loss: 0.01966 | mse_mse: 0.01613 |  0:01:26s\n",
      "epoch 43 | loss: 0.01614 | mse_mse: 0.01412 |  0:01:28s\n",
      "epoch 44 | loss: 0.0165  | mse_mse: 0.02539 |  0:01:30s\n",
      "epoch 45 | loss: 0.0195  | mse_mse: 0.01951 |  0:01:32s\n",
      "epoch 46 | loss: 0.02117 | mse_mse: 0.01553 |  0:01:34s\n",
      "epoch 47 | loss: 0.01606 | mse_mse: 0.01234 |  0:01:36s\n",
      "epoch 48 | loss: 0.0149  | mse_mse: 0.02122 |  0:01:38s\n",
      "epoch 49 | loss: 0.01426 | mse_mse: 0.01143 |  0:01:40s\n",
      "epoch 50 | loss: 0.01359 | mse_mse: 0.01615 |  0:01:42s\n",
      "epoch 51 | loss: 0.01578 | mse_mse: 0.01427 |  0:01:44s\n",
      "epoch 52 | loss: 0.01487 | mse_mse: 0.01028 |  0:01:46s\n",
      "epoch 53 | loss: 0.01239 | mse_mse: 0.01025 |  0:01:48s\n",
      "epoch 54 | loss: 0.01182 | mse_mse: 0.00995 |  0:01:50s\n",
      "epoch 55 | loss: 0.01223 | mse_mse: 0.01104 |  0:01:53s\n",
      "epoch 56 | loss: 0.01322 | mse_mse: 0.00941 |  0:01:55s\n",
      "epoch 57 | loss: 0.0136  | mse_mse: 0.01179 |  0:01:56s\n",
      "epoch 58 | loss: 0.01164 | mse_mse: 0.00945 |  0:01:59s\n",
      "epoch 59 | loss: 0.01253 | mse_mse: 0.0229  |  0:02:01s\n",
      "epoch 60 | loss: 0.01179 | mse_mse: 0.01195 |  0:02:03s\n",
      "epoch 61 | loss: 0.01155 | mse_mse: 0.01364 |  0:02:05s\n",
      "epoch 62 | loss: 0.01097 | mse_mse: 0.0093  |  0:02:07s\n",
      "epoch 63 | loss: 0.01189 | mse_mse: 0.01385 |  0:02:09s\n",
      "epoch 64 | loss: 0.01266 | mse_mse: 0.01844 |  0:02:11s\n",
      "epoch 65 | loss: 0.01587 | mse_mse: 0.00963 |  0:02:13s\n",
      "epoch 66 | loss: 0.01013 | mse_mse: 0.00989 |  0:02:15s\n",
      "epoch 67 | loss: 0.01046 | mse_mse: 0.00843 |  0:02:16s\n",
      "epoch 68 | loss: 0.00943 | mse_mse: 0.01102 |  0:02:19s\n",
      "epoch 69 | loss: 0.00938 | mse_mse: 0.00985 |  0:02:21s\n",
      "epoch 70 | loss: 0.013   | mse_mse: 0.00982 |  0:02:23s\n",
      "epoch 71 | loss: 0.01174 | mse_mse: 0.00775 |  0:02:25s\n",
      "epoch 72 | loss: 0.00939 | mse_mse: 0.00689 |  0:02:27s\n",
      "epoch 73 | loss: 0.00949 | mse_mse: 0.02407 |  0:02:29s\n",
      "epoch 74 | loss: 0.01273 | mse_mse: 0.01233 |  0:02:31s\n",
      "epoch 75 | loss: 0.00983 | mse_mse: 0.01816 |  0:02:32s\n",
      "epoch 76 | loss: 0.01104 | mse_mse: 0.00746 |  0:02:34s\n",
      "epoch 77 | loss: 0.00804 | mse_mse: 0.01048 |  0:02:37s\n",
      "epoch 78 | loss: 0.00779 | mse_mse: 0.00816 |  0:02:39s\n",
      "epoch 79 | loss: 0.00751 | mse_mse: 0.01302 |  0:02:41s\n",
      "epoch 80 | loss: 0.00924 | mse_mse: 0.00776 |  0:02:43s\n",
      "epoch 81 | loss: 0.00795 | mse_mse: 0.0074  |  0:02:45s\n",
      "epoch 82 | loss: 0.00746 | mse_mse: 0.01177 |  0:02:47s\n",
      "\n",
      "Early stopping occurred at epoch 82 with best_epoch = 72 and best_mse_mse = 0.00689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007245204728689761\n",
      "R2 Score: 0.9673147814080589\n",
      "\n",
      "Iteration 27/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.79493 | mse_mse: 1.05216 |  0:00:02s\n",
      "epoch 1  | loss: 0.37648 | mse_mse: 0.48047 |  0:00:05s\n",
      "epoch 2  | loss: 0.26645 | mse_mse: 0.20999 |  0:00:08s\n",
      "epoch 3  | loss: 0.17893 | mse_mse: 0.10538 |  0:00:11s\n",
      "epoch 4  | loss: 0.14768 | mse_mse: 0.1134  |  0:00:14s\n",
      "epoch 5  | loss: 0.14076 | mse_mse: 0.09718 |  0:00:17s\n",
      "epoch 6  | loss: 0.1196  | mse_mse: 0.13483 |  0:00:20s\n",
      "epoch 7  | loss: 0.11829 | mse_mse: 0.08014 |  0:00:23s\n",
      "epoch 8  | loss: 0.10797 | mse_mse: 0.08635 |  0:00:25s\n",
      "epoch 9  | loss: 0.10852 | mse_mse: 0.08203 |  0:00:28s\n",
      "epoch 10 | loss: 0.11642 | mse_mse: 0.09307 |  0:00:31s\n",
      "epoch 11 | loss: 0.10785 | mse_mse: 0.08754 |  0:00:34s\n",
      "epoch 12 | loss: 0.10858 | mse_mse: 0.09522 |  0:00:37s\n",
      "epoch 13 | loss: 0.11169 | mse_mse: 0.07872 |  0:00:40s\n",
      "epoch 14 | loss: 0.09954 | mse_mse: 0.08081 |  0:00:43s\n",
      "epoch 15 | loss: 0.09671 | mse_mse: 0.07419 |  0:00:46s\n",
      "epoch 16 | loss: 0.09587 | mse_mse: 0.08457 |  0:00:49s\n",
      "epoch 17 | loss: 0.08735 | mse_mse: 0.07441 |  0:00:52s\n",
      "epoch 18 | loss: 0.08268 | mse_mse: 0.07147 |  0:00:54s\n",
      "epoch 19 | loss: 0.08192 | mse_mse: 0.08358 |  0:00:57s\n",
      "epoch 20 | loss: 0.07845 | mse_mse: 0.07209 |  0:01:00s\n",
      "epoch 21 | loss: 0.07067 | mse_mse: 0.06014 |  0:01:03s\n",
      "epoch 22 | loss: 0.07069 | mse_mse: 0.06289 |  0:01:06s\n",
      "epoch 23 | loss: 0.06303 | mse_mse: 0.0663  |  0:01:09s\n",
      "epoch 24 | loss: 0.05888 | mse_mse: 0.05091 |  0:01:12s\n",
      "epoch 25 | loss: 0.0616  | mse_mse: 0.05236 |  0:01:15s\n",
      "epoch 26 | loss: 0.05046 | mse_mse: 0.04236 |  0:01:18s\n",
      "epoch 27 | loss: 0.04385 | mse_mse: 0.04548 |  0:01:21s\n",
      "epoch 28 | loss: 0.04043 | mse_mse: 0.03411 |  0:01:24s\n",
      "epoch 29 | loss: 0.03708 | mse_mse: 0.04067 |  0:01:27s\n",
      "epoch 30 | loss: 0.03465 | mse_mse: 0.03069 |  0:01:29s\n",
      "epoch 31 | loss: 0.0323  | mse_mse: 0.02697 |  0:01:32s\n",
      "epoch 32 | loss: 0.03115 | mse_mse: 0.02349 |  0:01:35s\n",
      "epoch 33 | loss: 0.02496 | mse_mse: 0.02524 |  0:01:38s\n",
      "epoch 34 | loss: 0.02586 | mse_mse: 0.01941 |  0:01:41s\n",
      "epoch 35 | loss: 0.02467 | mse_mse: 0.03571 |  0:01:44s\n",
      "epoch 36 | loss: 0.02574 | mse_mse: 0.01712 |  0:01:47s\n",
      "epoch 37 | loss: 0.02073 | mse_mse: 0.02404 |  0:01:50s\n",
      "epoch 38 | loss: 0.021   | mse_mse: 0.02291 |  0:01:53s\n",
      "epoch 39 | loss: 0.01951 | mse_mse: 0.01599 |  0:01:56s\n",
      "epoch 40 | loss: 0.02052 | mse_mse: 0.01609 |  0:01:58s\n",
      "epoch 41 | loss: 0.0174  | mse_mse: 0.01388 |  0:02:01s\n",
      "epoch 42 | loss: 0.01882 | mse_mse: 0.01799 |  0:02:04s\n",
      "epoch 43 | loss: 0.01883 | mse_mse: 0.01565 |  0:02:07s\n",
      "epoch 44 | loss: 0.01486 | mse_mse: 0.02131 |  0:02:10s\n",
      "epoch 45 | loss: 0.02026 | mse_mse: 0.02139 |  0:02:13s\n",
      "epoch 46 | loss: 0.01668 | mse_mse: 0.01373 |  0:02:16s\n",
      "epoch 47 | loss: 0.01505 | mse_mse: 0.01989 |  0:02:19s\n",
      "epoch 48 | loss: 0.01591 | mse_mse: 0.01568 |  0:02:22s\n",
      "epoch 49 | loss: 0.01711 | mse_mse: 0.01295 |  0:02:24s\n",
      "epoch 50 | loss: 0.0167  | mse_mse: 0.01899 |  0:02:27s\n",
      "epoch 51 | loss: 0.01654 | mse_mse: 0.01495 |  0:02:30s\n",
      "epoch 52 | loss: 0.01793 | mse_mse: 0.01124 |  0:02:33s\n",
      "epoch 53 | loss: 0.01385 | mse_mse: 0.01057 |  0:02:36s\n",
      "epoch 54 | loss: 0.01362 | mse_mse: 0.01118 |  0:02:39s\n",
      "epoch 55 | loss: 0.02094 | mse_mse: 0.01257 |  0:02:42s\n",
      "epoch 56 | loss: 0.01595 | mse_mse: 0.01222 |  0:02:45s\n",
      "epoch 57 | loss: 0.02213 | mse_mse: 0.01142 |  0:02:48s\n",
      "epoch 58 | loss: 0.02123 | mse_mse: 0.0207  |  0:02:51s\n",
      "epoch 59 | loss: 0.01867 | mse_mse: 0.0109  |  0:02:54s\n",
      "epoch 60 | loss: 0.01505 | mse_mse: 0.01175 |  0:02:56s\n",
      "epoch 61 | loss: 0.01759 | mse_mse: 0.01139 |  0:02:59s\n",
      "epoch 62 | loss: 0.01393 | mse_mse: 0.01065 |  0:03:02s\n",
      "epoch 63 | loss: 0.01425 | mse_mse: 0.00958 |  0:03:05s\n",
      "epoch 64 | loss: 0.01099 | mse_mse: 0.01852 |  0:03:08s\n",
      "epoch 65 | loss: 0.01146 | mse_mse: 0.01264 |  0:03:11s\n",
      "epoch 66 | loss: 0.01376 | mse_mse: 0.00905 |  0:03:14s\n",
      "epoch 67 | loss: 0.01145 | mse_mse: 0.00926 |  0:03:17s\n",
      "epoch 68 | loss: 0.0126  | mse_mse: 0.00953 |  0:03:20s\n",
      "epoch 69 | loss: 0.01625 | mse_mse: 0.01017 |  0:03:22s\n",
      "epoch 70 | loss: 0.01126 | mse_mse: 0.02212 |  0:03:25s\n",
      "epoch 71 | loss: 0.01562 | mse_mse: 0.01009 |  0:03:29s\n",
      "epoch 72 | loss: 0.01079 | mse_mse: 0.01568 |  0:03:31s\n",
      "epoch 73 | loss: 0.0129  | mse_mse: 0.01475 |  0:03:34s\n",
      "epoch 74 | loss: 0.01287 | mse_mse: 0.01223 |  0:03:37s\n",
      "epoch 75 | loss: 0.01087 | mse_mse: 0.00889 |  0:03:40s\n",
      "epoch 76 | loss: 0.01266 | mse_mse: 0.01046 |  0:03:43s\n",
      "epoch 77 | loss: 0.01169 | mse_mse: 0.00882 |  0:03:46s\n",
      "epoch 78 | loss: 0.01315 | mse_mse: 0.00943 |  0:03:49s\n",
      "epoch 79 | loss: 0.01048 | mse_mse: 0.01024 |  0:03:52s\n",
      "epoch 80 | loss: 0.01207 | mse_mse: 0.01123 |  0:03:54s\n",
      "epoch 81 | loss: 0.00957 | mse_mse: 0.01341 |  0:03:57s\n",
      "epoch 82 | loss: 0.00931 | mse_mse: 0.0094  |  0:04:00s\n",
      "epoch 83 | loss: 0.00966 | mse_mse: 0.01125 |  0:04:03s\n",
      "epoch 84 | loss: 0.0121  | mse_mse: 0.00792 |  0:04:06s\n",
      "epoch 85 | loss: 0.01118 | mse_mse: 0.00827 |  0:04:09s\n",
      "epoch 86 | loss: 0.01108 | mse_mse: 0.01195 |  0:04:12s\n",
      "epoch 87 | loss: 0.01336 | mse_mse: 0.00868 |  0:04:15s\n",
      "epoch 88 | loss: 0.00932 | mse_mse: 0.0083  |  0:04:18s\n",
      "epoch 89 | loss: 0.01398 | mse_mse: 0.01372 |  0:04:21s\n",
      "epoch 90 | loss: 0.01309 | mse_mse: 0.01005 |  0:04:24s\n",
      "epoch 91 | loss: 0.01095 | mse_mse: 0.01018 |  0:04:26s\n",
      "epoch 92 | loss: 0.01668 | mse_mse: 0.00803 |  0:04:29s\n",
      "epoch 93 | loss: 0.01472 | mse_mse: 0.01199 |  0:04:32s\n",
      "epoch 94 | loss: 0.01149 | mse_mse: 0.01069 |  0:04:35s\n",
      "\n",
      "Early stopping occurred at epoch 94 with best_epoch = 84 and best_mse_mse = 0.00792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008293747603658728\n",
      "R2 Score: 0.9625845005733887\n",
      "\n",
      "Iteration 28/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.73959 | mse_mse: 0.80659 |  0:00:03s\n",
      "epoch 1  | loss: 0.3799  | mse_mse: 0.33997 |  0:00:06s\n",
      "epoch 2  | loss: 0.23919 | mse_mse: 0.15493 |  0:00:09s\n",
      "epoch 3  | loss: 0.19658 | mse_mse: 0.14443 |  0:00:12s\n",
      "epoch 4  | loss: 0.1564  | mse_mse: 0.13501 |  0:00:15s\n",
      "epoch 5  | loss: 0.13282 | mse_mse: 0.11759 |  0:00:18s\n",
      "epoch 6  | loss: 0.12449 | mse_mse: 0.09859 |  0:00:21s\n",
      "epoch 7  | loss: 0.13048 | mse_mse: 0.09338 |  0:00:24s\n",
      "epoch 8  | loss: 0.12427 | mse_mse: 0.0969  |  0:00:27s\n",
      "epoch 9  | loss: 0.11804 | mse_mse: 0.08948 |  0:00:31s\n",
      "epoch 10 | loss: 0.11603 | mse_mse: 0.12064 |  0:00:34s\n",
      "epoch 11 | loss: 0.11963 | mse_mse: 0.0973  |  0:00:37s\n",
      "epoch 12 | loss: 0.11197 | mse_mse: 0.092   |  0:00:40s\n",
      "epoch 13 | loss: 0.11185 | mse_mse: 0.091   |  0:00:43s\n",
      "epoch 14 | loss: 0.11381 | mse_mse: 0.10759 |  0:00:46s\n",
      "epoch 15 | loss: 0.11804 | mse_mse: 0.09039 |  0:00:49s\n",
      "epoch 16 | loss: 0.11033 | mse_mse: 0.11459 |  0:00:52s\n",
      "epoch 17 | loss: 0.11498 | mse_mse: 0.08836 |  0:00:55s\n",
      "epoch 18 | loss: 0.10875 | mse_mse: 0.08708 |  0:00:59s\n",
      "epoch 19 | loss: 0.10339 | mse_mse: 0.09001 |  0:01:02s\n",
      "epoch 20 | loss: 0.1043  | mse_mse: 0.08802 |  0:01:05s\n",
      "epoch 21 | loss: 0.10516 | mse_mse: 0.08757 |  0:01:08s\n",
      "epoch 22 | loss: 0.10901 | mse_mse: 0.08927 |  0:01:11s\n",
      "epoch 23 | loss: 0.10076 | mse_mse: 0.08602 |  0:01:14s\n",
      "epoch 24 | loss: 0.10258 | mse_mse: 0.0852  |  0:01:17s\n",
      "epoch 25 | loss: 0.10045 | mse_mse: 0.08327 |  0:01:21s\n",
      "epoch 26 | loss: 0.0975  | mse_mse: 0.08047 |  0:01:24s\n",
      "epoch 27 | loss: 0.09456 | mse_mse: 0.08487 |  0:01:27s\n",
      "epoch 28 | loss: 0.09463 | mse_mse: 0.08493 |  0:01:30s\n",
      "epoch 29 | loss: 0.09373 | mse_mse: 0.07756 |  0:01:33s\n",
      "epoch 30 | loss: 0.08556 | mse_mse: 0.07109 |  0:01:36s\n",
      "epoch 31 | loss: 0.08186 | mse_mse: 0.06522 |  0:01:39s\n",
      "epoch 32 | loss: 0.07722 | mse_mse: 0.06262 |  0:01:42s\n",
      "epoch 33 | loss: 0.07381 | mse_mse: 0.06103 |  0:01:46s\n",
      "epoch 34 | loss: 0.07061 | mse_mse: 0.05954 |  0:01:49s\n",
      "epoch 35 | loss: 0.06637 | mse_mse: 0.05623 |  0:01:52s\n",
      "epoch 36 | loss: 0.06251 | mse_mse: 0.05518 |  0:01:55s\n",
      "epoch 37 | loss: 0.05738 | mse_mse: 0.05935 |  0:01:58s\n",
      "epoch 38 | loss: 0.05358 | mse_mse: 0.05286 |  0:02:01s\n",
      "epoch 39 | loss: 0.04885 | mse_mse: 0.04095 |  0:02:04s\n",
      "epoch 40 | loss: 0.04191 | mse_mse: 0.0335  |  0:02:08s\n",
      "epoch 41 | loss: 0.0384  | mse_mse: 0.03323 |  0:02:11s\n",
      "epoch 42 | loss: 0.03374 | mse_mse: 0.03383 |  0:02:14s\n",
      "epoch 43 | loss: 0.03216 | mse_mse: 0.02569 |  0:02:17s\n",
      "epoch 44 | loss: 0.0282  | mse_mse: 0.02447 |  0:02:20s\n",
      "epoch 45 | loss: 0.02765 | mse_mse: 0.02019 |  0:02:23s\n",
      "epoch 46 | loss: 0.02371 | mse_mse: 0.0207  |  0:02:26s\n",
      "epoch 47 | loss: 0.02474 | mse_mse: 0.02128 |  0:02:29s\n",
      "epoch 48 | loss: 0.0227  | mse_mse: 0.01901 |  0:02:33s\n",
      "epoch 49 | loss: 0.02155 | mse_mse: 0.01539 |  0:02:36s\n",
      "epoch 50 | loss: 0.0195  | mse_mse: 0.01546 |  0:02:39s\n",
      "epoch 51 | loss: 0.01755 | mse_mse: 0.01601 |  0:02:42s\n",
      "epoch 52 | loss: 0.01811 | mse_mse: 0.0142  |  0:02:45s\n",
      "epoch 53 | loss: 0.02022 | mse_mse: 0.0181  |  0:02:48s\n",
      "epoch 54 | loss: 0.01816 | mse_mse: 0.01405 |  0:02:51s\n",
      "epoch 55 | loss: 0.02132 | mse_mse: 0.02134 |  0:02:54s\n",
      "epoch 56 | loss: 0.0205  | mse_mse: 0.01498 |  0:02:58s\n",
      "epoch 57 | loss: 0.01492 | mse_mse: 0.01293 |  0:03:01s\n",
      "epoch 58 | loss: 0.01529 | mse_mse: 0.01175 |  0:03:04s\n",
      "epoch 59 | loss: 0.0195  | mse_mse: 0.02048 |  0:03:07s\n",
      "epoch 60 | loss: 0.01804 | mse_mse: 0.00988 |  0:03:10s\n",
      "epoch 61 | loss: 0.01375 | mse_mse: 0.01019 |  0:03:13s\n",
      "epoch 62 | loss: 0.01419 | mse_mse: 0.00948 |  0:03:17s\n",
      "epoch 63 | loss: 0.0129  | mse_mse: 0.01032 |  0:03:20s\n",
      "epoch 64 | loss: 0.01248 | mse_mse: 0.01063 |  0:03:23s\n",
      "epoch 65 | loss: 0.01269 | mse_mse: 0.00937 |  0:03:26s\n",
      "epoch 66 | loss: 0.01368 | mse_mse: 0.01307 |  0:03:29s\n",
      "epoch 67 | loss: 0.01284 | mse_mse: 0.01317 |  0:03:32s\n",
      "epoch 68 | loss: 0.0123  | mse_mse: 0.00981 |  0:03:35s\n",
      "epoch 69 | loss: 0.01199 | mse_mse: 0.00882 |  0:03:38s\n",
      "epoch 70 | loss: 0.01139 | mse_mse: 0.00999 |  0:03:42s\n",
      "epoch 71 | loss: 0.01861 | mse_mse: 0.01611 |  0:03:45s\n",
      "epoch 72 | loss: 0.01279 | mse_mse: 0.00792 |  0:03:48s\n",
      "epoch 73 | loss: 0.01014 | mse_mse: 0.00741 |  0:03:51s\n",
      "epoch 74 | loss: 0.0135  | mse_mse: 0.00796 |  0:03:54s\n",
      "epoch 75 | loss: 0.01308 | mse_mse: 0.00833 |  0:03:57s\n",
      "epoch 76 | loss: 0.01089 | mse_mse: 0.00779 |  0:04:00s\n",
      "epoch 77 | loss: 0.01045 | mse_mse: 0.01039 |  0:04:04s\n",
      "epoch 78 | loss: 0.0123  | mse_mse: 0.00961 |  0:04:07s\n",
      "epoch 79 | loss: 0.01242 | mse_mse: 0.00713 |  0:04:10s\n",
      "epoch 80 | loss: 0.01037 | mse_mse: 0.00899 |  0:04:13s\n",
      "epoch 81 | loss: 0.01162 | mse_mse: 0.00686 |  0:04:16s\n",
      "epoch 82 | loss: 0.01675 | mse_mse: 0.00795 |  0:04:19s\n",
      "epoch 83 | loss: 0.01269 | mse_mse: 0.00721 |  0:04:22s\n",
      "epoch 84 | loss: 0.00917 | mse_mse: 0.00802 |  0:04:25s\n",
      "epoch 85 | loss: 0.0094  | mse_mse: 0.01197 |  0:04:29s\n",
      "epoch 86 | loss: 0.0104  | mse_mse: 0.01077 |  0:04:32s\n",
      "epoch 87 | loss: 0.00938 | mse_mse: 0.00748 |  0:04:35s\n",
      "epoch 88 | loss: 0.00951 | mse_mse: 0.01302 |  0:04:38s\n",
      "epoch 89 | loss: 0.01025 | mse_mse: 0.01132 |  0:04:41s\n",
      "epoch 90 | loss: 0.01558 | mse_mse: 0.01327 |  0:04:44s\n",
      "epoch 91 | loss: 0.01082 | mse_mse: 0.00838 |  0:04:47s\n",
      "\n",
      "Early stopping occurred at epoch 91 with best_epoch = 81 and best_mse_mse = 0.00686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.006811966389957868\n",
      "R2 Score: 0.9692692451304971\n",
      "\n",
      "Iteration 29/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.70296 | mse_mse: 1.33763 |  0:00:03s\n",
      "epoch 1  | loss: 0.41432 | mse_mse: 0.81963 |  0:00:07s\n",
      "epoch 2  | loss: 0.45357 | mse_mse: 0.55693 |  0:00:11s\n",
      "epoch 3  | loss: 0.50265 | mse_mse: 0.35872 |  0:00:15s\n",
      "epoch 4  | loss: 0.29804 | mse_mse: 0.31962 |  0:00:19s\n",
      "epoch 5  | loss: 0.27587 | mse_mse: 0.23216 |  0:00:23s\n",
      "epoch 6  | loss: 0.22485 | mse_mse: 0.1842  |  0:00:27s\n",
      "epoch 7  | loss: 0.20044 | mse_mse: 0.18577 |  0:00:31s\n",
      "epoch 8  | loss: 0.15272 | mse_mse: 0.10946 |  0:00:35s\n",
      "epoch 9  | loss: 0.13889 | mse_mse: 0.10557 |  0:00:39s\n",
      "epoch 10 | loss: 0.14504 | mse_mse: 0.1012  |  0:00:43s\n",
      "epoch 11 | loss: 0.13208 | mse_mse: 0.10389 |  0:00:47s\n",
      "epoch 12 | loss: 0.12888 | mse_mse: 0.10692 |  0:00:51s\n",
      "epoch 13 | loss: 0.12941 | mse_mse: 0.10106 |  0:00:55s\n",
      "epoch 14 | loss: 0.1191  | mse_mse: 0.09452 |  0:00:59s\n",
      "epoch 15 | loss: 0.11826 | mse_mse: 0.10153 |  0:01:03s\n",
      "epoch 16 | loss: 0.12334 | mse_mse: 0.10769 |  0:01:07s\n",
      "epoch 17 | loss: 0.11407 | mse_mse: 0.10012 |  0:01:10s\n",
      "epoch 18 | loss: 0.11298 | mse_mse: 0.0923  |  0:01:14s\n",
      "epoch 19 | loss: 0.11286 | mse_mse: 0.11212 |  0:01:18s\n",
      "epoch 20 | loss: 0.11027 | mse_mse: 0.10516 |  0:01:22s\n",
      "epoch 21 | loss: 0.12014 | mse_mse: 0.10622 |  0:01:27s\n",
      "epoch 22 | loss: 0.11396 | mse_mse: 0.09303 |  0:01:31s\n",
      "epoch 23 | loss: 0.11139 | mse_mse: 0.09514 |  0:01:34s\n",
      "epoch 24 | loss: 0.11175 | mse_mse: 0.0891  |  0:01:38s\n",
      "epoch 25 | loss: 0.10813 | mse_mse: 0.09122 |  0:01:43s\n",
      "epoch 26 | loss: 0.10726 | mse_mse: 0.08445 |  0:01:46s\n",
      "epoch 27 | loss: 0.10439 | mse_mse: 0.09128 |  0:01:51s\n",
      "epoch 28 | loss: 0.10205 | mse_mse: 0.09827 |  0:01:55s\n",
      "epoch 29 | loss: 0.09922 | mse_mse: 0.08376 |  0:01:59s\n",
      "epoch 30 | loss: 0.09684 | mse_mse: 0.08519 |  0:02:02s\n",
      "epoch 31 | loss: 0.09572 | mse_mse: 0.08133 |  0:02:06s\n",
      "epoch 32 | loss: 0.09014 | mse_mse: 0.08293 |  0:02:10s\n",
      "epoch 33 | loss: 0.08876 | mse_mse: 0.07495 |  0:02:14s\n",
      "epoch 34 | loss: 0.08603 | mse_mse: 0.07898 |  0:02:18s\n",
      "epoch 35 | loss: 0.08456 | mse_mse: 0.07126 |  0:02:22s\n",
      "epoch 36 | loss: 0.08119 | mse_mse: 0.06908 |  0:02:26s\n",
      "epoch 37 | loss: 0.0775  | mse_mse: 0.06507 |  0:02:30s\n",
      "epoch 38 | loss: 0.07505 | mse_mse: 0.08021 |  0:02:34s\n",
      "epoch 39 | loss: 0.07098 | mse_mse: 0.068   |  0:02:38s\n",
      "epoch 40 | loss: 0.0655  | mse_mse: 0.06387 |  0:02:42s\n",
      "epoch 41 | loss: 0.06043 | mse_mse: 0.05702 |  0:02:46s\n",
      "epoch 42 | loss: 0.056   | mse_mse: 0.05303 |  0:02:50s\n",
      "epoch 43 | loss: 0.05534 | mse_mse: 0.05134 |  0:02:54s\n",
      "epoch 44 | loss: 0.05102 | mse_mse: 0.04862 |  0:02:58s\n",
      "epoch 45 | loss: 0.04777 | mse_mse: 0.04349 |  0:03:02s\n",
      "epoch 46 | loss: 0.05179 | mse_mse: 0.04523 |  0:03:06s\n",
      "epoch 47 | loss: 0.04276 | mse_mse: 0.04109 |  0:03:10s\n",
      "epoch 48 | loss: 0.03939 | mse_mse: 0.03574 |  0:03:14s\n",
      "epoch 49 | loss: 0.03469 | mse_mse: 0.03266 |  0:03:18s\n",
      "epoch 50 | loss: 0.03377 | mse_mse: 0.03185 |  0:03:22s\n",
      "epoch 51 | loss: 0.03134 | mse_mse: 0.03203 |  0:03:26s\n",
      "epoch 52 | loss: 0.0304  | mse_mse: 0.02876 |  0:03:30s\n",
      "epoch 53 | loss: 0.02714 | mse_mse: 0.02968 |  0:03:34s\n",
      "epoch 54 | loss: 0.03335 | mse_mse: 0.03311 |  0:03:38s\n",
      "epoch 55 | loss: 0.02691 | mse_mse: 0.0265  |  0:03:42s\n",
      "epoch 56 | loss: 0.02539 | mse_mse: 0.03082 |  0:03:46s\n",
      "epoch 57 | loss: 0.02357 | mse_mse: 0.02473 |  0:03:50s\n",
      "epoch 58 | loss: 0.02343 | mse_mse: 0.02295 |  0:03:54s\n",
      "epoch 59 | loss: 0.02415 | mse_mse: 0.02312 |  0:03:58s\n",
      "epoch 60 | loss: 0.01959 | mse_mse: 0.02138 |  0:04:02s\n",
      "epoch 61 | loss: 0.02262 | mse_mse: 0.02125 |  0:04:06s\n",
      "epoch 62 | loss: 0.02263 | mse_mse: 0.02476 |  0:04:10s\n",
      "epoch 63 | loss: 0.02042 | mse_mse: 0.02577 |  0:04:14s\n",
      "epoch 64 | loss: 0.02073 | mse_mse: 0.01996 |  0:04:18s\n",
      "epoch 65 | loss: 0.02003 | mse_mse: 0.01906 |  0:04:22s\n",
      "epoch 66 | loss: 0.01945 | mse_mse: 0.02031 |  0:04:26s\n",
      "epoch 67 | loss: 0.01997 | mse_mse: 0.0156  |  0:04:30s\n",
      "epoch 68 | loss: 0.01639 | mse_mse: 0.01978 |  0:04:34s\n",
      "epoch 69 | loss: 0.01846 | mse_mse: 0.01783 |  0:04:38s\n",
      "epoch 70 | loss: 0.02136 | mse_mse: 0.01547 |  0:04:42s\n",
      "epoch 71 | loss: 0.01466 | mse_mse: 0.01762 |  0:04:46s\n",
      "epoch 72 | loss: 0.02278 | mse_mse: 0.03423 |  0:04:50s\n",
      "epoch 73 | loss: 0.01564 | mse_mse: 0.01351 |  0:04:54s\n",
      "epoch 74 | loss: 0.01495 | mse_mse: 0.01645 |  0:04:58s\n",
      "epoch 75 | loss: 0.01539 | mse_mse: 0.01224 |  0:05:02s\n",
      "epoch 76 | loss: 0.01674 | mse_mse: 0.01156 |  0:05:05s\n",
      "epoch 77 | loss: 0.022   | mse_mse: 0.01812 |  0:05:10s\n",
      "epoch 78 | loss: 0.01683 | mse_mse: 0.01537 |  0:05:14s\n",
      "epoch 79 | loss: 0.01493 | mse_mse: 0.0205  |  0:05:18s\n",
      "epoch 80 | loss: 0.01354 | mse_mse: 0.00941 |  0:05:22s\n",
      "epoch 81 | loss: 0.01284 | mse_mse: 0.01228 |  0:05:26s\n",
      "epoch 82 | loss: 0.01114 | mse_mse: 0.00994 |  0:05:29s\n",
      "epoch 83 | loss: 0.01257 | mse_mse: 0.00957 |  0:05:33s\n",
      "epoch 84 | loss: 0.01035 | mse_mse: 0.01111 |  0:05:37s\n",
      "epoch 85 | loss: 0.01244 | mse_mse: 0.00925 |  0:05:41s\n",
      "epoch 86 | loss: 0.01335 | mse_mse: 0.00907 |  0:05:45s\n",
      "epoch 87 | loss: 0.01253 | mse_mse: 0.02081 |  0:05:49s\n",
      "epoch 88 | loss: 0.01125 | mse_mse: 0.00839 |  0:05:53s\n",
      "epoch 89 | loss: 0.01079 | mse_mse: 0.00963 |  0:05:57s\n",
      "epoch 90 | loss: 0.01292 | mse_mse: 0.01031 |  0:06:01s\n",
      "epoch 91 | loss: 0.01203 | mse_mse: 0.00787 |  0:06:05s\n",
      "epoch 92 | loss: 0.00961 | mse_mse: 0.00775 |  0:06:09s\n",
      "epoch 93 | loss: 0.01099 | mse_mse: 0.01229 |  0:06:13s\n",
      "epoch 94 | loss: 0.01252 | mse_mse: 0.00876 |  0:06:17s\n",
      "epoch 95 | loss: 0.01121 | mse_mse: 0.01127 |  0:06:21s\n",
      "epoch 96 | loss: 0.01337 | mse_mse: 0.00865 |  0:06:26s\n",
      "epoch 97 | loss: 0.01035 | mse_mse: 0.00903 |  0:06:29s\n",
      "epoch 98 | loss: 0.01665 | mse_mse: 0.01699 |  0:06:33s\n",
      "epoch 99 | loss: 0.01106 | mse_mse: 0.00897 |  0:06:37s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 92 and best_mse_mse = 0.00775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007839153111830774\n",
      "R2 Score: 0.9646353080926369\n",
      "\n",
      "Iteration 30/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.2137  | mse_mse: 0.57334 |  0:00:04s\n",
      "epoch 1  | loss: 0.34076 | mse_mse: 0.39307 |  0:00:08s\n",
      "epoch 2  | loss: 0.42834 | mse_mse: 0.26713 |  0:00:12s\n",
      "epoch 3  | loss: 0.31229 | mse_mse: 0.23324 |  0:00:17s\n",
      "epoch 4  | loss: 0.30932 | mse_mse: 0.36207 |  0:00:21s\n",
      "epoch 5  | loss: 0.26867 | mse_mse: 0.23503 |  0:00:25s\n",
      "epoch 6  | loss: 0.25332 | mse_mse: 0.28408 |  0:00:29s\n",
      "epoch 7  | loss: 0.24883 | mse_mse: 0.33479 |  0:00:34s\n",
      "epoch 8  | loss: 0.25158 | mse_mse: 0.22809 |  0:00:38s\n",
      "epoch 9  | loss: 0.2512  | mse_mse: 0.23936 |  0:00:42s\n",
      "epoch 10 | loss: 0.24244 | mse_mse: 0.23185 |  0:00:46s\n",
      "epoch 11 | loss: 0.24835 | mse_mse: 0.22403 |  0:00:51s\n",
      "epoch 12 | loss: 0.25114 | mse_mse: 0.22036 |  0:00:55s\n",
      "epoch 13 | loss: 0.23528 | mse_mse: 0.21824 |  0:00:59s\n",
      "epoch 14 | loss: 0.23253 | mse_mse: 0.22803 |  0:01:03s\n",
      "epoch 15 | loss: 0.2259  | mse_mse: 0.20951 |  0:01:08s\n",
      "epoch 16 | loss: 0.23051 | mse_mse: 0.19967 |  0:01:12s\n",
      "epoch 17 | loss: 0.21262 | mse_mse: 0.18538 |  0:01:16s\n",
      "epoch 18 | loss: 0.18838 | mse_mse: 0.16167 |  0:01:20s\n",
      "epoch 19 | loss: 0.16807 | mse_mse: 0.14169 |  0:01:25s\n",
      "epoch 20 | loss: 0.13953 | mse_mse: 0.1275  |  0:01:29s\n",
      "epoch 21 | loss: 0.15203 | mse_mse: 0.11335 |  0:01:33s\n",
      "epoch 22 | loss: 0.11287 | mse_mse: 0.09922 |  0:01:38s\n",
      "epoch 23 | loss: 0.09824 | mse_mse: 0.1009  |  0:01:42s\n",
      "epoch 24 | loss: 0.07863 | mse_mse: 0.08306 |  0:01:46s\n",
      "epoch 25 | loss: 0.07277 | mse_mse: 0.07463 |  0:01:51s\n",
      "epoch 26 | loss: 0.07324 | mse_mse: 0.0732  |  0:01:55s\n",
      "epoch 27 | loss: 0.06296 | mse_mse: 0.05682 |  0:01:59s\n",
      "epoch 28 | loss: 0.05806 | mse_mse: 0.05424 |  0:02:03s\n",
      "epoch 29 | loss: 0.05734 | mse_mse: 0.05403 |  0:02:08s\n",
      "epoch 30 | loss: 0.05377 | mse_mse: 0.05302 |  0:02:12s\n",
      "epoch 31 | loss: 0.0522  | mse_mse: 0.08334 |  0:02:16s\n",
      "epoch 32 | loss: 0.05442 | mse_mse: 0.0481  |  0:02:21s\n",
      "epoch 33 | loss: 0.05281 | mse_mse: 0.06104 |  0:02:25s\n",
      "epoch 34 | loss: 0.04034 | mse_mse: 0.04667 |  0:02:29s\n",
      "epoch 35 | loss: 0.04146 | mse_mse: 0.03854 |  0:02:33s\n",
      "epoch 36 | loss: 0.03788 | mse_mse: 0.04831 |  0:02:38s\n",
      "epoch 37 | loss: 0.0397  | mse_mse: 0.04397 |  0:02:42s\n",
      "epoch 38 | loss: 0.04064 | mse_mse: 0.05632 |  0:02:46s\n",
      "epoch 39 | loss: 0.03905 | mse_mse: 0.0563  |  0:02:50s\n",
      "epoch 40 | loss: 0.03082 | mse_mse: 0.02676 |  0:02:55s\n",
      "epoch 41 | loss: 0.03074 | mse_mse: 0.05526 |  0:02:59s\n",
      "epoch 42 | loss: 0.03576 | mse_mse: 0.02853 |  0:03:03s\n",
      "epoch 43 | loss: 0.03138 | mse_mse: 0.0252  |  0:03:07s\n",
      "epoch 44 | loss: 0.02692 | mse_mse: 0.022   |  0:03:12s\n",
      "epoch 45 | loss: 0.0268  | mse_mse: 0.02144 |  0:03:16s\n",
      "epoch 46 | loss: 0.02569 | mse_mse: 0.02634 |  0:03:20s\n",
      "epoch 47 | loss: 0.02396 | mse_mse: 0.02181 |  0:03:25s\n",
      "epoch 48 | loss: 0.02215 | mse_mse: 0.02348 |  0:03:29s\n",
      "epoch 49 | loss: 0.02175 | mse_mse: 0.022   |  0:03:33s\n",
      "epoch 50 | loss: 0.01993 | mse_mse: 0.03303 |  0:03:37s\n",
      "epoch 51 | loss: 0.0216  | mse_mse: 0.0172  |  0:03:42s\n",
      "epoch 52 | loss: 0.0191  | mse_mse: 0.01855 |  0:03:46s\n",
      "epoch 53 | loss: 0.0185  | mse_mse: 0.02142 |  0:03:50s\n",
      "epoch 54 | loss: 0.01746 | mse_mse: 0.01407 |  0:03:54s\n",
      "epoch 55 | loss: 0.02029 | mse_mse: 0.01509 |  0:03:58s\n",
      "epoch 56 | loss: 0.01688 | mse_mse: 0.01431 |  0:04:03s\n",
      "epoch 57 | loss: 0.0179  | mse_mse: 0.01196 |  0:04:07s\n",
      "epoch 58 | loss: 0.01543 | mse_mse: 0.01287 |  0:04:11s\n",
      "epoch 59 | loss: 0.0177  | mse_mse: 0.02233 |  0:04:15s\n",
      "epoch 60 | loss: 0.01801 | mse_mse: 0.01456 |  0:04:20s\n",
      "epoch 61 | loss: 0.01592 | mse_mse: 0.01144 |  0:04:24s\n",
      "epoch 62 | loss: 0.01476 | mse_mse: 0.0104  |  0:04:28s\n",
      "epoch 63 | loss: 0.01699 | mse_mse: 0.01514 |  0:04:32s\n",
      "epoch 64 | loss: 0.01354 | mse_mse: 0.02182 |  0:04:37s\n",
      "epoch 65 | loss: 0.02148 | mse_mse: 0.00948 |  0:04:41s\n",
      "epoch 66 | loss: 0.01278 | mse_mse: 0.01182 |  0:04:45s\n",
      "epoch 67 | loss: 0.01418 | mse_mse: 0.01167 |  0:04:49s\n",
      "epoch 68 | loss: 0.01959 | mse_mse: 0.08277 |  0:04:54s\n",
      "epoch 69 | loss: 0.02755 | mse_mse: 0.01829 |  0:04:58s\n",
      "epoch 70 | loss: 0.02002 | mse_mse: 0.01755 |  0:05:02s\n",
      "epoch 71 | loss: 0.01901 | mse_mse: 0.01827 |  0:05:07s\n",
      "epoch 72 | loss: 0.01721 | mse_mse: 0.02812 |  0:05:11s\n",
      "epoch 73 | loss: 0.01616 | mse_mse: 0.01932 |  0:05:15s\n",
      "epoch 74 | loss: 0.01627 | mse_mse: 0.01286 |  0:05:19s\n",
      "epoch 75 | loss: 0.01441 | mse_mse: 0.02265 |  0:05:24s\n",
      "\n",
      "Early stopping occurred at epoch 75 with best_epoch = 65 and best_mse_mse = 0.00948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009659453552186484\n",
      "R2 Score: 0.9564234051825043\n",
      "\n",
      "Iteration 31/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.2345  | mse_mse: 1.83578 |  0:00:02s\n",
      "epoch 1  | loss: 0.33361 | mse_mse: 0.35182 |  0:00:04s\n",
      "epoch 2  | loss: 0.2723  | mse_mse: 0.33294 |  0:00:06s\n",
      "epoch 3  | loss: 0.25396 | mse_mse: 0.26701 |  0:00:08s\n",
      "epoch 4  | loss: 0.24509 | mse_mse: 0.23571 |  0:00:11s\n",
      "epoch 5  | loss: 0.23743 | mse_mse: 0.22957 |  0:00:13s\n",
      "epoch 6  | loss: 0.23374 | mse_mse: 0.22477 |  0:00:15s\n",
      "epoch 7  | loss: 0.22347 | mse_mse: 0.19564 |  0:00:17s\n",
      "epoch 8  | loss: 0.17176 | mse_mse: 0.16906 |  0:00:20s\n",
      "epoch 9  | loss: 0.12865 | mse_mse: 0.11786 |  0:00:22s\n",
      "epoch 10 | loss: 0.11079 | mse_mse: 0.08735 |  0:00:24s\n",
      "epoch 11 | loss: 0.09796 | mse_mse: 0.08232 |  0:00:27s\n",
      "epoch 12 | loss: 0.09074 | mse_mse: 0.08031 |  0:00:29s\n",
      "epoch 13 | loss: 0.09381 | mse_mse: 0.07417 |  0:00:31s\n",
      "epoch 14 | loss: 0.083   | mse_mse: 0.06955 |  0:00:33s\n",
      "epoch 15 | loss: 0.07173 | mse_mse: 0.05889 |  0:00:36s\n",
      "epoch 16 | loss: 0.06614 | mse_mse: 0.06409 |  0:00:38s\n",
      "epoch 17 | loss: 0.0599  | mse_mse: 0.05755 |  0:00:40s\n",
      "epoch 18 | loss: 0.05411 | mse_mse: 0.04753 |  0:00:42s\n",
      "epoch 19 | loss: 0.05162 | mse_mse: 0.04842 |  0:00:45s\n",
      "epoch 20 | loss: 0.04771 | mse_mse: 0.04126 |  0:00:47s\n",
      "epoch 21 | loss: 0.03971 | mse_mse: 0.03804 |  0:00:49s\n",
      "epoch 22 | loss: 0.03638 | mse_mse: 0.02973 |  0:00:51s\n",
      "epoch 23 | loss: 0.03028 | mse_mse: 0.02651 |  0:00:54s\n",
      "epoch 24 | loss: 0.0299  | mse_mse: 0.02586 |  0:00:56s\n",
      "epoch 25 | loss: 0.02371 | mse_mse: 0.01856 |  0:00:58s\n",
      "epoch 26 | loss: 0.02163 | mse_mse: 0.02286 |  0:01:01s\n",
      "epoch 27 | loss: 0.02084 | mse_mse: 0.01589 |  0:01:03s\n",
      "epoch 28 | loss: 0.02114 | mse_mse: 0.02416 |  0:01:05s\n",
      "epoch 29 | loss: 0.02308 | mse_mse: 0.03086 |  0:01:08s\n",
      "epoch 30 | loss: 0.02082 | mse_mse: 0.01892 |  0:01:10s\n",
      "epoch 31 | loss: 0.01651 | mse_mse: 0.01117 |  0:01:12s\n",
      "epoch 32 | loss: 0.01645 | mse_mse: 0.01324 |  0:01:14s\n",
      "epoch 33 | loss: 0.01448 | mse_mse: 0.01638 |  0:01:17s\n",
      "epoch 34 | loss: 0.01351 | mse_mse: 0.01314 |  0:01:19s\n",
      "epoch 35 | loss: 0.01144 | mse_mse: 0.00961 |  0:01:21s\n",
      "epoch 36 | loss: 0.01269 | mse_mse: 0.01077 |  0:01:23s\n",
      "epoch 37 | loss: 0.01124 | mse_mse: 0.00922 |  0:01:26s\n",
      "epoch 38 | loss: 0.01208 | mse_mse: 0.01485 |  0:01:28s\n",
      "epoch 39 | loss: 0.01145 | mse_mse: 0.01028 |  0:01:30s\n",
      "epoch 40 | loss: 0.01134 | mse_mse: 0.00973 |  0:01:33s\n",
      "epoch 41 | loss: 0.01188 | mse_mse: 0.00809 |  0:01:35s\n",
      "epoch 42 | loss: 0.01109 | mse_mse: 0.00948 |  0:01:37s\n",
      "epoch 43 | loss: 0.01414 | mse_mse: 0.01228 |  0:01:40s\n",
      "epoch 44 | loss: 0.0115  | mse_mse: 0.00761 |  0:01:42s\n",
      "epoch 45 | loss: 0.01215 | mse_mse: 0.00767 |  0:01:44s\n",
      "epoch 46 | loss: 0.01112 | mse_mse: 0.00742 |  0:01:46s\n",
      "epoch 47 | loss: 0.01069 | mse_mse: 0.00892 |  0:01:49s\n",
      "epoch 48 | loss: 0.01866 | mse_mse: 0.04889 |  0:01:51s\n",
      "epoch 49 | loss: 0.01399 | mse_mse: 0.00885 |  0:01:53s\n",
      "epoch 50 | loss: 0.00971 | mse_mse: 0.00719 |  0:01:55s\n",
      "epoch 51 | loss: 0.01066 | mse_mse: 0.02263 |  0:01:58s\n",
      "epoch 52 | loss: 0.01325 | mse_mse: 0.00675 |  0:02:00s\n",
      "epoch 53 | loss: 0.00923 | mse_mse: 0.00846 |  0:02:02s\n",
      "epoch 54 | loss: 0.00966 | mse_mse: 0.0118  |  0:02:04s\n",
      "epoch 55 | loss: 0.00956 | mse_mse: 0.00828 |  0:02:07s\n",
      "epoch 56 | loss: 0.00918 | mse_mse: 0.00781 |  0:02:09s\n",
      "epoch 57 | loss: 0.00944 | mse_mse: 0.00668 |  0:02:11s\n",
      "epoch 58 | loss: 0.01125 | mse_mse: 0.0088  |  0:02:14s\n",
      "epoch 59 | loss: 0.00929 | mse_mse: 0.00726 |  0:02:16s\n",
      "epoch 60 | loss: 0.00963 | mse_mse: 0.0106  |  0:02:18s\n",
      "epoch 61 | loss: 0.00919 | mse_mse: 0.00757 |  0:02:20s\n",
      "epoch 62 | loss: 0.00958 | mse_mse: 0.01425 |  0:02:23s\n",
      "epoch 63 | loss: 0.0103  | mse_mse: 0.01017 |  0:02:25s\n",
      "epoch 64 | loss: 0.01306 | mse_mse: 0.00986 |  0:02:27s\n",
      "epoch 65 | loss: 0.01238 | mse_mse: 0.00977 |  0:02:30s\n",
      "epoch 66 | loss: 0.00925 | mse_mse: 0.00924 |  0:02:32s\n",
      "epoch 67 | loss: 0.01399 | mse_mse: 0.00826 |  0:02:34s\n",
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 57 and best_mse_mse = 0.00668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.006952091596832435\n",
      "R2 Score: 0.9686370997062552\n",
      "\n",
      "Iteration 32/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.62763 | mse_mse: 0.77166 |  0:00:02s\n",
      "epoch 1  | loss: 0.32426 | mse_mse: 0.4217  |  0:00:04s\n",
      "epoch 2  | loss: 0.24673 | mse_mse: 0.17708 |  0:00:07s\n",
      "epoch 3  | loss: 0.15444 | mse_mse: 0.13662 |  0:00:09s\n",
      "epoch 4  | loss: 0.12857 | mse_mse: 0.1091  |  0:00:12s\n",
      "epoch 5  | loss: 0.11534 | mse_mse: 0.12017 |  0:00:14s\n",
      "epoch 6  | loss: 0.11634 | mse_mse: 0.07562 |  0:00:17s\n",
      "epoch 7  | loss: 0.1042  | mse_mse: 0.07402 |  0:00:19s\n",
      "epoch 8  | loss: 0.09868 | mse_mse: 0.09033 |  0:00:21s\n",
      "epoch 9  | loss: 0.0924  | mse_mse: 0.07699 |  0:00:24s\n",
      "epoch 10 | loss: 0.09902 | mse_mse: 0.07907 |  0:00:27s\n",
      "epoch 11 | loss: 0.09549 | mse_mse: 0.06825 |  0:00:29s\n",
      "epoch 12 | loss: 0.08876 | mse_mse: 0.068   |  0:00:31s\n",
      "epoch 13 | loss: 0.08572 | mse_mse: 0.07978 |  0:00:34s\n",
      "epoch 14 | loss: 0.08429 | mse_mse: 0.06665 |  0:00:36s\n",
      "epoch 15 | loss: 0.07503 | mse_mse: 0.06307 |  0:00:39s\n",
      "epoch 16 | loss: 0.07196 | mse_mse: 0.06868 |  0:00:41s\n",
      "epoch 17 | loss: 0.06973 | mse_mse: 0.05949 |  0:00:43s\n",
      "epoch 18 | loss: 0.06704 | mse_mse: 0.06003 |  0:00:46s\n",
      "epoch 19 | loss: 0.06488 | mse_mse: 0.05717 |  0:00:48s\n",
      "epoch 20 | loss: 0.06447 | mse_mse: 0.0579  |  0:00:51s\n",
      "epoch 21 | loss: 0.06491 | mse_mse: 0.05346 |  0:00:53s\n",
      "epoch 22 | loss: 0.06105 | mse_mse: 0.05195 |  0:00:56s\n",
      "epoch 23 | loss: 0.05513 | mse_mse: 0.05303 |  0:00:58s\n",
      "epoch 24 | loss: 0.05499 | mse_mse: 0.04832 |  0:01:01s\n",
      "epoch 25 | loss: 0.05427 | mse_mse: 0.04853 |  0:01:03s\n",
      "epoch 26 | loss: 0.0514  | mse_mse: 0.04727 |  0:01:06s\n",
      "epoch 27 | loss: 0.05155 | mse_mse: 0.04457 |  0:01:08s\n",
      "epoch 28 | loss: 0.04721 | mse_mse: 0.0416  |  0:01:11s\n",
      "epoch 29 | loss: 0.04319 | mse_mse: 0.04302 |  0:01:13s\n",
      "epoch 30 | loss: 0.04219 | mse_mse: 0.03885 |  0:01:16s\n",
      "epoch 31 | loss: 0.03902 | mse_mse: 0.03901 |  0:01:18s\n",
      "epoch 32 | loss: 0.03783 | mse_mse: 0.03897 |  0:01:20s\n",
      "epoch 33 | loss: 0.03748 | mse_mse: 0.03712 |  0:01:23s\n",
      "epoch 34 | loss: 0.03657 | mse_mse: 0.04052 |  0:01:25s\n",
      "epoch 35 | loss: 0.0322  | mse_mse: 0.03763 |  0:01:28s\n",
      "epoch 36 | loss: 0.03277 | mse_mse: 0.0344  |  0:01:30s\n",
      "epoch 37 | loss: 0.02947 | mse_mse: 0.02822 |  0:01:33s\n",
      "epoch 38 | loss: 0.02714 | mse_mse: 0.02718 |  0:01:35s\n",
      "epoch 39 | loss: 0.02706 | mse_mse: 0.03849 |  0:01:38s\n",
      "epoch 40 | loss: 0.02629 | mse_mse: 0.02619 |  0:01:40s\n",
      "epoch 41 | loss: 0.02228 | mse_mse: 0.02238 |  0:01:43s\n",
      "epoch 42 | loss: 0.02452 | mse_mse: 0.01974 |  0:01:45s\n",
      "epoch 43 | loss: 0.02108 | mse_mse: 0.0386  |  0:01:48s\n",
      "epoch 44 | loss: 0.02521 | mse_mse: 0.01644 |  0:01:50s\n",
      "epoch 45 | loss: 0.01889 | mse_mse: 0.01734 |  0:01:53s\n",
      "epoch 46 | loss: 0.0158  | mse_mse: 0.01572 |  0:01:55s\n",
      "epoch 47 | loss: 0.01872 | mse_mse: 0.0223  |  0:01:58s\n",
      "epoch 48 | loss: 0.01753 | mse_mse: 0.01633 |  0:02:00s\n",
      "epoch 49 | loss: 0.01377 | mse_mse: 0.01847 |  0:02:03s\n",
      "epoch 50 | loss: 0.01562 | mse_mse: 0.01349 |  0:02:05s\n",
      "epoch 51 | loss: 0.01326 | mse_mse: 0.01176 |  0:02:08s\n",
      "epoch 52 | loss: 0.01204 | mse_mse: 0.01147 |  0:02:10s\n",
      "epoch 53 | loss: 0.01299 | mse_mse: 0.01381 |  0:02:13s\n",
      "epoch 54 | loss: 0.01361 | mse_mse: 0.01577 |  0:02:15s\n",
      "epoch 55 | loss: 0.01312 | mse_mse: 0.01141 |  0:02:18s\n",
      "epoch 56 | loss: 0.01345 | mse_mse: 0.01122 |  0:02:20s\n",
      "epoch 57 | loss: 0.01584 | mse_mse: 0.01452 |  0:02:23s\n",
      "epoch 58 | loss: 0.01654 | mse_mse: 0.01804 |  0:02:25s\n",
      "epoch 59 | loss: 0.01314 | mse_mse: 0.01064 |  0:02:27s\n",
      "epoch 60 | loss: 0.01409 | mse_mse: 0.01119 |  0:02:30s\n",
      "epoch 61 | loss: 0.01439 | mse_mse: 0.01009 |  0:02:32s\n",
      "epoch 62 | loss: 0.011   | mse_mse: 0.01017 |  0:02:35s\n",
      "epoch 63 | loss: 0.01073 | mse_mse: 0.01073 |  0:02:37s\n",
      "epoch 64 | loss: 0.00941 | mse_mse: 0.00907 |  0:02:40s\n",
      "epoch 65 | loss: 0.01261 | mse_mse: 0.01069 |  0:02:42s\n",
      "epoch 66 | loss: 0.01082 | mse_mse: 0.00903 |  0:02:45s\n",
      "epoch 67 | loss: 0.01094 | mse_mse: 0.01267 |  0:02:47s\n",
      "epoch 68 | loss: 0.00883 | mse_mse: 0.01012 |  0:02:50s\n",
      "epoch 69 | loss: 0.00979 | mse_mse: 0.0089  |  0:02:52s\n",
      "epoch 70 | loss: 0.00942 | mse_mse: 0.00964 |  0:02:55s\n",
      "epoch 71 | loss: 0.00842 | mse_mse: 0.00862 |  0:02:57s\n",
      "epoch 72 | loss: 0.00874 | mse_mse: 0.00934 |  0:02:59s\n",
      "epoch 73 | loss: 0.00858 | mse_mse: 0.00865 |  0:03:02s\n",
      "epoch 74 | loss: 0.01144 | mse_mse: 0.02907 |  0:03:04s\n",
      "epoch 75 | loss: 0.01012 | mse_mse: 0.00903 |  0:03:07s\n",
      "epoch 76 | loss: 0.00939 | mse_mse: 0.00979 |  0:03:09s\n",
      "epoch 77 | loss: 0.01516 | mse_mse: 0.00875 |  0:03:12s\n",
      "epoch 78 | loss: 0.00954 | mse_mse: 0.00942 |  0:03:14s\n",
      "epoch 79 | loss: 0.0088  | mse_mse: 0.01045 |  0:03:17s\n",
      "epoch 80 | loss: 0.00726 | mse_mse: 0.01396 |  0:03:19s\n",
      "epoch 81 | loss: 0.00856 | mse_mse: 0.00961 |  0:03:22s\n",
      "\n",
      "Early stopping occurred at epoch 81 with best_epoch = 71 and best_mse_mse = 0.00862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009236023580059467\n",
      "R2 Score: 0.9583336205201811\n",
      "\n",
      "Iteration 33/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.17829 | mse_mse: 1.24941 |  0:00:03s\n",
      "epoch 1  | loss: 0.3194  | mse_mse: 0.42663 |  0:00:06s\n",
      "epoch 2  | loss: 0.3276  | mse_mse: 0.29578 |  0:00:10s\n",
      "epoch 3  | loss: 0.27098 | mse_mse: 0.28266 |  0:00:13s\n",
      "epoch 4  | loss: 0.25826 | mse_mse: 0.33424 |  0:00:17s\n",
      "epoch 5  | loss: 0.25978 | mse_mse: 0.23881 |  0:00:20s\n",
      "epoch 6  | loss: 0.26301 | mse_mse: 0.27546 |  0:00:24s\n",
      "epoch 7  | loss: 0.24425 | mse_mse: 0.21889 |  0:00:27s\n",
      "epoch 8  | loss: 0.23648 | mse_mse: 0.25636 |  0:00:31s\n",
      "epoch 9  | loss: 0.23471 | mse_mse: 0.20429 |  0:00:34s\n",
      "epoch 10 | loss: 0.2126  | mse_mse: 0.18418 |  0:00:38s\n",
      "epoch 11 | loss: 0.21047 | mse_mse: 0.19782 |  0:00:41s\n",
      "epoch 12 | loss: 0.21204 | mse_mse: 0.21607 |  0:00:45s\n",
      "epoch 13 | loss: 0.21245 | mse_mse: 0.18726 |  0:00:48s\n",
      "epoch 14 | loss: 0.19777 | mse_mse: 0.21407 |  0:00:52s\n",
      "epoch 15 | loss: 0.20396 | mse_mse: 0.18023 |  0:00:55s\n",
      "epoch 16 | loss: 0.19543 | mse_mse: 0.18335 |  0:00:59s\n",
      "epoch 17 | loss: 0.20124 | mse_mse: 0.16934 |  0:01:02s\n",
      "epoch 18 | loss: 0.18517 | mse_mse: 0.16679 |  0:01:06s\n",
      "epoch 19 | loss: 0.17998 | mse_mse: 0.16517 |  0:01:09s\n",
      "epoch 20 | loss: 0.16824 | mse_mse: 0.14255 |  0:01:13s\n",
      "epoch 21 | loss: 0.15637 | mse_mse: 0.14006 |  0:01:17s\n",
      "epoch 22 | loss: 0.14922 | mse_mse: 0.13417 |  0:01:20s\n",
      "epoch 23 | loss: 0.13549 | mse_mse: 0.12534 |  0:01:24s\n",
      "epoch 24 | loss: 0.12443 | mse_mse: 0.10339 |  0:01:27s\n",
      "epoch 25 | loss: 0.10465 | mse_mse: 0.09365 |  0:01:31s\n",
      "epoch 26 | loss: 0.08968 | mse_mse: 0.10248 |  0:01:34s\n",
      "epoch 27 | loss: 0.08429 | mse_mse: 0.06984 |  0:01:38s\n",
      "epoch 28 | loss: 0.07067 | mse_mse: 0.06287 |  0:01:42s\n",
      "epoch 29 | loss: 0.05937 | mse_mse: 0.0515  |  0:01:45s\n",
      "epoch 30 | loss: 0.05452 | mse_mse: 0.04972 |  0:01:49s\n",
      "epoch 31 | loss: 0.04879 | mse_mse: 0.04749 |  0:01:52s\n",
      "epoch 32 | loss: 0.04207 | mse_mse: 0.03978 |  0:01:56s\n",
      "epoch 33 | loss: 0.03969 | mse_mse: 0.0354  |  0:01:59s\n",
      "epoch 34 | loss: 0.03491 | mse_mse: 0.03433 |  0:02:03s\n",
      "epoch 35 | loss: 0.03802 | mse_mse: 0.02759 |  0:02:06s\n",
      "epoch 36 | loss: 0.03446 | mse_mse: 0.02885 |  0:02:10s\n",
      "epoch 37 | loss: 0.03091 | mse_mse: 0.03885 |  0:02:13s\n",
      "epoch 38 | loss: 0.03823 | mse_mse: 0.03162 |  0:02:17s\n",
      "epoch 39 | loss: 0.0298  | mse_mse: 0.02115 |  0:02:20s\n",
      "epoch 40 | loss: 0.02523 | mse_mse: 0.01952 |  0:02:24s\n",
      "epoch 41 | loss: 0.02555 | mse_mse: 0.01892 |  0:02:27s\n",
      "epoch 42 | loss: 0.02084 | mse_mse: 0.02304 |  0:02:31s\n",
      "epoch 43 | loss: 0.02413 | mse_mse: 0.01989 |  0:02:35s\n",
      "epoch 44 | loss: 0.01962 | mse_mse: 0.0154  |  0:02:38s\n",
      "epoch 45 | loss: 0.02044 | mse_mse: 0.01868 |  0:02:41s\n",
      "epoch 46 | loss: 0.01911 | mse_mse: 0.02945 |  0:02:45s\n",
      "epoch 47 | loss: 0.02133 | mse_mse: 0.0144  |  0:02:48s\n",
      "epoch 48 | loss: 0.0237  | mse_mse: 0.01331 |  0:02:52s\n",
      "epoch 49 | loss: 0.01954 | mse_mse: 0.01851 |  0:02:56s\n",
      "epoch 50 | loss: 0.02136 | mse_mse: 0.01899 |  0:02:59s\n",
      "epoch 51 | loss: 0.01843 | mse_mse: 0.01495 |  0:03:03s\n",
      "epoch 52 | loss: 0.01527 | mse_mse: 0.01298 |  0:03:06s\n",
      "epoch 53 | loss: 0.01321 | mse_mse: 0.01555 |  0:03:10s\n",
      "epoch 54 | loss: 0.01545 | mse_mse: 0.01423 |  0:03:13s\n",
      "epoch 55 | loss: 0.01364 | mse_mse: 0.01021 |  0:03:17s\n",
      "epoch 56 | loss: 0.01447 | mse_mse: 0.01126 |  0:03:20s\n",
      "epoch 57 | loss: 0.01289 | mse_mse: 0.01445 |  0:03:24s\n",
      "epoch 58 | loss: 0.01328 | mse_mse: 0.01065 |  0:03:27s\n",
      "epoch 59 | loss: 0.01435 | mse_mse: 0.01698 |  0:03:31s\n",
      "epoch 60 | loss: 0.01261 | mse_mse: 0.02382 |  0:03:34s\n",
      "epoch 61 | loss: 0.01639 | mse_mse: 0.00958 |  0:03:38s\n",
      "epoch 62 | loss: 0.01243 | mse_mse: 0.01051 |  0:03:42s\n",
      "epoch 63 | loss: 0.01073 | mse_mse: 0.00834 |  0:03:45s\n",
      "epoch 64 | loss: 0.01067 | mse_mse: 0.00757 |  0:03:48s\n",
      "epoch 65 | loss: 0.01129 | mse_mse: 0.03517 |  0:03:52s\n",
      "epoch 66 | loss: 0.01914 | mse_mse: 0.00831 |  0:03:56s\n",
      "epoch 67 | loss: 0.00971 | mse_mse: 0.01916 |  0:03:59s\n",
      "epoch 68 | loss: 0.01224 | mse_mse: 0.00961 |  0:04:03s\n",
      "epoch 69 | loss: 0.01039 | mse_mse: 0.01245 |  0:04:06s\n",
      "epoch 70 | loss: 0.01734 | mse_mse: 0.01064 |  0:04:10s\n",
      "epoch 71 | loss: 0.01261 | mse_mse: 0.00837 |  0:04:13s\n",
      "epoch 72 | loss: 0.01214 | mse_mse: 0.01116 |  0:04:17s\n",
      "epoch 73 | loss: 0.0105  | mse_mse: 0.00705 |  0:04:20s\n",
      "epoch 74 | loss: 0.01142 | mse_mse: 0.01006 |  0:04:24s\n",
      "epoch 75 | loss: 0.00965 | mse_mse: 0.0095  |  0:04:27s\n",
      "epoch 76 | loss: 0.01254 | mse_mse: 0.00702 |  0:04:31s\n",
      "epoch 77 | loss: 0.0101  | mse_mse: 0.00764 |  0:04:35s\n",
      "epoch 78 | loss: 0.01363 | mse_mse: 0.02516 |  0:04:38s\n",
      "epoch 79 | loss: 0.01418 | mse_mse: 0.00827 |  0:04:42s\n",
      "epoch 80 | loss: 0.01031 | mse_mse: 0.01542 |  0:04:45s\n",
      "epoch 81 | loss: 0.01002 | mse_mse: 0.00923 |  0:04:49s\n",
      "epoch 82 | loss: 0.0134  | mse_mse: 0.02737 |  0:04:52s\n",
      "epoch 83 | loss: 0.0111  | mse_mse: 0.00792 |  0:04:56s\n",
      "epoch 84 | loss: 0.00928 | mse_mse: 0.00997 |  0:04:59s\n",
      "epoch 85 | loss: 0.01037 | mse_mse: 0.01308 |  0:05:03s\n",
      "epoch 86 | loss: 0.00967 | mse_mse: 0.0088  |  0:05:06s\n",
      "\n",
      "Early stopping occurred at epoch 86 with best_epoch = 76 and best_mse_mse = 0.00702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.006867712161954994\n",
      "R2 Score: 0.9690177597948119\n",
      "\n",
      "Iteration 34/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.14176 | mse_mse: 0.84154 |  0:00:03s\n",
      "epoch 1  | loss: 0.32402 | mse_mse: 0.46859 |  0:00:07s\n",
      "epoch 2  | loss: 0.28284 | mse_mse: 0.39993 |  0:00:11s\n",
      "epoch 3  | loss: 0.27781 | mse_mse: 0.26578 |  0:00:15s\n",
      "epoch 4  | loss: 0.25503 | mse_mse: 0.27641 |  0:00:19s\n",
      "epoch 5  | loss: 0.24503 | mse_mse: 0.22872 |  0:00:22s\n",
      "epoch 6  | loss: 0.2446  | mse_mse: 0.23995 |  0:00:26s\n",
      "epoch 7  | loss: 0.23634 | mse_mse: 0.22715 |  0:00:30s\n",
      "epoch 8  | loss: 0.24148 | mse_mse: 0.22344 |  0:00:34s\n",
      "epoch 9  | loss: 0.24069 | mse_mse: 0.22422 |  0:00:37s\n",
      "epoch 10 | loss: 0.23497 | mse_mse: 0.21789 |  0:00:41s\n",
      "epoch 11 | loss: 0.2335  | mse_mse: 0.22057 |  0:00:45s\n",
      "epoch 12 | loss: 0.23221 | mse_mse: 0.22387 |  0:00:49s\n",
      "epoch 13 | loss: 0.23446 | mse_mse: 0.21375 |  0:00:53s\n",
      "epoch 14 | loss: 0.23148 | mse_mse: 0.22486 |  0:00:56s\n",
      "epoch 15 | loss: 0.22777 | mse_mse: 0.21382 |  0:01:00s\n",
      "epoch 16 | loss: 0.22288 | mse_mse: 0.2097  |  0:01:04s\n",
      "epoch 17 | loss: 0.2133  | mse_mse: 0.19391 |  0:01:08s\n",
      "epoch 18 | loss: 0.19193 | mse_mse: 0.17004 |  0:01:11s\n",
      "epoch 19 | loss: 0.1696  | mse_mse: 0.13398 |  0:01:15s\n",
      "epoch 20 | loss: 0.1338  | mse_mse: 0.11543 |  0:01:19s\n",
      "epoch 21 | loss: 0.13297 | mse_mse: 0.09894 |  0:01:23s\n",
      "epoch 22 | loss: 0.10836 | mse_mse: 0.09625 |  0:01:27s\n",
      "epoch 23 | loss: 0.09705 | mse_mse: 0.08412 |  0:01:31s\n",
      "epoch 24 | loss: 0.08557 | mse_mse: 0.07192 |  0:01:35s\n",
      "epoch 25 | loss: 0.07375 | mse_mse: 0.06038 |  0:01:39s\n",
      "epoch 26 | loss: 0.06838 | mse_mse: 0.08167 |  0:01:43s\n",
      "epoch 27 | loss: 0.06998 | mse_mse: 0.07774 |  0:01:46s\n",
      "epoch 28 | loss: 0.06005 | mse_mse: 0.04154 |  0:01:50s\n",
      "epoch 29 | loss: 0.0434  | mse_mse: 0.03553 |  0:01:54s\n",
      "epoch 30 | loss: 0.03799 | mse_mse: 0.03213 |  0:01:58s\n",
      "epoch 31 | loss: 0.03025 | mse_mse: 0.02657 |  0:02:02s\n",
      "epoch 32 | loss: 0.02782 | mse_mse: 0.02334 |  0:02:06s\n",
      "epoch 33 | loss: 0.02741 | mse_mse: 0.02216 |  0:02:10s\n",
      "epoch 34 | loss: 0.03167 | mse_mse: 0.02032 |  0:02:13s\n",
      "epoch 35 | loss: 0.02491 | mse_mse: 0.02159 |  0:02:17s\n",
      "epoch 36 | loss: 0.02653 | mse_mse: 0.01702 |  0:02:21s\n",
      "epoch 37 | loss: 0.02211 | mse_mse: 0.02438 |  0:02:25s\n",
      "epoch 38 | loss: 0.01921 | mse_mse: 0.02096 |  0:02:29s\n",
      "epoch 39 | loss: 0.02094 | mse_mse: 0.01763 |  0:02:33s\n",
      "epoch 40 | loss: 0.0196  | mse_mse: 0.02726 |  0:02:36s\n",
      "epoch 41 | loss: 0.01744 | mse_mse: 0.01367 |  0:02:40s\n",
      "epoch 42 | loss: 0.01839 | mse_mse: 0.0161  |  0:02:44s\n",
      "epoch 43 | loss: 0.01883 | mse_mse: 0.0149  |  0:02:48s\n",
      "epoch 44 | loss: 0.01622 | mse_mse: 0.02889 |  0:02:52s\n",
      "epoch 45 | loss: 0.02109 | mse_mse: 0.01339 |  0:02:56s\n",
      "epoch 46 | loss: 0.01734 | mse_mse: 0.01631 |  0:02:59s\n",
      "epoch 47 | loss: 0.01919 | mse_mse: 0.01285 |  0:03:03s\n",
      "epoch 48 | loss: 0.01855 | mse_mse: 0.01386 |  0:03:07s\n",
      "epoch 49 | loss: 0.01533 | mse_mse: 0.0149  |  0:03:11s\n",
      "epoch 50 | loss: 0.01466 | mse_mse: 0.01009 |  0:03:15s\n",
      "epoch 51 | loss: 0.01354 | mse_mse: 0.02064 |  0:03:19s\n",
      "epoch 52 | loss: 0.01807 | mse_mse: 0.01221 |  0:03:23s\n",
      "epoch 53 | loss: 0.01327 | mse_mse: 0.01523 |  0:03:26s\n",
      "epoch 54 | loss: 0.01634 | mse_mse: 0.02499 |  0:03:30s\n",
      "epoch 55 | loss: 0.01278 | mse_mse: 0.0123  |  0:03:34s\n",
      "epoch 56 | loss: 0.01717 | mse_mse: 0.02189 |  0:03:38s\n",
      "epoch 57 | loss: 0.01306 | mse_mse: 0.02415 |  0:03:42s\n",
      "epoch 58 | loss: 0.01595 | mse_mse: 0.04567 |  0:03:45s\n",
      "epoch 59 | loss: 0.01344 | mse_mse: 0.00942 |  0:03:49s\n",
      "epoch 60 | loss: 0.01108 | mse_mse: 0.00977 |  0:03:53s\n",
      "epoch 61 | loss: 0.01193 | mse_mse: 0.01673 |  0:03:57s\n",
      "epoch 62 | loss: 0.01483 | mse_mse: 0.01031 |  0:04:01s\n",
      "epoch 63 | loss: 0.01311 | mse_mse: 0.01437 |  0:04:05s\n",
      "epoch 64 | loss: 0.01074 | mse_mse: 0.01309 |  0:04:09s\n",
      "epoch 65 | loss: 0.01279 | mse_mse: 0.00934 |  0:04:13s\n",
      "epoch 66 | loss: 0.01043 | mse_mse: 0.0134  |  0:04:16s\n",
      "epoch 67 | loss: 0.01071 | mse_mse: 0.00718 |  0:04:20s\n",
      "epoch 68 | loss: 0.01469 | mse_mse: 0.02745 |  0:04:24s\n",
      "epoch 69 | loss: 0.01297 | mse_mse: 0.01178 |  0:04:28s\n",
      "epoch 70 | loss: 0.01158 | mse_mse: 0.00742 |  0:04:32s\n",
      "epoch 71 | loss: 0.01069 | mse_mse: 0.00826 |  0:04:36s\n",
      "epoch 72 | loss: 0.0117  | mse_mse: 0.0086  |  0:04:40s\n",
      "epoch 73 | loss: 0.00989 | mse_mse: 0.00956 |  0:04:43s\n",
      "epoch 74 | loss: 0.00983 | mse_mse: 0.00689 |  0:04:47s\n",
      "epoch 75 | loss: 0.0131  | mse_mse: 0.0101  |  0:04:51s\n",
      "epoch 76 | loss: 0.01026 | mse_mse: 0.00804 |  0:04:55s\n",
      "epoch 77 | loss: 0.01004 | mse_mse: 0.00852 |  0:04:59s\n",
      "epoch 78 | loss: 0.01041 | mse_mse: 0.01098 |  0:05:03s\n",
      "epoch 79 | loss: 0.01152 | mse_mse: 0.00998 |  0:05:07s\n",
      "epoch 80 | loss: 0.01174 | mse_mse: 0.01301 |  0:05:10s\n",
      "epoch 81 | loss: 0.01071 | mse_mse: 0.01034 |  0:05:14s\n",
      "epoch 82 | loss: 0.01028 | mse_mse: 0.0082  |  0:05:18s\n",
      "epoch 83 | loss: 0.0086  | mse_mse: 0.00889 |  0:05:22s\n",
      "epoch 84 | loss: 0.01021 | mse_mse: 0.00814 |  0:05:26s\n",
      "\n",
      "Early stopping occurred at epoch 84 with best_epoch = 74 and best_mse_mse = 0.00689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007392710870035852\n",
      "R2 Score: 0.9666493384490132\n",
      "\n",
      "Iteration 35/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.91116 | mse_mse: 1.00178 |  0:00:04s\n",
      "epoch 1  | loss: 0.4296  | mse_mse: 0.35906 |  0:00:09s\n",
      "epoch 2  | loss: 0.41196 | mse_mse: 0.32544 |  0:00:14s\n",
      "epoch 3  | loss: 0.34702 | mse_mse: 0.11864 |  0:00:19s\n",
      "epoch 4  | loss: 0.31666 | mse_mse: 0.1857  |  0:00:23s\n",
      "epoch 5  | loss: 0.18653 | mse_mse: 0.09919 |  0:00:28s\n",
      "epoch 6  | loss: 0.13996 | mse_mse: 0.09775 |  0:00:33s\n",
      "epoch 7  | loss: 0.13662 | mse_mse: 0.10067 |  0:00:38s\n",
      "epoch 8  | loss: 0.13733 | mse_mse: 0.10083 |  0:00:42s\n",
      "epoch 9  | loss: 0.11782 | mse_mse: 0.0888  |  0:00:47s\n",
      "epoch 10 | loss: 0.12941 | mse_mse: 0.10172 |  0:00:52s\n",
      "epoch 11 | loss: 0.11258 | mse_mse: 0.09177 |  0:00:57s\n",
      "epoch 12 | loss: 0.11004 | mse_mse: 0.09065 |  0:01:01s\n",
      "epoch 13 | loss: 0.11044 | mse_mse: 0.09839 |  0:01:06s\n",
      "epoch 14 | loss: 0.11255 | mse_mse: 0.08745 |  0:01:11s\n",
      "epoch 15 | loss: 0.11719 | mse_mse: 0.08978 |  0:01:15s\n",
      "epoch 16 | loss: 0.11502 | mse_mse: 0.09019 |  0:01:20s\n",
      "epoch 17 | loss: 0.12161 | mse_mse: 0.1102  |  0:01:25s\n",
      "epoch 18 | loss: 0.11192 | mse_mse: 0.08638 |  0:01:30s\n",
      "epoch 19 | loss: 0.10569 | mse_mse: 0.0941  |  0:01:35s\n",
      "epoch 20 | loss: 0.10828 | mse_mse: 0.08761 |  0:01:39s\n",
      "epoch 21 | loss: 0.10611 | mse_mse: 0.0891  |  0:01:44s\n",
      "epoch 22 | loss: 0.1109  | mse_mse: 0.10944 |  0:01:49s\n",
      "epoch 23 | loss: 0.11644 | mse_mse: 0.08797 |  0:01:54s\n",
      "epoch 24 | loss: 0.10343 | mse_mse: 0.10401 |  0:01:59s\n",
      "epoch 25 | loss: 0.11145 | mse_mse: 0.08698 |  0:02:03s\n",
      "epoch 26 | loss: 0.10533 | mse_mse: 0.08787 |  0:02:08s\n",
      "epoch 27 | loss: 0.10159 | mse_mse: 0.08887 |  0:02:13s\n",
      "epoch 28 | loss: 0.10526 | mse_mse: 0.085   |  0:02:18s\n",
      "epoch 29 | loss: 0.10417 | mse_mse: 0.08488 |  0:02:23s\n",
      "epoch 30 | loss: 0.10088 | mse_mse: 0.08745 |  0:02:28s\n",
      "epoch 31 | loss: 0.10206 | mse_mse: 0.08323 |  0:02:32s\n",
      "epoch 32 | loss: 0.1026  | mse_mse: 0.09534 |  0:02:37s\n",
      "epoch 33 | loss: 0.10155 | mse_mse: 0.08644 |  0:02:42s\n",
      "epoch 34 | loss: 0.09957 | mse_mse: 0.08538 |  0:02:47s\n",
      "epoch 35 | loss: 0.09575 | mse_mse: 0.08401 |  0:02:51s\n",
      "epoch 36 | loss: 0.09901 | mse_mse: 0.08805 |  0:02:56s\n",
      "epoch 37 | loss: 0.09659 | mse_mse: 0.08592 |  0:03:01s\n",
      "epoch 38 | loss: 0.09385 | mse_mse: 0.08848 |  0:03:06s\n",
      "epoch 39 | loss: 0.09843 | mse_mse: 0.08147 |  0:03:11s\n",
      "epoch 40 | loss: 0.09568 | mse_mse: 0.08564 |  0:03:16s\n",
      "epoch 41 | loss: 0.09386 | mse_mse: 0.08095 |  0:03:21s\n",
      "epoch 42 | loss: 0.09378 | mse_mse: 0.0806  |  0:03:25s\n",
      "epoch 43 | loss: 0.09037 | mse_mse: 0.08084 |  0:03:30s\n",
      "epoch 44 | loss: 0.08585 | mse_mse: 0.07626 |  0:03:35s\n",
      "epoch 45 | loss: 0.08751 | mse_mse: 0.0773  |  0:03:40s\n",
      "epoch 46 | loss: 0.08856 | mse_mse: 0.07666 |  0:03:45s\n",
      "epoch 47 | loss: 0.08601 | mse_mse: 0.0792  |  0:03:50s\n",
      "epoch 48 | loss: 0.08209 | mse_mse: 0.07814 |  0:03:54s\n",
      "epoch 49 | loss: 0.08175 | mse_mse: 0.07391 |  0:03:59s\n",
      "epoch 50 | loss: 0.07967 | mse_mse: 0.07274 |  0:04:04s\n",
      "epoch 51 | loss: 0.07808 | mse_mse: 0.06913 |  0:04:09s\n",
      "epoch 52 | loss: 0.07867 | mse_mse: 0.08375 |  0:04:14s\n",
      "epoch 53 | loss: 0.07742 | mse_mse: 0.07229 |  0:04:19s\n",
      "epoch 54 | loss: 0.08426 | mse_mse: 0.07835 |  0:04:23s\n",
      "epoch 55 | loss: 0.07834 | mse_mse: 0.06947 |  0:04:28s\n",
      "epoch 56 | loss: 0.0774  | mse_mse: 0.06897 |  0:04:33s\n",
      "epoch 57 | loss: 0.07497 | mse_mse: 0.06779 |  0:04:38s\n",
      "epoch 58 | loss: 0.07336 | mse_mse: 0.06588 |  0:04:43s\n",
      "epoch 59 | loss: 0.07539 | mse_mse: 0.06631 |  0:04:48s\n",
      "epoch 60 | loss: 0.07471 | mse_mse: 0.07367 |  0:04:53s\n",
      "epoch 61 | loss: 0.07631 | mse_mse: 0.1068  |  0:04:57s\n",
      "epoch 62 | loss: 0.08052 | mse_mse: 0.06312 |  0:05:02s\n",
      "epoch 63 | loss: 0.07988 | mse_mse: 0.0765  |  0:05:07s\n",
      "epoch 64 | loss: 0.07357 | mse_mse: 0.06545 |  0:05:12s\n",
      "epoch 65 | loss: 0.06842 | mse_mse: 0.06215 |  0:05:17s\n",
      "epoch 66 | loss: 0.06975 | mse_mse: 0.06647 |  0:05:22s\n",
      "epoch 67 | loss: 0.06825 | mse_mse: 0.06549 |  0:05:26s\n",
      "epoch 68 | loss: 0.0688  | mse_mse: 0.06901 |  0:05:31s\n",
      "epoch 69 | loss: 0.07046 | mse_mse: 0.07304 |  0:05:36s\n",
      "epoch 70 | loss: 0.07007 | mse_mse: 0.05892 |  0:05:41s\n",
      "epoch 71 | loss: 0.06416 | mse_mse: 0.05761 |  0:05:46s\n",
      "epoch 72 | loss: 0.066   | mse_mse: 0.07095 |  0:05:51s\n",
      "epoch 73 | loss: 0.06579 | mse_mse: 0.05704 |  0:05:55s\n",
      "epoch 74 | loss: 0.06416 | mse_mse: 0.05514 |  0:06:00s\n",
      "epoch 75 | loss: 0.06227 | mse_mse: 0.05799 |  0:06:05s\n",
      "epoch 76 | loss: 0.05912 | mse_mse: 0.05354 |  0:06:10s\n",
      "epoch 77 | loss: 0.05894 | mse_mse: 0.05602 |  0:06:15s\n",
      "epoch 78 | loss: 0.05655 | mse_mse: 0.05305 |  0:06:20s\n",
      "epoch 79 | loss: 0.0582  | mse_mse: 0.04722 |  0:06:25s\n",
      "epoch 80 | loss: 0.05515 | mse_mse: 0.04494 |  0:06:29s\n",
      "epoch 81 | loss: 0.05314 | mse_mse: 0.04413 |  0:06:34s\n",
      "epoch 82 | loss: 0.04976 | mse_mse: 0.04239 |  0:06:39s\n",
      "epoch 83 | loss: 0.05177 | mse_mse: 0.04364 |  0:06:44s\n",
      "epoch 84 | loss: 0.04655 | mse_mse: 0.04632 |  0:06:49s\n",
      "epoch 85 | loss: 0.04627 | mse_mse: 0.05024 |  0:06:54s\n",
      "epoch 86 | loss: 0.04732 | mse_mse: 0.03817 |  0:06:59s\n",
      "epoch 87 | loss: 0.0484  | mse_mse: 0.03802 |  0:07:03s\n",
      "epoch 88 | loss: 0.04278 | mse_mse: 0.03411 |  0:07:08s\n",
      "epoch 89 | loss: 0.0411  | mse_mse: 0.0338  |  0:07:13s\n",
      "epoch 90 | loss: 0.03989 | mse_mse: 0.03332 |  0:07:17s\n",
      "epoch 91 | loss: 0.03326 | mse_mse: 0.02994 |  0:07:22s\n",
      "epoch 92 | loss: 0.03301 | mse_mse: 0.02966 |  0:07:27s\n",
      "epoch 93 | loss: 0.03372 | mse_mse: 0.02567 |  0:07:32s\n",
      "epoch 94 | loss: 0.02894 | mse_mse: 0.02743 |  0:07:36s\n",
      "epoch 95 | loss: 0.03235 | mse_mse: 0.02309 |  0:07:41s\n",
      "epoch 96 | loss: 0.03011 | mse_mse: 0.02815 |  0:07:46s\n",
      "epoch 97 | loss: 0.02618 | mse_mse: 0.03067 |  0:07:51s\n",
      "epoch 98 | loss: 0.02595 | mse_mse: 0.0198  |  0:07:55s\n",
      "epoch 99 | loss: 0.02499 | mse_mse: 0.01843 |  0:08:00s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_mse_mse = 0.01843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.018853727195841722\n",
      "R2 Score: 0.9149453717672442\n",
      "\n",
      "Iteration 36/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.8856  | mse_mse: 1.10348 |  0:00:05s\n",
      "epoch 1  | loss: 0.41469 | mse_mse: 0.24155 |  0:00:10s\n",
      "epoch 2  | loss: 0.37475 | mse_mse: 0.57115 |  0:00:15s\n",
      "epoch 3  | loss: 0.44145 | mse_mse: 0.40362 |  0:00:20s\n",
      "epoch 4  | loss: 0.33362 | mse_mse: 0.25866 |  0:00:25s\n",
      "epoch 5  | loss: 0.25614 | mse_mse: 0.22904 |  0:00:30s\n",
      "epoch 6  | loss: 0.24366 | mse_mse: 0.24235 |  0:00:35s\n",
      "epoch 7  | loss: 0.23323 | mse_mse: 0.20184 |  0:00:40s\n",
      "epoch 8  | loss: 0.22166 | mse_mse: 0.22238 |  0:00:46s\n",
      "epoch 9  | loss: 0.21462 | mse_mse: 0.1863  |  0:00:51s\n",
      "epoch 10 | loss: 0.20743 | mse_mse: 0.1829  |  0:00:56s\n",
      "epoch 11 | loss: 0.19924 | mse_mse: 0.17312 |  0:01:01s\n",
      "epoch 12 | loss: 0.20392 | mse_mse: 0.18028 |  0:01:06s\n",
      "epoch 13 | loss: 0.1773  | mse_mse: 0.13699 |  0:01:11s\n",
      "epoch 14 | loss: 0.162   | mse_mse: 0.12835 |  0:01:17s\n",
      "epoch 15 | loss: 0.13188 | mse_mse: 0.11974 |  0:01:22s\n",
      "epoch 16 | loss: 0.12423 | mse_mse: 0.10776 |  0:01:27s\n",
      "epoch 17 | loss: 0.10566 | mse_mse: 0.08761 |  0:01:32s\n",
      "epoch 18 | loss: 0.10578 | mse_mse: 0.09679 |  0:01:37s\n",
      "epoch 19 | loss: 0.09777 | mse_mse: 0.09134 |  0:01:42s\n",
      "epoch 20 | loss: 0.09339 | mse_mse: 0.08177 |  0:01:48s\n",
      "epoch 21 | loss: 0.09032 | mse_mse: 0.0924  |  0:01:53s\n",
      "epoch 22 | loss: 0.08966 | mse_mse: 0.08536 |  0:01:58s\n",
      "epoch 23 | loss: 0.08539 | mse_mse: 0.07462 |  0:02:03s\n",
      "epoch 24 | loss: 0.08785 | mse_mse: 0.07152 |  0:02:09s\n",
      "epoch 25 | loss: 0.08163 | mse_mse: 0.07402 |  0:02:14s\n",
      "epoch 26 | loss: 0.08138 | mse_mse: 0.07134 |  0:02:19s\n",
      "epoch 27 | loss: 0.08749 | mse_mse: 0.09174 |  0:02:24s\n",
      "epoch 28 | loss: 0.0803  | mse_mse: 0.07941 |  0:02:29s\n",
      "epoch 29 | loss: 0.08735 | mse_mse: 0.06962 |  0:02:35s\n",
      "epoch 30 | loss: 0.0791  | mse_mse: 0.06722 |  0:02:40s\n",
      "epoch 31 | loss: 0.08009 | mse_mse: 0.0647  |  0:02:45s\n",
      "epoch 32 | loss: 0.0802  | mse_mse: 0.06622 |  0:02:50s\n",
      "epoch 33 | loss: 0.07496 | mse_mse: 0.06347 |  0:02:55s\n",
      "epoch 34 | loss: 0.07092 | mse_mse: 0.06734 |  0:03:01s\n",
      "epoch 35 | loss: 0.07576 | mse_mse: 0.08362 |  0:03:06s\n",
      "epoch 36 | loss: 0.07806 | mse_mse: 0.07108 |  0:03:11s\n",
      "epoch 37 | loss: 0.07271 | mse_mse: 0.08071 |  0:03:16s\n",
      "epoch 38 | loss: 0.07401 | mse_mse: 0.06558 |  0:03:21s\n",
      "epoch 39 | loss: 0.0717  | mse_mse: 0.06863 |  0:03:27s\n",
      "epoch 40 | loss: 0.07616 | mse_mse: 0.06184 |  0:03:32s\n",
      "epoch 41 | loss: 0.06728 | mse_mse: 0.06718 |  0:03:37s\n",
      "epoch 42 | loss: 0.06747 | mse_mse: 0.06251 |  0:03:42s\n",
      "epoch 43 | loss: 0.06217 | mse_mse: 0.05748 |  0:03:47s\n",
      "epoch 44 | loss: 0.05948 | mse_mse: 0.05521 |  0:03:52s\n",
      "epoch 45 | loss: 0.06067 | mse_mse: 0.05419 |  0:03:58s\n",
      "epoch 46 | loss: 0.05623 | mse_mse: 0.05316 |  0:04:03s\n",
      "epoch 47 | loss: 0.05543 | mse_mse: 0.05629 |  0:04:08s\n",
      "epoch 48 | loss: 0.05905 | mse_mse: 0.06795 |  0:04:13s\n",
      "epoch 49 | loss: 0.05479 | mse_mse: 0.0474  |  0:04:18s\n",
      "epoch 50 | loss: 0.04678 | mse_mse: 0.04887 |  0:04:24s\n",
      "epoch 51 | loss: 0.0481  | mse_mse: 0.04717 |  0:04:29s\n",
      "epoch 52 | loss: 0.04561 | mse_mse: 0.04474 |  0:04:34s\n",
      "epoch 53 | loss: 0.04347 | mse_mse: 0.04184 |  0:04:39s\n",
      "epoch 54 | loss: 0.0409  | mse_mse: 0.03588 |  0:04:45s\n",
      "epoch 55 | loss: 0.03976 | mse_mse: 0.04222 |  0:04:50s\n",
      "epoch 56 | loss: 0.04007 | mse_mse: 0.03434 |  0:04:55s\n",
      "epoch 57 | loss: 0.03698 | mse_mse: 0.03819 |  0:05:00s\n",
      "epoch 58 | loss: 0.03788 | mse_mse: 0.04362 |  0:05:06s\n",
      "epoch 59 | loss: 0.03603 | mse_mse: 0.03013 |  0:05:11s\n",
      "epoch 60 | loss: 0.03403 | mse_mse: 0.03134 |  0:05:16s\n",
      "epoch 61 | loss: 0.0314  | mse_mse: 0.02877 |  0:05:21s\n",
      "epoch 62 | loss: 0.03082 | mse_mse: 0.0311  |  0:05:27s\n",
      "epoch 63 | loss: 0.03042 | mse_mse: 0.04479 |  0:05:32s\n",
      "epoch 64 | loss: 0.03142 | mse_mse: 0.02716 |  0:05:37s\n",
      "epoch 65 | loss: 0.03319 | mse_mse: 0.02652 |  0:05:42s\n",
      "epoch 66 | loss: 0.027   | mse_mse: 0.02965 |  0:05:48s\n",
      "epoch 67 | loss: 0.0299  | mse_mse: 0.02584 |  0:05:53s\n",
      "epoch 68 | loss: 0.02712 | mse_mse: 0.04757 |  0:05:58s\n",
      "epoch 69 | loss: 0.02789 | mse_mse: 0.0315  |  0:06:03s\n",
      "epoch 70 | loss: 0.02612 | mse_mse: 0.0492  |  0:06:08s\n",
      "epoch 71 | loss: 0.02572 | mse_mse: 0.02469 |  0:06:14s\n",
      "epoch 72 | loss: 0.02597 | mse_mse: 0.06829 |  0:06:19s\n",
      "epoch 73 | loss: 0.02329 | mse_mse: 0.01988 |  0:06:24s\n",
      "epoch 74 | loss: 0.02485 | mse_mse: 0.04518 |  0:06:29s\n",
      "epoch 75 | loss: 0.02286 | mse_mse: 0.01796 |  0:06:35s\n",
      "epoch 76 | loss: 0.02206 | mse_mse: 0.02793 |  0:06:40s\n",
      "epoch 77 | loss: 0.02683 | mse_mse: 0.01602 |  0:06:45s\n",
      "epoch 78 | loss: 0.02021 | mse_mse: 0.0168  |  0:06:50s\n",
      "epoch 79 | loss: 0.02138 | mse_mse: 0.01729 |  0:06:56s\n",
      "epoch 80 | loss: 0.02244 | mse_mse: 0.01541 |  0:07:01s\n",
      "epoch 81 | loss: 0.02031 | mse_mse: 0.02485 |  0:07:06s\n",
      "epoch 82 | loss: 0.01761 | mse_mse: 0.0165  |  0:07:11s\n",
      "epoch 83 | loss: 0.01825 | mse_mse: 0.04442 |  0:07:17s\n",
      "epoch 84 | loss: 0.01676 | mse_mse: 0.02332 |  0:07:22s\n",
      "epoch 85 | loss: 0.01816 | mse_mse: 0.02027 |  0:07:27s\n",
      "epoch 86 | loss: 0.01619 | mse_mse: 0.0122  |  0:07:32s\n",
      "epoch 87 | loss: 0.01332 | mse_mse: 0.01845 |  0:07:38s\n",
      "epoch 88 | loss: 0.01721 | mse_mse: 0.01652 |  0:07:43s\n",
      "epoch 89 | loss: 0.01549 | mse_mse: 0.01592 |  0:07:48s\n",
      "epoch 90 | loss: 0.01318 | mse_mse: 0.0142  |  0:07:53s\n",
      "epoch 91 | loss: 0.01392 | mse_mse: 0.0116  |  0:07:58s\n",
      "epoch 92 | loss: 0.01412 | mse_mse: 0.01064 |  0:08:04s\n",
      "epoch 93 | loss: 0.01292 | mse_mse: 0.01042 |  0:08:09s\n",
      "epoch 94 | loss: 0.01796 | mse_mse: 0.00961 |  0:08:14s\n",
      "epoch 95 | loss: 0.01257 | mse_mse: 0.01549 |  0:08:19s\n",
      "epoch 96 | loss: 0.01166 | mse_mse: 0.00958 |  0:08:25s\n",
      "epoch 97 | loss: 0.0134  | mse_mse: 0.02459 |  0:08:30s\n",
      "epoch 98 | loss: 0.01184 | mse_mse: 0.01048 |  0:08:35s\n",
      "epoch 99 | loss: 0.01209 | mse_mse: 0.01046 |  0:08:40s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 96 and best_mse_mse = 0.00958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0097063774751889\n",
      "R2 Score: 0.9562117177646937\n",
      "\n",
      "Iteration 37/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.64538 | mse_mse: 1.45941 |  0:00:02s\n",
      "epoch 1  | loss: 0.33909 | mse_mse: 0.45218 |  0:00:04s\n",
      "epoch 2  | loss: 0.25912 | mse_mse: 0.26751 |  0:00:06s\n",
      "epoch 3  | loss: 0.23296 | mse_mse: 0.18742 |  0:00:08s\n",
      "epoch 4  | loss: 0.21163 | mse_mse: 0.18179 |  0:00:11s\n",
      "epoch 5  | loss: 0.20404 | mse_mse: 0.19385 |  0:00:13s\n",
      "epoch 6  | loss: 0.20478 | mse_mse: 0.17939 |  0:00:15s\n",
      "epoch 7  | loss: 0.19906 | mse_mse: 0.16449 |  0:00:17s\n",
      "epoch 8  | loss: 0.18508 | mse_mse: 0.15739 |  0:00:19s\n",
      "epoch 9  | loss: 0.17431 | mse_mse: 0.13679 |  0:00:21s\n",
      "epoch 10 | loss: 0.15183 | mse_mse: 0.12598 |  0:00:24s\n",
      "epoch 11 | loss: 0.12384 | mse_mse: 0.12099 |  0:00:26s\n",
      "epoch 12 | loss: 0.10303 | mse_mse: 0.08609 |  0:00:28s\n",
      "epoch 13 | loss: 0.09596 | mse_mse: 0.08084 |  0:00:30s\n",
      "epoch 14 | loss: 0.08788 | mse_mse: 0.06855 |  0:00:32s\n",
      "epoch 15 | loss: 0.08059 | mse_mse: 0.07654 |  0:00:35s\n",
      "epoch 16 | loss: 0.07634 | mse_mse: 0.06171 |  0:00:37s\n",
      "epoch 17 | loss: 0.07273 | mse_mse: 0.05823 |  0:00:39s\n",
      "epoch 18 | loss: 0.07375 | mse_mse: 0.05645 |  0:00:41s\n",
      "epoch 19 | loss: 0.06403 | mse_mse: 0.06009 |  0:00:43s\n",
      "epoch 20 | loss: 0.06235 | mse_mse: 0.07107 |  0:00:45s\n",
      "epoch 21 | loss: 0.06161 | mse_mse: 0.05404 |  0:00:48s\n",
      "epoch 22 | loss: 0.05631 | mse_mse: 0.04824 |  0:00:50s\n",
      "epoch 23 | loss: 0.05289 | mse_mse: 0.04464 |  0:00:52s\n",
      "epoch 24 | loss: 0.053   | mse_mse: 0.04264 |  0:00:54s\n",
      "epoch 25 | loss: 0.04817 | mse_mse: 0.03748 |  0:00:56s\n",
      "epoch 26 | loss: 0.04424 | mse_mse: 0.03697 |  0:00:59s\n",
      "epoch 27 | loss: 0.04149 | mse_mse: 0.04557 |  0:01:01s\n",
      "epoch 28 | loss: 0.04228 | mse_mse: 0.03237 |  0:01:03s\n",
      "epoch 29 | loss: 0.03564 | mse_mse: 0.03056 |  0:01:05s\n",
      "epoch 30 | loss: 0.03608 | mse_mse: 0.03723 |  0:01:07s\n",
      "epoch 31 | loss: 0.0326  | mse_mse: 0.02686 |  0:01:10s\n",
      "epoch 32 | loss: 0.02716 | mse_mse: 0.03342 |  0:01:12s\n",
      "epoch 33 | loss: 0.02811 | mse_mse: 0.02257 |  0:01:14s\n",
      "epoch 34 | loss: 0.02431 | mse_mse: 0.02264 |  0:01:16s\n",
      "epoch 35 | loss: 0.02243 | mse_mse: 0.01808 |  0:01:18s\n",
      "epoch 36 | loss: 0.0221  | mse_mse: 0.01923 |  0:01:21s\n",
      "epoch 37 | loss: 0.02254 | mse_mse: 0.0251  |  0:01:23s\n",
      "epoch 38 | loss: 0.02004 | mse_mse: 0.01522 |  0:01:25s\n",
      "epoch 39 | loss: 0.0196  | mse_mse: 0.01566 |  0:01:27s\n",
      "epoch 40 | loss: 0.01505 | mse_mse: 0.01398 |  0:01:29s\n",
      "epoch 41 | loss: 0.01462 | mse_mse: 0.02358 |  0:01:31s\n",
      "epoch 42 | loss: 0.02134 | mse_mse: 0.0178  |  0:01:33s\n",
      "epoch 43 | loss: 0.0158  | mse_mse: 0.01786 |  0:01:36s\n",
      "epoch 44 | loss: 0.01523 | mse_mse: 0.01866 |  0:01:38s\n",
      "epoch 45 | loss: 0.01632 | mse_mse: 0.01592 |  0:01:40s\n",
      "epoch 46 | loss: 0.01636 | mse_mse: 0.02913 |  0:01:42s\n",
      "epoch 47 | loss: 0.01577 | mse_mse: 0.01085 |  0:01:44s\n",
      "epoch 48 | loss: 0.01571 | mse_mse: 0.00952 |  0:01:47s\n",
      "epoch 49 | loss: 0.01257 | mse_mse: 0.00977 |  0:01:49s\n",
      "epoch 50 | loss: 0.01277 | mse_mse: 0.02017 |  0:01:51s\n",
      "epoch 51 | loss: 0.016   | mse_mse: 0.01583 |  0:01:53s\n",
      "epoch 52 | loss: 0.0185  | mse_mse: 0.01044 |  0:01:55s\n",
      "epoch 53 | loss: 0.01461 | mse_mse: 0.02186 |  0:01:57s\n",
      "epoch 54 | loss: 0.01263 | mse_mse: 0.01183 |  0:02:00s\n",
      "epoch 55 | loss: 0.01145 | mse_mse: 0.00971 |  0:02:02s\n",
      "epoch 56 | loss: 0.01228 | mse_mse: 0.0144  |  0:02:04s\n",
      "epoch 57 | loss: 0.0157  | mse_mse: 0.01101 |  0:02:06s\n",
      "epoch 58 | loss: 0.0178  | mse_mse: 0.01396 |  0:02:08s\n",
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 48 and best_mse_mse = 0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009494435693454387\n",
      "R2 Score: 0.957167848574542\n",
      "\n",
      "Iteration 38/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.15972 | mse_mse: 0.98917 |  0:00:02s\n",
      "epoch 1  | loss: 0.32472 | mse_mse: 0.55316 |  0:00:04s\n",
      "epoch 2  | loss: 0.26725 | mse_mse: 0.35732 |  0:00:07s\n",
      "epoch 3  | loss: 0.25507 | mse_mse: 0.26735 |  0:00:09s\n",
      "epoch 4  | loss: 0.24362 | mse_mse: 0.29053 |  0:00:11s\n",
      "epoch 5  | loss: 0.24203 | mse_mse: 0.23922 |  0:00:14s\n",
      "epoch 6  | loss: 0.23675 | mse_mse: 0.28917 |  0:00:16s\n",
      "epoch 7  | loss: 0.23085 | mse_mse: 0.20478 |  0:00:18s\n",
      "epoch 8  | loss: 0.21582 | mse_mse: 0.20299 |  0:00:21s\n",
      "epoch 9  | loss: 0.15504 | mse_mse: 0.14111 |  0:00:23s\n",
      "epoch 10 | loss: 0.09516 | mse_mse: 0.06702 |  0:00:25s\n",
      "epoch 11 | loss: 0.07954 | mse_mse: 0.05969 |  0:00:28s\n",
      "epoch 12 | loss: 0.05711 | mse_mse: 0.05081 |  0:00:30s\n",
      "epoch 13 | loss: 0.05666 | mse_mse: 0.04462 |  0:00:32s\n",
      "epoch 14 | loss: 0.04709 | mse_mse: 0.04252 |  0:00:35s\n",
      "epoch 15 | loss: 0.03608 | mse_mse: 0.0341  |  0:00:37s\n",
      "epoch 16 | loss: 0.03258 | mse_mse: 0.02315 |  0:00:40s\n",
      "epoch 17 | loss: 0.02948 | mse_mse: 0.02292 |  0:00:42s\n",
      "epoch 18 | loss: 0.02568 | mse_mse: 0.02327 |  0:00:44s\n",
      "epoch 19 | loss: 0.02898 | mse_mse: 0.02135 |  0:00:47s\n",
      "epoch 20 | loss: 0.02566 | mse_mse: 0.01626 |  0:00:49s\n",
      "epoch 21 | loss: 0.02637 | mse_mse: 0.01559 |  0:00:52s\n",
      "epoch 22 | loss: 0.02208 | mse_mse: 0.01802 |  0:00:54s\n",
      "epoch 23 | loss: 0.01887 | mse_mse: 0.02744 |  0:00:56s\n",
      "epoch 24 | loss: 0.01758 | mse_mse: 0.01543 |  0:00:58s\n",
      "epoch 25 | loss: 0.01781 | mse_mse: 0.0229  |  0:01:01s\n",
      "epoch 26 | loss: 0.02289 | mse_mse: 0.01321 |  0:01:03s\n",
      "epoch 27 | loss: 0.0147  | mse_mse: 0.0127  |  0:01:05s\n",
      "epoch 28 | loss: 0.01421 | mse_mse: 0.02754 |  0:01:08s\n",
      "epoch 29 | loss: 0.01388 | mse_mse: 0.01338 |  0:01:10s\n",
      "epoch 30 | loss: 0.01511 | mse_mse: 0.015   |  0:01:13s\n",
      "epoch 31 | loss: 0.01453 | mse_mse: 0.01296 |  0:01:15s\n",
      "epoch 32 | loss: 0.01322 | mse_mse: 0.0103  |  0:01:17s\n",
      "epoch 33 | loss: 0.01377 | mse_mse: 0.01104 |  0:01:20s\n",
      "epoch 34 | loss: 0.01123 | mse_mse: 0.01425 |  0:01:22s\n",
      "epoch 35 | loss: 0.01156 | mse_mse: 0.01113 |  0:01:25s\n",
      "epoch 36 | loss: 0.01577 | mse_mse: 0.01453 |  0:01:27s\n",
      "epoch 37 | loss: 0.01417 | mse_mse: 0.02134 |  0:01:29s\n",
      "epoch 38 | loss: 0.01809 | mse_mse: 0.03397 |  0:01:32s\n",
      "epoch 39 | loss: 0.01469 | mse_mse: 0.0134  |  0:01:34s\n",
      "epoch 40 | loss: 0.01173 | mse_mse: 0.00875 |  0:01:36s\n",
      "epoch 41 | loss: 0.01379 | mse_mse: 0.00852 |  0:01:39s\n",
      "epoch 42 | loss: 0.01133 | mse_mse: 0.00971 |  0:01:41s\n",
      "epoch 43 | loss: 0.01583 | mse_mse: 0.01377 |  0:01:43s\n",
      "epoch 44 | loss: 0.01586 | mse_mse: 0.01289 |  0:01:45s\n",
      "epoch 45 | loss: 0.01385 | mse_mse: 0.00766 |  0:01:48s\n",
      "epoch 46 | loss: 0.01116 | mse_mse: 0.00881 |  0:01:50s\n",
      "epoch 47 | loss: 0.01117 | mse_mse: 0.0125  |  0:01:52s\n",
      "epoch 48 | loss: 0.01337 | mse_mse: 0.00972 |  0:01:55s\n",
      "epoch 49 | loss: 0.00907 | mse_mse: 0.00744 |  0:01:57s\n",
      "epoch 50 | loss: 0.01029 | mse_mse: 0.00784 |  0:02:00s\n",
      "epoch 51 | loss: 0.01102 | mse_mse: 0.01842 |  0:02:02s\n",
      "epoch 52 | loss: 0.00801 | mse_mse: 0.00991 |  0:02:04s\n",
      "epoch 53 | loss: 0.00963 | mse_mse: 0.01025 |  0:02:07s\n",
      "epoch 54 | loss: 0.01278 | mse_mse: 0.01351 |  0:02:09s\n",
      "epoch 55 | loss: 0.00884 | mse_mse: 0.01095 |  0:02:11s\n",
      "epoch 56 | loss: 0.01309 | mse_mse: 0.01227 |  0:02:14s\n",
      "epoch 57 | loss: 0.01033 | mse_mse: 0.00827 |  0:02:16s\n",
      "epoch 58 | loss: 0.01165 | mse_mse: 0.01255 |  0:02:18s\n",
      "epoch 59 | loss: 0.00948 | mse_mse: 0.01885 |  0:02:21s\n",
      "\n",
      "Early stopping occurred at epoch 59 with best_epoch = 49 and best_mse_mse = 0.00744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007837720143866519\n",
      "R2 Score: 0.9646417726264769\n",
      "\n",
      "Iteration 39/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.55977 | mse_mse: 1.25283 |  0:00:03s\n",
      "epoch 1  | loss: 0.4356  | mse_mse: 0.78023 |  0:00:06s\n",
      "epoch 2  | loss: 0.3339  | mse_mse: 0.36296 |  0:00:10s\n",
      "epoch 3  | loss: 0.26603 | mse_mse: 0.28107 |  0:00:13s\n",
      "epoch 4  | loss: 0.26568 | mse_mse: 0.32841 |  0:00:16s\n",
      "epoch 5  | loss: 0.25346 | mse_mse: 0.24493 |  0:00:19s\n",
      "epoch 6  | loss: 0.25069 | mse_mse: 0.25012 |  0:00:23s\n",
      "epoch 7  | loss: 0.24348 | mse_mse: 0.29109 |  0:00:26s\n",
      "epoch 8  | loss: 0.24464 | mse_mse: 0.24424 |  0:00:29s\n",
      "epoch 9  | loss: 0.23949 | mse_mse: 0.24785 |  0:00:33s\n",
      "epoch 10 | loss: 0.23812 | mse_mse: 0.21577 |  0:00:36s\n",
      "epoch 11 | loss: 0.23342 | mse_mse: 0.21281 |  0:00:39s\n",
      "epoch 12 | loss: 0.23584 | mse_mse: 0.21931 |  0:00:43s\n",
      "epoch 13 | loss: 0.21884 | mse_mse: 0.19167 |  0:00:46s\n",
      "epoch 14 | loss: 0.20672 | mse_mse: 0.17121 |  0:00:49s\n",
      "epoch 15 | loss: 0.18268 | mse_mse: 0.15322 |  0:00:53s\n",
      "epoch 16 | loss: 0.15993 | mse_mse: 0.12595 |  0:00:56s\n",
      "epoch 17 | loss: 0.13178 | mse_mse: 0.1066  |  0:00:59s\n",
      "epoch 18 | loss: 0.11338 | mse_mse: 0.09046 |  0:01:03s\n",
      "epoch 19 | loss: 0.09226 | mse_mse: 0.07923 |  0:01:06s\n",
      "epoch 20 | loss: 0.08554 | mse_mse: 0.07471 |  0:01:09s\n",
      "epoch 21 | loss: 0.07354 | mse_mse: 0.06143 |  0:01:13s\n",
      "epoch 22 | loss: 0.05541 | mse_mse: 0.04486 |  0:01:17s\n",
      "epoch 23 | loss: 0.05125 | mse_mse: 0.04151 |  0:01:22s\n",
      "epoch 24 | loss: 0.04151 | mse_mse: 0.03935 |  0:01:25s\n",
      "epoch 25 | loss: 0.03768 | mse_mse: 0.03117 |  0:01:28s\n",
      "epoch 26 | loss: 0.03938 | mse_mse: 0.03506 |  0:01:32s\n",
      "epoch 27 | loss: 0.03301 | mse_mse: 0.02753 |  0:01:35s\n",
      "epoch 28 | loss: 0.03588 | mse_mse: 0.02503 |  0:01:39s\n",
      "epoch 29 | loss: 0.02957 | mse_mse: 0.02408 |  0:01:42s\n",
      "epoch 30 | loss: 0.02807 | mse_mse: 0.02154 |  0:01:45s\n",
      "epoch 31 | loss: 0.02795 | mse_mse: 0.06522 |  0:01:49s\n",
      "epoch 32 | loss: 0.03141 | mse_mse: 0.0173  |  0:01:52s\n",
      "epoch 33 | loss: 0.02157 | mse_mse: 0.02311 |  0:01:55s\n",
      "epoch 34 | loss: 0.03777 | mse_mse: 0.05038 |  0:01:59s\n",
      "epoch 35 | loss: 0.03024 | mse_mse: 0.02731 |  0:02:02s\n",
      "epoch 36 | loss: 0.02634 | mse_mse: 0.01869 |  0:02:05s\n",
      "epoch 37 | loss: 0.02082 | mse_mse: 0.01744 |  0:02:09s\n",
      "epoch 38 | loss: 0.02294 | mse_mse: 0.01771 |  0:02:12s\n",
      "epoch 39 | loss: 0.01833 | mse_mse: 0.01713 |  0:02:15s\n",
      "epoch 40 | loss: 0.01855 | mse_mse: 0.01906 |  0:02:19s\n",
      "epoch 41 | loss: 0.01751 | mse_mse: 0.01339 |  0:02:22s\n",
      "epoch 42 | loss: 0.01706 | mse_mse: 0.01871 |  0:02:25s\n",
      "epoch 43 | loss: 0.02026 | mse_mse: 0.07611 |  0:02:29s\n",
      "epoch 44 | loss: 0.01919 | mse_mse: 0.02054 |  0:02:32s\n",
      "epoch 45 | loss: 0.01716 | mse_mse: 0.0169  |  0:02:35s\n",
      "epoch 46 | loss: 0.017   | mse_mse: 0.01636 |  0:02:39s\n",
      "epoch 47 | loss: 0.01661 | mse_mse: 0.01455 |  0:02:42s\n",
      "epoch 48 | loss: 0.02016 | mse_mse: 0.04979 |  0:02:46s\n",
      "epoch 49 | loss: 0.02664 | mse_mse: 0.01512 |  0:02:49s\n",
      "epoch 50 | loss: 0.01481 | mse_mse: 0.0165  |  0:02:52s\n",
      "epoch 51 | loss: 0.02142 | mse_mse: 0.03183 |  0:02:55s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 41 and best_mse_mse = 0.01339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.013411276146188615\n",
      "R2 Score: 0.9394978459753845\n",
      "\n",
      "Iteration 40/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.9893  | mse_mse: 0.94476 |  0:00:03s\n",
      "epoch 1  | loss: 0.44448 | mse_mse: 0.46555 |  0:00:07s\n",
      "epoch 2  | loss: 0.31057 | mse_mse: 0.12016 |  0:00:10s\n",
      "epoch 3  | loss: 0.21095 | mse_mse: 0.30217 |  0:00:14s\n",
      "epoch 4  | loss: 0.17421 | mse_mse: 0.12341 |  0:00:18s\n",
      "epoch 5  | loss: 0.13206 | mse_mse: 0.08347 |  0:00:21s\n",
      "epoch 6  | loss: 0.11195 | mse_mse: 0.07725 |  0:00:25s\n",
      "epoch 7  | loss: 0.11109 | mse_mse: 0.07738 |  0:00:28s\n",
      "epoch 8  | loss: 0.10287 | mse_mse: 0.0898  |  0:00:32s\n",
      "epoch 9  | loss: 0.09962 | mse_mse: 0.07741 |  0:00:36s\n",
      "epoch 10 | loss: 0.09425 | mse_mse: 0.06801 |  0:00:39s\n",
      "epoch 11 | loss: 0.09037 | mse_mse: 0.06974 |  0:00:43s\n",
      "epoch 12 | loss: 0.09286 | mse_mse: 0.07284 |  0:00:46s\n",
      "epoch 13 | loss: 0.08809 | mse_mse: 0.07085 |  0:00:50s\n",
      "epoch 14 | loss: 0.0904  | mse_mse: 0.06804 |  0:00:54s\n",
      "epoch 15 | loss: 0.08783 | mse_mse: 0.11152 |  0:00:57s\n",
      "epoch 16 | loss: 0.09436 | mse_mse: 0.07956 |  0:01:01s\n",
      "epoch 17 | loss: 0.08412 | mse_mse: 0.06867 |  0:01:04s\n",
      "epoch 18 | loss: 0.07846 | mse_mse: 0.06387 |  0:01:08s\n",
      "epoch 19 | loss: 0.07553 | mse_mse: 0.06101 |  0:01:12s\n",
      "epoch 20 | loss: 0.08447 | mse_mse: 0.05753 |  0:01:15s\n",
      "epoch 21 | loss: 0.06872 | mse_mse: 0.05379 |  0:01:19s\n",
      "epoch 22 | loss: 0.06691 | mse_mse: 0.04944 |  0:01:23s\n",
      "epoch 23 | loss: 0.05859 | mse_mse: 0.05323 |  0:01:26s\n",
      "epoch 24 | loss: 0.05896 | mse_mse: 0.05509 |  0:01:30s\n",
      "epoch 25 | loss: 0.05698 | mse_mse: 0.04703 |  0:01:33s\n",
      "epoch 26 | loss: 0.04789 | mse_mse: 0.03693 |  0:01:37s\n",
      "epoch 27 | loss: 0.0395  | mse_mse: 0.03352 |  0:01:41s\n",
      "epoch 28 | loss: 0.0337  | mse_mse: 0.0281  |  0:01:44s\n",
      "epoch 29 | loss: 0.03256 | mse_mse: 0.02344 |  0:01:48s\n",
      "epoch 30 | loss: 0.02874 | mse_mse: 0.02878 |  0:01:52s\n",
      "epoch 31 | loss: 0.03257 | mse_mse: 0.02892 |  0:01:55s\n",
      "epoch 32 | loss: 0.02665 | mse_mse: 0.02307 |  0:01:59s\n",
      "epoch 33 | loss: 0.02392 | mse_mse: 0.02261 |  0:02:02s\n",
      "epoch 34 | loss: 0.02078 | mse_mse: 0.01608 |  0:02:06s\n",
      "epoch 35 | loss: 0.02094 | mse_mse: 0.01492 |  0:02:10s\n",
      "epoch 36 | loss: 0.02302 | mse_mse: 0.02509 |  0:02:13s\n",
      "epoch 37 | loss: 0.01622 | mse_mse: 0.0142  |  0:02:17s\n",
      "epoch 38 | loss: 0.01614 | mse_mse: 0.01162 |  0:02:21s\n",
      "epoch 39 | loss: 0.01536 | mse_mse: 0.01297 |  0:02:24s\n",
      "epoch 40 | loss: 0.01758 | mse_mse: 0.02605 |  0:02:28s\n",
      "epoch 41 | loss: 0.02393 | mse_mse: 0.01402 |  0:02:31s\n",
      "epoch 42 | loss: 0.01333 | mse_mse: 0.01169 |  0:02:35s\n",
      "epoch 43 | loss: 0.01974 | mse_mse: 0.02341 |  0:02:38s\n",
      "epoch 44 | loss: 0.01496 | mse_mse: 0.00984 |  0:02:42s\n",
      "epoch 45 | loss: 0.01167 | mse_mse: 0.00965 |  0:02:46s\n",
      "epoch 46 | loss: 0.01359 | mse_mse: 0.00987 |  0:02:49s\n",
      "epoch 47 | loss: 0.01617 | mse_mse: 0.01821 |  0:02:53s\n",
      "epoch 48 | loss: 0.01448 | mse_mse: 0.00987 |  0:02:57s\n",
      "epoch 49 | loss: 0.01508 | mse_mse: 0.01567 |  0:03:00s\n",
      "epoch 50 | loss: 0.0104  | mse_mse: 0.01045 |  0:03:04s\n",
      "epoch 51 | loss: 0.01417 | mse_mse: 0.01505 |  0:03:07s\n",
      "epoch 52 | loss: 0.01187 | mse_mse: 0.00778 |  0:03:11s\n",
      "epoch 53 | loss: 0.01074 | mse_mse: 0.00859 |  0:03:15s\n",
      "epoch 54 | loss: 0.01496 | mse_mse: 0.00977 |  0:03:18s\n",
      "epoch 55 | loss: 0.01117 | mse_mse: 0.00927 |  0:03:22s\n",
      "epoch 56 | loss: 0.01294 | mse_mse: 0.01367 |  0:03:26s\n",
      "epoch 57 | loss: 0.01246 | mse_mse: 0.00938 |  0:03:29s\n",
      "epoch 58 | loss: 0.00872 | mse_mse: 0.00944 |  0:03:33s\n",
      "epoch 59 | loss: 0.01363 | mse_mse: 0.01279 |  0:03:36s\n",
      "epoch 60 | loss: 0.01358 | mse_mse: 0.01031 |  0:03:40s\n",
      "epoch 61 | loss: 0.01515 | mse_mse: 0.01352 |  0:03:43s\n",
      "epoch 62 | loss: 0.00986 | mse_mse: 0.00763 |  0:03:47s\n",
      "epoch 63 | loss: 0.00968 | mse_mse: 0.01154 |  0:03:51s\n",
      "epoch 64 | loss: 0.01023 | mse_mse: 0.00791 |  0:03:54s\n",
      "epoch 65 | loss: 0.00992 | mse_mse: 0.01042 |  0:03:58s\n",
      "epoch 66 | loss: 0.01113 | mse_mse: 0.01922 |  0:04:02s\n",
      "epoch 67 | loss: 0.01465 | mse_mse: 0.00845 |  0:04:06s\n",
      "epoch 68 | loss: 0.01066 | mse_mse: 0.0078  |  0:04:10s\n",
      "epoch 69 | loss: 0.01135 | mse_mse: 0.00879 |  0:04:13s\n",
      "epoch 70 | loss: 0.0098  | mse_mse: 0.00798 |  0:04:17s\n",
      "epoch 71 | loss: 0.01085 | mse_mse: 0.00942 |  0:04:20s\n",
      "epoch 72 | loss: 0.00886 | mse_mse: 0.00755 |  0:04:24s\n",
      "epoch 73 | loss: 0.0077  | mse_mse: 0.00802 |  0:04:28s\n",
      "epoch 74 | loss: 0.01055 | mse_mse: 0.00881 |  0:04:31s\n",
      "epoch 75 | loss: 0.00877 | mse_mse: 0.00859 |  0:04:35s\n",
      "epoch 76 | loss: 0.00842 | mse_mse: 0.00777 |  0:04:39s\n",
      "epoch 77 | loss: 0.00952 | mse_mse: 0.00802 |  0:04:42s\n",
      "epoch 78 | loss: 0.00933 | mse_mse: 0.01267 |  0:04:46s\n",
      "epoch 79 | loss: 0.01093 | mse_mse: 0.01626 |  0:04:49s\n",
      "epoch 80 | loss: 0.00914 | mse_mse: 0.00945 |  0:04:53s\n",
      "epoch 81 | loss: 0.01094 | mse_mse: 0.0079  |  0:04:56s\n",
      "epoch 82 | loss: 0.00913 | mse_mse: 0.00745 |  0:05:00s\n",
      "epoch 83 | loss: 0.01461 | mse_mse: 0.01059 |  0:05:04s\n",
      "epoch 84 | loss: 0.01107 | mse_mse: 0.00778 |  0:05:07s\n",
      "epoch 85 | loss: 0.00834 | mse_mse: 0.00756 |  0:05:11s\n",
      "epoch 86 | loss: 0.00948 | mse_mse: 0.02583 |  0:05:14s\n",
      "epoch 87 | loss: 0.01364 | mse_mse: 0.01151 |  0:05:18s\n",
      "epoch 88 | loss: 0.00984 | mse_mse: 0.0088  |  0:05:22s\n",
      "epoch 89 | loss: 0.00787 | mse_mse: 0.00792 |  0:05:25s\n",
      "epoch 90 | loss: 0.01173 | mse_mse: 0.00749 |  0:05:29s\n",
      "epoch 91 | loss: 0.00825 | mse_mse: 0.01402 |  0:05:32s\n",
      "epoch 92 | loss: 0.0101  | mse_mse: 0.00833 |  0:05:36s\n",
      "\n",
      "Early stopping occurred at epoch 92 with best_epoch = 82 and best_mse_mse = 0.00745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007464913438379984\n",
      "R2 Score: 0.9663236117349174\n",
      "\n",
      "Iteration 41/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.7051  | mse_mse: 0.97927 |  0:00:04s\n",
      "epoch 1  | loss: 0.43428 | mse_mse: 0.77195 |  0:00:09s\n",
      "epoch 2  | loss: 0.30338 | mse_mse: 0.13758 |  0:00:13s\n",
      "epoch 3  | loss: 0.44533 | mse_mse: 0.17731 |  0:00:18s\n",
      "epoch 4  | loss: 0.20693 | mse_mse: 0.15254 |  0:00:22s\n",
      "epoch 5  | loss: 0.17846 | mse_mse: 0.20491 |  0:00:27s\n",
      "epoch 6  | loss: 0.15707 | mse_mse: 0.10875 |  0:00:31s\n",
      "epoch 7  | loss: 0.20749 | mse_mse: 0.09628 |  0:00:36s\n",
      "epoch 8  | loss: 0.1329  | mse_mse: 0.09175 |  0:00:40s\n",
      "epoch 9  | loss: 0.12604 | mse_mse: 0.09411 |  0:00:45s\n",
      "epoch 10 | loss: 0.11895 | mse_mse: 0.10097 |  0:00:49s\n",
      "epoch 11 | loss: 0.12612 | mse_mse: 0.09986 |  0:00:54s\n",
      "epoch 12 | loss: 0.11928 | mse_mse: 0.09135 |  0:00:58s\n",
      "epoch 13 | loss: 0.10884 | mse_mse: 0.08784 |  0:01:03s\n",
      "epoch 14 | loss: 0.10775 | mse_mse: 0.0882  |  0:01:07s\n",
      "epoch 15 | loss: 0.11876 | mse_mse: 0.10042 |  0:01:12s\n",
      "epoch 16 | loss: 0.11488 | mse_mse: 0.0909  |  0:01:16s\n",
      "epoch 17 | loss: 0.10975 | mse_mse: 0.09516 |  0:01:21s\n",
      "epoch 18 | loss: 0.10858 | mse_mse: 0.08981 |  0:01:25s\n",
      "epoch 19 | loss: 0.10456 | mse_mse: 0.08691 |  0:01:30s\n",
      "epoch 20 | loss: 0.10197 | mse_mse: 0.09047 |  0:01:34s\n",
      "epoch 21 | loss: 0.10143 | mse_mse: 0.08759 |  0:01:39s\n",
      "epoch 22 | loss: 0.10296 | mse_mse: 0.08488 |  0:01:43s\n",
      "epoch 23 | loss: 0.09651 | mse_mse: 0.08285 |  0:01:48s\n",
      "epoch 24 | loss: 0.09821 | mse_mse: 0.09381 |  0:01:52s\n",
      "epoch 25 | loss: 0.09895 | mse_mse: 0.07983 |  0:01:57s\n",
      "epoch 26 | loss: 0.09729 | mse_mse: 0.09299 |  0:02:02s\n",
      "epoch 27 | loss: 0.09255 | mse_mse: 0.08219 |  0:02:06s\n",
      "epoch 28 | loss: 0.09322 | mse_mse: 0.0799  |  0:02:11s\n",
      "epoch 29 | loss: 0.08969 | mse_mse: 0.07873 |  0:02:15s\n",
      "epoch 30 | loss: 0.08466 | mse_mse: 0.07465 |  0:02:20s\n",
      "epoch 31 | loss: 0.08398 | mse_mse: 0.07615 |  0:02:24s\n",
      "epoch 32 | loss: 0.0817  | mse_mse: 0.07091 |  0:02:29s\n",
      "epoch 33 | loss: 0.07863 | mse_mse: 0.06683 |  0:02:33s\n",
      "epoch 34 | loss: 0.079   | mse_mse: 0.06957 |  0:02:38s\n",
      "epoch 35 | loss: 0.07275 | mse_mse: 0.06504 |  0:02:42s\n",
      "epoch 36 | loss: 0.06974 | mse_mse: 0.06448 |  0:02:47s\n",
      "epoch 37 | loss: 0.06839 | mse_mse: 0.06286 |  0:02:51s\n",
      "epoch 38 | loss: 0.0648  | mse_mse: 0.07059 |  0:02:56s\n",
      "epoch 39 | loss: 0.06439 | mse_mse: 0.05462 |  0:03:00s\n",
      "epoch 40 | loss: 0.06424 | mse_mse: 0.05776 |  0:03:05s\n",
      "epoch 41 | loss: 0.05785 | mse_mse: 0.05885 |  0:03:09s\n",
      "epoch 42 | loss: 0.05468 | mse_mse: 0.04861 |  0:03:14s\n",
      "epoch 43 | loss: 0.05076 | mse_mse: 0.06474 |  0:03:18s\n",
      "epoch 44 | loss: 0.05004 | mse_mse: 0.0421  |  0:03:23s\n",
      "epoch 45 | loss: 0.04645 | mse_mse: 0.0485  |  0:03:28s\n",
      "epoch 46 | loss: 0.04734 | mse_mse: 0.03873 |  0:03:32s\n",
      "epoch 47 | loss: 0.04183 | mse_mse: 0.04313 |  0:03:36s\n",
      "epoch 48 | loss: 0.04304 | mse_mse: 0.03655 |  0:03:41s\n",
      "epoch 49 | loss: 0.03775 | mse_mse: 0.03449 |  0:03:45s\n",
      "epoch 50 | loss: 0.03559 | mse_mse: 0.03525 |  0:03:50s\n",
      "epoch 51 | loss: 0.03885 | mse_mse: 0.05076 |  0:03:55s\n",
      "epoch 52 | loss: 0.04729 | mse_mse: 0.06251 |  0:03:59s\n",
      "epoch 53 | loss: 0.0431  | mse_mse: 0.02911 |  0:04:04s\n",
      "epoch 54 | loss: 0.02968 | mse_mse: 0.02636 |  0:04:08s\n",
      "epoch 55 | loss: 0.03184 | mse_mse: 0.03421 |  0:04:13s\n",
      "epoch 56 | loss: 0.02807 | mse_mse: 0.02435 |  0:04:17s\n",
      "epoch 57 | loss: 0.02634 | mse_mse: 0.02478 |  0:04:22s\n",
      "epoch 58 | loss: 0.02713 | mse_mse: 0.02844 |  0:04:26s\n",
      "epoch 59 | loss: 0.02703 | mse_mse: 0.03432 |  0:04:31s\n",
      "epoch 60 | loss: 0.02643 | mse_mse: 0.02446 |  0:04:35s\n",
      "epoch 61 | loss: 0.02661 | mse_mse: 0.02146 |  0:04:40s\n",
      "epoch 62 | loss: 0.02235 | mse_mse: 0.02222 |  0:04:44s\n",
      "epoch 63 | loss: 0.02548 | mse_mse: 0.02678 |  0:04:49s\n",
      "epoch 64 | loss: 0.02574 | mse_mse: 0.02092 |  0:04:54s\n",
      "epoch 65 | loss: 0.02518 | mse_mse: 0.01801 |  0:04:58s\n",
      "epoch 66 | loss: 0.0213  | mse_mse: 0.01717 |  0:05:03s\n",
      "epoch 67 | loss: 0.02555 | mse_mse: 0.01808 |  0:05:07s\n",
      "epoch 68 | loss: 0.01973 | mse_mse: 0.01482 |  0:05:12s\n",
      "epoch 69 | loss: 0.01894 | mse_mse: 0.01482 |  0:05:16s\n",
      "epoch 70 | loss: 0.01614 | mse_mse: 0.01488 |  0:05:21s\n",
      "epoch 71 | loss: 0.01643 | mse_mse: 0.01253 |  0:05:25s\n",
      "epoch 72 | loss: 0.02111 | mse_mse: 0.01812 |  0:05:30s\n",
      "epoch 73 | loss: 0.0184  | mse_mse: 0.01131 |  0:05:34s\n",
      "epoch 74 | loss: 0.01525 | mse_mse: 0.01432 |  0:05:39s\n",
      "epoch 75 | loss: 0.01541 | mse_mse: 0.01654 |  0:05:43s\n",
      "epoch 76 | loss: 0.02166 | mse_mse: 0.02292 |  0:05:48s\n",
      "epoch 77 | loss: 0.02055 | mse_mse: 0.01283 |  0:05:52s\n",
      "epoch 78 | loss: 0.01843 | mse_mse: 0.01279 |  0:05:57s\n",
      "epoch 79 | loss: 0.0166  | mse_mse: 0.01102 |  0:06:02s\n",
      "epoch 80 | loss: 0.0172  | mse_mse: 0.01292 |  0:06:06s\n",
      "epoch 81 | loss: 0.01633 | mse_mse: 0.01865 |  0:06:11s\n",
      "epoch 82 | loss: 0.01421 | mse_mse: 0.01033 |  0:06:15s\n",
      "epoch 83 | loss: 0.01657 | mse_mse: 0.02564 |  0:06:20s\n",
      "epoch 84 | loss: 0.02267 | mse_mse: 0.01457 |  0:06:25s\n",
      "epoch 85 | loss: 0.02039 | mse_mse: 0.02401 |  0:06:29s\n",
      "epoch 86 | loss: 0.01571 | mse_mse: 0.01305 |  0:06:33s\n",
      "epoch 87 | loss: 0.01479 | mse_mse: 0.01029 |  0:06:38s\n",
      "epoch 88 | loss: 0.01355 | mse_mse: 0.00944 |  0:06:42s\n",
      "epoch 89 | loss: 0.01277 | mse_mse: 0.00928 |  0:06:47s\n",
      "epoch 90 | loss: 0.01433 | mse_mse: 0.00931 |  0:06:51s\n",
      "epoch 91 | loss: 0.01347 | mse_mse: 0.0178  |  0:06:56s\n",
      "epoch 92 | loss: 0.01385 | mse_mse: 0.01097 |  0:07:00s\n",
      "epoch 93 | loss: 0.01252 | mse_mse: 0.01193 |  0:07:04s\n",
      "epoch 94 | loss: 0.01232 | mse_mse: 0.00904 |  0:07:09s\n",
      "epoch 95 | loss: 0.01076 | mse_mse: 0.00901 |  0:07:13s\n",
      "epoch 96 | loss: 0.01059 | mse_mse: 0.0078  |  0:07:18s\n",
      "epoch 97 | loss: 0.01345 | mse_mse: 0.00906 |  0:07:22s\n",
      "epoch 98 | loss: 0.01052 | mse_mse: 0.01121 |  0:07:27s\n",
      "epoch 99 | loss: 0.013   | mse_mse: 0.0077  |  0:07:31s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_mse_mse = 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007917965661320614\n",
      "R2 Score: 0.9642797618376548\n",
      "\n",
      "Iteration 42/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.04908 | mse_mse: 0.90533 |  0:00:04s\n",
      "epoch 1  | loss: 0.53572 | mse_mse: 0.5384  |  0:00:09s\n",
      "epoch 2  | loss: 0.39287 | mse_mse: 0.45632 |  0:00:14s\n",
      "epoch 3  | loss: 0.32598 | mse_mse: 0.34404 |  0:00:19s\n",
      "epoch 4  | loss: 0.30924 | mse_mse: 0.25631 |  0:00:24s\n",
      "epoch 5  | loss: 0.27025 | mse_mse: 0.29805 |  0:00:29s\n",
      "epoch 6  | loss: 0.26232 | mse_mse: 0.22707 |  0:00:34s\n",
      "epoch 7  | loss: 0.261   | mse_mse: 0.22666 |  0:00:38s\n",
      "epoch 8  | loss: 0.26006 | mse_mse: 0.26987 |  0:00:43s\n",
      "epoch 9  | loss: 0.23761 | mse_mse: 0.25226 |  0:00:48s\n",
      "epoch 10 | loss: 0.23992 | mse_mse: 0.21929 |  0:00:53s\n",
      "epoch 11 | loss: 0.23861 | mse_mse: 0.24807 |  0:00:58s\n",
      "epoch 12 | loss: 0.25396 | mse_mse: 0.25275 |  0:01:03s\n",
      "epoch 13 | loss: 0.25986 | mse_mse: 0.22521 |  0:01:08s\n",
      "epoch 14 | loss: 0.23838 | mse_mse: 0.22582 |  0:01:12s\n",
      "epoch 15 | loss: 0.23454 | mse_mse: 0.22019 |  0:01:17s\n",
      "epoch 16 | loss: 0.23594 | mse_mse: 0.22321 |  0:01:22s\n",
      "epoch 17 | loss: 0.23797 | mse_mse: 0.21229 |  0:01:27s\n",
      "epoch 18 | loss: 0.22876 | mse_mse: 0.22402 |  0:01:32s\n",
      "epoch 19 | loss: 0.23178 | mse_mse: 0.21398 |  0:01:37s\n",
      "epoch 20 | loss: 0.2262  | mse_mse: 0.21705 |  0:01:42s\n",
      "epoch 21 | loss: 0.22651 | mse_mse: 0.2225  |  0:01:47s\n",
      "epoch 22 | loss: 0.22928 | mse_mse: 0.22668 |  0:01:51s\n",
      "epoch 23 | loss: 0.22194 | mse_mse: 0.21228 |  0:01:56s\n",
      "epoch 24 | loss: 0.22279 | mse_mse: 0.21691 |  0:02:01s\n",
      "epoch 25 | loss: 0.22159 | mse_mse: 0.21191 |  0:02:06s\n",
      "epoch 26 | loss: 0.22314 | mse_mse: 0.21831 |  0:02:11s\n",
      "epoch 27 | loss: 0.22321 | mse_mse: 0.21152 |  0:02:16s\n",
      "epoch 28 | loss: 0.22289 | mse_mse: 0.20607 |  0:02:21s\n",
      "epoch 29 | loss: 0.21684 | mse_mse: 0.20739 |  0:02:26s\n",
      "epoch 30 | loss: 0.21868 | mse_mse: 0.20686 |  0:02:30s\n",
      "epoch 31 | loss: 0.22045 | mse_mse: 0.20673 |  0:02:35s\n",
      "epoch 32 | loss: 0.22317 | mse_mse: 0.20934 |  0:02:40s\n",
      "epoch 33 | loss: 0.22262 | mse_mse: 0.20484 |  0:02:45s\n",
      "epoch 34 | loss: 0.21704 | mse_mse: 0.20297 |  0:02:50s\n",
      "epoch 35 | loss: 0.21512 | mse_mse: 0.20164 |  0:02:55s\n",
      "epoch 36 | loss: 0.21232 | mse_mse: 0.20089 |  0:03:01s\n",
      "epoch 37 | loss: 0.21566 | mse_mse: 0.2105  |  0:03:06s\n",
      "epoch 38 | loss: 0.2141  | mse_mse: 0.20729 |  0:03:11s\n",
      "epoch 39 | loss: 0.22212 | mse_mse: 0.20461 |  0:03:16s\n",
      "epoch 40 | loss: 0.2149  | mse_mse: 0.20729 |  0:03:20s\n",
      "epoch 41 | loss: 0.22206 | mse_mse: 0.20356 |  0:03:25s\n",
      "epoch 42 | loss: 0.21813 | mse_mse: 0.20374 |  0:03:30s\n",
      "epoch 43 | loss: 0.22135 | mse_mse: 0.20073 |  0:03:35s\n",
      "epoch 44 | loss: 0.22016 | mse_mse: 0.21566 |  0:03:40s\n",
      "epoch 45 | loss: 0.21517 | mse_mse: 0.20729 |  0:03:45s\n",
      "epoch 46 | loss: 0.21125 | mse_mse: 0.19939 |  0:03:50s\n",
      "epoch 47 | loss: 0.20498 | mse_mse: 0.1829  |  0:03:55s\n",
      "epoch 48 | loss: 0.19937 | mse_mse: 0.16257 |  0:04:00s\n",
      "epoch 49 | loss: 0.16605 | mse_mse: 0.12499 |  0:04:04s\n",
      "epoch 50 | loss: 0.12667 | mse_mse: 0.10014 |  0:04:09s\n",
      "epoch 51 | loss: 0.10184 | mse_mse: 0.09283 |  0:04:14s\n",
      "epoch 52 | loss: 0.09802 | mse_mse: 0.08238 |  0:04:19s\n",
      "epoch 53 | loss: 0.08161 | mse_mse: 0.05586 |  0:04:24s\n",
      "epoch 54 | loss: 0.06541 | mse_mse: 0.07169 |  0:04:29s\n",
      "epoch 55 | loss: 0.05004 | mse_mse: 0.0398  |  0:04:34s\n",
      "epoch 56 | loss: 0.04007 | mse_mse: 0.03713 |  0:04:39s\n",
      "epoch 57 | loss: 0.04895 | mse_mse: 0.05008 |  0:04:44s\n",
      "epoch 58 | loss: 0.04302 | mse_mse: 0.03865 |  0:04:49s\n",
      "epoch 59 | loss: 0.03399 | mse_mse: 0.02566 |  0:04:54s\n",
      "epoch 60 | loss: 0.03015 | mse_mse: 0.03154 |  0:04:58s\n",
      "epoch 61 | loss: 0.02696 | mse_mse: 0.02393 |  0:05:03s\n",
      "epoch 62 | loss: 0.02575 | mse_mse: 0.01855 |  0:05:08s\n",
      "epoch 63 | loss: 0.0239  | mse_mse: 0.01875 |  0:05:13s\n",
      "epoch 64 | loss: 0.02111 | mse_mse: 0.01572 |  0:05:18s\n",
      "epoch 65 | loss: 0.01964 | mse_mse: 0.01649 |  0:05:23s\n",
      "epoch 66 | loss: 0.0168  | mse_mse: 0.01497 |  0:05:28s\n",
      "epoch 67 | loss: 0.01733 | mse_mse: 0.01394 |  0:05:33s\n",
      "epoch 68 | loss: 0.02181 | mse_mse: 0.01343 |  0:05:38s\n",
      "epoch 69 | loss: 0.01924 | mse_mse: 0.01939 |  0:05:42s\n",
      "epoch 70 | loss: 0.0149  | mse_mse: 0.01198 |  0:05:47s\n",
      "epoch 71 | loss: 0.01763 | mse_mse: 0.01731 |  0:05:52s\n",
      "epoch 72 | loss: 0.01779 | mse_mse: 0.01406 |  0:05:57s\n",
      "epoch 73 | loss: 0.01461 | mse_mse: 0.01018 |  0:06:02s\n",
      "epoch 74 | loss: 0.01517 | mse_mse: 0.00966 |  0:06:07s\n",
      "epoch 75 | loss: 0.01428 | mse_mse: 0.01061 |  0:06:12s\n",
      "epoch 76 | loss: 0.01534 | mse_mse: 0.03707 |  0:06:17s\n",
      "epoch 77 | loss: 0.01778 | mse_mse: 0.01549 |  0:06:21s\n",
      "epoch 78 | loss: 0.01486 | mse_mse: 0.01427 |  0:06:26s\n",
      "epoch 79 | loss: 0.0156  | mse_mse: 0.01657 |  0:06:31s\n",
      "epoch 80 | loss: 0.01371 | mse_mse: 0.00878 |  0:06:36s\n",
      "epoch 81 | loss: 0.01732 | mse_mse: 0.01164 |  0:06:41s\n",
      "epoch 82 | loss: 0.0149  | mse_mse: 0.02556 |  0:06:46s\n",
      "epoch 83 | loss: 0.01819 | mse_mse: 0.05439 |  0:06:51s\n",
      "epoch 84 | loss: 0.01768 | mse_mse: 0.015   |  0:06:55s\n",
      "epoch 85 | loss: 0.01444 | mse_mse: 0.01197 |  0:07:00s\n",
      "epoch 86 | loss: 0.01544 | mse_mse: 0.03699 |  0:07:05s\n",
      "epoch 87 | loss: 0.01986 | mse_mse: 0.01449 |  0:07:10s\n",
      "epoch 88 | loss: 0.01489 | mse_mse: 0.01391 |  0:07:15s\n",
      "epoch 89 | loss: 0.01534 | mse_mse: 0.01772 |  0:07:20s\n",
      "epoch 90 | loss: 0.01777 | mse_mse: 0.0183  |  0:07:25s\n",
      "\n",
      "Early stopping occurred at epoch 90 with best_epoch = 80 and best_mse_mse = 0.00878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009081123525299694\n",
      "R2 Score: 0.9590324195658007\n",
      "\n",
      "Iteration 43/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.8486  | mse_mse: 1.30079 |  0:00:02s\n",
      "epoch 1  | loss: 0.30518 | mse_mse: 0.56072 |  0:00:04s\n",
      "epoch 2  | loss: 0.26718 | mse_mse: 0.41191 |  0:00:06s\n",
      "epoch 3  | loss: 0.25069 | mse_mse: 0.30821 |  0:00:09s\n",
      "epoch 4  | loss: 0.23827 | mse_mse: 0.21219 |  0:00:11s\n",
      "epoch 5  | loss: 0.23743 | mse_mse: 0.19299 |  0:00:13s\n",
      "epoch 6  | loss: 0.21238 | mse_mse: 0.1873  |  0:00:15s\n",
      "epoch 7  | loss: 0.17882 | mse_mse: 0.14061 |  0:00:18s\n",
      "epoch 8  | loss: 0.12812 | mse_mse: 0.14265 |  0:00:20s\n",
      "epoch 9  | loss: 0.09802 | mse_mse: 0.07011 |  0:00:22s\n",
      "epoch 10 | loss: 0.09062 | mse_mse: 0.07972 |  0:00:24s\n",
      "epoch 11 | loss: 0.07002 | mse_mse: 0.07688 |  0:00:27s\n",
      "epoch 12 | loss: 0.05844 | mse_mse: 0.04828 |  0:00:29s\n",
      "epoch 13 | loss: 0.05592 | mse_mse: 0.03763 |  0:00:31s\n",
      "epoch 14 | loss: 0.04372 | mse_mse: 0.03105 |  0:00:33s\n",
      "epoch 15 | loss: 0.04032 | mse_mse: 0.02922 |  0:00:36s\n",
      "epoch 16 | loss: 0.04077 | mse_mse: 0.04919 |  0:00:38s\n",
      "epoch 17 | loss: 0.03424 | mse_mse: 0.03462 |  0:00:40s\n",
      "epoch 18 | loss: 0.0291  | mse_mse: 0.02046 |  0:00:42s\n",
      "epoch 19 | loss: 0.02714 | mse_mse: 0.02331 |  0:00:45s\n",
      "epoch 20 | loss: 0.02426 | mse_mse: 0.01997 |  0:00:47s\n",
      "epoch 21 | loss: 0.02639 | mse_mse: 0.01769 |  0:00:49s\n",
      "epoch 22 | loss: 0.02147 | mse_mse: 0.01509 |  0:00:51s\n",
      "epoch 23 | loss: 0.02234 | mse_mse: 0.02508 |  0:00:54s\n",
      "epoch 24 | loss: 0.02107 | mse_mse: 0.01558 |  0:00:56s\n",
      "epoch 25 | loss: 0.01971 | mse_mse: 0.01666 |  0:00:58s\n",
      "epoch 26 | loss: 0.01691 | mse_mse: 0.01682 |  0:01:00s\n",
      "epoch 27 | loss: 0.01666 | mse_mse: 0.0133  |  0:01:03s\n",
      "epoch 28 | loss: 0.0187  | mse_mse: 0.02067 |  0:01:05s\n",
      "epoch 29 | loss: 0.01852 | mse_mse: 0.01413 |  0:01:07s\n",
      "epoch 30 | loss: 0.02235 | mse_mse: 0.01416 |  0:01:10s\n",
      "epoch 31 | loss: 0.01844 | mse_mse: 0.01493 |  0:01:12s\n",
      "epoch 32 | loss: 0.01719 | mse_mse: 0.01379 |  0:01:14s\n",
      "epoch 33 | loss: 0.01556 | mse_mse: 0.02479 |  0:01:16s\n",
      "epoch 34 | loss: 0.02136 | mse_mse: 0.01111 |  0:01:19s\n",
      "epoch 35 | loss: 0.01442 | mse_mse: 0.01609 |  0:01:21s\n",
      "epoch 36 | loss: 0.01657 | mse_mse: 0.01611 |  0:01:23s\n",
      "epoch 37 | loss: 0.01496 | mse_mse: 0.01169 |  0:01:26s\n",
      "epoch 38 | loss: 0.01415 | mse_mse: 0.00934 |  0:01:28s\n",
      "epoch 39 | loss: 0.01491 | mse_mse: 0.01011 |  0:01:30s\n",
      "epoch 40 | loss: 0.01625 | mse_mse: 0.01848 |  0:01:32s\n",
      "epoch 41 | loss: 0.01409 | mse_mse: 0.03712 |  0:01:34s\n",
      "epoch 42 | loss: 0.01362 | mse_mse: 0.00994 |  0:01:37s\n",
      "epoch 43 | loss: 0.01471 | mse_mse: 0.00923 |  0:01:39s\n",
      "epoch 44 | loss: 0.01541 | mse_mse: 0.00962 |  0:01:41s\n",
      "epoch 45 | loss: 0.01816 | mse_mse: 0.01889 |  0:01:43s\n",
      "epoch 46 | loss: 0.01415 | mse_mse: 0.0092  |  0:01:46s\n",
      "epoch 47 | loss: 0.0143  | mse_mse: 0.01136 |  0:01:48s\n",
      "epoch 48 | loss: 0.01158 | mse_mse: 0.01094 |  0:01:50s\n",
      "epoch 49 | loss: 0.01391 | mse_mse: 0.00955 |  0:01:52s\n",
      "epoch 50 | loss: 0.01222 | mse_mse: 0.01035 |  0:01:55s\n",
      "epoch 51 | loss: 0.01156 | mse_mse: 0.01349 |  0:01:57s\n",
      "epoch 52 | loss: 0.01382 | mse_mse: 0.01385 |  0:01:59s\n",
      "epoch 53 | loss: 0.01066 | mse_mse: 0.00871 |  0:02:01s\n",
      "epoch 54 | loss: 0.0144  | mse_mse: 0.01385 |  0:02:04s\n",
      "epoch 55 | loss: 0.01478 | mse_mse: 0.03979 |  0:02:06s\n",
      "epoch 56 | loss: 0.01183 | mse_mse: 0.00805 |  0:02:08s\n",
      "epoch 57 | loss: 0.01547 | mse_mse: 0.01196 |  0:02:10s\n",
      "epoch 58 | loss: 0.01304 | mse_mse: 0.01154 |  0:02:13s\n",
      "epoch 59 | loss: 0.01217 | mse_mse: 0.00859 |  0:02:15s\n",
      "epoch 60 | loss: 0.01122 | mse_mse: 0.01795 |  0:02:17s\n",
      "epoch 61 | loss: 0.0118  | mse_mse: 0.00818 |  0:02:20s\n",
      "epoch 62 | loss: 0.00887 | mse_mse: 0.00958 |  0:02:22s\n",
      "epoch 63 | loss: 0.01404 | mse_mse: 0.01348 |  0:02:24s\n",
      "epoch 64 | loss: 0.01234 | mse_mse: 0.00768 |  0:02:26s\n",
      "epoch 65 | loss: 0.01    | mse_mse: 0.00942 |  0:02:29s\n",
      "epoch 66 | loss: 0.00962 | mse_mse: 0.00937 |  0:02:31s\n",
      "epoch 67 | loss: 0.01044 | mse_mse: 0.00765 |  0:02:33s\n",
      "epoch 68 | loss: 0.01915 | mse_mse: 0.03705 |  0:02:35s\n",
      "epoch 69 | loss: 0.00965 | mse_mse: 0.0091  |  0:02:38s\n",
      "epoch 70 | loss: 0.01151 | mse_mse: 0.00841 |  0:02:40s\n",
      "epoch 71 | loss: 0.011   | mse_mse: 0.01086 |  0:02:42s\n",
      "epoch 72 | loss: 0.01012 | mse_mse: 0.01039 |  0:02:44s\n",
      "epoch 73 | loss: 0.01422 | mse_mse: 0.01214 |  0:02:47s\n",
      "epoch 74 | loss: 0.00951 | mse_mse: 0.01053 |  0:02:49s\n",
      "epoch 75 | loss: 0.01063 | mse_mse: 0.00821 |  0:02:51s\n",
      "epoch 76 | loss: 0.00912 | mse_mse: 0.00863 |  0:02:53s\n",
      "epoch 77 | loss: 0.01172 | mse_mse: 0.00779 |  0:02:56s\n",
      "\n",
      "Early stopping occurred at epoch 77 with best_epoch = 67 and best_mse_mse = 0.00765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008004680702349144\n",
      "R2 Score: 0.9638885651527629\n",
      "\n",
      "Iteration 44/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.95343 | mse_mse: 1.47905 |  0:00:02s\n",
      "epoch 1  | loss: 0.3204  | mse_mse: 0.60091 |  0:00:04s\n",
      "epoch 2  | loss: 0.26891 | mse_mse: 0.30532 |  0:00:07s\n",
      "epoch 3  | loss: 0.24138 | mse_mse: 0.22545 |  0:00:09s\n",
      "epoch 4  | loss: 0.23541 | mse_mse: 0.18757 |  0:00:12s\n",
      "epoch 5  | loss: 0.21614 | mse_mse: 0.1947  |  0:00:14s\n",
      "epoch 6  | loss: 0.19594 | mse_mse: 0.17826 |  0:00:16s\n",
      "epoch 7  | loss: 0.168   | mse_mse: 0.13815 |  0:00:19s\n",
      "epoch 8  | loss: 0.1306  | mse_mse: 0.12551 |  0:00:21s\n",
      "epoch 9  | loss: 0.10411 | mse_mse: 0.08628 |  0:00:24s\n",
      "epoch 10 | loss: 0.08738 | mse_mse: 0.09473 |  0:00:26s\n",
      "epoch 11 | loss: 0.07471 | mse_mse: 0.0668  |  0:00:29s\n",
      "epoch 12 | loss: 0.07427 | mse_mse: 0.05341 |  0:00:31s\n",
      "epoch 13 | loss: 0.065   | mse_mse: 0.04784 |  0:00:34s\n",
      "epoch 14 | loss: 0.05783 | mse_mse: 0.04166 |  0:00:36s\n",
      "epoch 15 | loss: 0.04923 | mse_mse: 0.03814 |  0:00:38s\n",
      "epoch 16 | loss: 0.04383 | mse_mse: 0.0342  |  0:00:41s\n",
      "epoch 17 | loss: 0.04339 | mse_mse: 0.04028 |  0:00:43s\n",
      "epoch 18 | loss: 0.0379  | mse_mse: 0.02744 |  0:00:46s\n",
      "epoch 19 | loss: 0.02953 | mse_mse: 0.02314 |  0:00:48s\n",
      "epoch 20 | loss: 0.02614 | mse_mse: 0.02807 |  0:00:51s\n",
      "epoch 21 | loss: 0.02573 | mse_mse: 0.02106 |  0:00:53s\n",
      "epoch 22 | loss: 0.02747 | mse_mse: 0.02179 |  0:00:56s\n",
      "epoch 23 | loss: 0.02897 | mse_mse: 0.01994 |  0:00:58s\n",
      "epoch 24 | loss: 0.02976 | mse_mse: 0.02014 |  0:01:01s\n",
      "epoch 25 | loss: 0.02101 | mse_mse: 0.01634 |  0:01:03s\n",
      "epoch 26 | loss: 0.02135 | mse_mse: 0.01941 |  0:01:05s\n",
      "epoch 27 | loss: 0.02173 | mse_mse: 0.01844 |  0:01:08s\n",
      "epoch 28 | loss: 0.01648 | mse_mse: 0.01481 |  0:01:10s\n",
      "epoch 29 | loss: 0.0176  | mse_mse: 0.01754 |  0:01:13s\n",
      "epoch 30 | loss: 0.01843 | mse_mse: 0.01437 |  0:01:15s\n",
      "epoch 31 | loss: 0.0177  | mse_mse: 0.01825 |  0:01:18s\n",
      "epoch 32 | loss: 0.01621 | mse_mse: 0.01301 |  0:01:20s\n",
      "epoch 33 | loss: 0.01584 | mse_mse: 0.01259 |  0:01:23s\n",
      "epoch 34 | loss: 0.01562 | mse_mse: 0.01832 |  0:01:25s\n",
      "epoch 35 | loss: 0.01524 | mse_mse: 0.01153 |  0:01:27s\n",
      "epoch 36 | loss: 0.01319 | mse_mse: 0.01457 |  0:01:30s\n",
      "epoch 37 | loss: 0.01469 | mse_mse: 0.01296 |  0:01:32s\n",
      "epoch 38 | loss: 0.01723 | mse_mse: 0.01067 |  0:01:35s\n",
      "epoch 39 | loss: 0.0118  | mse_mse: 0.01279 |  0:01:37s\n",
      "epoch 40 | loss: 0.01198 | mse_mse: 0.0114  |  0:01:40s\n",
      "epoch 41 | loss: 0.01    | mse_mse: 0.00933 |  0:01:42s\n",
      "epoch 42 | loss: 0.00963 | mse_mse: 0.01614 |  0:01:45s\n",
      "epoch 43 | loss: 0.01081 | mse_mse: 0.01075 |  0:01:47s\n",
      "epoch 44 | loss: 0.01059 | mse_mse: 0.01153 |  0:01:49s\n",
      "epoch 45 | loss: 0.0117  | mse_mse: 0.00994 |  0:01:52s\n",
      "epoch 46 | loss: 0.01511 | mse_mse: 0.00921 |  0:01:54s\n",
      "epoch 47 | loss: 0.01464 | mse_mse: 0.01281 |  0:01:57s\n",
      "epoch 48 | loss: 0.01083 | mse_mse: 0.00961 |  0:01:59s\n",
      "epoch 49 | loss: 0.0104  | mse_mse: 0.00892 |  0:02:02s\n",
      "epoch 50 | loss: 0.0162  | mse_mse: 0.01056 |  0:02:04s\n",
      "epoch 51 | loss: 0.01145 | mse_mse: 0.01112 |  0:02:06s\n",
      "epoch 52 | loss: 0.01066 | mse_mse: 0.01029 |  0:02:09s\n",
      "epoch 53 | loss: 0.01039 | mse_mse: 0.00867 |  0:02:11s\n",
      "epoch 54 | loss: 0.01014 | mse_mse: 0.00875 |  0:02:14s\n",
      "epoch 55 | loss: 0.0087  | mse_mse: 0.00823 |  0:02:16s\n",
      "epoch 56 | loss: 0.00993 | mse_mse: 0.0103  |  0:02:19s\n",
      "epoch 57 | loss: 0.01302 | mse_mse: 0.01983 |  0:02:22s\n",
      "epoch 58 | loss: 0.01062 | mse_mse: 0.01011 |  0:02:24s\n",
      "epoch 59 | loss: 0.01583 | mse_mse: 0.00859 |  0:02:27s\n",
      "epoch 60 | loss: 0.00772 | mse_mse: 0.00866 |  0:02:29s\n",
      "epoch 61 | loss: 0.00869 | mse_mse: 0.01121 |  0:02:32s\n",
      "epoch 62 | loss: 0.00896 | mse_mse: 0.00794 |  0:02:34s\n",
      "epoch 63 | loss: 0.01379 | mse_mse: 0.01842 |  0:02:37s\n",
      "epoch 64 | loss: 0.012   | mse_mse: 0.01914 |  0:02:39s\n",
      "epoch 65 | loss: 0.01025 | mse_mse: 0.01084 |  0:02:42s\n",
      "epoch 66 | loss: 0.00939 | mse_mse: 0.00895 |  0:02:44s\n",
      "epoch 67 | loss: 0.00862 | mse_mse: 0.01001 |  0:02:47s\n",
      "epoch 68 | loss: 0.00885 | mse_mse: 0.013   |  0:02:49s\n",
      "epoch 69 | loss: 0.01089 | mse_mse: 0.00825 |  0:02:52s\n",
      "epoch 70 | loss: 0.00779 | mse_mse: 0.00898 |  0:02:54s\n",
      "epoch 71 | loss: 0.00819 | mse_mse: 0.00765 |  0:02:56s\n",
      "epoch 72 | loss: 0.00871 | mse_mse: 0.00864 |  0:02:59s\n",
      "epoch 73 | loss: 0.00856 | mse_mse: 0.00819 |  0:03:01s\n",
      "epoch 74 | loss: 0.00879 | mse_mse: 0.00846 |  0:03:04s\n",
      "epoch 75 | loss: 0.00917 | mse_mse: 0.00833 |  0:03:06s\n",
      "epoch 76 | loss: 0.01911 | mse_mse: 0.04534 |  0:03:08s\n",
      "epoch 77 | loss: 0.01301 | mse_mse: 0.01906 |  0:03:11s\n",
      "epoch 78 | loss: 0.01298 | mse_mse: 0.00908 |  0:03:13s\n",
      "epoch 79 | loss: 0.00975 | mse_mse: 0.00941 |  0:03:16s\n",
      "epoch 80 | loss: 0.00892 | mse_mse: 0.01185 |  0:03:18s\n",
      "epoch 81 | loss: 0.00882 | mse_mse: 0.00892 |  0:03:21s\n",
      "\n",
      "Early stopping occurred at epoch 81 with best_epoch = 71 and best_mse_mse = 0.00765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007858936240610879\n",
      "R2 Score: 0.9645460606644655\n",
      "\n",
      "Iteration 45/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.15552 | mse_mse: 0.76616 |  0:00:03s\n",
      "epoch 1  | loss: 0.44671 | mse_mse: 0.59127 |  0:00:07s\n",
      "epoch 2  | loss: 0.32457 | mse_mse: 0.37346 |  0:00:10s\n",
      "epoch 3  | loss: 0.29616 | mse_mse: 0.36673 |  0:00:13s\n",
      "epoch 4  | loss: 0.26339 | mse_mse: 0.23015 |  0:00:17s\n",
      "epoch 5  | loss: 0.25439 | mse_mse: 0.22947 |  0:00:20s\n",
      "epoch 6  | loss: 0.24929 | mse_mse: 0.24829 |  0:00:24s\n",
      "epoch 7  | loss: 0.20029 | mse_mse: 0.10623 |  0:00:27s\n",
      "epoch 8  | loss: 0.15496 | mse_mse: 0.09975 |  0:00:31s\n",
      "epoch 9  | loss: 0.13145 | mse_mse: 0.10228 |  0:00:34s\n",
      "epoch 10 | loss: 0.13832 | mse_mse: 0.09075 |  0:00:38s\n",
      "epoch 11 | loss: 0.12287 | mse_mse: 0.08807 |  0:00:41s\n",
      "epoch 12 | loss: 0.12493 | mse_mse: 0.1161  |  0:00:45s\n",
      "epoch 13 | loss: 0.115   | mse_mse: 0.08765 |  0:00:48s\n",
      "epoch 14 | loss: 0.10705 | mse_mse: 0.0895  |  0:00:52s\n",
      "epoch 15 | loss: 0.10563 | mse_mse: 0.08751 |  0:00:55s\n",
      "epoch 16 | loss: 0.10508 | mse_mse: 0.08841 |  0:00:58s\n",
      "epoch 17 | loss: 0.10225 | mse_mse: 0.08848 |  0:01:02s\n",
      "epoch 18 | loss: 0.11009 | mse_mse: 0.13065 |  0:01:05s\n",
      "epoch 19 | loss: 0.1065  | mse_mse: 0.08412 |  0:01:09s\n",
      "epoch 20 | loss: 0.10235 | mse_mse: 0.08827 |  0:01:12s\n",
      "epoch 21 | loss: 0.09992 | mse_mse: 0.08356 |  0:01:16s\n",
      "epoch 22 | loss: 0.10198 | mse_mse: 0.08035 |  0:01:19s\n",
      "epoch 23 | loss: 0.10061 | mse_mse: 0.0963  |  0:01:23s\n",
      "epoch 24 | loss: 0.09984 | mse_mse: 0.11558 |  0:01:27s\n",
      "epoch 25 | loss: 0.09699 | mse_mse: 0.08095 |  0:01:30s\n",
      "epoch 26 | loss: 0.09091 | mse_mse: 0.07619 |  0:01:33s\n",
      "epoch 27 | loss: 0.08556 | mse_mse: 0.06984 |  0:01:37s\n",
      "epoch 28 | loss: 0.07585 | mse_mse: 0.06949 |  0:01:41s\n",
      "epoch 29 | loss: 0.06849 | mse_mse: 0.06969 |  0:01:44s\n",
      "epoch 30 | loss: 0.06223 | mse_mse: 0.0469  |  0:01:48s\n",
      "epoch 31 | loss: 0.05359 | mse_mse: 0.04096 |  0:01:51s\n",
      "epoch 32 | loss: 0.04905 | mse_mse: 0.04629 |  0:01:55s\n",
      "epoch 33 | loss: 0.04396 | mse_mse: 0.0314  |  0:01:58s\n",
      "epoch 34 | loss: 0.04461 | mse_mse: 0.02824 |  0:02:02s\n",
      "epoch 35 | loss: 0.03184 | mse_mse: 0.02603 |  0:02:05s\n",
      "epoch 36 | loss: 0.02825 | mse_mse: 0.02564 |  0:02:08s\n",
      "epoch 37 | loss: 0.02616 | mse_mse: 0.04347 |  0:02:12s\n",
      "epoch 38 | loss: 0.02386 | mse_mse: 0.01913 |  0:02:15s\n",
      "epoch 39 | loss: 0.02839 | mse_mse: 0.05379 |  0:02:19s\n",
      "epoch 40 | loss: 0.02935 | mse_mse: 0.01655 |  0:02:22s\n",
      "epoch 41 | loss: 0.01957 | mse_mse: 0.01678 |  0:02:26s\n",
      "epoch 42 | loss: 0.02237 | mse_mse: 0.01734 |  0:02:29s\n",
      "epoch 43 | loss: 0.01781 | mse_mse: 0.01282 |  0:02:33s\n",
      "epoch 44 | loss: 0.01557 | mse_mse: 0.01982 |  0:02:36s\n",
      "epoch 45 | loss: 0.01791 | mse_mse: 0.01291 |  0:02:40s\n",
      "epoch 46 | loss: 0.0187  | mse_mse: 0.02485 |  0:02:43s\n",
      "epoch 47 | loss: 0.02324 | mse_mse: 0.01685 |  0:02:47s\n",
      "epoch 48 | loss: 0.02485 | mse_mse: 0.02726 |  0:02:50s\n",
      "epoch 49 | loss: 0.02169 | mse_mse: 0.01198 |  0:02:54s\n",
      "epoch 50 | loss: 0.01874 | mse_mse: 0.02849 |  0:02:57s\n",
      "epoch 51 | loss: 0.01508 | mse_mse: 0.01103 |  0:03:01s\n",
      "epoch 52 | loss: 0.01229 | mse_mse: 0.00994 |  0:03:04s\n",
      "epoch 53 | loss: 0.01386 | mse_mse: 0.01478 |  0:03:07s\n",
      "epoch 54 | loss: 0.01248 | mse_mse: 0.00949 |  0:03:11s\n",
      "epoch 55 | loss: 0.0162  | mse_mse: 0.0165  |  0:03:15s\n",
      "epoch 56 | loss: 0.01509 | mse_mse: 0.01723 |  0:03:18s\n",
      "epoch 57 | loss: 0.01874 | mse_mse: 0.01202 |  0:03:21s\n",
      "epoch 58 | loss: 0.01744 | mse_mse: 0.03259 |  0:03:25s\n",
      "epoch 59 | loss: 0.01365 | mse_mse: 0.01108 |  0:03:29s\n",
      "epoch 60 | loss: 0.01902 | mse_mse: 0.01977 |  0:03:32s\n",
      "epoch 61 | loss: 0.01574 | mse_mse: 0.01079 |  0:03:36s\n",
      "epoch 62 | loss: 0.01127 | mse_mse: 0.01119 |  0:03:39s\n",
      "epoch 63 | loss: 0.0111  | mse_mse: 0.00986 |  0:03:42s\n",
      "epoch 64 | loss: 0.01482 | mse_mse: 0.01335 |  0:03:46s\n",
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 54 and best_mse_mse = 0.00949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009247822108503627\n",
      "R2 Score: 0.9582803939385037\n",
      "\n",
      "Iteration 46/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.52656 | mse_mse: 0.88963 |  0:00:03s\n",
      "epoch 1  | loss: 0.31684 | mse_mse: 0.23132 |  0:00:07s\n",
      "epoch 2  | loss: 0.21979 | mse_mse: 0.20079 |  0:00:11s\n",
      "epoch 3  | loss: 0.17522 | mse_mse: 0.13716 |  0:00:15s\n",
      "epoch 4  | loss: 0.15626 | mse_mse: 0.08905 |  0:00:18s\n",
      "epoch 5  | loss: 0.13814 | mse_mse: 0.0989  |  0:00:22s\n",
      "epoch 6  | loss: 0.12009 | mse_mse: 0.08082 |  0:00:26s\n",
      "epoch 7  | loss: 0.1151  | mse_mse: 0.10149 |  0:00:30s\n",
      "epoch 8  | loss: 0.11363 | mse_mse: 0.08593 |  0:00:33s\n",
      "epoch 9  | loss: 0.10839 | mse_mse: 0.08503 |  0:00:37s\n",
      "epoch 10 | loss: 0.10687 | mse_mse: 0.09664 |  0:00:41s\n",
      "epoch 11 | loss: 0.10559 | mse_mse: 0.08314 |  0:00:45s\n",
      "epoch 12 | loss: 0.10328 | mse_mse: 0.09143 |  0:00:49s\n",
      "epoch 13 | loss: 0.1     | mse_mse: 0.07816 |  0:00:53s\n",
      "epoch 14 | loss: 0.09451 | mse_mse: 0.08058 |  0:00:56s\n",
      "epoch 15 | loss: 0.09811 | mse_mse: 0.09086 |  0:01:00s\n",
      "epoch 16 | loss: 0.09651 | mse_mse: 0.09074 |  0:01:04s\n",
      "epoch 17 | loss: 0.10027 | mse_mse: 0.07407 |  0:01:08s\n",
      "epoch 18 | loss: 0.09515 | mse_mse: 0.09207 |  0:01:12s\n",
      "epoch 19 | loss: 0.08782 | mse_mse: 0.08068 |  0:01:15s\n",
      "epoch 20 | loss: 0.09194 | mse_mse: 0.09665 |  0:01:19s\n",
      "epoch 21 | loss: 0.08942 | mse_mse: 0.07233 |  0:01:23s\n",
      "epoch 22 | loss: 0.08168 | mse_mse: 0.08994 |  0:01:27s\n",
      "epoch 23 | loss: 0.081   | mse_mse: 0.06946 |  0:01:31s\n",
      "epoch 24 | loss: 0.07597 | mse_mse: 0.07044 |  0:01:34s\n",
      "epoch 25 | loss: 0.07411 | mse_mse: 0.06569 |  0:01:38s\n",
      "epoch 26 | loss: 0.07409 | mse_mse: 0.06891 |  0:01:42s\n",
      "epoch 27 | loss: 0.0649  | mse_mse: 0.05442 |  0:01:46s\n",
      "epoch 28 | loss: 0.06206 | mse_mse: 0.05254 |  0:01:49s\n",
      "epoch 29 | loss: 0.05464 | mse_mse: 0.04922 |  0:01:53s\n",
      "epoch 30 | loss: 0.0551  | mse_mse: 0.05371 |  0:01:57s\n",
      "epoch 31 | loss: 0.05291 | mse_mse: 0.05449 |  0:02:01s\n",
      "epoch 32 | loss: 0.04747 | mse_mse: 0.04837 |  0:02:05s\n",
      "epoch 33 | loss: 0.04297 | mse_mse: 0.04204 |  0:02:08s\n",
      "epoch 34 | loss: 0.04069 | mse_mse: 0.03826 |  0:02:12s\n",
      "epoch 35 | loss: 0.03924 | mse_mse: 0.04205 |  0:02:16s\n",
      "epoch 36 | loss: 0.0382  | mse_mse: 0.0358  |  0:02:20s\n",
      "epoch 37 | loss: 0.04062 | mse_mse: 0.03385 |  0:02:24s\n",
      "epoch 38 | loss: 0.03228 | mse_mse: 0.03024 |  0:02:27s\n",
      "epoch 39 | loss: 0.03074 | mse_mse: 0.02958 |  0:02:31s\n",
      "epoch 40 | loss: 0.02955 | mse_mse: 0.04036 |  0:02:35s\n",
      "epoch 41 | loss: 0.02941 | mse_mse: 0.02466 |  0:02:39s\n",
      "epoch 42 | loss: 0.02654 | mse_mse: 0.02911 |  0:02:43s\n",
      "epoch 43 | loss: 0.02487 | mse_mse: 0.0298  |  0:02:47s\n",
      "epoch 44 | loss: 0.03122 | mse_mse: 0.02089 |  0:02:50s\n",
      "epoch 45 | loss: 0.02563 | mse_mse: 0.03747 |  0:02:54s\n",
      "epoch 46 | loss: 0.02414 | mse_mse: 0.03048 |  0:02:58s\n",
      "epoch 47 | loss: 0.01971 | mse_mse: 0.02208 |  0:03:02s\n",
      "epoch 48 | loss: 0.0207  | mse_mse: 0.01736 |  0:03:05s\n",
      "epoch 49 | loss: 0.02051 | mse_mse: 0.02208 |  0:03:09s\n",
      "epoch 50 | loss: 0.01861 | mse_mse: 0.01613 |  0:03:13s\n",
      "epoch 51 | loss: 0.02385 | mse_mse: 0.02105 |  0:03:17s\n",
      "epoch 52 | loss: 0.02112 | mse_mse: 0.01463 |  0:03:21s\n",
      "epoch 53 | loss: 0.01965 | mse_mse: 0.01619 |  0:03:25s\n",
      "epoch 54 | loss: 0.01512 | mse_mse: 0.01252 |  0:03:28s\n",
      "epoch 55 | loss: 0.01804 | mse_mse: 0.01732 |  0:03:32s\n",
      "epoch 56 | loss: 0.01958 | mse_mse: 0.0157  |  0:03:36s\n",
      "epoch 57 | loss: 0.019   | mse_mse: 0.01641 |  0:03:40s\n",
      "epoch 58 | loss: 0.01725 | mse_mse: 0.01568 |  0:03:43s\n",
      "epoch 59 | loss: 0.01534 | mse_mse: 0.02093 |  0:03:47s\n",
      "epoch 60 | loss: 0.01871 | mse_mse: 0.01127 |  0:03:51s\n",
      "epoch 61 | loss: 0.01743 | mse_mse: 0.01107 |  0:03:55s\n",
      "epoch 62 | loss: 0.01348 | mse_mse: 0.01241 |  0:03:58s\n",
      "epoch 63 | loss: 0.01206 | mse_mse: 0.01334 |  0:04:02s\n",
      "epoch 64 | loss: 0.01645 | mse_mse: 0.01126 |  0:04:06s\n",
      "epoch 65 | loss: 0.01271 | mse_mse: 0.01347 |  0:04:10s\n",
      "epoch 66 | loss: 0.01361 | mse_mse: 0.01461 |  0:04:14s\n",
      "epoch 67 | loss: 0.01278 | mse_mse: 0.01405 |  0:04:17s\n",
      "epoch 68 | loss: 0.01352 | mse_mse: 0.01098 |  0:04:21s\n",
      "epoch 69 | loss: 0.01613 | mse_mse: 0.01148 |  0:04:25s\n",
      "epoch 70 | loss: 0.01112 | mse_mse: 0.01033 |  0:04:29s\n",
      "epoch 71 | loss: 0.00999 | mse_mse: 0.00866 |  0:04:33s\n",
      "epoch 72 | loss: 0.01263 | mse_mse: 0.01348 |  0:04:36s\n",
      "epoch 73 | loss: 0.01099 | mse_mse: 0.01688 |  0:04:40s\n",
      "epoch 74 | loss: 0.01343 | mse_mse: 0.01076 |  0:04:44s\n",
      "epoch 75 | loss: 0.01163 | mse_mse: 0.00855 |  0:04:48s\n",
      "epoch 76 | loss: 0.01043 | mse_mse: 0.00778 |  0:04:51s\n",
      "epoch 77 | loss: 0.01024 | mse_mse: 0.00846 |  0:04:55s\n",
      "epoch 78 | loss: 0.01106 | mse_mse: 0.01839 |  0:04:59s\n",
      "epoch 79 | loss: 0.01125 | mse_mse: 0.00841 |  0:05:03s\n",
      "epoch 80 | loss: 0.00979 | mse_mse: 0.01039 |  0:05:07s\n",
      "epoch 81 | loss: 0.01022 | mse_mse: 0.02174 |  0:05:10s\n",
      "epoch 82 | loss: 0.00935 | mse_mse: 0.01316 |  0:05:14s\n",
      "epoch 83 | loss: 0.01041 | mse_mse: 0.02417 |  0:05:18s\n",
      "epoch 84 | loss: 0.01123 | mse_mse: 0.00812 |  0:05:22s\n",
      "epoch 85 | loss: 0.01026 | mse_mse: 0.00849 |  0:05:26s\n",
      "epoch 86 | loss: 0.01015 | mse_mse: 0.01856 |  0:05:29s\n",
      "\n",
      "Early stopping occurred at epoch 86 with best_epoch = 76 and best_mse_mse = 0.00778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007762925916360478\n",
      "R2 Score: 0.9649791910662582\n",
      "\n",
      "Iteration 47/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.93382 | mse_mse: 1.36393 |  0:00:04s\n",
      "epoch 1  | loss: 0.54901 | mse_mse: 0.38844 |  0:00:09s\n",
      "epoch 2  | loss: 0.67916 | mse_mse: 0.23416 |  0:00:13s\n",
      "epoch 3  | loss: 0.34981 | mse_mse: 0.25279 |  0:00:18s\n",
      "epoch 4  | loss: 0.33375 | mse_mse: 0.11608 |  0:00:23s\n",
      "epoch 5  | loss: 0.15825 | mse_mse: 0.11666 |  0:00:28s\n",
      "epoch 6  | loss: 0.14975 | mse_mse: 0.09331 |  0:00:32s\n",
      "epoch 7  | loss: 0.14187 | mse_mse: 0.10112 |  0:00:37s\n",
      "epoch 8  | loss: 0.14914 | mse_mse: 0.09101 |  0:00:42s\n",
      "epoch 9  | loss: 0.12487 | mse_mse: 0.12147 |  0:00:46s\n",
      "epoch 10 | loss: 0.12665 | mse_mse: 0.12321 |  0:00:51s\n",
      "epoch 11 | loss: 0.12572 | mse_mse: 0.09136 |  0:00:56s\n",
      "epoch 12 | loss: 0.118   | mse_mse: 0.10972 |  0:01:01s\n",
      "epoch 13 | loss: 0.11781 | mse_mse: 0.09283 |  0:01:05s\n",
      "epoch 14 | loss: 0.11581 | mse_mse: 0.09797 |  0:01:10s\n",
      "epoch 15 | loss: 0.11493 | mse_mse: 0.09108 |  0:01:15s\n",
      "epoch 16 | loss: 0.11494 | mse_mse: 0.11605 |  0:01:19s\n",
      "epoch 17 | loss: 0.11411 | mse_mse: 0.11528 |  0:01:24s\n",
      "epoch 18 | loss: 0.11792 | mse_mse: 0.09975 |  0:01:29s\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_mse_mse = 0.09101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.096352325759078\n",
      "R2 Score: 0.5653267302707528\n",
      "\n",
      "Iteration 48/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 6.2719  | mse_mse: 1.51291 |  0:00:04s\n",
      "epoch 1  | loss: 0.68107 | mse_mse: 0.70458 |  0:00:10s\n",
      "epoch 2  | loss: 0.7271  | mse_mse: 1.33134 |  0:00:15s\n",
      "epoch 3  | loss: 0.35155 | mse_mse: 0.3687  |  0:00:20s\n",
      "epoch 4  | loss: 0.3006  | mse_mse: 0.31856 |  0:00:25s\n",
      "epoch 5  | loss: 0.28382 | mse_mse: 0.24171 |  0:00:30s\n",
      "epoch 6  | loss: 0.26799 | mse_mse: 0.22153 |  0:00:36s\n",
      "epoch 7  | loss: 0.26251 | mse_mse: 0.23369 |  0:00:41s\n",
      "epoch 8  | loss: 0.25657 | mse_mse: 0.2774  |  0:00:47s\n",
      "epoch 9  | loss: 0.25325 | mse_mse: 0.21916 |  0:00:52s\n",
      "epoch 10 | loss: 0.23777 | mse_mse: 0.22451 |  0:00:57s\n",
      "epoch 11 | loss: 0.23982 | mse_mse: 0.21963 |  0:01:02s\n",
      "epoch 12 | loss: 0.24593 | mse_mse: 0.21736 |  0:01:07s\n",
      "epoch 13 | loss: 0.23943 | mse_mse: 0.21815 |  0:01:12s\n",
      "epoch 14 | loss: 0.23882 | mse_mse: 0.22105 |  0:01:17s\n",
      "epoch 15 | loss: 0.24727 | mse_mse: 0.22121 |  0:01:22s\n",
      "epoch 16 | loss: 0.23573 | mse_mse: 0.21592 |  0:01:27s\n",
      "epoch 17 | loss: 0.22524 | mse_mse: 0.21184 |  0:01:32s\n",
      "epoch 18 | loss: 0.22568 | mse_mse: 0.21297 |  0:01:38s\n",
      "epoch 19 | loss: 0.2251  | mse_mse: 0.20887 |  0:01:43s\n",
      "epoch 20 | loss: 0.23131 | mse_mse: 0.20577 |  0:01:48s\n",
      "epoch 21 | loss: 0.22121 | mse_mse: 0.20927 |  0:01:53s\n",
      "epoch 22 | loss: 0.21898 | mse_mse: 0.21007 |  0:01:58s\n",
      "epoch 23 | loss: 0.21755 | mse_mse: 0.20951 |  0:02:04s\n",
      "epoch 24 | loss: 0.22046 | mse_mse: 0.20333 |  0:02:09s\n",
      "epoch 25 | loss: 0.22052 | mse_mse: 0.20868 |  0:02:14s\n",
      "epoch 26 | loss: 0.21608 | mse_mse: 0.21961 |  0:02:19s\n",
      "epoch 27 | loss: 0.2156  | mse_mse: 0.19766 |  0:02:24s\n",
      "epoch 28 | loss: 0.23449 | mse_mse: 0.20317 |  0:02:29s\n",
      "epoch 29 | loss: 0.21521 | mse_mse: 0.19685 |  0:02:34s\n",
      "epoch 30 | loss: 0.21229 | mse_mse: 0.1975  |  0:02:40s\n",
      "epoch 31 | loss: 0.21063 | mse_mse: 0.21593 |  0:02:45s\n",
      "epoch 32 | loss: 0.22319 | mse_mse: 0.20011 |  0:02:50s\n",
      "epoch 33 | loss: 0.2141  | mse_mse: 0.20391 |  0:02:55s\n",
      "epoch 34 | loss: 0.21385 | mse_mse: 0.20435 |  0:03:00s\n",
      "epoch 35 | loss: 0.21411 | mse_mse: 0.19581 |  0:03:05s\n",
      "epoch 36 | loss: 0.20688 | mse_mse: 0.22238 |  0:03:10s\n",
      "epoch 37 | loss: 0.21106 | mse_mse: 0.20033 |  0:03:16s\n",
      "epoch 38 | loss: 0.20421 | mse_mse: 0.20242 |  0:03:21s\n",
      "epoch 39 | loss: 0.19962 | mse_mse: 0.19037 |  0:03:26s\n",
      "epoch 40 | loss: 0.19504 | mse_mse: 0.19473 |  0:03:31s\n",
      "epoch 41 | loss: 0.18442 | mse_mse: 0.16618 |  0:03:36s\n",
      "epoch 42 | loss: 0.15928 | mse_mse: 0.13502 |  0:03:41s\n",
      "epoch 43 | loss: 0.13236 | mse_mse: 0.108   |  0:03:46s\n",
      "epoch 44 | loss: 0.12393 | mse_mse: 0.11895 |  0:03:51s\n",
      "epoch 45 | loss: 0.10961 | mse_mse: 0.09335 |  0:03:56s\n",
      "epoch 46 | loss: 0.10224 | mse_mse: 0.081   |  0:04:02s\n",
      "epoch 47 | loss: 0.08841 | mse_mse: 0.0814  |  0:04:07s\n",
      "epoch 48 | loss: 0.07448 | mse_mse: 0.07394 |  0:04:12s\n",
      "epoch 49 | loss: 0.06932 | mse_mse: 0.06184 |  0:04:17s\n",
      "epoch 50 | loss: 0.06468 | mse_mse: 0.07086 |  0:04:22s\n",
      "epoch 51 | loss: 0.06382 | mse_mse: 0.06198 |  0:04:27s\n",
      "epoch 52 | loss: 0.0551  | mse_mse: 0.06469 |  0:04:32s\n",
      "epoch 53 | loss: 0.05857 | mse_mse: 0.06821 |  0:04:37s\n",
      "epoch 54 | loss: 0.0595  | mse_mse: 0.07007 |  0:04:42s\n",
      "epoch 55 | loss: 0.05536 | mse_mse: 0.048   |  0:04:47s\n",
      "epoch 56 | loss: 0.04104 | mse_mse: 0.03867 |  0:04:52s\n",
      "epoch 57 | loss: 0.03894 | mse_mse: 0.05349 |  0:04:58s\n",
      "epoch 58 | loss: 0.04319 | mse_mse: 0.03842 |  0:05:03s\n",
      "epoch 59 | loss: 0.04019 | mse_mse: 0.04682 |  0:05:08s\n",
      "epoch 60 | loss: 0.03287 | mse_mse: 0.02654 |  0:05:13s\n",
      "epoch 61 | loss: 0.02687 | mse_mse: 0.02721 |  0:05:18s\n",
      "epoch 62 | loss: 0.03005 | mse_mse: 0.02186 |  0:05:23s\n",
      "epoch 63 | loss: 0.02305 | mse_mse: 0.01797 |  0:05:28s\n",
      "epoch 64 | loss: 0.02179 | mse_mse: 0.01914 |  0:05:33s\n",
      "epoch 65 | loss: 0.02032 | mse_mse: 0.02467 |  0:05:38s\n",
      "epoch 66 | loss: 0.02036 | mse_mse: 0.01474 |  0:05:43s\n",
      "epoch 67 | loss: 0.01953 | mse_mse: 0.0128  |  0:05:49s\n",
      "epoch 68 | loss: 0.01934 | mse_mse: 0.01361 |  0:05:54s\n",
      "epoch 69 | loss: 0.01614 | mse_mse: 0.01378 |  0:05:59s\n",
      "epoch 70 | loss: 0.01803 | mse_mse: 0.01557 |  0:06:04s\n",
      "epoch 71 | loss: 0.01679 | mse_mse: 0.01412 |  0:06:09s\n",
      "epoch 72 | loss: 0.01958 | mse_mse: 0.01695 |  0:06:14s\n",
      "epoch 73 | loss: 0.01606 | mse_mse: 0.00943 |  0:06:19s\n",
      "epoch 74 | loss: 0.01495 | mse_mse: 0.01119 |  0:06:25s\n",
      "epoch 75 | loss: 0.01469 | mse_mse: 0.01059 |  0:06:30s\n",
      "epoch 76 | loss: 0.01435 | mse_mse: 0.01142 |  0:06:35s\n",
      "epoch 77 | loss: 0.01203 | mse_mse: 0.01522 |  0:06:40s\n",
      "epoch 78 | loss: 0.01426 | mse_mse: 0.00814 |  0:06:45s\n",
      "epoch 79 | loss: 0.01385 | mse_mse: 0.00856 |  0:06:50s\n",
      "epoch 80 | loss: 0.01369 | mse_mse: 0.03641 |  0:06:55s\n",
      "epoch 81 | loss: 0.01474 | mse_mse: 0.00826 |  0:07:01s\n",
      "epoch 82 | loss: 0.01147 | mse_mse: 0.01111 |  0:07:06s\n",
      "epoch 83 | loss: 0.01377 | mse_mse: 0.0073  |  0:07:11s\n",
      "epoch 84 | loss: 0.01362 | mse_mse: 0.01039 |  0:07:16s\n",
      "epoch 85 | loss: 0.01103 | mse_mse: 0.01099 |  0:07:21s\n",
      "epoch 86 | loss: 0.01349 | mse_mse: 0.01143 |  0:07:26s\n",
      "epoch 87 | loss: 0.0114  | mse_mse: 0.01259 |  0:07:31s\n",
      "epoch 88 | loss: 0.01307 | mse_mse: 0.00781 |  0:07:36s\n",
      "epoch 89 | loss: 0.0115  | mse_mse: 0.00738 |  0:07:42s\n",
      "epoch 90 | loss: 0.01126 | mse_mse: 0.0133  |  0:07:47s\n",
      "epoch 91 | loss: 0.01546 | mse_mse: 0.01517 |  0:07:52s\n",
      "epoch 92 | loss: 0.01123 | mse_mse: 0.00954 |  0:07:57s\n",
      "epoch 93 | loss: 0.01293 | mse_mse: 0.01329 |  0:08:02s\n",
      "\n",
      "Early stopping occurred at epoch 93 with best_epoch = 83 and best_mse_mse = 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007823393610911113\n",
      "R2 Score: 0.9647064037692599\n",
      "\n",
      "Iteration 49/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.17788 | mse_mse: 0.78084 |  0:00:02s\n",
      "epoch 1  | loss: 0.30843 | mse_mse: 0.39399 |  0:00:04s\n",
      "epoch 2  | loss: 0.2094  | mse_mse: 0.15483 |  0:00:07s\n",
      "epoch 3  | loss: 0.16749 | mse_mse: 0.11601 |  0:00:09s\n",
      "epoch 4  | loss: 0.14736 | mse_mse: 0.12799 |  0:00:11s\n",
      "epoch 5  | loss: 0.12932 | mse_mse: 0.08937 |  0:00:14s\n",
      "epoch 6  | loss: 0.12047 | mse_mse: 0.10934 |  0:00:16s\n",
      "epoch 7  | loss: 0.11718 | mse_mse: 0.08862 |  0:00:19s\n",
      "epoch 8  | loss: 0.11622 | mse_mse: 0.09346 |  0:00:21s\n",
      "epoch 9  | loss: 0.10879 | mse_mse: 0.09348 |  0:00:23s\n",
      "epoch 10 | loss: 0.10655 | mse_mse: 0.09231 |  0:00:26s\n",
      "epoch 11 | loss: 0.10628 | mse_mse: 0.09048 |  0:00:28s\n",
      "epoch 12 | loss: 0.10384 | mse_mse: 0.08845 |  0:00:31s\n",
      "epoch 13 | loss: 0.10662 | mse_mse: 0.09146 |  0:00:33s\n",
      "epoch 14 | loss: 0.10198 | mse_mse: 0.09868 |  0:00:36s\n",
      "epoch 15 | loss: 0.09984 | mse_mse: 0.08757 |  0:00:38s\n",
      "epoch 16 | loss: 0.0967  | mse_mse: 0.09053 |  0:00:40s\n",
      "epoch 17 | loss: 0.09321 | mse_mse: 0.08323 |  0:00:43s\n",
      "epoch 18 | loss: 0.08957 | mse_mse: 0.07961 |  0:00:45s\n",
      "epoch 19 | loss: 0.08595 | mse_mse: 0.07553 |  0:00:48s\n",
      "epoch 20 | loss: 0.06935 | mse_mse: 0.06486 |  0:00:50s\n",
      "epoch 21 | loss: 0.06372 | mse_mse: 0.06249 |  0:00:52s\n",
      "epoch 22 | loss: 0.05846 | mse_mse: 0.04845 |  0:00:55s\n",
      "epoch 23 | loss: 0.04846 | mse_mse: 0.05856 |  0:00:58s\n",
      "epoch 24 | loss: 0.04946 | mse_mse: 0.03927 |  0:01:00s\n",
      "epoch 25 | loss: 0.04145 | mse_mse: 0.04247 |  0:01:02s\n",
      "epoch 26 | loss: 0.0403  | mse_mse: 0.03615 |  0:01:05s\n",
      "epoch 27 | loss: 0.03176 | mse_mse: 0.03149 |  0:01:07s\n",
      "epoch 28 | loss: 0.03288 | mse_mse: 0.02823 |  0:01:10s\n",
      "epoch 29 | loss: 0.02482 | mse_mse: 0.02444 |  0:01:12s\n",
      "epoch 30 | loss: 0.02449 | mse_mse: 0.02071 |  0:01:14s\n",
      "epoch 31 | loss: 0.02201 | mse_mse: 0.01994 |  0:01:17s\n",
      "epoch 32 | loss: 0.02051 | mse_mse: 0.02407 |  0:01:19s\n",
      "epoch 33 | loss: 0.01783 | mse_mse: 0.02233 |  0:01:22s\n",
      "epoch 34 | loss: 0.01905 | mse_mse: 0.01742 |  0:01:24s\n",
      "epoch 35 | loss: 0.01692 | mse_mse: 0.01519 |  0:01:26s\n",
      "epoch 36 | loss: 0.01472 | mse_mse: 0.01875 |  0:01:29s\n",
      "epoch 37 | loss: 0.01525 | mse_mse: 0.02251 |  0:01:31s\n",
      "epoch 38 | loss: 0.01629 | mse_mse: 0.02006 |  0:01:34s\n",
      "epoch 39 | loss: 0.01613 | mse_mse: 0.01229 |  0:01:36s\n",
      "epoch 40 | loss: 0.01321 | mse_mse: 0.01217 |  0:01:38s\n",
      "epoch 41 | loss: 0.0138  | mse_mse: 0.0138  |  0:01:41s\n",
      "epoch 42 | loss: 0.01291 | mse_mse: 0.01362 |  0:01:43s\n",
      "epoch 43 | loss: 0.011   | mse_mse: 0.01108 |  0:01:46s\n",
      "epoch 44 | loss: 0.01277 | mse_mse: 0.00924 |  0:01:48s\n",
      "epoch 45 | loss: 0.01321 | mse_mse: 0.01189 |  0:01:50s\n",
      "epoch 46 | loss: 0.01492 | mse_mse: 0.01037 |  0:01:53s\n",
      "epoch 47 | loss: 0.01151 | mse_mse: 0.00884 |  0:01:55s\n",
      "epoch 48 | loss: 0.01061 | mse_mse: 0.01157 |  0:01:58s\n",
      "epoch 49 | loss: 0.01317 | mse_mse: 0.01819 |  0:02:00s\n",
      "epoch 50 | loss: 0.01296 | mse_mse: 0.0087  |  0:02:02s\n",
      "epoch 51 | loss: 0.01106 | mse_mse: 0.0128  |  0:02:05s\n",
      "epoch 52 | loss: 0.00984 | mse_mse: 0.01063 |  0:02:07s\n",
      "epoch 53 | loss: 0.00907 | mse_mse: 0.00932 |  0:02:10s\n",
      "epoch 54 | loss: 0.01038 | mse_mse: 0.01646 |  0:02:12s\n",
      "epoch 55 | loss: 0.01072 | mse_mse: 0.00811 |  0:02:14s\n",
      "epoch 56 | loss: 0.0124  | mse_mse: 0.01038 |  0:02:17s\n",
      "epoch 57 | loss: 0.00867 | mse_mse: 0.00869 |  0:02:19s\n",
      "epoch 58 | loss: 0.01103 | mse_mse: 0.01447 |  0:02:22s\n",
      "epoch 59 | loss: 0.01181 | mse_mse: 0.0172  |  0:02:24s\n",
      "epoch 60 | loss: 0.00934 | mse_mse: 0.00921 |  0:02:26s\n",
      "epoch 61 | loss: 0.00953 | mse_mse: 0.00828 |  0:02:29s\n",
      "epoch 62 | loss: 0.01215 | mse_mse: 0.02441 |  0:02:31s\n",
      "epoch 63 | loss: 0.00982 | mse_mse: 0.00773 |  0:02:34s\n",
      "epoch 64 | loss: 0.00847 | mse_mse: 0.01013 |  0:02:36s\n",
      "epoch 65 | loss: 0.01205 | mse_mse: 0.01149 |  0:02:38s\n",
      "epoch 66 | loss: 0.00815 | mse_mse: 0.008   |  0:02:41s\n",
      "epoch 67 | loss: 0.01334 | mse_mse: 0.0182  |  0:02:43s\n",
      "epoch 68 | loss: 0.0103  | mse_mse: 0.00728 |  0:02:46s\n",
      "epoch 69 | loss: 0.0075  | mse_mse: 0.00731 |  0:02:48s\n",
      "epoch 70 | loss: 0.00821 | mse_mse: 0.01109 |  0:02:50s\n",
      "epoch 71 | loss: 0.00879 | mse_mse: 0.00872 |  0:02:53s\n",
      "epoch 72 | loss: 0.00944 | mse_mse: 0.00722 |  0:02:55s\n",
      "epoch 73 | loss: 0.00742 | mse_mse: 0.00703 |  0:02:58s\n",
      "epoch 74 | loss: 0.0072  | mse_mse: 0.01631 |  0:03:00s\n",
      "epoch 75 | loss: 0.00917 | mse_mse: 0.00809 |  0:03:02s\n",
      "epoch 76 | loss: 0.00654 | mse_mse: 0.00767 |  0:03:05s\n",
      "epoch 77 | loss: 0.01189 | mse_mse: 0.00985 |  0:03:07s\n",
      "epoch 78 | loss: 0.00694 | mse_mse: 0.01095 |  0:03:10s\n",
      "epoch 79 | loss: 0.00719 | mse_mse: 0.00949 |  0:03:12s\n",
      "epoch 80 | loss: 0.00899 | mse_mse: 0.00847 |  0:03:14s\n",
      "epoch 81 | loss: 0.01013 | mse_mse: 0.0143  |  0:03:17s\n",
      "epoch 82 | loss: 0.00648 | mse_mse: 0.00828 |  0:03:19s\n",
      "epoch 83 | loss: 0.01043 | mse_mse: 0.0092  |  0:03:21s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 73 and best_mse_mse = 0.00703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007449979545838862\n",
      "R2 Score: 0.966390982852838\n",
      "\n",
      "Iteration 50/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.00136 | mse_mse: 1.18308 |  0:00:02s\n",
      "epoch 1  | loss: 0.32338 | mse_mse: 0.52177 |  0:00:05s\n",
      "epoch 2  | loss: 0.2681  | mse_mse: 0.31818 |  0:00:07s\n",
      "epoch 3  | loss: 0.24464 | mse_mse: 0.30962 |  0:00:10s\n",
      "epoch 4  | loss: 0.23945 | mse_mse: 0.25664 |  0:00:13s\n",
      "epoch 5  | loss: 0.24021 | mse_mse: 0.21445 |  0:00:15s\n",
      "epoch 6  | loss: 0.21944 | mse_mse: 0.2046  |  0:00:18s\n",
      "epoch 7  | loss: 0.21449 | mse_mse: 0.19996 |  0:00:20s\n",
      "epoch 8  | loss: 0.19745 | mse_mse: 0.15846 |  0:00:23s\n",
      "epoch 9  | loss: 0.16724 | mse_mse: 0.1352  |  0:00:26s\n",
      "epoch 10 | loss: 0.11621 | mse_mse: 0.13019 |  0:00:28s\n",
      "epoch 11 | loss: 0.09193 | mse_mse: 0.05478 |  0:00:31s\n",
      "epoch 12 | loss: 0.06838 | mse_mse: 0.04802 |  0:00:33s\n",
      "epoch 13 | loss: 0.06052 | mse_mse: 0.05335 |  0:00:36s\n",
      "epoch 14 | loss: 0.04999 | mse_mse: 0.05631 |  0:00:39s\n",
      "epoch 15 | loss: 0.04185 | mse_mse: 0.03353 |  0:00:41s\n",
      "epoch 16 | loss: 0.03875 | mse_mse: 0.03141 |  0:00:44s\n",
      "epoch 17 | loss: 0.03694 | mse_mse: 0.02743 |  0:00:46s\n",
      "epoch 18 | loss: 0.0273  | mse_mse: 0.02734 |  0:00:49s\n",
      "epoch 19 | loss: 0.02683 | mse_mse: 0.02976 |  0:00:52s\n",
      "epoch 20 | loss: 0.02627 | mse_mse: 0.02344 |  0:00:54s\n",
      "epoch 21 | loss: 0.02252 | mse_mse: 0.02478 |  0:00:57s\n",
      "epoch 22 | loss: 0.02183 | mse_mse: 0.01611 |  0:00:59s\n",
      "epoch 23 | loss: 0.0182  | mse_mse: 0.01709 |  0:01:02s\n",
      "epoch 24 | loss: 0.02125 | mse_mse: 0.01345 |  0:01:05s\n",
      "epoch 25 | loss: 0.02048 | mse_mse: 0.01406 |  0:01:07s\n",
      "epoch 26 | loss: 0.02082 | mse_mse: 0.0199  |  0:01:10s\n",
      "epoch 27 | loss: 0.01817 | mse_mse: 0.01856 |  0:01:13s\n",
      "epoch 28 | loss: 0.01686 | mse_mse: 0.01239 |  0:01:15s\n",
      "epoch 29 | loss: 0.0141  | mse_mse: 0.01698 |  0:01:18s\n",
      "epoch 30 | loss: 0.01368 | mse_mse: 0.01203 |  0:01:21s\n",
      "epoch 31 | loss: 0.01594 | mse_mse: 0.0168  |  0:01:23s\n",
      "epoch 32 | loss: 0.01533 | mse_mse: 0.01749 |  0:01:26s\n",
      "epoch 33 | loss: 0.01536 | mse_mse: 0.00964 |  0:01:29s\n",
      "epoch 34 | loss: 0.01494 | mse_mse: 0.01029 |  0:01:31s\n",
      "epoch 35 | loss: 0.01463 | mse_mse: 0.01442 |  0:01:34s\n",
      "epoch 36 | loss: 0.01499 | mse_mse: 0.00928 |  0:01:36s\n",
      "epoch 37 | loss: 0.012   | mse_mse: 0.01115 |  0:01:39s\n",
      "epoch 38 | loss: 0.01113 | mse_mse: 0.00867 |  0:01:42s\n",
      "epoch 39 | loss: 0.0149  | mse_mse: 0.01772 |  0:01:44s\n",
      "epoch 40 | loss: 0.01386 | mse_mse: 0.01161 |  0:01:47s\n",
      "epoch 41 | loss: 0.01358 | mse_mse: 0.01293 |  0:01:50s\n",
      "epoch 42 | loss: 0.01263 | mse_mse: 0.0084  |  0:01:52s\n",
      "epoch 43 | loss: 0.01103 | mse_mse: 0.01244 |  0:01:55s\n",
      "epoch 44 | loss: 0.01156 | mse_mse: 0.00956 |  0:01:57s\n",
      "epoch 45 | loss: 0.01395 | mse_mse: 0.01276 |  0:02:00s\n",
      "epoch 46 | loss: 0.0113  | mse_mse: 0.01155 |  0:02:03s\n",
      "epoch 47 | loss: 0.01027 | mse_mse: 0.02028 |  0:02:05s\n",
      "epoch 48 | loss: 0.01196 | mse_mse: 0.00898 |  0:02:08s\n",
      "epoch 49 | loss: 0.01012 | mse_mse: 0.01005 |  0:02:11s\n",
      "epoch 50 | loss: 0.01057 | mse_mse: 0.01046 |  0:02:13s\n",
      "epoch 51 | loss: 0.01028 | mse_mse: 0.00919 |  0:02:16s\n",
      "epoch 52 | loss: 0.0124  | mse_mse: 0.01566 |  0:02:18s\n",
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 42 and best_mse_mse = 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008452415014122779\n",
      "R2 Score: 0.9618687058941991\n",
      "\n",
      "Iteration 51/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.51174 | mse_mse: 1.26744 |  0:00:03s\n",
      "epoch 1  | loss: 0.42054 | mse_mse: 0.4247  |  0:00:07s\n",
      "epoch 2  | loss: 0.3464  | mse_mse: 0.46389 |  0:00:11s\n",
      "epoch 3  | loss: 0.26828 | mse_mse: 0.25898 |  0:00:15s\n",
      "epoch 4  | loss: 0.26659 | mse_mse: 0.24631 |  0:00:18s\n",
      "epoch 5  | loss: 0.25703 | mse_mse: 0.23654 |  0:00:23s\n",
      "epoch 6  | loss: 0.24837 | mse_mse: 0.24297 |  0:00:27s\n",
      "epoch 7  | loss: 0.24123 | mse_mse: 0.22126 |  0:00:30s\n",
      "epoch 8  | loss: 0.23969 | mse_mse: 0.22758 |  0:00:34s\n",
      "epoch 9  | loss: 0.23479 | mse_mse: 0.23011 |  0:00:38s\n",
      "epoch 10 | loss: 0.23298 | mse_mse: 0.22337 |  0:00:41s\n",
      "epoch 11 | loss: 0.24093 | mse_mse: 0.23393 |  0:00:45s\n",
      "epoch 12 | loss: 0.23826 | mse_mse: 0.22864 |  0:00:49s\n",
      "epoch 13 | loss: 0.23615 | mse_mse: 0.23973 |  0:00:52s\n",
      "epoch 14 | loss: 0.23179 | mse_mse: 0.22024 |  0:00:56s\n",
      "epoch 15 | loss: 0.2299  | mse_mse: 0.22503 |  0:01:00s\n",
      "epoch 16 | loss: 0.2329  | mse_mse: 0.2171  |  0:01:03s\n",
      "epoch 17 | loss: 0.22526 | mse_mse: 0.21542 |  0:01:07s\n",
      "epoch 18 | loss: 0.22813 | mse_mse: 0.21835 |  0:01:11s\n",
      "epoch 19 | loss: 0.22415 | mse_mse: 0.2077  |  0:01:15s\n",
      "epoch 20 | loss: 0.22184 | mse_mse: 0.2155  |  0:01:18s\n",
      "epoch 21 | loss: 0.21794 | mse_mse: 0.22048 |  0:01:22s\n",
      "epoch 22 | loss: 0.22136 | mse_mse: 0.19911 |  0:01:26s\n",
      "epoch 23 | loss: 0.2071  | mse_mse: 0.19885 |  0:01:29s\n",
      "epoch 24 | loss: 0.19165 | mse_mse: 0.18294 |  0:01:33s\n",
      "epoch 25 | loss: 0.17311 | mse_mse: 0.1719  |  0:01:37s\n",
      "epoch 26 | loss: 0.14696 | mse_mse: 0.12451 |  0:01:41s\n",
      "epoch 27 | loss: 0.11898 | mse_mse: 0.10524 |  0:01:45s\n",
      "epoch 28 | loss: 0.10272 | mse_mse: 0.09293 |  0:01:48s\n",
      "epoch 29 | loss: 0.08943 | mse_mse: 0.07525 |  0:01:52s\n",
      "epoch 30 | loss: 0.07935 | mse_mse: 0.06319 |  0:01:56s\n",
      "epoch 31 | loss: 0.06515 | mse_mse: 0.05323 |  0:02:00s\n",
      "epoch 32 | loss: 0.05856 | mse_mse: 0.04892 |  0:02:03s\n",
      "epoch 33 | loss: 0.05509 | mse_mse: 0.04087 |  0:02:07s\n",
      "epoch 34 | loss: 0.04414 | mse_mse: 0.03896 |  0:02:11s\n",
      "epoch 35 | loss: 0.04179 | mse_mse: 0.03495 |  0:02:15s\n",
      "epoch 36 | loss: 0.038   | mse_mse: 0.04671 |  0:02:18s\n",
      "epoch 37 | loss: 0.06203 | mse_mse: 0.031   |  0:02:22s\n",
      "epoch 38 | loss: 0.03461 | mse_mse: 0.03498 |  0:02:26s\n",
      "epoch 39 | loss: 0.0316  | mse_mse: 0.02595 |  0:02:29s\n",
      "epoch 40 | loss: 0.03104 | mse_mse: 0.0302  |  0:02:33s\n",
      "epoch 41 | loss: 0.02896 | mse_mse: 0.02703 |  0:02:37s\n",
      "epoch 42 | loss: 0.03285 | mse_mse: 0.02389 |  0:02:41s\n",
      "epoch 43 | loss: 0.02757 | mse_mse: 0.02328 |  0:02:44s\n",
      "epoch 44 | loss: 0.03006 | mse_mse: 0.04861 |  0:02:48s\n",
      "epoch 45 | loss: 0.0293  | mse_mse: 0.02968 |  0:02:52s\n",
      "epoch 46 | loss: 0.0256  | mse_mse: 0.02577 |  0:02:56s\n",
      "epoch 47 | loss: 0.02157 | mse_mse: 0.02071 |  0:02:59s\n",
      "epoch 48 | loss: 0.02305 | mse_mse: 0.01946 |  0:03:03s\n",
      "epoch 49 | loss: 0.02348 | mse_mse: 0.02983 |  0:03:07s\n",
      "epoch 50 | loss: 0.02435 | mse_mse: 0.01841 |  0:03:11s\n",
      "epoch 51 | loss: 0.01806 | mse_mse: 0.01514 |  0:03:14s\n",
      "epoch 52 | loss: 0.02302 | mse_mse: 0.02179 |  0:03:18s\n",
      "epoch 53 | loss: 0.01653 | mse_mse: 0.01533 |  0:03:22s\n",
      "epoch 54 | loss: 0.01994 | mse_mse: 0.01239 |  0:03:26s\n",
      "epoch 55 | loss: 0.02686 | mse_mse: 0.02578 |  0:03:29s\n",
      "epoch 56 | loss: 0.01976 | mse_mse: 0.01421 |  0:03:33s\n",
      "epoch 57 | loss: 0.01739 | mse_mse: 0.01303 |  0:03:37s\n",
      "epoch 58 | loss: 0.02155 | mse_mse: 0.02074 |  0:03:41s\n",
      "epoch 59 | loss: 0.01806 | mse_mse: 0.01058 |  0:03:44s\n",
      "epoch 60 | loss: 0.01375 | mse_mse: 0.01091 |  0:03:48s\n",
      "epoch 61 | loss: 0.01627 | mse_mse: 0.0323  |  0:03:52s\n",
      "epoch 62 | loss: 0.01939 | mse_mse: 0.01608 |  0:03:55s\n",
      "epoch 63 | loss: 0.01529 | mse_mse: 0.01091 |  0:03:59s\n",
      "epoch 64 | loss: 0.01667 | mse_mse: 0.06661 |  0:04:03s\n",
      "epoch 65 | loss: 0.02147 | mse_mse: 0.02695 |  0:04:07s\n",
      "epoch 66 | loss: 0.01508 | mse_mse: 0.01816 |  0:04:10s\n",
      "epoch 67 | loss: 0.01326 | mse_mse: 0.01024 |  0:04:14s\n",
      "epoch 68 | loss: 0.01078 | mse_mse: 0.01832 |  0:04:18s\n",
      "epoch 69 | loss: 0.01523 | mse_mse: 0.00992 |  0:04:22s\n",
      "epoch 70 | loss: 0.0121  | mse_mse: 0.00966 |  0:04:25s\n",
      "epoch 71 | loss: 0.01323 | mse_mse: 0.01235 |  0:04:29s\n",
      "epoch 72 | loss: 0.01199 | mse_mse: 0.02169 |  0:04:33s\n",
      "epoch 73 | loss: 0.01565 | mse_mse: 0.01581 |  0:04:37s\n",
      "epoch 74 | loss: 0.01177 | mse_mse: 0.00999 |  0:04:40s\n",
      "epoch 75 | loss: 0.01088 | mse_mse: 0.00999 |  0:04:44s\n",
      "epoch 76 | loss: 0.01131 | mse_mse: 0.01124 |  0:04:48s\n",
      "epoch 77 | loss: 0.01397 | mse_mse: 0.02028 |  0:04:51s\n",
      "epoch 78 | loss: 0.01227 | mse_mse: 0.00844 |  0:04:55s\n",
      "epoch 79 | loss: 0.0113  | mse_mse: 0.01137 |  0:04:59s\n",
      "epoch 80 | loss: 0.01294 | mse_mse: 0.00895 |  0:05:03s\n",
      "epoch 81 | loss: 0.01211 | mse_mse: 0.00921 |  0:05:06s\n",
      "epoch 82 | loss: 0.01104 | mse_mse: 0.00867 |  0:05:10s\n",
      "epoch 83 | loss: 0.01009 | mse_mse: 0.00786 |  0:05:14s\n",
      "epoch 84 | loss: 0.01372 | mse_mse: 0.00865 |  0:05:18s\n",
      "epoch 85 | loss: 0.01157 | mse_mse: 0.00806 |  0:05:21s\n",
      "epoch 86 | loss: 0.01092 | mse_mse: 0.00738 |  0:05:25s\n",
      "epoch 87 | loss: 0.01053 | mse_mse: 0.00784 |  0:05:29s\n",
      "epoch 88 | loss: 0.01116 | mse_mse: 0.00954 |  0:05:33s\n",
      "epoch 89 | loss: 0.01131 | mse_mse: 0.01667 |  0:05:36s\n",
      "epoch 90 | loss: 0.0123  | mse_mse: 0.01504 |  0:05:40s\n",
      "epoch 91 | loss: 0.01394 | mse_mse: 0.00849 |  0:05:44s\n",
      "epoch 92 | loss: 0.00907 | mse_mse: 0.0094  |  0:05:48s\n",
      "epoch 93 | loss: 0.00945 | mse_mse: 0.02383 |  0:05:51s\n",
      "epoch 94 | loss: 0.01322 | mse_mse: 0.02641 |  0:05:55s\n",
      "epoch 95 | loss: 0.01389 | mse_mse: 0.01931 |  0:05:59s\n",
      "epoch 96 | loss: 0.0168  | mse_mse: 0.00915 |  0:06:02s\n",
      "\n",
      "Early stopping occurred at epoch 96 with best_epoch = 86 and best_mse_mse = 0.00738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007223458926143179\n",
      "R2 Score: 0.9674128830264821\n",
      "\n",
      "Iteration 52/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.63482 | mse_mse: 1.20848 |  0:00:03s\n",
      "epoch 1  | loss: 0.41355 | mse_mse: 0.68488 |  0:00:07s\n",
      "epoch 2  | loss: 0.2665  | mse_mse: 0.66796 |  0:00:11s\n",
      "epoch 3  | loss: 0.22406 | mse_mse: 0.12428 |  0:00:16s\n",
      "epoch 4  | loss: 0.16324 | mse_mse: 0.09961 |  0:00:20s\n",
      "epoch 5  | loss: 0.1372  | mse_mse: 0.10697 |  0:00:24s\n",
      "epoch 6  | loss: 0.15245 | mse_mse: 0.13026 |  0:00:28s\n",
      "epoch 7  | loss: 0.1241  | mse_mse: 0.08409 |  0:00:32s\n",
      "epoch 8  | loss: 0.11498 | mse_mse: 0.10078 |  0:00:36s\n",
      "epoch 9  | loss: 0.11356 | mse_mse: 0.08215 |  0:00:40s\n",
      "epoch 10 | loss: 0.1128  | mse_mse: 0.08262 |  0:00:44s\n",
      "epoch 11 | loss: 0.1108  | mse_mse: 0.08759 |  0:00:48s\n",
      "epoch 12 | loss: 0.10401 | mse_mse: 0.08054 |  0:00:52s\n",
      "epoch 13 | loss: 0.10082 | mse_mse: 0.08295 |  0:00:56s\n",
      "epoch 14 | loss: 0.101   | mse_mse: 0.11187 |  0:01:00s\n",
      "epoch 15 | loss: 0.10012 | mse_mse: 0.08142 |  0:01:04s\n",
      "epoch 16 | loss: 0.09996 | mse_mse: 0.07961 |  0:01:08s\n",
      "epoch 17 | loss: 0.09845 | mse_mse: 0.08159 |  0:01:12s\n",
      "epoch 18 | loss: 0.0981  | mse_mse: 0.07938 |  0:01:16s\n",
      "epoch 19 | loss: 0.0933  | mse_mse: 0.08965 |  0:01:20s\n",
      "epoch 20 | loss: 0.09446 | mse_mse: 0.09325 |  0:01:24s\n",
      "epoch 21 | loss: 0.09173 | mse_mse: 0.08604 |  0:01:28s\n",
      "epoch 22 | loss: 0.09903 | mse_mse: 0.07782 |  0:01:32s\n",
      "epoch 23 | loss: 0.09011 | mse_mse: 0.07295 |  0:01:36s\n",
      "epoch 24 | loss: 0.08067 | mse_mse: 0.06553 |  0:01:40s\n",
      "epoch 25 | loss: 0.07462 | mse_mse: 0.06144 |  0:01:44s\n",
      "epoch 26 | loss: 0.06678 | mse_mse: 0.06228 |  0:01:49s\n",
      "epoch 27 | loss: 0.06501 | mse_mse: 0.05248 |  0:01:53s\n",
      "epoch 28 | loss: 0.05849 | mse_mse: 0.04798 |  0:01:57s\n",
      "epoch 29 | loss: 0.05973 | mse_mse: 0.0515  |  0:02:01s\n",
      "epoch 30 | loss: 0.05286 | mse_mse: 0.04704 |  0:02:05s\n",
      "epoch 31 | loss: 0.0519  | mse_mse: 0.04096 |  0:02:09s\n",
      "epoch 32 | loss: 0.04439 | mse_mse: 0.05432 |  0:02:13s\n",
      "epoch 33 | loss: 0.04402 | mse_mse: 0.03739 |  0:02:17s\n",
      "epoch 34 | loss: 0.0389  | mse_mse: 0.03444 |  0:02:22s\n",
      "epoch 35 | loss: 0.03714 | mse_mse: 0.03188 |  0:02:26s\n",
      "epoch 36 | loss: 0.03367 | mse_mse: 0.0302  |  0:02:30s\n",
      "epoch 37 | loss: 0.03002 | mse_mse: 0.02797 |  0:02:34s\n",
      "epoch 38 | loss: 0.02713 | mse_mse: 0.02435 |  0:02:38s\n",
      "epoch 39 | loss: 0.02833 | mse_mse: 0.02444 |  0:02:42s\n",
      "epoch 40 | loss: 0.02392 | mse_mse: 0.02533 |  0:02:46s\n",
      "epoch 41 | loss: 0.02614 | mse_mse: 0.02275 |  0:02:50s\n",
      "epoch 42 | loss: 0.02216 | mse_mse: 0.02145 |  0:02:54s\n",
      "epoch 43 | loss: 0.02064 | mse_mse: 0.02006 |  0:02:59s\n",
      "epoch 44 | loss: 0.02144 | mse_mse: 0.01742 |  0:03:03s\n",
      "epoch 45 | loss: 0.01806 | mse_mse: 0.01549 |  0:03:07s\n",
      "epoch 46 | loss: 0.01655 | mse_mse: 0.01563 |  0:03:11s\n",
      "epoch 47 | loss: 0.01893 | mse_mse: 0.01436 |  0:03:15s\n",
      "epoch 48 | loss: 0.01692 | mse_mse: 0.01984 |  0:03:19s\n",
      "epoch 49 | loss: 0.01776 | mse_mse: 0.01818 |  0:03:23s\n",
      "epoch 50 | loss: 0.01852 | mse_mse: 0.01352 |  0:03:27s\n",
      "epoch 51 | loss: 0.0166  | mse_mse: 0.05802 |  0:03:31s\n",
      "epoch 52 | loss: 0.02302 | mse_mse: 0.0135  |  0:03:35s\n",
      "epoch 53 | loss: 0.01403 | mse_mse: 0.0159  |  0:03:40s\n",
      "epoch 54 | loss: 0.01564 | mse_mse: 0.02532 |  0:03:44s\n",
      "epoch 55 | loss: 0.01908 | mse_mse: 0.01458 |  0:03:48s\n",
      "epoch 56 | loss: 0.02184 | mse_mse: 0.01574 |  0:03:52s\n",
      "epoch 57 | loss: 0.016   | mse_mse: 0.01172 |  0:03:56s\n",
      "epoch 58 | loss: 0.01654 | mse_mse: 0.01461 |  0:04:00s\n",
      "epoch 59 | loss: 0.01297 | mse_mse: 0.01289 |  0:04:04s\n",
      "epoch 60 | loss: 0.01461 | mse_mse: 0.01015 |  0:04:08s\n",
      "epoch 61 | loss: 0.01165 | mse_mse: 0.01179 |  0:04:12s\n",
      "epoch 62 | loss: 0.01628 | mse_mse: 0.01776 |  0:04:16s\n",
      "epoch 63 | loss: 0.01214 | mse_mse: 0.01016 |  0:04:20s\n",
      "epoch 64 | loss: 0.01208 | mse_mse: 0.01352 |  0:04:24s\n",
      "epoch 65 | loss: 0.01658 | mse_mse: 0.01046 |  0:04:28s\n",
      "epoch 66 | loss: 0.01335 | mse_mse: 0.00838 |  0:04:32s\n",
      "epoch 67 | loss: 0.01179 | mse_mse: 0.00838 |  0:04:37s\n",
      "epoch 68 | loss: 0.01331 | mse_mse: 0.0153  |  0:04:41s\n",
      "epoch 69 | loss: 0.0118  | mse_mse: 0.01039 |  0:04:45s\n",
      "epoch 70 | loss: 0.00951 | mse_mse: 0.00989 |  0:04:49s\n",
      "epoch 71 | loss: 0.01156 | mse_mse: 0.00833 |  0:04:53s\n",
      "epoch 72 | loss: 0.0101  | mse_mse: 0.00819 |  0:04:57s\n",
      "epoch 73 | loss: 0.01164 | mse_mse: 0.011   |  0:05:01s\n",
      "epoch 74 | loss: 0.0113  | mse_mse: 0.00855 |  0:05:05s\n",
      "epoch 75 | loss: 0.01061 | mse_mse: 0.01157 |  0:05:09s\n",
      "epoch 76 | loss: 0.00938 | mse_mse: 0.00892 |  0:05:13s\n",
      "epoch 77 | loss: 0.01211 | mse_mse: 0.01895 |  0:05:17s\n",
      "epoch 78 | loss: 0.01494 | mse_mse: 0.01582 |  0:05:22s\n",
      "epoch 79 | loss: 0.01121 | mse_mse: 0.00924 |  0:05:26s\n",
      "epoch 80 | loss: 0.01083 | mse_mse: 0.01028 |  0:05:30s\n",
      "epoch 81 | loss: 0.01006 | mse_mse: 0.01778 |  0:05:34s\n",
      "epoch 82 | loss: 0.01461 | mse_mse: 0.01401 |  0:05:38s\n",
      "\n",
      "Early stopping occurred at epoch 82 with best_epoch = 72 and best_mse_mse = 0.00819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008280826723617686\n",
      "R2 Score: 0.9626427904084391\n",
      "\n",
      "Iteration 53/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.89745 | mse_mse: 1.67217 |  0:00:04s\n",
      "epoch 1  | loss: 0.58568 | mse_mse: 0.75569 |  0:00:09s\n",
      "epoch 2  | loss: 0.4409  | mse_mse: 0.59757 |  0:00:15s\n",
      "epoch 3  | loss: 0.50825 | mse_mse: 0.40527 |  0:00:19s\n",
      "epoch 4  | loss: 0.51083 | mse_mse: 0.30656 |  0:00:24s\n",
      "epoch 5  | loss: 0.24693 | mse_mse: 0.37457 |  0:00:29s\n",
      "epoch 6  | loss: 0.2626  | mse_mse: 0.20615 |  0:00:34s\n",
      "epoch 7  | loss: 0.25417 | mse_mse: 0.27554 |  0:00:39s\n",
      "epoch 8  | loss: 0.22617 | mse_mse: 0.19951 |  0:00:44s\n",
      "epoch 9  | loss: 0.22147 | mse_mse: 0.1972  |  0:00:49s\n",
      "epoch 10 | loss: 0.21741 | mse_mse: 0.19483 |  0:00:54s\n",
      "epoch 11 | loss: 0.22113 | mse_mse: 0.19445 |  0:00:59s\n",
      "epoch 12 | loss: 0.21651 | mse_mse: 0.20087 |  0:01:04s\n",
      "epoch 13 | loss: 0.21089 | mse_mse: 0.21538 |  0:01:09s\n",
      "epoch 14 | loss: 0.23859 | mse_mse: 0.23905 |  0:01:14s\n",
      "epoch 15 | loss: 0.21193 | mse_mse: 0.19396 |  0:01:19s\n",
      "epoch 16 | loss: 0.20474 | mse_mse: 0.18969 |  0:01:24s\n",
      "epoch 17 | loss: 0.19664 | mse_mse: 0.19913 |  0:01:29s\n",
      "epoch 18 | loss: 0.19757 | mse_mse: 0.18246 |  0:01:34s\n",
      "epoch 19 | loss: 0.2024  | mse_mse: 0.17927 |  0:01:39s\n",
      "epoch 20 | loss: 0.19202 | mse_mse: 0.17092 |  0:01:45s\n",
      "epoch 21 | loss: 0.1754  | mse_mse: 0.15826 |  0:01:50s\n",
      "epoch 22 | loss: 0.15657 | mse_mse: 0.15079 |  0:01:55s\n",
      "epoch 23 | loss: 0.1573  | mse_mse: 0.1294  |  0:02:00s\n",
      "epoch 24 | loss: 0.12952 | mse_mse: 0.11562 |  0:02:05s\n",
      "epoch 25 | loss: 0.12674 | mse_mse: 0.10148 |  0:02:10s\n",
      "epoch 26 | loss: 0.10779 | mse_mse: 0.11884 |  0:02:15s\n",
      "epoch 27 | loss: 0.10584 | mse_mse: 0.09156 |  0:02:20s\n",
      "epoch 28 | loss: 0.09984 | mse_mse: 0.09502 |  0:02:25s\n",
      "epoch 29 | loss: 0.09985 | mse_mse: 0.08865 |  0:02:30s\n",
      "epoch 30 | loss: 0.10029 | mse_mse: 0.0834  |  0:02:36s\n",
      "epoch 31 | loss: 0.08253 | mse_mse: 0.07157 |  0:02:41s\n",
      "epoch 32 | loss: 0.07412 | mse_mse: 0.06771 |  0:02:46s\n",
      "epoch 33 | loss: 0.07149 | mse_mse: 0.06753 |  0:02:51s\n",
      "epoch 34 | loss: 0.07246 | mse_mse: 0.07269 |  0:02:56s\n",
      "epoch 35 | loss: 0.06279 | mse_mse: 0.07889 |  0:03:01s\n",
      "epoch 36 | loss: 0.05901 | mse_mse: 0.0539  |  0:03:06s\n",
      "epoch 37 | loss: 0.06104 | mse_mse: 0.07848 |  0:03:11s\n",
      "epoch 38 | loss: 0.05428 | mse_mse: 0.043   |  0:03:16s\n",
      "epoch 39 | loss: 0.04755 | mse_mse: 0.03852 |  0:03:21s\n",
      "epoch 40 | loss: 0.04873 | mse_mse: 0.04359 |  0:03:26s\n",
      "epoch 41 | loss: 0.04542 | mse_mse: 0.04164 |  0:03:31s\n",
      "epoch 42 | loss: 0.04194 | mse_mse: 0.04983 |  0:03:36s\n",
      "epoch 43 | loss: 0.04079 | mse_mse: 0.03507 |  0:03:41s\n",
      "epoch 44 | loss: 0.03734 | mse_mse: 0.04399 |  0:03:46s\n",
      "epoch 45 | loss: 0.04051 | mse_mse: 0.03297 |  0:03:51s\n",
      "epoch 46 | loss: 0.0394  | mse_mse: 0.02991 |  0:03:56s\n",
      "epoch 47 | loss: 0.034   | mse_mse: 0.0342  |  0:04:01s\n",
      "epoch 48 | loss: 0.03211 | mse_mse: 0.03065 |  0:04:06s\n",
      "epoch 49 | loss: 0.03306 | mse_mse: 0.02673 |  0:04:11s\n",
      "epoch 50 | loss: 0.03461 | mse_mse: 0.0281  |  0:04:16s\n",
      "epoch 51 | loss: 0.03408 | mse_mse: 0.02797 |  0:04:21s\n",
      "epoch 52 | loss: 0.02908 | mse_mse: 0.02617 |  0:04:26s\n",
      "epoch 53 | loss: 0.03299 | mse_mse: 0.02115 |  0:04:31s\n",
      "epoch 54 | loss: 0.02534 | mse_mse: 0.02954 |  0:04:36s\n",
      "epoch 55 | loss: 0.02506 | mse_mse: 0.01775 |  0:04:41s\n",
      "epoch 56 | loss: 0.02375 | mse_mse: 0.03558 |  0:04:47s\n",
      "epoch 57 | loss: 0.02183 | mse_mse: 0.025   |  0:04:52s\n",
      "epoch 58 | loss: 0.01909 | mse_mse: 0.01639 |  0:04:57s\n",
      "epoch 59 | loss: 0.02117 | mse_mse: 0.04372 |  0:05:02s\n",
      "epoch 60 | loss: 0.0274  | mse_mse: 0.02104 |  0:05:07s\n",
      "epoch 61 | loss: 0.02676 | mse_mse: 0.02311 |  0:05:12s\n",
      "epoch 62 | loss: 0.01903 | mse_mse: 0.01526 |  0:05:17s\n",
      "epoch 63 | loss: 0.02072 | mse_mse: 0.01878 |  0:05:22s\n",
      "epoch 64 | loss: 0.02458 | mse_mse: 0.03795 |  0:05:27s\n",
      "epoch 65 | loss: 0.0256  | mse_mse: 0.03836 |  0:05:32s\n",
      "epoch 66 | loss: 0.02014 | mse_mse: 0.04344 |  0:05:37s\n",
      "epoch 67 | loss: 0.02182 | mse_mse: 0.01973 |  0:05:42s\n",
      "epoch 68 | loss: 0.01964 | mse_mse: 0.01387 |  0:05:47s\n",
      "epoch 69 | loss: 0.02045 | mse_mse: 0.01487 |  0:05:52s\n",
      "epoch 70 | loss: 0.02079 | mse_mse: 0.01551 |  0:05:57s\n",
      "epoch 71 | loss: 0.01747 | mse_mse: 0.01664 |  0:06:02s\n",
      "epoch 72 | loss: 0.01869 | mse_mse: 0.01395 |  0:06:07s\n",
      "epoch 73 | loss: 0.01854 | mse_mse: 0.02401 |  0:06:12s\n",
      "epoch 74 | loss: 0.01565 | mse_mse: 0.01068 |  0:06:17s\n",
      "epoch 75 | loss: 0.01438 | mse_mse: 0.01173 |  0:06:23s\n",
      "epoch 76 | loss: 0.01428 | mse_mse: 0.01422 |  0:06:28s\n",
      "epoch 77 | loss: 0.01619 | mse_mse: 0.01231 |  0:06:34s\n",
      "epoch 78 | loss: 0.01288 | mse_mse: 0.00811 |  0:06:39s\n",
      "epoch 79 | loss: 0.01353 | mse_mse: 0.00872 |  0:06:44s\n",
      "epoch 80 | loss: 0.0118  | mse_mse: 0.01812 |  0:06:49s\n",
      "epoch 81 | loss: 0.01446 | mse_mse: 0.01053 |  0:06:55s\n",
      "epoch 82 | loss: 0.01565 | mse_mse: 0.0143  |  0:07:00s\n",
      "epoch 83 | loss: 0.01129 | mse_mse: 0.00853 |  0:07:05s\n",
      "epoch 84 | loss: 0.01117 | mse_mse: 0.00811 |  0:07:10s\n",
      "epoch 85 | loss: 0.01362 | mse_mse: 0.02333 |  0:07:15s\n",
      "epoch 86 | loss: 0.01588 | mse_mse: 0.01734 |  0:07:20s\n",
      "epoch 87 | loss: 0.01559 | mse_mse: 0.01494 |  0:07:25s\n",
      "epoch 88 | loss: 0.01236 | mse_mse: 0.00825 |  0:07:30s\n",
      "epoch 89 | loss: 0.00941 | mse_mse: 0.01649 |  0:07:35s\n",
      "epoch 90 | loss: 0.012   | mse_mse: 0.01121 |  0:07:40s\n",
      "epoch 91 | loss: 0.02261 | mse_mse: 0.02193 |  0:07:45s\n",
      "epoch 92 | loss: 0.02202 | mse_mse: 0.01485 |  0:07:50s\n",
      "epoch 93 | loss: 0.01703 | mse_mse: 0.01699 |  0:07:55s\n",
      "epoch 94 | loss: 0.0157  | mse_mse: 0.014   |  0:08:01s\n",
      "\n",
      "Early stopping occurred at epoch 94 with best_epoch = 84 and best_mse_mse = 0.00811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008578732406097639\n",
      "R2 Score: 0.961298851525238\n",
      "\n",
      "Iteration 54/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.67803 | mse_mse: 1.3701  |  0:00:05s\n",
      "epoch 1  | loss: 1.01698 | mse_mse: 0.68618 |  0:00:10s\n",
      "epoch 2  | loss: 0.44295 | mse_mse: 0.40575 |  0:00:16s\n",
      "epoch 3  | loss: 0.42806 | mse_mse: 0.513   |  0:00:21s\n",
      "epoch 4  | loss: 0.27217 | mse_mse: 0.58956 |  0:00:27s\n",
      "epoch 5  | loss: 0.27568 | mse_mse: 0.26442 |  0:00:32s\n",
      "epoch 6  | loss: 0.24842 | mse_mse: 0.22992 |  0:00:37s\n",
      "epoch 7  | loss: 0.25071 | mse_mse: 0.24684 |  0:00:43s\n",
      "epoch 8  | loss: 0.24663 | mse_mse: 0.255   |  0:00:48s\n",
      "epoch 9  | loss: 0.24942 | mse_mse: 0.24417 |  0:00:53s\n",
      "epoch 10 | loss: 0.24433 | mse_mse: 0.22656 |  0:00:59s\n",
      "epoch 11 | loss: 0.24142 | mse_mse: 0.23637 |  0:01:04s\n",
      "epoch 12 | loss: 0.24151 | mse_mse: 0.24534 |  0:01:10s\n",
      "epoch 13 | loss: 0.23701 | mse_mse: 0.21686 |  0:01:15s\n",
      "epoch 14 | loss: 0.2349  | mse_mse: 0.21894 |  0:01:20s\n",
      "epoch 15 | loss: 0.22878 | mse_mse: 0.21198 |  0:01:26s\n",
      "epoch 16 | loss: 0.22307 | mse_mse: 0.21177 |  0:01:31s\n",
      "epoch 17 | loss: 0.22658 | mse_mse: 0.2177  |  0:01:37s\n",
      "epoch 18 | loss: 0.22028 | mse_mse: 0.20049 |  0:01:42s\n",
      "epoch 19 | loss: 0.20741 | mse_mse: 0.1855  |  0:01:47s\n",
      "epoch 20 | loss: 0.18916 | mse_mse: 0.1589  |  0:01:53s\n",
      "epoch 21 | loss: 0.16956 | mse_mse: 0.14832 |  0:01:58s\n",
      "epoch 22 | loss: 0.16773 | mse_mse: 0.13984 |  0:02:04s\n",
      "epoch 23 | loss: 0.14507 | mse_mse: 0.12207 |  0:02:09s\n",
      "epoch 24 | loss: 0.12725 | mse_mse: 0.1109  |  0:02:15s\n",
      "epoch 25 | loss: 0.11791 | mse_mse: 0.10531 |  0:02:20s\n",
      "epoch 26 | loss: 0.1008  | mse_mse: 0.08802 |  0:02:26s\n",
      "epoch 27 | loss: 0.09195 | mse_mse: 0.07578 |  0:02:31s\n",
      "epoch 28 | loss: 0.07871 | mse_mse: 0.06727 |  0:02:37s\n",
      "epoch 29 | loss: 0.07558 | mse_mse: 0.05984 |  0:02:42s\n",
      "epoch 30 | loss: 0.05983 | mse_mse: 0.05755 |  0:02:48s\n",
      "epoch 31 | loss: 0.05299 | mse_mse: 0.04713 |  0:02:53s\n",
      "epoch 32 | loss: 0.04784 | mse_mse: 0.04352 |  0:02:59s\n",
      "epoch 33 | loss: 0.0451  | mse_mse: 0.04255 |  0:03:04s\n",
      "epoch 34 | loss: 0.04715 | mse_mse: 0.03817 |  0:03:10s\n",
      "epoch 35 | loss: 0.04023 | mse_mse: 0.03342 |  0:03:15s\n",
      "epoch 36 | loss: 0.03306 | mse_mse: 0.03524 |  0:03:21s\n",
      "epoch 37 | loss: 0.03161 | mse_mse: 0.03086 |  0:03:26s\n",
      "epoch 38 | loss: 0.03237 | mse_mse: 0.04183 |  0:03:32s\n",
      "epoch 39 | loss: 0.02962 | mse_mse: 0.03576 |  0:03:37s\n",
      "epoch 40 | loss: 0.03506 | mse_mse: 0.03519 |  0:03:43s\n",
      "epoch 41 | loss: 0.0292  | mse_mse: 0.02519 |  0:03:48s\n",
      "epoch 42 | loss: 0.026   | mse_mse: 0.02232 |  0:03:54s\n",
      "epoch 43 | loss: 0.02543 | mse_mse: 0.03598 |  0:03:59s\n",
      "epoch 44 | loss: 0.022   | mse_mse: 0.02003 |  0:04:05s\n",
      "epoch 45 | loss: 0.02592 | mse_mse: 0.01793 |  0:04:10s\n",
      "epoch 46 | loss: 0.02554 | mse_mse: 0.03185 |  0:04:16s\n",
      "epoch 47 | loss: 0.02897 | mse_mse: 0.02518 |  0:04:21s\n",
      "epoch 48 | loss: 0.02322 | mse_mse: 0.01927 |  0:04:27s\n",
      "epoch 49 | loss: 0.01959 | mse_mse: 0.02864 |  0:04:32s\n",
      "epoch 50 | loss: 0.02181 | mse_mse: 0.02985 |  0:04:38s\n",
      "epoch 51 | loss: 0.02124 | mse_mse: 0.01915 |  0:04:43s\n",
      "epoch 52 | loss: 0.01622 | mse_mse: 0.02101 |  0:04:49s\n",
      "epoch 53 | loss: 0.01805 | mse_mse: 0.01542 |  0:04:54s\n",
      "epoch 54 | loss: 0.02768 | mse_mse: 0.02515 |  0:05:00s\n",
      "epoch 55 | loss: 0.02466 | mse_mse: 0.01884 |  0:05:05s\n",
      "epoch 56 | loss: 0.02006 | mse_mse: 0.0152  |  0:05:11s\n",
      "epoch 57 | loss: 0.01821 | mse_mse: 0.01474 |  0:05:16s\n",
      "epoch 58 | loss: 0.01682 | mse_mse: 0.03487 |  0:05:22s\n",
      "epoch 59 | loss: 0.01657 | mse_mse: 0.0172  |  0:05:27s\n",
      "epoch 60 | loss: 0.01415 | mse_mse: 0.0132  |  0:05:33s\n",
      "epoch 61 | loss: 0.02311 | mse_mse: 0.01558 |  0:05:38s\n",
      "epoch 62 | loss: 0.0156  | mse_mse: 0.01219 |  0:05:44s\n",
      "epoch 63 | loss: 0.01426 | mse_mse: 0.01675 |  0:05:49s\n",
      "epoch 64 | loss: 0.01595 | mse_mse: 0.02034 |  0:05:55s\n",
      "epoch 65 | loss: 0.01648 | mse_mse: 0.01031 |  0:06:00s\n",
      "epoch 66 | loss: 0.02469 | mse_mse: 0.02194 |  0:06:06s\n",
      "epoch 67 | loss: 0.01691 | mse_mse: 0.01174 |  0:06:11s\n",
      "epoch 68 | loss: 0.01174 | mse_mse: 0.01463 |  0:06:17s\n",
      "epoch 69 | loss: 0.01414 | mse_mse: 0.01822 |  0:06:22s\n",
      "epoch 70 | loss: 0.01456 | mse_mse: 0.01473 |  0:06:27s\n",
      "epoch 71 | loss: 0.01673 | mse_mse: 0.01055 |  0:06:33s\n",
      "epoch 72 | loss: 0.01748 | mse_mse: 0.03362 |  0:06:38s\n",
      "epoch 73 | loss: 0.01956 | mse_mse: 0.011   |  0:06:44s\n",
      "epoch 74 | loss: 0.01103 | mse_mse: 0.01989 |  0:06:49s\n",
      "epoch 75 | loss: 0.01454 | mse_mse: 0.01363 |  0:06:55s\n",
      "\n",
      "Early stopping occurred at epoch 75 with best_epoch = 65 and best_mse_mse = 0.01031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010589293649987022\n",
      "R2 Score: 0.9522286269822673\n"
     ]
    }
   ],
   "source": [
    "best_mse = float('inf')\n",
    "best_model = None\n",
    "best_params = None\n",
    "iter = 0\n",
    "for b, n_e, n_d, n_a, n_s, n_i in params:\n",
    "    iter += 1\n",
    "    print(f'\\nIteration {iter}/{comb}')\n",
    "    print(f\"Configuration batch size: {b} - epochs: {n_e} - n_d: {n_d} - n_a: {n_a} - steps: {n_s} - n_indipendent: {n_i}\")\n",
    "    \n",
    "    model = get_model(b, n_e, n_d, n_a, n_s, n_i)\n",
    "    #save results for each iteration with tensorboard\n",
    "    log = f'bach_size_{b}_nEpochs_{n_e}_nd_{n_d}_na_{n_a}_nSteps_{n_s}_nIndipendent_{n_i}'\n",
    "\n",
    "    if pca_t == True:\n",
    "        if os.path.exists(\"./tabpca/\"+log):\n",
    "            print(\"Model already trained. Skipping...\")\n",
    "            continue\n",
    "        writer = SummaryWriter(f'tab_pca/bach_size_{b}_nEpochs_{n_e}_nd_{n_d}_na_{n_a}_nSteps_{n_s}_nIndipendent_{n_i}')\n",
    "    else:\n",
    "        if os.path.exists(\"./tab_no_pca/\"+log):\n",
    "            print(\"Model already trained. Skipping...\")\n",
    "            continue\n",
    "        writer = SummaryWriter(f'tab_no_pca/bach_size_{b}_nEpochs_{n_e}_nd_{n_d}_na_{n_a}_nSteps_{n_s}_nIndipendent_{n_i}')\n",
    "\n",
    "    #fit model\n",
    "    model.fit(\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_name=['mse'],\n",
    "        patience=10,\n",
    "        batch_size=b\n",
    "    )\n",
    "\n",
    "    # evaluate model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "   #save hparams for each iteration with tensorboard\n",
    "    writer.add_hparams(\n",
    "        {'batch_size': b, 'n_epochs': n_e, 'n_d': n_d, 'n_a': n_a, 'n_steps': n_s, 'n_indipendent': n_i},\n",
    "        {'hparam/mse': mse, 'hparam/r2': r2}\n",
    "    )\n",
    "\n",
    "    \n",
    "    print('MSE:', mse)\n",
    "    print('R2 Score:', r2)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_params = (b, n_e, n_d, n_a, n_s, n_i)\n",
    "        print('Best model updated')\n",
    "    writer.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabNetRegressor(n_d=8, n_a=16, n_steps=3, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=1, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=552, output_dim=1, device_name='auto', n_shared_decoder=1, n_indep_decoder=1)\n",
      "Best MSE:  0.006645834471059633\n",
      "R2 score 0.9700187143708603\n"
     ]
    }
   ],
   "source": [
    "#pint the best model\n",
    "print(best_model)\n",
    "print(\"Best MSE: \", best_mse)\n",
    "print(\"R2 score\", r2_score(y_test, best_model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at best_model_tabnet_pca_256.csv.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'best_model_tabnet_pca_256.csv.zip'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the best model in a file csv\n",
    "best_model.save_model('best_model_tabnet_pca_256.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
