{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from itertools import product\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "df = pd.read_csv('dataset-ml-25m/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train set:  10362\n",
      "Numebr of test set:  3454\n"
     ]
    }
   ],
   "source": [
    "#split data and labels \n",
    "X = df.drop(['rating'], axis=1)\n",
    "y = df['rating']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "#count the numebr of x_train \n",
    "print(\"Number of train set: \", X_train.shape[0])\n",
    "print(\"Numebr of test set: \", X_test.shape[0])\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot dataset after PCA\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_name = f\"linear_regression\"\n",
    "writer = SummaryWriter(f\"results/tradML/pca/LinearRegression/{log_name}\")\n",
    "\n",
    "lin_regr = linear_model.LinearRegression()\n",
    "lin_regr.fit(X_train, y_train)\n",
    "y_pred = lin_regr.predict(X_test)\n",
    "\n",
    "# Compute the RSS\n",
    "mse = mean_squared_error(y_test, y_pred) \n",
    "print('Mean Square Error:', mse)\n",
    "writer.add_scalar('Loss', mse)\n",
    "writer.flush()\n",
    "\n",
    "# Compute the R-square index\n",
    "rsquare = r2_score(y_test, y_pred) \n",
    "print('R-square:', rsquare)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso regression\n",
    "import copy\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "alpha = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "\n",
    "best_mse = float('inf')\n",
    "best_a = None\n",
    "best_lasso = None\n",
    "\n",
    "i = 0\n",
    "max_iter = len(alpha)\n",
    "\n",
    "for a in alpha:\n",
    "    i += 1\n",
    "    log_name = f\"alpha\"\n",
    "    writer = SummaryWriter(f\"results/tradML/pca/Lasso/{log_name}\")\n",
    "\n",
    "    lasso = Lasso(alpha=a)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    y_pred = lasso.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred) \n",
    "\n",
    "    writer.add_scalar('Loss', mse, a)\n",
    "    writer.add_hparams(\n",
    "        {'alpha': a},\n",
    "        {'mse': mse}\n",
    "    )\n",
    "\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_a = a\n",
    "        lasso_best = copy.deepcopy(lasso)\n",
    "\n",
    "    print(\"Iteration: {}/{} - Alpha: {} - MSE: {:.4f} - Best MSE: {:.4f}\".format(i, max_iter, a, mse, best_mse), end='\\r')\n",
    "\n",
    "y_pred = lasso_best.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nHyperparameter Tuning\")\n",
    "print(\"Alpha: \", best_a)\n",
    "print(\"MSE: \", best_mse)\n",
    "print(\"R2: \", r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "kernel = ['linear', 'poly', 'rbf']\n",
    "c = [0.001, 0.01, 0.1, 1]\n",
    "epsilon = [0.001, 0.01, 0.1, 1]\n",
    "\n",
    "best_mse = float('inf')\n",
    "best_kernel = None\n",
    "best_c = None\n",
    "best_epsilon = None\n",
    "best_svr = None\n",
    "\n",
    "i = 0\n",
    "max_iter = len(kernel) * len(c) * len(epsilon)\n",
    "\n",
    "for k, c, e in product(kernel, c, epsilon):\n",
    "    i+=1\n",
    "    log_name = f\"kernel={k}, c={c}, epsilon={e}\"\n",
    "    writer = SummaryWriter(f\"results/tradML/pca/SVR/{log_name}\")\n",
    "\n",
    "    svr = SVR(kernel=k, C=c, epsilon=e)\n",
    "    svr.fit(X_train, y_train)\n",
    "    y_pred = svr.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    writer.add_scalar('Loss', mse)\n",
    "    writer.add_hparams(\n",
    "        {'kernel': k, 'C': c, 'epsilon': e},\n",
    "        {'mse': mse}\n",
    "    )\n",
    "    \n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_kernel = k\n",
    "        best_c = c\n",
    "        best_epsilon = e\n",
    "        svr_best = copy.deepcopy(svr)\n",
    "\n",
    "    print(\"Iteration: {}/{} - Kernel: {} - C: {} - Epsilon: {} - MSE: {:.4f} - Best MSE: {:.4f}\".format(i, max_iter, k, c, e, mse, best_mse), end='\\r')\n",
    "\n",
    "y_pred = svr_best.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nHyperparameter Tuning\")\n",
    "print(\"Kernel: \", best_kernel)\n",
    "print(\"C: \", best_c)\n",
    "print(\"Epsilon: \", best_epsilon)\n",
    "print(\"MSE: \", best_mse)\n",
    "print(\"R2: \", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(max_depth= 10)\n",
    "dt= dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  0.020054903976457348\n",
      "R2 Score:  0.9157019426735893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred= dt.predict(X_train)\n",
    "print(\"Mean Squared Error: \", mean_squared_error(y_train, y_pred))\n",
    "print (\"R2 Score: \", r2_score(y_train, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
