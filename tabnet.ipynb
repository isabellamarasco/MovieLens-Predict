{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import product\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def fix_random(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "fix_random(42)\n",
    "\n",
    "pca_t = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "df = pd.read_csv('dataset-ml-25m/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train set:  9946\n",
      "Numebr of test set:  2764\n",
      "Number of validation set:  1106\n"
     ]
    }
   ],
   "source": [
    "# Dividi il dataset in feature e target\n",
    "X = df.drop(['rating'], axis=1).to_numpy()\n",
    "y = df['rating'].to_numpy()\n",
    "\n",
    "# Dividi il dataset in training, validation e test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1, random_state=42)\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "#count the numebr of x_train \n",
    "print(\"Number of train set: \", X_train.shape[0])\n",
    "print(\"Numebr of test set: \", X_test.shape[0])\n",
    "print(\"Number of validation set: \", X_val.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA is not applied\n"
     ]
    }
   ],
   "source": [
    "# Applica la riduzione della dimensionalit√† con PCA\n",
    "if pca_t == True:\n",
    "    pca = PCA(n_components=0.95)\n",
    "    pca.fit(X_train)\n",
    "    X_train = pca.transform(X_train)\n",
    "    X_val = pca.transform(X_val)\n",
    "    X_test = pca.transform(X_test)\n",
    "else:\n",
    "    print (\"PCA is not applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations:  54\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [256]\n",
    "n_epochs = [200]\n",
    "# Dimension of the prediction  layer\n",
    "n_d = [8, 16, 32]\n",
    "#Dimension of the attention  layer\n",
    "n_a = [8, 16, 32]\n",
    "#Number of successive steps in the network\n",
    "n_steps = [3, 5, 7]\n",
    "# Number of independent GLU layer in each GLU block\n",
    "n_indipendent = [2, 3]\n",
    "\n",
    "params = list(product(batch_sizes, n_epochs, n_d, n_a, n_steps, n_indipendent))\n",
    "comb = len(batch_sizes)*len(n_d)*len(n_a) *len(n_steps) *len(n_indipendent)\n",
    "print(\"Number of combinations: \", comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_d, n_a, n_steps, n_indipendent):\n",
    "    model = TabNetRegressor(\n",
    "        n_d=n_d,\n",
    "        n_a=n_a,\n",
    "        n_steps=n_steps,\n",
    "        n_independent=n_indipendent\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.4039  | mse_mse: 0.69878 |  0:00:02s\n",
      "epoch 1  | loss: 0.17248 | mse_mse: 0.25698 |  0:00:05s\n",
      "epoch 2  | loss: 0.09203 | mse_mse: 0.15026 |  0:00:08s\n",
      "epoch 3  | loss: 0.08277 | mse_mse: 0.16298 |  0:00:11s\n",
      "epoch 4  | loss: 0.07352 | mse_mse: 0.12721 |  0:00:14s\n",
      "epoch 5  | loss: 0.06916 | mse_mse: 0.10039 |  0:00:17s\n",
      "epoch 6  | loss: 0.06224 | mse_mse: 0.10151 |  0:00:20s\n",
      "epoch 7  | loss: 0.06907 | mse_mse: 0.09728 |  0:00:23s\n",
      "epoch 8  | loss: 0.05664 | mse_mse: 0.06888 |  0:00:27s\n",
      "epoch 9  | loss: 0.05378 | mse_mse: 0.06184 |  0:00:30s\n",
      "epoch 10 | loss: 0.04512 | mse_mse: 0.05265 |  0:00:33s\n",
      "epoch 11 | loss: 0.04459 | mse_mse: 0.05764 |  0:00:36s\n",
      "epoch 12 | loss: 0.04484 | mse_mse: 0.03851 |  0:00:39s\n",
      "epoch 13 | loss: 0.03895 | mse_mse: 0.04361 |  0:00:42s\n",
      "epoch 14 | loss: 0.04081 | mse_mse: 0.03167 |  0:00:45s\n",
      "epoch 15 | loss: 0.0333  | mse_mse: 0.03246 |  0:00:47s\n",
      "epoch 16 | loss: 0.03019 | mse_mse: 0.02912 |  0:00:50s\n",
      "epoch 17 | loss: 0.03134 | mse_mse: 0.02424 |  0:00:54s\n",
      "epoch 18 | loss: 0.0274  | mse_mse: 0.02248 |  0:00:56s\n",
      "epoch 19 | loss: 0.02966 | mse_mse: 0.02547 |  0:00:59s\n",
      "epoch 20 | loss: 0.02456 | mse_mse: 0.02002 |  0:01:03s\n",
      "epoch 21 | loss: 0.02579 | mse_mse: 0.01618 |  0:01:06s\n",
      "epoch 22 | loss: 0.02069 | mse_mse: 0.01345 |  0:01:09s\n",
      "epoch 23 | loss: 0.02344 | mse_mse: 0.02063 |  0:01:12s\n",
      "epoch 24 | loss: 0.01888 | mse_mse: 0.01327 |  0:01:15s\n",
      "epoch 25 | loss: 0.02035 | mse_mse: 0.01161 |  0:01:18s\n",
      "epoch 26 | loss: 0.01613 | mse_mse: 0.01219 |  0:01:21s\n",
      "epoch 27 | loss: 0.01863 | mse_mse: 0.01035 |  0:01:24s\n",
      "epoch 28 | loss: 0.01457 | mse_mse: 0.00854 |  0:01:27s\n",
      "epoch 29 | loss: 0.01538 | mse_mse: 0.01589 |  0:01:30s\n",
      "epoch 30 | loss: 0.01511 | mse_mse: 0.00793 |  0:01:32s\n",
      "epoch 31 | loss: 0.01286 | mse_mse: 0.00889 |  0:01:35s\n",
      "epoch 32 | loss: 0.0125  | mse_mse: 0.00806 |  0:01:38s\n",
      "epoch 33 | loss: 0.01377 | mse_mse: 0.00809 |  0:01:40s\n",
      "epoch 34 | loss: 0.01305 | mse_mse: 0.01481 |  0:01:43s\n",
      "epoch 35 | loss: 0.01327 | mse_mse: 0.00946 |  0:01:46s\n",
      "epoch 36 | loss: 0.01519 | mse_mse: 0.00792 |  0:01:50s\n",
      "epoch 37 | loss: 0.01324 | mse_mse: 0.00745 |  0:01:53s\n",
      "epoch 38 | loss: 0.01294 | mse_mse: 0.00842 |  0:01:55s\n",
      "epoch 39 | loss: 0.01028 | mse_mse: 0.00855 |  0:01:58s\n",
      "epoch 40 | loss: 0.01086 | mse_mse: 0.0077  |  0:02:01s\n",
      "epoch 41 | loss: 0.01175 | mse_mse: 0.00917 |  0:02:04s\n",
      "epoch 42 | loss: 0.01236 | mse_mse: 0.01146 |  0:02:07s\n",
      "epoch 43 | loss: 0.01344 | mse_mse: 0.02389 |  0:02:09s\n",
      "epoch 44 | loss: 0.01187 | mse_mse: 0.00818 |  0:02:12s\n",
      "epoch 45 | loss: 0.01105 | mse_mse: 0.00745 |  0:02:15s\n",
      "epoch 46 | loss: 0.01148 | mse_mse: 0.0083  |  0:02:18s\n",
      "epoch 47 | loss: 0.01078 | mse_mse: 0.01396 |  0:02:21s\n",
      "epoch 48 | loss: 0.01017 | mse_mse: 0.00724 |  0:02:24s\n",
      "epoch 49 | loss: 0.00909 | mse_mse: 0.00712 |  0:02:27s\n",
      "epoch 50 | loss: 0.00927 | mse_mse: 0.00794 |  0:02:29s\n",
      "epoch 51 | loss: 0.00945 | mse_mse: 0.0058  |  0:02:32s\n",
      "epoch 52 | loss: 0.00793 | mse_mse: 0.00611 |  0:02:35s\n",
      "epoch 53 | loss: 0.00858 | mse_mse: 0.00711 |  0:02:38s\n",
      "epoch 54 | loss: 0.0136  | mse_mse: 0.00628 |  0:02:41s\n",
      "epoch 55 | loss: 0.01041 | mse_mse: 0.00585 |  0:02:43s\n",
      "epoch 56 | loss: 0.00878 | mse_mse: 0.0058  |  0:02:46s\n",
      "epoch 57 | loss: 0.00812 | mse_mse: 0.00713 |  0:02:49s\n",
      "epoch 58 | loss: 0.01    | mse_mse: 0.00524 |  0:02:52s\n",
      "epoch 59 | loss: 0.00844 | mse_mse: 0.00665 |  0:02:55s\n",
      "epoch 60 | loss: 0.0097  | mse_mse: 0.00579 |  0:02:57s\n",
      "epoch 61 | loss: 0.00998 | mse_mse: 0.00892 |  0:03:00s\n",
      "epoch 62 | loss: 0.01247 | mse_mse: 0.00701 |  0:03:03s\n",
      "epoch 63 | loss: 0.01014 | mse_mse: 0.01158 |  0:03:06s\n",
      "epoch 64 | loss: 0.00924 | mse_mse: 0.0079  |  0:03:09s\n",
      "epoch 65 | loss: 0.0091  | mse_mse: 0.00978 |  0:03:12s\n",
      "epoch 66 | loss: 0.00782 | mse_mse: 0.00657 |  0:03:15s\n",
      "epoch 67 | loss: 0.00882 | mse_mse: 0.00842 |  0:03:18s\n",
      "epoch 68 | loss: 0.01534 | mse_mse: 0.00537 |  0:03:21s\n",
      "\n",
      "Early stopping occurred at epoch 68 with best_epoch = 58 and best_mse_mse = 0.00524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.005526278937905899\n",
      "R2 Score: 0.9750693538899957\n",
      "Best model updated\n",
      "\n",
      "Iteration 2/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.3238  | mse_mse: 0.57706 |  0:00:02s\n",
      "epoch 1  | loss: 0.16757 | mse_mse: 0.52904 |  0:00:05s\n",
      "epoch 2  | loss: 0.10265 | mse_mse: 0.15376 |  0:00:08s\n",
      "epoch 3  | loss: 0.07497 | mse_mse: 0.13216 |  0:00:10s\n",
      "epoch 4  | loss: 0.06532 | mse_mse: 0.1197  |  0:00:13s\n",
      "epoch 5  | loss: 0.05518 | mse_mse: 0.09137 |  0:00:16s\n",
      "epoch 6  | loss: 0.05117 | mse_mse: 0.0813  |  0:00:18s\n",
      "epoch 7  | loss: 0.04811 | mse_mse: 0.06773 |  0:00:21s\n",
      "epoch 8  | loss: 0.04495 | mse_mse: 0.05773 |  0:00:23s\n",
      "epoch 9  | loss: 0.05148 | mse_mse: 0.05802 |  0:00:26s\n",
      "epoch 10 | loss: 0.04486 | mse_mse: 0.04503 |  0:00:29s\n",
      "epoch 11 | loss: 0.051   | mse_mse: 0.05554 |  0:00:31s\n",
      "epoch 12 | loss: 0.04343 | mse_mse: 0.03532 |  0:00:34s\n",
      "epoch 13 | loss: 0.03648 | mse_mse: 0.03402 |  0:00:37s\n",
      "epoch 14 | loss: 0.04014 | mse_mse: 0.02898 |  0:00:40s\n",
      "epoch 15 | loss: 0.03585 | mse_mse: 0.03112 |  0:00:42s\n",
      "epoch 16 | loss: 0.03585 | mse_mse: 0.02804 |  0:00:45s\n",
      "epoch 17 | loss: 0.03538 | mse_mse: 0.0336  |  0:00:48s\n",
      "epoch 18 | loss: 0.03538 | mse_mse: 0.02636 |  0:00:50s\n",
      "epoch 19 | loss: 0.03349 | mse_mse: 0.02978 |  0:00:53s\n",
      "epoch 20 | loss: 0.03601 | mse_mse: 0.02215 |  0:00:56s\n",
      "epoch 21 | loss: 0.02885 | mse_mse: 0.02201 |  0:00:58s\n",
      "epoch 22 | loss: 0.02441 | mse_mse: 0.02093 |  0:01:01s\n",
      "epoch 23 | loss: 0.02381 | mse_mse: 0.01841 |  0:01:04s\n",
      "epoch 24 | loss: 0.02294 | mse_mse: 0.01972 |  0:01:06s\n",
      "epoch 25 | loss: 0.02347 | mse_mse: 0.02072 |  0:01:09s\n",
      "epoch 26 | loss: 0.02087 | mse_mse: 0.0174  |  0:01:12s\n",
      "epoch 27 | loss: 0.02027 | mse_mse: 0.02592 |  0:01:15s\n",
      "epoch 28 | loss: 0.02641 | mse_mse: 0.0233  |  0:01:17s\n",
      "epoch 29 | loss: 0.02021 | mse_mse: 0.02049 |  0:01:20s\n",
      "epoch 30 | loss: 0.01766 | mse_mse: 0.01235 |  0:01:23s\n",
      "epoch 31 | loss: 0.01605 | mse_mse: 0.01367 |  0:01:25s\n",
      "epoch 32 | loss: 0.01775 | mse_mse: 0.01198 |  0:01:28s\n",
      "epoch 33 | loss: 0.0157  | mse_mse: 0.01389 |  0:01:31s\n",
      "epoch 34 | loss: 0.01826 | mse_mse: 0.01156 |  0:01:33s\n",
      "epoch 35 | loss: 0.01579 | mse_mse: 0.00994 |  0:01:36s\n",
      "epoch 36 | loss: 0.01518 | mse_mse: 0.01151 |  0:01:39s\n",
      "epoch 37 | loss: 0.01489 | mse_mse: 0.01181 |  0:01:41s\n",
      "epoch 38 | loss: 0.01539 | mse_mse: 0.00996 |  0:01:44s\n",
      "epoch 39 | loss: 0.01383 | mse_mse: 0.01844 |  0:01:47s\n",
      "epoch 40 | loss: 0.01851 | mse_mse: 0.01064 |  0:01:50s\n",
      "epoch 41 | loss: 0.01575 | mse_mse: 0.01111 |  0:01:52s\n",
      "epoch 42 | loss: 0.01296 | mse_mse: 0.01064 |  0:01:55s\n",
      "epoch 43 | loss: 0.01119 | mse_mse: 0.01446 |  0:01:57s\n",
      "epoch 44 | loss: 0.01351 | mse_mse: 0.00953 |  0:02:00s\n",
      "epoch 45 | loss: 0.01243 | mse_mse: 0.00787 |  0:02:03s\n",
      "epoch 46 | loss: 0.01095 | mse_mse: 0.01221 |  0:02:06s\n",
      "epoch 47 | loss: 0.01168 | mse_mse: 0.02215 |  0:02:09s\n",
      "epoch 48 | loss: 0.01117 | mse_mse: 0.01522 |  0:02:13s\n",
      "epoch 49 | loss: 0.01578 | mse_mse: 0.01054 |  0:02:17s\n",
      "epoch 50 | loss: 0.01161 | mse_mse: 0.00867 |  0:02:20s\n",
      "epoch 51 | loss: 0.01031 | mse_mse: 0.01056 |  0:02:24s\n",
      "epoch 52 | loss: 0.01246 | mse_mse: 0.01733 |  0:02:27s\n",
      "epoch 53 | loss: 0.01271 | mse_mse: 0.00852 |  0:02:31s\n",
      "epoch 54 | loss: 0.01234 | mse_mse: 0.01422 |  0:02:34s\n",
      "epoch 55 | loss: 0.0125  | mse_mse: 0.01144 |  0:02:38s\n",
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 45 and best_mse_mse = 0.00787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008532716878491857\n",
      "R2 Score: 0.9615064409081111\n",
      "\n",
      "Iteration 3/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.57145 | mse_mse: 0.48526 |  0:00:05s\n",
      "epoch 1  | loss: 0.3007  | mse_mse: 0.24514 |  0:00:09s\n",
      "epoch 2  | loss: 0.18964 | mse_mse: 0.27131 |  0:00:13s\n",
      "epoch 3  | loss: 0.10451 | mse_mse: 0.13929 |  0:00:17s\n",
      "epoch 4  | loss: 0.08345 | mse_mse: 0.15542 |  0:00:21s\n",
      "epoch 5  | loss: 0.08233 | mse_mse: 0.1434  |  0:00:25s\n",
      "epoch 6  | loss: 0.06686 | mse_mse: 0.10767 |  0:00:30s\n",
      "epoch 7  | loss: 0.06373 | mse_mse: 0.0898  |  0:00:34s\n",
      "epoch 8  | loss: 0.05655 | mse_mse: 0.0661  |  0:00:38s\n",
      "epoch 9  | loss: 0.0564  | mse_mse: 0.05069 |  0:00:42s\n",
      "epoch 10 | loss: 0.05143 | mse_mse: 0.05349 |  0:00:46s\n",
      "epoch 11 | loss: 0.05158 | mse_mse: 0.04885 |  0:00:50s\n",
      "epoch 12 | loss: 0.04584 | mse_mse: 0.04665 |  0:00:54s\n",
      "epoch 13 | loss: 0.04288 | mse_mse: 0.04919 |  0:00:58s\n",
      "epoch 14 | loss: 0.04145 | mse_mse: 0.03584 |  0:01:03s\n",
      "epoch 15 | loss: 0.04363 | mse_mse: 0.0357  |  0:01:07s\n",
      "epoch 16 | loss: 0.0418  | mse_mse: 0.03246 |  0:01:11s\n",
      "epoch 17 | loss: 0.03532 | mse_mse: 0.03592 |  0:01:15s\n",
      "epoch 18 | loss: 0.03615 | mse_mse: 0.03085 |  0:01:19s\n",
      "epoch 19 | loss: 0.03173 | mse_mse: 0.0268  |  0:01:24s\n",
      "epoch 20 | loss: 0.03174 | mse_mse: 0.0308  |  0:01:28s\n",
      "epoch 21 | loss: 0.03206 | mse_mse: 0.04652 |  0:01:33s\n",
      "epoch 22 | loss: 0.03541 | mse_mse: 0.02506 |  0:01:38s\n",
      "epoch 23 | loss: 0.03092 | mse_mse: 0.02651 |  0:01:43s\n",
      "epoch 24 | loss: 0.02774 | mse_mse: 0.03124 |  0:01:49s\n",
      "epoch 25 | loss: 0.03218 | mse_mse: 0.027   |  0:01:57s\n",
      "epoch 26 | loss: 0.02654 | mse_mse: 0.02443 |  0:02:02s\n",
      "epoch 27 | loss: 0.0252  | mse_mse: 0.02028 |  0:02:07s\n",
      "epoch 28 | loss: 0.02518 | mse_mse: 0.02873 |  0:02:12s\n",
      "epoch 29 | loss: 0.02377 | mse_mse: 0.01765 |  0:02:17s\n",
      "epoch 30 | loss: 0.02888 | mse_mse: 0.02086 |  0:02:21s\n",
      "epoch 31 | loss: 0.02457 | mse_mse: 0.03277 |  0:02:26s\n",
      "epoch 32 | loss: 0.02494 | mse_mse: 0.0212  |  0:02:30s\n",
      "epoch 33 | loss: 0.02511 | mse_mse: 0.01832 |  0:02:35s\n",
      "epoch 34 | loss: 0.02496 | mse_mse: 0.01833 |  0:02:39s\n",
      "epoch 35 | loss: 0.02283 | mse_mse: 0.01869 |  0:02:44s\n",
      "epoch 36 | loss: 0.02166 | mse_mse: 0.03066 |  0:02:49s\n",
      "epoch 37 | loss: 0.02848 | mse_mse: 0.02149 |  0:02:53s\n",
      "epoch 38 | loss: 0.02014 | mse_mse: 0.01763 |  0:02:58s\n",
      "epoch 39 | loss: 0.01887 | mse_mse: 0.01533 |  0:03:03s\n",
      "epoch 40 | loss: 0.01825 | mse_mse: 0.05603 |  0:03:08s\n",
      "epoch 41 | loss: 0.027   | mse_mse: 0.01573 |  0:03:13s\n",
      "epoch 42 | loss: 0.01788 | mse_mse: 0.01814 |  0:03:17s\n",
      "epoch 43 | loss: 0.01538 | mse_mse: 0.01354 |  0:03:22s\n",
      "epoch 44 | loss: 0.01545 | mse_mse: 0.01509 |  0:03:26s\n",
      "epoch 45 | loss: 0.01692 | mse_mse: 0.02371 |  0:03:31s\n",
      "epoch 46 | loss: 0.01647 | mse_mse: 0.01377 |  0:03:35s\n",
      "epoch 47 | loss: 0.016   | mse_mse: 0.01284 |  0:03:40s\n",
      "epoch 48 | loss: 0.01292 | mse_mse: 0.01152 |  0:03:44s\n",
      "epoch 49 | loss: 0.01286 | mse_mse: 0.01462 |  0:03:49s\n",
      "epoch 50 | loss: 0.01304 | mse_mse: 0.01417 |  0:03:53s\n",
      "epoch 51 | loss: 0.01202 | mse_mse: 0.01173 |  0:03:58s\n",
      "epoch 52 | loss: 0.01131 | mse_mse: 0.01418 |  0:04:02s\n",
      "epoch 53 | loss: 0.0117  | mse_mse: 0.00889 |  0:04:07s\n",
      "epoch 54 | loss: 0.01303 | mse_mse: 0.01054 |  0:04:12s\n",
      "epoch 55 | loss: 0.0145  | mse_mse: 0.02106 |  0:04:16s\n",
      "epoch 56 | loss: 0.01478 | mse_mse: 0.0188  |  0:04:21s\n",
      "epoch 57 | loss: 0.0117  | mse_mse: 0.01047 |  0:04:25s\n",
      "epoch 58 | loss: 0.01154 | mse_mse: 0.00803 |  0:04:30s\n",
      "epoch 59 | loss: 0.01108 | mse_mse: 0.00798 |  0:04:34s\n",
      "epoch 60 | loss: 0.00992 | mse_mse: 0.0097  |  0:04:39s\n",
      "epoch 61 | loss: 0.0124  | mse_mse: 0.00795 |  0:04:43s\n",
      "epoch 62 | loss: 0.01122 | mse_mse: 0.00926 |  0:04:48s\n",
      "epoch 63 | loss: 0.01097 | mse_mse: 0.01011 |  0:04:52s\n",
      "epoch 64 | loss: 0.00988 | mse_mse: 0.0147  |  0:04:57s\n",
      "epoch 65 | loss: 0.01112 | mse_mse: 0.00711 |  0:05:01s\n",
      "epoch 66 | loss: 0.01026 | mse_mse: 0.01202 |  0:05:06s\n",
      "epoch 67 | loss: 0.01165 | mse_mse: 0.00987 |  0:05:10s\n",
      "epoch 68 | loss: 0.01031 | mse_mse: 0.0105  |  0:05:15s\n",
      "epoch 69 | loss: 0.00872 | mse_mse: 0.00887 |  0:05:19s\n",
      "epoch 70 | loss: 0.00989 | mse_mse: 0.01018 |  0:05:24s\n",
      "epoch 71 | loss: 0.01084 | mse_mse: 0.01144 |  0:05:29s\n",
      "epoch 72 | loss: 0.00906 | mse_mse: 0.00648 |  0:05:33s\n",
      "epoch 73 | loss: 0.00825 | mse_mse: 0.00595 |  0:05:38s\n",
      "epoch 74 | loss: 0.0106  | mse_mse: 0.01718 |  0:05:42s\n",
      "epoch 75 | loss: 0.01457 | mse_mse: 0.00835 |  0:05:47s\n",
      "epoch 76 | loss: 0.01356 | mse_mse: 0.009   |  0:05:51s\n",
      "epoch 77 | loss: 0.00776 | mse_mse: 0.00654 |  0:05:56s\n",
      "epoch 78 | loss: 0.00693 | mse_mse: 0.00731 |  0:06:00s\n",
      "epoch 79 | loss: 0.01082 | mse_mse: 0.00955 |  0:06:05s\n",
      "epoch 80 | loss: 0.01336 | mse_mse: 0.01095 |  0:06:09s\n",
      "epoch 81 | loss: 0.00836 | mse_mse: 0.00606 |  0:06:14s\n",
      "epoch 82 | loss: 0.00932 | mse_mse: 0.00784 |  0:06:18s\n",
      "epoch 83 | loss: 0.00875 | mse_mse: 0.00603 |  0:06:23s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 73 and best_mse_mse = 0.00595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.006350975585124985\n",
      "R2 Score: 0.9713489082717155\n",
      "\n",
      "Iteration 4/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.8052  | mse_mse: 0.37427 |  0:00:04s\n",
      "epoch 1  | loss: 0.28861 | mse_mse: 0.23303 |  0:00:09s\n",
      "epoch 2  | loss: 0.12905 | mse_mse: 0.26113 |  0:00:13s\n",
      "epoch 3  | loss: 0.09393 | mse_mse: 0.15425 |  0:00:18s\n",
      "epoch 4  | loss: 0.06614 | mse_mse: 0.13844 |  0:00:22s\n",
      "epoch 5  | loss: 0.06335 | mse_mse: 0.12214 |  0:00:27s\n",
      "epoch 6  | loss: 0.05824 | mse_mse: 0.11704 |  0:00:32s\n",
      "epoch 7  | loss: 0.05662 | mse_mse: 0.10265 |  0:00:36s\n",
      "epoch 8  | loss: 0.05385 | mse_mse: 0.08733 |  0:00:41s\n",
      "epoch 9  | loss: 0.05237 | mse_mse: 0.07883 |  0:00:45s\n",
      "epoch 10 | loss: 0.05449 | mse_mse: 0.09411 |  0:00:50s\n",
      "epoch 11 | loss: 0.05842 | mse_mse: 0.06101 |  0:00:55s\n",
      "epoch 12 | loss: 0.05714 | mse_mse: 0.05828 |  0:00:59s\n",
      "epoch 13 | loss: 0.05606 | mse_mse: 0.05198 |  0:01:04s\n",
      "epoch 14 | loss: 0.06184 | mse_mse: 0.04895 |  0:01:08s\n",
      "epoch 15 | loss: 0.05464 | mse_mse: 0.05258 |  0:01:13s\n",
      "epoch 16 | loss: 0.06176 | mse_mse: 0.06299 |  0:01:19s\n",
      "epoch 17 | loss: 0.05331 | mse_mse: 0.04422 |  0:01:25s\n",
      "epoch 18 | loss: 0.05316 | mse_mse: 0.04201 |  0:01:31s\n",
      "epoch 19 | loss: 0.04744 | mse_mse: 0.043   |  0:01:36s\n",
      "epoch 20 | loss: 0.05464 | mse_mse: 0.04188 |  0:01:40s\n",
      "epoch 21 | loss: 0.04615 | mse_mse: 0.03836 |  0:01:45s\n",
      "epoch 22 | loss: 0.04696 | mse_mse: 0.0441  |  0:01:50s\n",
      "epoch 23 | loss: 0.05041 | mse_mse: 0.04357 |  0:01:54s\n",
      "epoch 24 | loss: 0.04611 | mse_mse: 0.04191 |  0:01:59s\n",
      "epoch 25 | loss: 0.05208 | mse_mse: 0.03772 |  0:02:04s\n",
      "epoch 26 | loss: 0.04586 | mse_mse: 0.04257 |  0:02:08s\n",
      "epoch 27 | loss: 0.04531 | mse_mse: 0.0405  |  0:02:13s\n",
      "epoch 28 | loss: 0.04851 | mse_mse: 0.03886 |  0:02:18s\n",
      "epoch 29 | loss: 0.04764 | mse_mse: 0.05424 |  0:02:22s\n",
      "epoch 30 | loss: 0.04747 | mse_mse: 0.03689 |  0:02:27s\n",
      "epoch 31 | loss: 0.04753 | mse_mse: 0.0393  |  0:02:32s\n",
      "epoch 32 | loss: 0.04474 | mse_mse: 0.0398  |  0:02:37s\n",
      "epoch 33 | loss: 0.04447 | mse_mse: 0.03587 |  0:02:41s\n",
      "epoch 34 | loss: 0.04425 | mse_mse: 0.04153 |  0:02:46s\n",
      "epoch 35 | loss: 0.04564 | mse_mse: 0.04948 |  0:02:51s\n",
      "epoch 36 | loss: 0.04188 | mse_mse: 0.03834 |  0:02:55s\n",
      "epoch 37 | loss: 0.04154 | mse_mse: 0.03258 |  0:03:00s\n",
      "epoch 38 | loss: 0.0394  | mse_mse: 0.0366  |  0:03:05s\n",
      "epoch 39 | loss: 0.04484 | mse_mse: 0.03218 |  0:03:10s\n",
      "epoch 40 | loss: 0.04337 | mse_mse: 0.03869 |  0:03:14s\n",
      "epoch 41 | loss: 0.0504  | mse_mse: 0.05284 |  0:03:19s\n",
      "epoch 42 | loss: 0.04888 | mse_mse: 0.05143 |  0:03:23s\n",
      "epoch 43 | loss: 0.05105 | mse_mse: 0.0475  |  0:03:28s\n",
      "epoch 44 | loss: 0.04874 | mse_mse: 0.0435  |  0:03:33s\n",
      "epoch 45 | loss: 0.04851 | mse_mse: 0.0606  |  0:03:38s\n",
      "epoch 46 | loss: 0.04857 | mse_mse: 0.0338  |  0:03:42s\n",
      "epoch 47 | loss: 0.03952 | mse_mse: 0.0326  |  0:03:47s\n",
      "epoch 48 | loss: 0.03704 | mse_mse: 0.03712 |  0:03:52s\n",
      "epoch 49 | loss: 0.03959 | mse_mse: 0.03966 |  0:03:56s\n",
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 39 and best_mse_mse = 0.03218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.032990309610079045\n",
      "R2 Score: 0.851171150933612\n",
      "\n",
      "Iteration 5/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.49641 | mse_mse: 0.56788 |  0:00:06s\n",
      "epoch 1  | loss: 0.27736 | mse_mse: 0.24426 |  0:00:12s\n",
      "epoch 2  | loss: 0.19115 | mse_mse: 0.26549 |  0:00:18s\n",
      "epoch 3  | loss: 0.18002 | mse_mse: 0.16715 |  0:00:25s\n",
      "epoch 4  | loss: 0.15903 | mse_mse: 0.17078 |  0:00:31s\n",
      "epoch 5  | loss: 0.13942 | mse_mse: 0.12894 |  0:00:37s\n",
      "epoch 6  | loss: 0.11804 | mse_mse: 0.3211  |  0:00:43s\n",
      "epoch 7  | loss: 0.10072 | mse_mse: 0.19191 |  0:00:49s\n",
      "epoch 8  | loss: 0.09544 | mse_mse: 0.11577 |  0:00:56s\n",
      "epoch 9  | loss: 0.09133 | mse_mse: 0.2034  |  0:01:02s\n",
      "epoch 10 | loss: 0.08956 | mse_mse: 0.10166 |  0:01:08s\n",
      "epoch 11 | loss: 0.08435 | mse_mse: 0.08614 |  0:01:14s\n",
      "epoch 12 | loss: 0.0845  | mse_mse: 0.08414 |  0:01:20s\n",
      "epoch 13 | loss: 0.07781 | mse_mse: 0.06526 |  0:01:27s\n",
      "epoch 14 | loss: 0.07816 | mse_mse: 0.06655 |  0:01:33s\n",
      "epoch 15 | loss: 0.08059 | mse_mse: 0.06503 |  0:01:39s\n",
      "epoch 16 | loss: 0.08684 | mse_mse: 0.06414 |  0:01:45s\n",
      "epoch 17 | loss: 0.07927 | mse_mse: 0.07356 |  0:01:52s\n",
      "epoch 18 | loss: 0.07304 | mse_mse: 0.06216 |  0:01:58s\n",
      "epoch 19 | loss: 0.07594 | mse_mse: 0.0797  |  0:02:04s\n",
      "epoch 20 | loss: 0.07149 | mse_mse: 0.06735 |  0:02:10s\n",
      "epoch 21 | loss: 0.07062 | mse_mse: 0.05865 |  0:02:17s\n",
      "epoch 22 | loss: 0.07644 | mse_mse: 0.05998 |  0:02:23s\n",
      "epoch 23 | loss: 0.06964 | mse_mse: 0.07023 |  0:02:29s\n",
      "epoch 24 | loss: 0.06056 | mse_mse: 0.06201 |  0:02:35s\n",
      "epoch 25 | loss: 0.05739 | mse_mse: 0.05505 |  0:02:41s\n",
      "epoch 26 | loss: 0.05931 | mse_mse: 0.05492 |  0:02:48s\n",
      "epoch 27 | loss: 0.05563 | mse_mse: 0.04812 |  0:02:54s\n",
      "epoch 28 | loss: 0.05144 | mse_mse: 0.04823 |  0:03:00s\n",
      "epoch 29 | loss: 0.04743 | mse_mse: 0.03946 |  0:03:06s\n",
      "epoch 30 | loss: 0.04281 | mse_mse: 0.03842 |  0:03:12s\n",
      "epoch 31 | loss: 0.04928 | mse_mse: 0.03353 |  0:03:19s\n",
      "epoch 32 | loss: 0.03843 | mse_mse: 0.03166 |  0:03:25s\n",
      "epoch 33 | loss: 0.03741 | mse_mse: 0.03831 |  0:03:31s\n",
      "epoch 34 | loss: 0.03489 | mse_mse: 0.03949 |  0:03:38s\n",
      "epoch 35 | loss: 0.03523 | mse_mse: 0.03925 |  0:03:44s\n",
      "epoch 36 | loss: 0.03678 | mse_mse: 0.03184 |  0:03:50s\n",
      "epoch 37 | loss: 0.03271 | mse_mse: 0.03946 |  0:03:57s\n",
      "epoch 38 | loss: 0.03211 | mse_mse: 0.02504 |  0:04:03s\n",
      "epoch 39 | loss: 0.03029 | mse_mse: 0.02304 |  0:04:10s\n",
      "epoch 40 | loss: 0.03396 | mse_mse: 0.02548 |  0:04:17s\n",
      "epoch 41 | loss: 0.0258  | mse_mse: 0.01924 |  0:04:24s\n",
      "epoch 42 | loss: 0.0272  | mse_mse: 0.03167 |  0:04:30s\n",
      "epoch 43 | loss: 0.02761 | mse_mse: 0.02426 |  0:04:36s\n",
      "epoch 44 | loss: 0.02531 | mse_mse: 0.02689 |  0:04:43s\n",
      "epoch 45 | loss: 0.02941 | mse_mse: 0.02696 |  0:04:51s\n",
      "epoch 46 | loss: 0.02806 | mse_mse: 0.02522 |  0:05:00s\n",
      "epoch 47 | loss: 0.03045 | mse_mse: 0.02225 |  0:05:08s\n",
      "epoch 48 | loss: 0.02703 | mse_mse: 0.02124 |  0:05:15s\n",
      "epoch 49 | loss: 0.02403 | mse_mse: 0.01848 |  0:05:23s\n",
      "epoch 50 | loss: 0.02436 | mse_mse: 0.01703 |  0:05:30s\n",
      "epoch 51 | loss: 0.02646 | mse_mse: 0.02112 |  0:05:38s\n",
      "epoch 52 | loss: 0.01967 | mse_mse: 0.01578 |  0:05:45s\n",
      "epoch 53 | loss: 0.02248 | mse_mse: 0.0206  |  0:05:52s\n",
      "epoch 54 | loss: 0.02086 | mse_mse: 0.01674 |  0:06:00s\n",
      "epoch 55 | loss: 0.02123 | mse_mse: 0.01616 |  0:06:07s\n",
      "epoch 56 | loss: 0.02014 | mse_mse: 0.01573 |  0:06:14s\n",
      "epoch 57 | loss: 0.02207 | mse_mse: 0.02211 |  0:06:21s\n",
      "epoch 58 | loss: 0.021   | mse_mse: 0.0142  |  0:06:28s\n",
      "epoch 59 | loss: 0.01599 | mse_mse: 0.01885 |  0:06:35s\n",
      "epoch 60 | loss: 0.01867 | mse_mse: 0.01447 |  0:06:43s\n",
      "epoch 61 | loss: 0.02006 | mse_mse: 0.01315 |  0:06:49s\n",
      "epoch 62 | loss: 0.01873 | mse_mse: 0.01447 |  0:06:56s\n",
      "epoch 63 | loss: 0.01461 | mse_mse: 0.01563 |  0:07:02s\n",
      "epoch 64 | loss: 0.01675 | mse_mse: 0.01077 |  0:07:09s\n",
      "epoch 65 | loss: 0.01552 | mse_mse: 0.01287 |  0:07:15s\n",
      "epoch 66 | loss: 0.01895 | mse_mse: 0.01821 |  0:07:22s\n",
      "epoch 67 | loss: 0.01407 | mse_mse: 0.01359 |  0:07:28s\n",
      "epoch 68 | loss: 0.01332 | mse_mse: 0.01278 |  0:07:34s\n",
      "epoch 69 | loss: 0.01496 | mse_mse: 0.0118  |  0:07:41s\n",
      "epoch 70 | loss: 0.01174 | mse_mse: 0.00916 |  0:07:48s\n",
      "epoch 71 | loss: 0.01253 | mse_mse: 0.01054 |  0:07:54s\n",
      "epoch 72 | loss: 0.01233 | mse_mse: 0.00996 |  0:08:01s\n",
      "epoch 73 | loss: 0.01461 | mse_mse: 0.01471 |  0:08:07s\n",
      "epoch 74 | loss: 0.01391 | mse_mse: 0.00825 |  0:08:14s\n",
      "epoch 75 | loss: 0.01181 | mse_mse: 0.00966 |  0:08:21s\n",
      "epoch 76 | loss: 0.01155 | mse_mse: 0.01708 |  0:08:30s\n",
      "epoch 77 | loss: 0.01252 | mse_mse: 0.00895 |  0:08:38s\n",
      "epoch 78 | loss: 0.01728 | mse_mse: 0.01798 |  0:08:46s\n",
      "epoch 79 | loss: 0.01558 | mse_mse: 0.02031 |  0:08:55s\n",
      "epoch 80 | loss: 0.01917 | mse_mse: 0.02579 |  0:09:02s\n",
      "epoch 81 | loss: 0.01116 | mse_mse: 0.01136 |  0:09:09s\n",
      "epoch 82 | loss: 0.01658 | mse_mse: 0.00871 |  0:09:15s\n",
      "epoch 83 | loss: 0.01233 | mse_mse: 0.00908 |  0:09:22s\n",
      "epoch 84 | loss: 0.01056 | mse_mse: 0.00991 |  0:09:28s\n",
      "\n",
      "Early stopping occurred at epoch 84 with best_epoch = 74 and best_mse_mse = 0.00825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008055255859832576\n",
      "R2 Score: 0.9636604059578788\n",
      "\n",
      "Iteration 6/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 8 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 14.49632| mse_mse: 1.67985 |  0:00:05s\n",
      "epoch 1  | loss: 0.5422  | mse_mse: 0.47298 |  0:00:12s\n",
      "epoch 2  | loss: 0.37026 | mse_mse: 0.19545 |  0:00:18s\n",
      "epoch 3  | loss: 0.19852 | mse_mse: 0.16964 |  0:00:25s\n",
      "epoch 4  | loss: 0.17372 | mse_mse: 0.18672 |  0:00:31s\n",
      "epoch 5  | loss: 0.13244 | mse_mse: 0.13394 |  0:00:38s\n",
      "epoch 6  | loss: 0.1295  | mse_mse: 0.11768 |  0:00:44s\n",
      "epoch 7  | loss: 0.11869 | mse_mse: 0.11157 |  0:00:50s\n",
      "epoch 8  | loss: 0.11189 | mse_mse: 0.10346 |  0:00:57s\n",
      "epoch 9  | loss: 0.1046  | mse_mse: 0.13329 |  0:01:03s\n",
      "epoch 10 | loss: 0.10727 | mse_mse: 0.10832 |  0:01:10s\n",
      "epoch 11 | loss: 0.10005 | mse_mse: 0.10502 |  0:01:16s\n",
      "epoch 12 | loss: 0.09482 | mse_mse: 0.08944 |  0:01:22s\n",
      "epoch 13 | loss: 0.08629 | mse_mse: 0.0754  |  0:01:29s\n",
      "epoch 14 | loss: 0.08014 | mse_mse: 0.06954 |  0:01:37s\n",
      "epoch 15 | loss: 0.07485 | mse_mse: 0.0642  |  0:01:46s\n",
      "epoch 16 | loss: 0.06734 | mse_mse: 0.05485 |  0:01:57s\n",
      "epoch 17 | loss: 0.06113 | mse_mse: 0.04869 |  0:02:05s\n",
      "epoch 18 | loss: 0.05315 | mse_mse: 0.04196 |  0:02:12s\n",
      "epoch 19 | loss: 0.04788 | mse_mse: 0.04254 |  0:02:19s\n",
      "epoch 20 | loss: 0.04321 | mse_mse: 0.03549 |  0:02:27s\n",
      "epoch 21 | loss: 0.04208 | mse_mse: 0.03262 |  0:02:34s\n",
      "epoch 22 | loss: 0.041   | mse_mse: 0.05007 |  0:02:42s\n",
      "epoch 23 | loss: 0.03745 | mse_mse: 0.036   |  0:02:49s\n",
      "epoch 24 | loss: 0.04281 | mse_mse: 0.0389  |  0:02:56s\n",
      "epoch 25 | loss: 0.03771 | mse_mse: 0.03397 |  0:03:05s\n",
      "epoch 26 | loss: 0.04454 | mse_mse: 0.03776 |  0:03:12s\n",
      "epoch 27 | loss: 0.03762 | mse_mse: 0.04547 |  0:03:20s\n",
      "epoch 28 | loss: 0.03785 | mse_mse: 0.03039 |  0:03:27s\n",
      "epoch 29 | loss: 0.03333 | mse_mse: 0.02537 |  0:03:33s\n",
      "epoch 30 | loss: 0.02984 | mse_mse: 0.03311 |  0:03:40s\n",
      "epoch 31 | loss: 0.02909 | mse_mse: 0.02787 |  0:03:47s\n",
      "epoch 32 | loss: 0.02958 | mse_mse: 0.03514 |  0:03:54s\n",
      "epoch 33 | loss: 0.03544 | mse_mse: 0.04217 |  0:04:01s\n",
      "epoch 34 | loss: 0.03505 | mse_mse: 0.02736 |  0:04:07s\n",
      "epoch 35 | loss: 0.03756 | mse_mse: 0.04086 |  0:04:14s\n",
      "epoch 36 | loss: 0.03447 | mse_mse: 0.02801 |  0:04:20s\n",
      "epoch 37 | loss: 0.03324 | mse_mse: 0.02647 |  0:04:27s\n",
      "epoch 38 | loss: 0.03083 | mse_mse: 0.02386 |  0:04:36s\n",
      "epoch 39 | loss: 0.02944 | mse_mse: 0.02536 |  0:04:43s\n",
      "epoch 40 | loss: 0.02662 | mse_mse: 0.02599 |  0:04:51s\n",
      "epoch 41 | loss: 0.02197 | mse_mse: 0.02076 |  0:04:59s\n",
      "epoch 42 | loss: 0.02266 | mse_mse: 0.02315 |  0:05:07s\n",
      "epoch 43 | loss: 0.02434 | mse_mse: 0.01851 |  0:05:15s\n",
      "epoch 44 | loss: 0.02149 | mse_mse: 0.01819 |  0:05:23s\n",
      "epoch 45 | loss: 0.02184 | mse_mse: 0.0191  |  0:05:30s\n",
      "epoch 46 | loss: 0.02106 | mse_mse: 0.01488 |  0:05:38s\n",
      "epoch 47 | loss: 0.01845 | mse_mse: 0.01535 |  0:05:45s\n",
      "epoch 48 | loss: 0.01679 | mse_mse: 0.018   |  0:05:52s\n",
      "epoch 49 | loss: 0.01809 | mse_mse: 0.02327 |  0:05:58s\n",
      "epoch 50 | loss: 0.01748 | mse_mse: 0.01376 |  0:06:04s\n",
      "epoch 51 | loss: 0.01765 | mse_mse: 0.02619 |  0:06:10s\n",
      "epoch 52 | loss: 0.01737 | mse_mse: 0.01704 |  0:06:16s\n",
      "epoch 53 | loss: 0.01363 | mse_mse: 0.01524 |  0:06:22s\n",
      "epoch 54 | loss: 0.01313 | mse_mse: 0.01451 |  0:06:28s\n",
      "epoch 55 | loss: 0.0183  | mse_mse: 0.0108  |  0:06:34s\n",
      "epoch 56 | loss: 0.01742 | mse_mse: 0.07944 |  0:06:40s\n",
      "epoch 57 | loss: 0.01607 | mse_mse: 0.01545 |  0:06:47s\n",
      "epoch 58 | loss: 0.0155  | mse_mse: 0.01115 |  0:06:55s\n",
      "epoch 59 | loss: 0.01642 | mse_mse: 0.01068 |  0:07:03s\n",
      "epoch 60 | loss: 0.01569 | mse_mse: 0.01896 |  0:07:11s\n",
      "epoch 61 | loss: 0.01345 | mse_mse: 0.01095 |  0:07:17s\n",
      "epoch 62 | loss: 0.01163 | mse_mse: 0.05171 |  0:07:24s\n",
      "epoch 63 | loss: 0.01485 | mse_mse: 0.00884 |  0:07:30s\n",
      "epoch 64 | loss: 0.01115 | mse_mse: 0.00806 |  0:07:36s\n",
      "epoch 65 | loss: 0.01459 | mse_mse: 0.0122  |  0:07:42s\n",
      "epoch 66 | loss: 0.01255 | mse_mse: 0.00784 |  0:07:48s\n",
      "epoch 67 | loss: 0.01072 | mse_mse: 0.01215 |  0:07:54s\n",
      "epoch 68 | loss: 0.00982 | mse_mse: 0.00823 |  0:08:00s\n",
      "epoch 69 | loss: 0.01174 | mse_mse: 0.00685 |  0:08:06s\n",
      "epoch 70 | loss: 0.01044 | mse_mse: 0.00754 |  0:08:12s\n",
      "epoch 71 | loss: 0.01041 | mse_mse: 0.00686 |  0:08:18s\n",
      "epoch 72 | loss: 0.00934 | mse_mse: 0.00689 |  0:08:24s\n",
      "epoch 73 | loss: 0.01217 | mse_mse: 0.009   |  0:08:30s\n",
      "epoch 74 | loss: 0.01297 | mse_mse: 0.00805 |  0:08:36s\n",
      "epoch 75 | loss: 0.01133 | mse_mse: 0.02419 |  0:08:42s\n",
      "epoch 76 | loss: 0.01073 | mse_mse: 0.00735 |  0:08:48s\n",
      "epoch 77 | loss: 0.01072 | mse_mse: 0.00974 |  0:08:53s\n",
      "epoch 78 | loss: 0.01113 | mse_mse: 0.01108 |  0:08:59s\n",
      "epoch 79 | loss: 0.01221 | mse_mse: 0.00687 |  0:09:05s\n",
      "\n",
      "Early stopping occurred at epoch 79 with best_epoch = 69 and best_mse_mse = 0.00685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.006730171688943681\n",
      "R2 Score: 0.9696382447353977\n",
      "\n",
      "Iteration 7/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.79271 | mse_mse: 1.19444 |  0:00:02s\n",
      "epoch 1  | loss: 0.21933 | mse_mse: 0.20502 |  0:00:04s\n",
      "epoch 2  | loss: 0.10975 | mse_mse: 0.16226 |  0:00:07s\n",
      "epoch 3  | loss: 0.08249 | mse_mse: 0.11118 |  0:00:09s\n",
      "epoch 4  | loss: 0.07091 | mse_mse: 0.08288 |  0:00:12s\n",
      "epoch 5  | loss: 0.06016 | mse_mse: 0.07302 |  0:00:15s\n",
      "epoch 6  | loss: 0.05395 | mse_mse: 0.0707  |  0:00:17s\n",
      "epoch 7  | loss: 0.05407 | mse_mse: 0.06885 |  0:00:20s\n",
      "epoch 8  | loss: 0.05512 | mse_mse: 0.06883 |  0:00:23s\n",
      "epoch 9  | loss: 0.05082 | mse_mse: 0.0535  |  0:00:25s\n",
      "epoch 10 | loss: 0.04718 | mse_mse: 0.04439 |  0:00:28s\n",
      "epoch 11 | loss: 0.04281 | mse_mse: 0.04129 |  0:00:31s\n",
      "epoch 12 | loss: 0.04376 | mse_mse: 0.04452 |  0:00:33s\n",
      "epoch 13 | loss: 0.03974 | mse_mse: 0.03243 |  0:00:36s\n",
      "epoch 14 | loss: 0.03723 | mse_mse: 0.03052 |  0:00:38s\n",
      "epoch 15 | loss: 0.03764 | mse_mse: 0.02996 |  0:00:41s\n",
      "epoch 16 | loss: 0.04261 | mse_mse: 0.0263  |  0:00:44s\n",
      "epoch 17 | loss: 0.03283 | mse_mse: 0.02861 |  0:00:46s\n",
      "epoch 18 | loss: 0.02996 | mse_mse: 0.02333 |  0:00:49s\n",
      "epoch 19 | loss: 0.02554 | mse_mse: 0.01979 |  0:00:52s\n",
      "epoch 20 | loss: 0.02557 | mse_mse: 0.02054 |  0:00:55s\n",
      "epoch 21 | loss: 0.02051 | mse_mse: 0.01792 |  0:00:57s\n",
      "epoch 22 | loss: 0.02126 | mse_mse: 0.0175  |  0:01:00s\n",
      "epoch 23 | loss: 0.02071 | mse_mse: 0.01766 |  0:01:03s\n",
      "epoch 24 | loss: 0.01788 | mse_mse: 0.01302 |  0:01:05s\n",
      "epoch 25 | loss: 0.01748 | mse_mse: 0.01639 |  0:01:08s\n",
      "epoch 26 | loss: 0.01636 | mse_mse: 0.01273 |  0:01:11s\n",
      "epoch 27 | loss: 0.01759 | mse_mse: 0.01259 |  0:01:13s\n",
      "epoch 28 | loss: 0.01696 | mse_mse: 0.01219 |  0:01:16s\n",
      "epoch 29 | loss: 0.01739 | mse_mse: 0.00998 |  0:01:19s\n",
      "epoch 30 | loss: 0.01492 | mse_mse: 0.01055 |  0:01:21s\n",
      "epoch 31 | loss: 0.01505 | mse_mse: 0.01033 |  0:01:24s\n",
      "epoch 32 | loss: 0.01858 | mse_mse: 0.0174  |  0:01:28s\n",
      "epoch 33 | loss: 0.01544 | mse_mse: 0.00908 |  0:01:31s\n",
      "epoch 34 | loss: 0.01274 | mse_mse: 0.01157 |  0:01:34s\n",
      "epoch 35 | loss: 0.01296 | mse_mse: 0.00947 |  0:01:38s\n",
      "epoch 36 | loss: 0.01127 | mse_mse: 0.00842 |  0:01:41s\n",
      "epoch 37 | loss: 0.01687 | mse_mse: 0.00961 |  0:01:45s\n",
      "epoch 38 | loss: 0.0143  | mse_mse: 0.00776 |  0:01:48s\n",
      "epoch 39 | loss: 0.0154  | mse_mse: 0.0147  |  0:01:53s\n",
      "epoch 40 | loss: 0.01636 | mse_mse: 0.01909 |  0:01:57s\n",
      "epoch 41 | loss: 0.01296 | mse_mse: 0.01948 |  0:02:01s\n",
      "epoch 42 | loss: 0.01162 | mse_mse: 0.00834 |  0:02:04s\n",
      "epoch 43 | loss: 0.01172 | mse_mse: 0.01028 |  0:02:08s\n",
      "epoch 44 | loss: 0.01316 | mse_mse: 0.00793 |  0:02:12s\n",
      "epoch 45 | loss: 0.0115  | mse_mse: 0.00734 |  0:02:15s\n",
      "epoch 46 | loss: 0.01138 | mse_mse: 0.00662 |  0:02:19s\n",
      "epoch 47 | loss: 0.01023 | mse_mse: 0.00615 |  0:02:22s\n",
      "epoch 48 | loss: 0.01113 | mse_mse: 0.0102  |  0:02:25s\n",
      "epoch 49 | loss: 0.01157 | mse_mse: 0.00793 |  0:02:29s\n",
      "epoch 50 | loss: 0.00989 | mse_mse: 0.00665 |  0:02:33s\n",
      "epoch 51 | loss: 0.00954 | mse_mse: 0.01223 |  0:02:36s\n",
      "epoch 52 | loss: 0.01224 | mse_mse: 0.00834 |  0:02:39s\n",
      "epoch 53 | loss: 0.00968 | mse_mse: 0.02002 |  0:02:42s\n",
      "epoch 54 | loss: 0.0118  | mse_mse: 0.00811 |  0:02:45s\n",
      "epoch 55 | loss: 0.00994 | mse_mse: 0.00644 |  0:02:48s\n",
      "epoch 56 | loss: 0.01429 | mse_mse: 0.00802 |  0:02:51s\n",
      "epoch 57 | loss: 0.00995 | mse_mse: 0.00663 |  0:02:54s\n",
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 47 and best_mse_mse = 0.00615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.006230954600143073\n",
      "R2 Score: 0.9718903577236847\n",
      "\n",
      "Iteration 8/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.97601 | mse_mse: 0.58973 |  0:00:02s\n",
      "epoch 1  | loss: 0.17231 | mse_mse: 0.19666 |  0:00:05s\n",
      "epoch 2  | loss: 0.08968 | mse_mse: 0.11505 |  0:00:08s\n",
      "epoch 3  | loss: 0.07459 | mse_mse: 0.08986 |  0:00:11s\n",
      "epoch 4  | loss: 0.06128 | mse_mse: 0.08679 |  0:00:14s\n",
      "epoch 5  | loss: 0.05403 | mse_mse: 0.07946 |  0:00:16s\n",
      "epoch 6  | loss: 0.05048 | mse_mse: 0.06849 |  0:00:19s\n",
      "epoch 7  | loss: 0.04184 | mse_mse: 0.05826 |  0:00:22s\n",
      "epoch 8  | loss: 0.04066 | mse_mse: 0.044   |  0:00:25s\n",
      "epoch 9  | loss: 0.03622 | mse_mse: 0.03648 |  0:00:28s\n",
      "epoch 10 | loss: 0.03054 | mse_mse: 0.03747 |  0:00:30s\n",
      "epoch 11 | loss: 0.02798 | mse_mse: 0.0345  |  0:00:33s\n",
      "epoch 12 | loss: 0.02491 | mse_mse: 0.02554 |  0:00:36s\n",
      "epoch 13 | loss: 0.02468 | mse_mse: 0.02061 |  0:00:39s\n",
      "epoch 14 | loss: 0.02348 | mse_mse: 0.02313 |  0:00:42s\n",
      "epoch 15 | loss: 0.02243 | mse_mse: 0.023   |  0:00:45s\n",
      "epoch 16 | loss: 0.01987 | mse_mse: 0.01561 |  0:00:47s\n",
      "epoch 17 | loss: 0.02284 | mse_mse: 0.01383 |  0:00:50s\n",
      "epoch 18 | loss: 0.01925 | mse_mse: 0.01625 |  0:00:53s\n",
      "epoch 19 | loss: 0.01679 | mse_mse: 0.01129 |  0:00:56s\n",
      "epoch 20 | loss: 0.01768 | mse_mse: 0.0136  |  0:00:59s\n",
      "epoch 21 | loss: 0.01537 | mse_mse: 0.01103 |  0:01:02s\n",
      "epoch 22 | loss: 0.02175 | mse_mse: 0.01318 |  0:01:05s\n",
      "epoch 23 | loss: 0.01471 | mse_mse: 0.01168 |  0:01:08s\n",
      "epoch 24 | loss: 0.01881 | mse_mse: 0.01197 |  0:01:11s\n",
      "epoch 25 | loss: 0.01374 | mse_mse: 0.01299 |  0:01:14s\n",
      "epoch 26 | loss: 0.01458 | mse_mse: 0.00882 |  0:01:17s\n",
      "epoch 27 | loss: 0.01466 | mse_mse: 0.00972 |  0:01:20s\n",
      "epoch 28 | loss: 0.01173 | mse_mse: 0.01243 |  0:01:23s\n",
      "epoch 29 | loss: 0.01102 | mse_mse: 0.00968 |  0:01:25s\n",
      "epoch 30 | loss: 0.01154 | mse_mse: 0.00938 |  0:01:28s\n",
      "epoch 31 | loss: 0.01108 | mse_mse: 0.01038 |  0:01:31s\n",
      "epoch 32 | loss: 0.01261 | mse_mse: 0.00922 |  0:01:34s\n",
      "epoch 33 | loss: 0.01312 | mse_mse: 0.01053 |  0:01:37s\n",
      "epoch 34 | loss: 0.01572 | mse_mse: 0.01131 |  0:01:40s\n",
      "epoch 35 | loss: 0.01185 | mse_mse: 0.01101 |  0:01:43s\n",
      "epoch 36 | loss: 0.01056 | mse_mse: 0.00866 |  0:01:46s\n",
      "epoch 37 | loss: 0.01136 | mse_mse: 0.00841 |  0:01:49s\n",
      "epoch 38 | loss: 0.01149 | mse_mse: 0.00785 |  0:01:51s\n",
      "epoch 39 | loss: 0.01291 | mse_mse: 0.00747 |  0:01:54s\n",
      "epoch 40 | loss: 0.01302 | mse_mse: 0.01637 |  0:01:57s\n",
      "epoch 41 | loss: 0.01319 | mse_mse: 0.00911 |  0:02:00s\n",
      "epoch 42 | loss: 0.01167 | mse_mse: 0.00994 |  0:02:03s\n",
      "epoch 43 | loss: 0.01393 | mse_mse: 0.00776 |  0:02:06s\n",
      "epoch 44 | loss: 0.01033 | mse_mse: 0.00696 |  0:02:09s\n",
      "epoch 45 | loss: 0.01277 | mse_mse: 0.01059 |  0:02:11s\n",
      "epoch 46 | loss: 0.01044 | mse_mse: 0.02125 |  0:02:14s\n",
      "epoch 47 | loss: 0.01217 | mse_mse: 0.00846 |  0:02:17s\n",
      "epoch 48 | loss: 0.01246 | mse_mse: 0.01062 |  0:02:20s\n",
      "epoch 49 | loss: 0.0094  | mse_mse: 0.00709 |  0:02:23s\n",
      "epoch 50 | loss: 0.01084 | mse_mse: 0.00907 |  0:02:26s\n",
      "epoch 51 | loss: 0.01037 | mse_mse: 0.0119  |  0:02:29s\n",
      "epoch 52 | loss: 0.01015 | mse_mse: 0.00997 |  0:02:32s\n",
      "epoch 53 | loss: 0.00982 | mse_mse: 0.00921 |  0:02:35s\n",
      "epoch 54 | loss: 0.01777 | mse_mse: 0.02349 |  0:02:38s\n",
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 44 and best_mse_mse = 0.00696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.006908604365104165\n",
      "R2 Score: 0.9688332832135851\n",
      "\n",
      "Iteration 9/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.19463 | mse_mse: 0.33069 |  0:00:04s\n",
      "epoch 1  | loss: 0.25937 | mse_mse: 0.28258 |  0:00:08s\n",
      "epoch 2  | loss: 0.17339 | mse_mse: 0.25694 |  0:00:13s\n",
      "epoch 3  | loss: 0.14209 | mse_mse: 0.19563 |  0:00:17s\n",
      "epoch 4  | loss: 0.11309 | mse_mse: 0.1406  |  0:00:21s\n",
      "epoch 5  | loss: 0.09869 | mse_mse: 0.11217 |  0:00:26s\n",
      "epoch 6  | loss: 0.08186 | mse_mse: 0.10547 |  0:00:30s\n",
      "epoch 7  | loss: 0.07698 | mse_mse: 0.11411 |  0:00:35s\n",
      "epoch 8  | loss: 0.07593 | mse_mse: 0.08216 |  0:00:40s\n",
      "epoch 9  | loss: 0.07777 | mse_mse: 0.09733 |  0:00:46s\n",
      "epoch 10 | loss: 0.07442 | mse_mse: 0.06583 |  0:00:52s\n",
      "epoch 11 | loss: 0.06756 | mse_mse: 0.05653 |  0:00:57s\n",
      "epoch 12 | loss: 0.06486 | mse_mse: 0.07037 |  0:01:02s\n",
      "epoch 13 | loss: 0.06561 | mse_mse: 0.0521  |  0:01:07s\n",
      "epoch 14 | loss: 0.05637 | mse_mse: 0.04658 |  0:01:13s\n",
      "epoch 15 | loss: 0.0513  | mse_mse: 0.04647 |  0:01:18s\n",
      "epoch 16 | loss: 0.05073 | mse_mse: 0.04854 |  0:01:24s\n",
      "epoch 17 | loss: 0.04922 | mse_mse: 0.04751 |  0:01:30s\n",
      "epoch 18 | loss: 0.04595 | mse_mse: 0.04263 |  0:01:35s\n",
      "epoch 19 | loss: 0.0512  | mse_mse: 0.04219 |  0:01:40s\n",
      "epoch 20 | loss: 0.04751 | mse_mse: 0.04747 |  0:01:45s\n",
      "epoch 21 | loss: 0.04607 | mse_mse: 0.03922 |  0:01:49s\n",
      "epoch 22 | loss: 0.04452 | mse_mse: 0.04324 |  0:01:54s\n",
      "epoch 23 | loss: 0.04078 | mse_mse: 0.03587 |  0:02:00s\n",
      "epoch 24 | loss: 0.04685 | mse_mse: 0.03952 |  0:02:06s\n",
      "epoch 25 | loss: 0.04067 | mse_mse: 0.03769 |  0:02:11s\n",
      "epoch 26 | loss: 0.03926 | mse_mse: 0.03537 |  0:02:17s\n",
      "epoch 27 | loss: 0.03535 | mse_mse: 0.03486 |  0:02:23s\n",
      "epoch 28 | loss: 0.03889 | mse_mse: 0.02993 |  0:02:29s\n",
      "epoch 29 | loss: 0.03359 | mse_mse: 0.02744 |  0:02:34s\n",
      "epoch 30 | loss: 0.03077 | mse_mse: 0.02648 |  0:02:39s\n",
      "epoch 31 | loss: 0.0307  | mse_mse: 0.02957 |  0:02:44s\n",
      "epoch 32 | loss: 0.02958 | mse_mse: 0.03176 |  0:02:49s\n",
      "epoch 33 | loss: 0.0284  | mse_mse: 0.02742 |  0:02:54s\n",
      "epoch 34 | loss: 0.02829 | mse_mse: 0.03319 |  0:03:00s\n",
      "epoch 35 | loss: 0.04027 | mse_mse: 0.0322  |  0:03:05s\n",
      "epoch 36 | loss: 0.03095 | mse_mse: 0.03287 |  0:03:10s\n",
      "epoch 37 | loss: 0.03061 | mse_mse: 0.03381 |  0:03:15s\n",
      "epoch 38 | loss: 0.02608 | mse_mse: 0.02075 |  0:03:20s\n",
      "epoch 39 | loss: 0.02747 | mse_mse: 0.03705 |  0:03:24s\n",
      "epoch 40 | loss: 0.0278  | mse_mse: 0.02341 |  0:03:29s\n",
      "epoch 41 | loss: 0.02429 | mse_mse: 0.01974 |  0:03:34s\n",
      "epoch 42 | loss: 0.02712 | mse_mse: 0.02343 |  0:03:40s\n",
      "epoch 43 | loss: 0.02541 | mse_mse: 0.01974 |  0:03:45s\n",
      "epoch 44 | loss: 0.02476 | mse_mse: 0.02833 |  0:03:50s\n",
      "epoch 45 | loss: 0.02624 | mse_mse: 0.02952 |  0:03:56s\n",
      "epoch 46 | loss: 0.02676 | mse_mse: 0.02143 |  0:04:01s\n",
      "epoch 47 | loss: 0.02486 | mse_mse: 0.02108 |  0:04:07s\n",
      "epoch 48 | loss: 0.02254 | mse_mse: 0.018   |  0:04:11s\n",
      "epoch 49 | loss: 0.02209 | mse_mse: 0.01697 |  0:04:16s\n",
      "epoch 50 | loss: 0.02048 | mse_mse: 0.0152  |  0:04:21s\n",
      "epoch 51 | loss: 0.01909 | mse_mse: 0.02953 |  0:04:26s\n",
      "epoch 52 | loss: 0.02181 | mse_mse: 0.01761 |  0:04:31s\n",
      "epoch 53 | loss: 0.01877 | mse_mse: 0.01925 |  0:04:35s\n",
      "epoch 54 | loss: 0.01835 | mse_mse: 0.02025 |  0:04:40s\n",
      "epoch 55 | loss: 0.02091 | mse_mse: 0.02422 |  0:04:46s\n",
      "epoch 56 | loss: 0.01927 | mse_mse: 0.01859 |  0:04:51s\n",
      "epoch 57 | loss: 0.02138 | mse_mse: 0.01934 |  0:04:56s\n",
      "epoch 58 | loss: 0.0178  | mse_mse: 0.01816 |  0:05:01s\n",
      "epoch 59 | loss: 0.01664 | mse_mse: 0.01512 |  0:05:07s\n",
      "epoch 60 | loss: 0.01933 | mse_mse: 0.01644 |  0:05:12s\n",
      "epoch 61 | loss: 0.01783 | mse_mse: 0.01536 |  0:05:16s\n",
      "epoch 62 | loss: 0.01603 | mse_mse: 0.01386 |  0:05:21s\n",
      "epoch 63 | loss: 0.01328 | mse_mse: 0.01101 |  0:05:25s\n",
      "epoch 64 | loss: 0.01506 | mse_mse: 0.01027 |  0:05:30s\n",
      "epoch 65 | loss: 0.01814 | mse_mse: 0.01171 |  0:05:34s\n",
      "epoch 66 | loss: 0.0138  | mse_mse: 0.00969 |  0:05:39s\n",
      "epoch 67 | loss: 0.01158 | mse_mse: 0.00902 |  0:05:44s\n",
      "epoch 68 | loss: 0.01195 | mse_mse: 0.01093 |  0:05:49s\n",
      "epoch 69 | loss: 0.01207 | mse_mse: 0.00979 |  0:05:54s\n",
      "epoch 70 | loss: 0.01046 | mse_mse: 0.01066 |  0:06:00s\n",
      "epoch 71 | loss: 0.01255 | mse_mse: 0.00889 |  0:06:05s\n",
      "epoch 72 | loss: 0.0121  | mse_mse: 0.00841 |  0:06:10s\n",
      "epoch 73 | loss: 0.01399 | mse_mse: 0.01653 |  0:06:15s\n",
      "epoch 74 | loss: 0.01383 | mse_mse: 0.01281 |  0:06:21s\n",
      "epoch 75 | loss: 0.01198 | mse_mse: 0.01164 |  0:06:26s\n",
      "epoch 76 | loss: 0.01354 | mse_mse: 0.00953 |  0:06:32s\n",
      "epoch 77 | loss: 0.01467 | mse_mse: 0.01181 |  0:06:37s\n",
      "epoch 78 | loss: 0.01573 | mse_mse: 0.01217 |  0:06:44s\n",
      "epoch 79 | loss: 0.01486 | mse_mse: 0.00897 |  0:06:49s\n",
      "epoch 80 | loss: 0.01974 | mse_mse: 0.02122 |  0:06:54s\n",
      "epoch 81 | loss: 0.02272 | mse_mse: 0.02704 |  0:06:59s\n",
      "epoch 82 | loss: 0.01731 | mse_mse: 0.01414 |  0:07:04s\n",
      "\n",
      "Early stopping occurred at epoch 82 with best_epoch = 72 and best_mse_mse = 0.00841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008476534000123957\n",
      "R2 Score: 0.9617598981573325\n",
      "\n",
      "Iteration 10/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.36704 | mse_mse: 0.82886 |  0:00:05s\n",
      "epoch 1  | loss: 0.3425  | mse_mse: 0.3871  |  0:00:10s\n",
      "epoch 2  | loss: 0.19013 | mse_mse: 0.31379 |  0:00:15s\n",
      "epoch 3  | loss: 0.16329 | mse_mse: 0.16232 |  0:00:20s\n",
      "epoch 4  | loss: 0.11033 | mse_mse: 0.16426 |  0:00:24s\n",
      "epoch 5  | loss: 0.09682 | mse_mse: 0.12854 |  0:00:29s\n",
      "epoch 6  | loss: 0.09176 | mse_mse: 0.11181 |  0:00:34s\n",
      "epoch 7  | loss: 0.07655 | mse_mse: 0.09576 |  0:00:40s\n",
      "epoch 8  | loss: 0.07204 | mse_mse: 0.11358 |  0:00:45s\n",
      "epoch 9  | loss: 0.07389 | mse_mse: 0.09843 |  0:00:50s\n",
      "epoch 10 | loss: 0.06461 | mse_mse: 0.0639  |  0:00:54s\n",
      "epoch 11 | loss: 0.06114 | mse_mse: 0.06263 |  0:00:59s\n",
      "epoch 12 | loss: 0.0578  | mse_mse: 0.05804 |  0:01:04s\n",
      "epoch 13 | loss: 0.06046 | mse_mse: 0.09793 |  0:01:09s\n",
      "epoch 14 | loss: 0.05515 | mse_mse: 0.05748 |  0:01:14s\n",
      "epoch 15 | loss: 0.04821 | mse_mse: 0.04234 |  0:01:19s\n",
      "epoch 16 | loss: 0.04246 | mse_mse: 0.04083 |  0:01:25s\n",
      "epoch 17 | loss: 0.04066 | mse_mse: 0.03797 |  0:01:30s\n",
      "epoch 18 | loss: 0.03827 | mse_mse: 0.03185 |  0:01:35s\n",
      "epoch 19 | loss: 0.03212 | mse_mse: 0.02527 |  0:01:40s\n",
      "epoch 20 | loss: 0.03171 | mse_mse: 0.03119 |  0:01:45s\n",
      "epoch 21 | loss: 0.03392 | mse_mse: 0.0366  |  0:01:50s\n",
      "epoch 22 | loss: 0.03517 | mse_mse: 0.03043 |  0:01:55s\n",
      "epoch 23 | loss: 0.03145 | mse_mse: 0.02613 |  0:02:00s\n",
      "epoch 24 | loss: 0.0279  | mse_mse: 0.02134 |  0:02:05s\n",
      "epoch 25 | loss: 0.02599 | mse_mse: 0.02057 |  0:02:10s\n",
      "epoch 26 | loss: 0.02228 | mse_mse: 0.01992 |  0:02:16s\n",
      "epoch 27 | loss: 0.02207 | mse_mse: 0.02021 |  0:02:21s\n",
      "epoch 28 | loss: 0.02031 | mse_mse: 0.01772 |  0:02:26s\n",
      "epoch 29 | loss: 0.01992 | mse_mse: 0.01562 |  0:02:31s\n",
      "epoch 30 | loss: 0.02041 | mse_mse: 0.0173  |  0:02:36s\n",
      "epoch 31 | loss: 0.01795 | mse_mse: 0.01505 |  0:02:41s\n",
      "epoch 32 | loss: 0.01875 | mse_mse: 0.01894 |  0:02:45s\n",
      "epoch 33 | loss: 0.01782 | mse_mse: 0.02219 |  0:02:49s\n",
      "epoch 34 | loss: 0.01893 | mse_mse: 0.0125  |  0:02:54s\n",
      "epoch 35 | loss: 0.01415 | mse_mse: 0.01201 |  0:02:58s\n",
      "epoch 36 | loss: 0.01543 | mse_mse: 0.01486 |  0:03:03s\n",
      "epoch 37 | loss: 0.01588 | mse_mse: 0.02219 |  0:03:07s\n",
      "epoch 38 | loss: 0.01924 | mse_mse: 0.01468 |  0:03:11s\n",
      "epoch 39 | loss: 0.01457 | mse_mse: 0.01077 |  0:03:16s\n",
      "epoch 40 | loss: 0.01622 | mse_mse: 0.01424 |  0:03:21s\n",
      "epoch 41 | loss: 0.01333 | mse_mse: 0.01095 |  0:03:25s\n",
      "epoch 42 | loss: 0.01321 | mse_mse: 0.01152 |  0:03:30s\n",
      "epoch 43 | loss: 0.01496 | mse_mse: 0.01528 |  0:03:34s\n",
      "epoch 44 | loss: 0.01292 | mse_mse: 0.00782 |  0:03:39s\n",
      "epoch 45 | loss: 0.01252 | mse_mse: 0.00965 |  0:03:44s\n",
      "epoch 46 | loss: 0.01162 | mse_mse: 0.00736 |  0:03:49s\n",
      "epoch 47 | loss: 0.01496 | mse_mse: 0.01332 |  0:03:54s\n",
      "epoch 48 | loss: 0.01201 | mse_mse: 0.01218 |  0:03:59s\n",
      "epoch 49 | loss: 0.01322 | mse_mse: 0.00662 |  0:04:04s\n",
      "epoch 50 | loss: 0.01635 | mse_mse: 0.00696 |  0:04:09s\n",
      "epoch 51 | loss: 0.01369 | mse_mse: 0.00633 |  0:04:15s\n",
      "epoch 52 | loss: 0.01162 | mse_mse: 0.01917 |  0:04:20s\n",
      "epoch 53 | loss: 0.01257 | mse_mse: 0.00979 |  0:04:25s\n",
      "epoch 54 | loss: 0.01023 | mse_mse: 0.00648 |  0:04:30s\n",
      "epoch 55 | loss: 0.01045 | mse_mse: 0.00758 |  0:04:36s\n",
      "epoch 56 | loss: 0.01042 | mse_mse: 0.00726 |  0:04:41s\n",
      "epoch 57 | loss: 0.00962 | mse_mse: 0.00723 |  0:04:46s\n",
      "epoch 58 | loss: 0.0103  | mse_mse: 0.01903 |  0:04:51s\n",
      "epoch 59 | loss: 0.01097 | mse_mse: 0.0058  |  0:04:56s\n",
      "epoch 60 | loss: 0.00947 | mse_mse: 0.00877 |  0:05:01s\n",
      "epoch 61 | loss: 0.01067 | mse_mse: 0.01192 |  0:05:06s\n",
      "epoch 62 | loss: 0.01034 | mse_mse: 0.00702 |  0:05:11s\n",
      "epoch 63 | loss: 0.00973 | mse_mse: 0.00762 |  0:05:16s\n",
      "epoch 64 | loss: 0.00944 | mse_mse: 0.01778 |  0:05:22s\n",
      "epoch 65 | loss: 0.01156 | mse_mse: 0.00694 |  0:05:28s\n",
      "epoch 66 | loss: 0.01395 | mse_mse: 0.01904 |  0:05:35s\n",
      "epoch 67 | loss: 0.01037 | mse_mse: 0.01057 |  0:05:40s\n",
      "epoch 68 | loss: 0.00832 | mse_mse: 0.00579 |  0:05:46s\n",
      "epoch 69 | loss: 0.01412 | mse_mse: 0.02671 |  0:05:51s\n",
      "epoch 70 | loss: 0.01183 | mse_mse: 0.00851 |  0:05:56s\n",
      "epoch 71 | loss: 0.00903 | mse_mse: 0.00628 |  0:06:01s\n",
      "epoch 72 | loss: 0.00966 | mse_mse: 0.0069  |  0:06:06s\n",
      "epoch 73 | loss: 0.00834 | mse_mse: 0.00955 |  0:06:12s\n",
      "epoch 74 | loss: 0.00902 | mse_mse: 0.00554 |  0:06:17s\n",
      "epoch 75 | loss: 0.01103 | mse_mse: 0.0067  |  0:06:21s\n",
      "epoch 76 | loss: 0.00895 | mse_mse: 0.00722 |  0:06:26s\n",
      "epoch 77 | loss: 0.00758 | mse_mse: 0.00906 |  0:06:30s\n",
      "epoch 78 | loss: 0.01265 | mse_mse: 0.0081  |  0:06:35s\n",
      "epoch 79 | loss: 0.01127 | mse_mse: 0.00893 |  0:06:40s\n",
      "epoch 80 | loss: 0.00964 | mse_mse: 0.01137 |  0:06:45s\n",
      "epoch 81 | loss: 0.01215 | mse_mse: 0.00647 |  0:06:50s\n",
      "epoch 82 | loss: 0.01093 | mse_mse: 0.01181 |  0:06:54s\n",
      "epoch 83 | loss: 0.00903 | mse_mse: 0.0077  |  0:06:59s\n",
      "epoch 84 | loss: 0.01451 | mse_mse: 0.01479 |  0:07:04s\n",
      "\n",
      "Early stopping occurred at epoch 84 with best_epoch = 74 and best_mse_mse = 0.00554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.005519272542453411\n",
      "R2 Score: 0.9751009617707225\n",
      "Best model updated\n",
      "\n",
      "Iteration 11/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.97343 | mse_mse: 0.58833 |  0:00:05s\n",
      "epoch 1  | loss: 0.39566 | mse_mse: 0.31607 |  0:00:10s\n",
      "epoch 2  | loss: 0.19627 | mse_mse: 0.2992  |  0:00:16s\n",
      "epoch 3  | loss: 0.16083 | mse_mse: 0.24725 |  0:00:22s\n",
      "epoch 4  | loss: 0.17123 | mse_mse: 0.20724 |  0:00:27s\n",
      "epoch 5  | loss: 0.0951  | mse_mse: 0.15123 |  0:00:33s\n",
      "epoch 6  | loss: 0.09066 | mse_mse: 0.09839 |  0:00:39s\n",
      "epoch 7  | loss: 0.07716 | mse_mse: 0.14297 |  0:00:46s\n",
      "epoch 8  | loss: 0.07603 | mse_mse: 0.10498 |  0:00:52s\n",
      "epoch 9  | loss: 0.06728 | mse_mse: 0.08368 |  0:00:58s\n",
      "epoch 10 | loss: 0.06684 | mse_mse: 0.08138 |  0:01:04s\n",
      "epoch 11 | loss: 0.06392 | mse_mse: 0.07639 |  0:01:11s\n",
      "epoch 12 | loss: 0.06569 | mse_mse: 0.07174 |  0:01:17s\n",
      "epoch 13 | loss: 0.06597 | mse_mse: 0.06419 |  0:01:23s\n",
      "epoch 14 | loss: 0.06473 | mse_mse: 0.07086 |  0:01:29s\n",
      "epoch 15 | loss: 0.06342 | mse_mse: 0.05969 |  0:01:37s\n",
      "epoch 16 | loss: 0.06744 | mse_mse: 0.06905 |  0:01:44s\n",
      "epoch 17 | loss: 0.06119 | mse_mse: 0.06254 |  0:01:52s\n",
      "epoch 18 | loss: 0.06232 | mse_mse: 0.05816 |  0:01:58s\n",
      "epoch 19 | loss: 0.06471 | mse_mse: 0.06324 |  0:02:05s\n",
      "epoch 20 | loss: 0.06911 | mse_mse: 0.06988 |  0:02:11s\n",
      "epoch 21 | loss: 0.06251 | mse_mse: 0.0581  |  0:02:17s\n",
      "epoch 22 | loss: 0.06047 | mse_mse: 0.06352 |  0:02:23s\n",
      "epoch 23 | loss: 0.05893 | mse_mse: 0.04752 |  0:02:29s\n",
      "epoch 24 | loss: 0.0542  | mse_mse: 0.04787 |  0:02:36s\n",
      "epoch 25 | loss: 0.05502 | mse_mse: 0.04709 |  0:02:43s\n",
      "epoch 26 | loss: 0.05139 | mse_mse: 0.04764 |  0:02:49s\n",
      "epoch 27 | loss: 0.04836 | mse_mse: 0.04567 |  0:02:56s\n",
      "epoch 28 | loss: 0.05364 | mse_mse: 0.04144 |  0:03:04s\n",
      "epoch 29 | loss: 0.05218 | mse_mse: 0.04671 |  0:03:11s\n",
      "epoch 30 | loss: 0.04716 | mse_mse: 0.03993 |  0:03:17s\n",
      "epoch 31 | loss: 0.04279 | mse_mse: 0.03876 |  0:03:24s\n",
      "epoch 32 | loss: 0.04359 | mse_mse: 0.03653 |  0:03:30s\n",
      "epoch 33 | loss: 0.04191 | mse_mse: 0.03253 |  0:03:37s\n",
      "epoch 34 | loss: 0.03879 | mse_mse: 0.03326 |  0:03:44s\n",
      "epoch 35 | loss: 0.03544 | mse_mse: 0.03295 |  0:03:50s\n",
      "epoch 36 | loss: 0.03592 | mse_mse: 0.02845 |  0:03:56s\n",
      "epoch 37 | loss: 0.03572 | mse_mse: 0.0404  |  0:04:03s\n",
      "epoch 38 | loss: 0.04085 | mse_mse: 0.02982 |  0:04:09s\n",
      "epoch 39 | loss: 0.0336  | mse_mse: 0.03269 |  0:04:16s\n",
      "epoch 40 | loss: 0.0312  | mse_mse: 0.0309  |  0:04:22s\n",
      "epoch 41 | loss: 0.03535 | mse_mse: 0.03376 |  0:04:28s\n",
      "epoch 42 | loss: 0.03249 | mse_mse: 0.02842 |  0:04:35s\n",
      "epoch 43 | loss: 0.02882 | mse_mse: 0.02243 |  0:04:41s\n",
      "epoch 44 | loss: 0.02754 | mse_mse: 0.02906 |  0:04:47s\n",
      "epoch 45 | loss: 0.02249 | mse_mse: 0.02426 |  0:04:54s\n",
      "epoch 46 | loss: 0.02693 | mse_mse: 0.02484 |  0:05:00s\n",
      "epoch 47 | loss: 0.0244  | mse_mse: 0.01579 |  0:05:06s\n",
      "epoch 48 | loss: 0.01974 | mse_mse: 0.01491 |  0:05:13s\n",
      "epoch 49 | loss: 0.02508 | mse_mse: 0.02609 |  0:05:19s\n",
      "epoch 50 | loss: 0.01779 | mse_mse: 0.01383 |  0:05:26s\n",
      "epoch 51 | loss: 0.01868 | mse_mse: 0.0125  |  0:05:32s\n",
      "epoch 52 | loss: 0.0147  | mse_mse: 0.01155 |  0:05:38s\n",
      "epoch 53 | loss: 0.01579 | mse_mse: 0.01933 |  0:05:45s\n",
      "epoch 54 | loss: 0.01572 | mse_mse: 0.0125  |  0:05:51s\n",
      "epoch 55 | loss: 0.01395 | mse_mse: 0.00943 |  0:05:57s\n",
      "epoch 56 | loss: 0.01308 | mse_mse: 0.01179 |  0:06:03s\n",
      "epoch 57 | loss: 0.01707 | mse_mse: 0.01066 |  0:06:09s\n",
      "epoch 58 | loss: 0.01325 | mse_mse: 0.00928 |  0:06:15s\n",
      "epoch 59 | loss: 0.01275 | mse_mse: 0.01067 |  0:06:21s\n",
      "epoch 60 | loss: 0.01766 | mse_mse: 0.00924 |  0:06:28s\n",
      "epoch 61 | loss: 0.01065 | mse_mse: 0.01507 |  0:06:34s\n",
      "epoch 62 | loss: 0.01203 | mse_mse: 0.01582 |  0:06:40s\n",
      "epoch 63 | loss: 0.01655 | mse_mse: 0.01732 |  0:06:46s\n",
      "epoch 64 | loss: 0.01547 | mse_mse: 0.02211 |  0:06:53s\n",
      "epoch 65 | loss: 0.01325 | mse_mse: 0.02028 |  0:07:00s\n",
      "epoch 66 | loss: 0.01523 | mse_mse: 0.00883 |  0:07:06s\n",
      "epoch 67 | loss: 0.01252 | mse_mse: 0.01012 |  0:07:12s\n",
      "epoch 68 | loss: 0.01447 | mse_mse: 0.01398 |  0:07:18s\n",
      "epoch 69 | loss: 0.01245 | mse_mse: 0.00945 |  0:07:26s\n",
      "epoch 70 | loss: 0.01293 | mse_mse: 0.01423 |  0:07:32s\n",
      "epoch 71 | loss: 0.01233 | mse_mse: 0.00752 |  0:07:39s\n",
      "epoch 72 | loss: 0.013   | mse_mse: 0.01378 |  0:07:46s\n",
      "epoch 73 | loss: 0.01519 | mse_mse: 0.01171 |  0:07:53s\n",
      "epoch 74 | loss: 0.01312 | mse_mse: 0.00724 |  0:08:02s\n",
      "epoch 75 | loss: 0.0145  | mse_mse: 0.01197 |  0:08:09s\n",
      "epoch 76 | loss: 0.01164 | mse_mse: 0.00687 |  0:08:16s\n",
      "epoch 77 | loss: 0.01162 | mse_mse: 0.01519 |  0:08:23s\n",
      "epoch 78 | loss: 0.01284 | mse_mse: 0.01219 |  0:08:29s\n",
      "epoch 79 | loss: 0.0115  | mse_mse: 0.00739 |  0:08:36s\n",
      "epoch 80 | loss: 0.01259 | mse_mse: 0.00878 |  0:08:42s\n",
      "epoch 81 | loss: 0.01369 | mse_mse: 0.00805 |  0:08:48s\n",
      "epoch 82 | loss: 0.0106  | mse_mse: 0.00699 |  0:08:54s\n",
      "epoch 83 | loss: 0.01116 | mse_mse: 0.01004 |  0:09:01s\n",
      "epoch 84 | loss: 0.01245 | mse_mse: 0.00688 |  0:09:08s\n",
      "epoch 85 | loss: 0.01239 | mse_mse: 0.01788 |  0:09:14s\n",
      "epoch 86 | loss: 0.0179  | mse_mse: 0.01483 |  0:09:21s\n",
      "\n",
      "Early stopping occurred at epoch 86 with best_epoch = 76 and best_mse_mse = 0.00687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.006802127135397841\n",
      "R2 Score: 0.9693136328597771\n",
      "\n",
      "Iteration 12/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 16 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.22076 | mse_mse: 0.62052 |  0:00:06s\n",
      "epoch 1  | loss: 0.33357 | mse_mse: 0.25624 |  0:00:12s\n",
      "epoch 2  | loss: 0.21278 | mse_mse: 0.15788 |  0:00:19s\n",
      "epoch 3  | loss: 0.25943 | mse_mse: 0.17199 |  0:00:25s\n",
      "epoch 4  | loss: 0.14469 | mse_mse: 0.12924 |  0:00:31s\n",
      "epoch 5  | loss: 0.14549 | mse_mse: 0.1515  |  0:00:38s\n",
      "epoch 6  | loss: 0.14458 | mse_mse: 0.13811 |  0:00:44s\n",
      "epoch 7  | loss: 0.13829 | mse_mse: 0.10534 |  0:00:51s\n",
      "epoch 8  | loss: 0.0976  | mse_mse: 0.08785 |  0:00:58s\n",
      "epoch 9  | loss: 0.09105 | mse_mse: 0.12089 |  0:01:04s\n",
      "epoch 10 | loss: 0.08131 | mse_mse: 0.07759 |  0:01:11s\n",
      "epoch 11 | loss: 0.07218 | mse_mse: 0.0698  |  0:01:17s\n",
      "epoch 12 | loss: 0.08275 | mse_mse: 0.12147 |  0:01:24s\n",
      "epoch 13 | loss: 0.07374 | mse_mse: 0.0737  |  0:01:31s\n",
      "epoch 14 | loss: 0.07436 | mse_mse: 0.06164 |  0:01:37s\n",
      "epoch 15 | loss: 0.07454 | mse_mse: 0.06031 |  0:01:44s\n",
      "epoch 16 | loss: 0.06821 | mse_mse: 0.0634  |  0:01:50s\n",
      "epoch 17 | loss: 0.06835 | mse_mse: 0.06853 |  0:01:57s\n",
      "epoch 18 | loss: 0.06664 | mse_mse: 0.0581  |  0:02:03s\n",
      "epoch 19 | loss: 0.06156 | mse_mse: 0.05371 |  0:02:11s\n",
      "epoch 20 | loss: 0.05595 | mse_mse: 0.05422 |  0:02:17s\n",
      "epoch 21 | loss: 0.05778 | mse_mse: 0.04715 |  0:02:24s\n",
      "epoch 22 | loss: 0.04907 | mse_mse: 0.04364 |  0:02:33s\n",
      "epoch 23 | loss: 0.04405 | mse_mse: 0.03904 |  0:02:40s\n",
      "epoch 24 | loss: 0.05127 | mse_mse: 0.04785 |  0:02:47s\n",
      "epoch 25 | loss: 0.04387 | mse_mse: 0.04882 |  0:02:54s\n",
      "epoch 26 | loss: 0.03982 | mse_mse: 0.03624 |  0:03:01s\n",
      "epoch 27 | loss: 0.03728 | mse_mse: 0.03521 |  0:03:08s\n",
      "epoch 28 | loss: 0.03512 | mse_mse: 0.0283  |  0:03:15s\n",
      "epoch 29 | loss: 0.03564 | mse_mse: 0.03805 |  0:03:22s\n",
      "epoch 30 | loss: 0.0334  | mse_mse: 0.02481 |  0:03:29s\n",
      "epoch 31 | loss: 0.02971 | mse_mse: 0.02407 |  0:03:36s\n",
      "epoch 32 | loss: 0.02931 | mse_mse: 0.02079 |  0:03:44s\n",
      "epoch 33 | loss: 0.03074 | mse_mse: 0.02693 |  0:03:51s\n",
      "epoch 34 | loss: 0.03256 | mse_mse: 0.03003 |  0:03:58s\n",
      "epoch 35 | loss: 0.03264 | mse_mse: 0.03029 |  0:04:05s\n",
      "epoch 36 | loss: 0.02828 | mse_mse: 0.03538 |  0:04:12s\n",
      "epoch 37 | loss: 0.02441 | mse_mse: 0.02347 |  0:04:19s\n",
      "epoch 38 | loss: 0.02168 | mse_mse: 0.02807 |  0:04:25s\n",
      "epoch 39 | loss: 0.02397 | mse_mse: 0.01933 |  0:04:32s\n",
      "epoch 40 | loss: 0.02329 | mse_mse: 0.03283 |  0:04:39s\n",
      "epoch 41 | loss: 0.02392 | mse_mse: 0.02454 |  0:04:45s\n",
      "epoch 42 | loss: 0.02055 | mse_mse: 0.01898 |  0:04:52s\n",
      "epoch 43 | loss: 0.02072 | mse_mse: 0.01569 |  0:04:58s\n",
      "epoch 44 | loss: 0.02094 | mse_mse: 0.01649 |  0:05:05s\n",
      "epoch 45 | loss: 0.02044 | mse_mse: 0.01656 |  0:05:11s\n",
      "epoch 46 | loss: 0.01987 | mse_mse: 0.01724 |  0:05:18s\n",
      "epoch 47 | loss: 0.01864 | mse_mse: 0.01756 |  0:05:24s\n",
      "epoch 48 | loss: 0.02306 | mse_mse: 0.01729 |  0:05:31s\n",
      "epoch 49 | loss: 0.0209  | mse_mse: 0.01752 |  0:05:38s\n",
      "epoch 50 | loss: 0.02027 | mse_mse: 0.01429 |  0:05:45s\n",
      "epoch 51 | loss: 0.01707 | mse_mse: 0.01377 |  0:05:51s\n",
      "epoch 52 | loss: 0.01601 | mse_mse: 0.01355 |  0:05:58s\n",
      "epoch 53 | loss: 0.01686 | mse_mse: 0.01385 |  0:06:05s\n",
      "epoch 54 | loss: 0.02485 | mse_mse: 0.03142 |  0:06:11s\n",
      "epoch 55 | loss: 0.02322 | mse_mse: 0.01783 |  0:06:18s\n",
      "epoch 56 | loss: 0.02059 | mse_mse: 0.01505 |  0:06:25s\n",
      "epoch 57 | loss: 0.01907 | mse_mse: 0.01382 |  0:06:32s\n",
      "epoch 58 | loss: 0.01559 | mse_mse: 0.01143 |  0:06:39s\n",
      "epoch 59 | loss: 0.0154  | mse_mse: 0.011   |  0:06:46s\n",
      "epoch 60 | loss: 0.01805 | mse_mse: 0.01386 |  0:06:54s\n",
      "epoch 61 | loss: 0.01839 | mse_mse: 0.01106 |  0:07:01s\n",
      "epoch 62 | loss: 0.01479 | mse_mse: 0.01083 |  0:07:08s\n",
      "epoch 63 | loss: 0.01211 | mse_mse: 0.01009 |  0:07:16s\n",
      "epoch 64 | loss: 0.01434 | mse_mse: 0.01111 |  0:07:22s\n",
      "epoch 65 | loss: 0.01283 | mse_mse: 0.00937 |  0:07:29s\n",
      "epoch 66 | loss: 0.0159  | mse_mse: 0.01141 |  0:07:36s\n",
      "epoch 67 | loss: 0.01178 | mse_mse: 0.00957 |  0:07:43s\n",
      "epoch 68 | loss: 0.01141 | mse_mse: 0.0075  |  0:07:50s\n",
      "epoch 69 | loss: 0.01193 | mse_mse: 0.00974 |  0:07:58s\n",
      "epoch 70 | loss: 0.0114  | mse_mse: 0.02664 |  0:08:05s\n",
      "epoch 71 | loss: 0.01212 | mse_mse: 0.00719 |  0:08:12s\n",
      "epoch 72 | loss: 0.01335 | mse_mse: 0.03199 |  0:08:18s\n",
      "epoch 73 | loss: 0.01862 | mse_mse: 0.01206 |  0:08:25s\n",
      "epoch 74 | loss: 0.01043 | mse_mse: 0.00692 |  0:08:32s\n",
      "epoch 75 | loss: 0.00964 | mse_mse: 0.00746 |  0:08:39s\n",
      "epoch 76 | loss: 0.00969 | mse_mse: 0.01006 |  0:08:46s\n",
      "epoch 77 | loss: 0.01067 | mse_mse: 0.00716 |  0:08:53s\n",
      "epoch 78 | loss: 0.01041 | mse_mse: 0.00914 |  0:09:00s\n",
      "epoch 79 | loss: 0.0116  | mse_mse: 0.01007 |  0:09:07s\n",
      "epoch 80 | loss: 0.00961 | mse_mse: 0.01366 |  0:09:14s\n",
      "epoch 81 | loss: 0.01254 | mse_mse: 0.01063 |  0:09:22s\n",
      "epoch 82 | loss: 0.01035 | mse_mse: 0.00612 |  0:09:29s\n",
      "epoch 83 | loss: 0.0084  | mse_mse: 0.01003 |  0:09:36s\n",
      "epoch 84 | loss: 0.01027 | mse_mse: 0.00602 |  0:09:43s\n",
      "epoch 85 | loss: 0.01326 | mse_mse: 0.01329 |  0:09:49s\n",
      "epoch 86 | loss: 0.01093 | mse_mse: 0.0094  |  0:09:56s\n",
      "epoch 87 | loss: 0.01454 | mse_mse: 0.00841 |  0:10:02s\n",
      "epoch 88 | loss: 0.01874 | mse_mse: 0.26608 |  0:10:09s\n",
      "epoch 89 | loss: 0.02689 | mse_mse: 0.01888 |  0:10:16s\n",
      "epoch 90 | loss: 0.01588 | mse_mse: 0.01221 |  0:10:23s\n",
      "epoch 91 | loss: 0.01354 | mse_mse: 0.0171  |  0:10:30s\n",
      "epoch 92 | loss: 0.0127  | mse_mse: 0.01215 |  0:10:36s\n",
      "epoch 93 | loss: 0.01123 | mse_mse: 0.01396 |  0:10:42s\n",
      "epoch 94 | loss: 0.01159 | mse_mse: 0.01406 |  0:10:49s\n",
      "\n",
      "Early stopping occurred at epoch 94 with best_epoch = 84 and best_mse_mse = 0.00602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.006241429584135391\n",
      "R2 Score: 0.971843102034666\n",
      "\n",
      "Iteration 13/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.51918 | mse_mse: 0.96642 |  0:00:02s\n",
      "epoch 1  | loss: 0.21863 | mse_mse: 0.43272 |  0:00:06s\n",
      "epoch 2  | loss: 0.10517 | mse_mse: 0.16422 |  0:00:13s\n",
      "epoch 3  | loss: 0.06937 | mse_mse: 0.12628 |  0:00:18s\n",
      "epoch 4  | loss: 0.06014 | mse_mse: 0.09761 |  0:00:22s\n",
      "epoch 5  | loss: 0.05546 | mse_mse: 0.09849 |  0:00:26s\n",
      "epoch 6  | loss: 0.04907 | mse_mse: 0.08057 |  0:00:30s\n",
      "epoch 7  | loss: 0.04523 | mse_mse: 0.0831  |  0:00:34s\n",
      "epoch 8  | loss: 0.04147 | mse_mse: 0.05806 |  0:00:38s\n",
      "epoch 9  | loss: 0.04246 | mse_mse: 0.06121 |  0:00:41s\n",
      "epoch 10 | loss: 0.04096 | mse_mse: 0.04098 |  0:00:45s\n",
      "epoch 11 | loss: 0.03494 | mse_mse: 0.05168 |  0:00:49s\n",
      "epoch 12 | loss: 0.03326 | mse_mse: 0.03248 |  0:00:52s\n",
      "epoch 13 | loss: 0.03176 | mse_mse: 0.02691 |  0:00:55s\n",
      "epoch 14 | loss: 0.02996 | mse_mse: 0.02744 |  0:01:00s\n",
      "epoch 15 | loss: 0.02794 | mse_mse: 0.02425 |  0:01:04s\n",
      "epoch 16 | loss: 0.02436 | mse_mse: 0.0208  |  0:01:07s\n",
      "epoch 17 | loss: 0.02476 | mse_mse: 0.02195 |  0:01:11s\n",
      "epoch 18 | loss: 0.02282 | mse_mse: 0.02497 |  0:01:15s\n",
      "epoch 19 | loss: 0.02283 | mse_mse: 0.01857 |  0:01:18s\n",
      "epoch 20 | loss: 0.02158 | mse_mse: 0.01635 |  0:01:22s\n",
      "epoch 21 | loss: 0.0199  | mse_mse: 0.01482 |  0:01:25s\n",
      "epoch 22 | loss: 0.02137 | mse_mse: 0.01722 |  0:01:29s\n",
      "epoch 23 | loss: 0.02112 | mse_mse: 0.02645 |  0:01:33s\n",
      "epoch 24 | loss: 0.02097 | mse_mse: 0.02361 |  0:01:37s\n",
      "epoch 25 | loss: 0.03266 | mse_mse: 0.02569 |  0:01:41s\n",
      "epoch 26 | loss: 0.02629 | mse_mse: 0.02498 |  0:01:45s\n",
      "epoch 27 | loss: 0.02159 | mse_mse: 0.02771 |  0:01:49s\n",
      "epoch 28 | loss: 0.02016 | mse_mse: 0.01811 |  0:01:54s\n",
      "epoch 29 | loss: 0.01867 | mse_mse: 0.01629 |  0:01:58s\n",
      "epoch 30 | loss: 0.01719 | mse_mse: 0.01216 |  0:02:02s\n",
      "epoch 31 | loss: 0.01737 | mse_mse: 0.02016 |  0:02:06s\n",
      "epoch 32 | loss: 0.01718 | mse_mse: 0.01152 |  0:02:10s\n",
      "epoch 33 | loss: 0.01939 | mse_mse: 0.01263 |  0:02:14s\n",
      "epoch 34 | loss: 0.01408 | mse_mse: 0.01046 |  0:02:18s\n",
      "epoch 35 | loss: 0.01507 | mse_mse: 0.01355 |  0:02:21s\n",
      "epoch 36 | loss: 0.01544 | mse_mse: 0.01065 |  0:02:25s\n",
      "epoch 37 | loss: 0.01344 | mse_mse: 0.00864 |  0:02:28s\n",
      "epoch 38 | loss: 0.01199 | mse_mse: 0.00844 |  0:02:32s\n",
      "epoch 39 | loss: 0.01145 | mse_mse: 0.01303 |  0:02:36s\n",
      "epoch 40 | loss: 0.01466 | mse_mse: 0.01057 |  0:02:40s\n",
      "epoch 41 | loss: 0.01705 | mse_mse: 0.02872 |  0:02:43s\n",
      "epoch 42 | loss: 0.01496 | mse_mse: 0.01099 |  0:02:47s\n",
      "epoch 43 | loss: 0.01167 | mse_mse: 0.00793 |  0:02:50s\n",
      "epoch 44 | loss: 0.01305 | mse_mse: 0.00917 |  0:02:54s\n",
      "epoch 45 | loss: 0.00979 | mse_mse: 0.01015 |  0:02:57s\n",
      "epoch 46 | loss: 0.01389 | mse_mse: 0.01132 |  0:03:01s\n",
      "epoch 47 | loss: 0.01366 | mse_mse: 0.01063 |  0:03:05s\n",
      "epoch 48 | loss: 0.01267 | mse_mse: 0.00638 |  0:03:08s\n",
      "epoch 49 | loss: 0.01084 | mse_mse: 0.00674 |  0:03:12s\n",
      "epoch 50 | loss: 0.01006 | mse_mse: 0.00688 |  0:03:16s\n",
      "epoch 51 | loss: 0.00991 | mse_mse: 0.00904 |  0:03:19s\n",
      "epoch 52 | loss: 0.01073 | mse_mse: 0.0076  |  0:03:23s\n",
      "epoch 53 | loss: 0.0103  | mse_mse: 0.00681 |  0:03:26s\n",
      "epoch 54 | loss: 0.00881 | mse_mse: 0.00573 |  0:03:29s\n",
      "epoch 55 | loss: 0.00892 | mse_mse: 0.00595 |  0:03:33s\n",
      "epoch 56 | loss: 0.01013 | mse_mse: 0.0064  |  0:03:36s\n",
      "epoch 57 | loss: 0.00999 | mse_mse: 0.00826 |  0:03:39s\n",
      "epoch 58 | loss: 0.00881 | mse_mse: 0.00718 |  0:03:42s\n",
      "epoch 59 | loss: 0.00959 | mse_mse: 0.00639 |  0:03:46s\n",
      "epoch 60 | loss: 0.01025 | mse_mse: 0.01101 |  0:03:49s\n",
      "epoch 61 | loss: 0.01428 | mse_mse: 0.00772 |  0:03:52s\n",
      "epoch 62 | loss: 0.01077 | mse_mse: 0.00696 |  0:03:55s\n",
      "epoch 63 | loss: 0.01153 | mse_mse: 0.00617 |  0:03:59s\n",
      "epoch 64 | loss: 0.00857 | mse_mse: 0.00564 |  0:04:02s\n",
      "epoch 65 | loss: 0.0096  | mse_mse: 0.00886 |  0:04:05s\n",
      "epoch 66 | loss: 0.00774 | mse_mse: 0.0076  |  0:04:08s\n",
      "epoch 67 | loss: 0.00812 | mse_mse: 0.00636 |  0:04:11s\n",
      "epoch 68 | loss: 0.00783 | mse_mse: 0.00553 |  0:04:15s\n",
      "epoch 69 | loss: 0.00736 | mse_mse: 0.01209 |  0:04:18s\n",
      "epoch 70 | loss: 0.00906 | mse_mse: 0.0078  |  0:04:21s\n",
      "epoch 71 | loss: 0.00727 | mse_mse: 0.00649 |  0:04:24s\n",
      "epoch 72 | loss: 0.00823 | mse_mse: 0.01009 |  0:04:28s\n",
      "epoch 73 | loss: 0.00959 | mse_mse: 0.00869 |  0:04:31s\n",
      "epoch 74 | loss: 0.00993 | mse_mse: 0.00554 |  0:04:34s\n",
      "epoch 75 | loss: 0.00808 | mse_mse: 0.0092  |  0:04:38s\n",
      "epoch 76 | loss: 0.00828 | mse_mse: 0.00738 |  0:04:41s\n",
      "epoch 77 | loss: 0.00772 | mse_mse: 0.0093  |  0:04:44s\n",
      "epoch 78 | loss: 0.00755 | mse_mse: 0.00572 |  0:04:48s\n",
      "\n",
      "Early stopping occurred at epoch 78 with best_epoch = 68 and best_mse_mse = 0.00553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.005571695833547698\n",
      "R2 Score: 0.9748644651094287\n",
      "\n",
      "Iteration 14/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.56758 | mse_mse: 0.4886  |  0:00:03s\n",
      "epoch 1  | loss: 0.15705 | mse_mse: 0.21099 |  0:00:06s\n",
      "epoch 2  | loss: 0.0898  | mse_mse: 0.18421 |  0:00:09s\n",
      "epoch 3  | loss: 0.067   | mse_mse: 0.14872 |  0:00:12s\n",
      "epoch 4  | loss: 0.06382 | mse_mse: 0.12313 |  0:00:16s\n",
      "epoch 5  | loss: 0.05509 | mse_mse: 0.09069 |  0:00:19s\n",
      "epoch 6  | loss: 0.04694 | mse_mse: 0.0854  |  0:00:22s\n",
      "epoch 7  | loss: 0.04202 | mse_mse: 0.06773 |  0:00:26s\n",
      "epoch 8  | loss: 0.03721 | mse_mse: 0.06061 |  0:00:29s\n",
      "epoch 9  | loss: 0.03531 | mse_mse: 0.04647 |  0:00:32s\n",
      "epoch 10 | loss: 0.03764 | mse_mse: 0.04077 |  0:00:36s\n",
      "epoch 11 | loss: 0.03351 | mse_mse: 0.04571 |  0:00:39s\n",
      "epoch 12 | loss: 0.03094 | mse_mse: 0.03499 |  0:00:43s\n",
      "epoch 13 | loss: 0.02831 | mse_mse: 0.02773 |  0:00:46s\n",
      "epoch 14 | loss: 0.02667 | mse_mse: 0.02155 |  0:00:50s\n",
      "epoch 15 | loss: 0.02358 | mse_mse: 0.02323 |  0:00:53s\n",
      "epoch 16 | loss: 0.02135 | mse_mse: 0.02278 |  0:00:57s\n",
      "epoch 17 | loss: 0.02101 | mse_mse: 0.02422 |  0:01:00s\n",
      "epoch 18 | loss: 0.02181 | mse_mse: 0.03384 |  0:01:03s\n",
      "epoch 19 | loss: 0.02343 | mse_mse: 0.01906 |  0:01:07s\n",
      "epoch 20 | loss: 0.01871 | mse_mse: 0.011   |  0:01:10s\n",
      "epoch 21 | loss: 0.01537 | mse_mse: 0.01307 |  0:01:14s\n",
      "epoch 22 | loss: 0.01505 | mse_mse: 0.01454 |  0:01:17s\n",
      "epoch 23 | loss: 0.0159  | mse_mse: 0.01278 |  0:01:21s\n",
      "epoch 24 | loss: 0.0141  | mse_mse: 0.01477 |  0:01:24s\n",
      "epoch 25 | loss: 0.01691 | mse_mse: 0.01988 |  0:01:27s\n",
      "epoch 26 | loss: 0.01311 | mse_mse: 0.01153 |  0:01:31s\n",
      "epoch 27 | loss: 0.01287 | mse_mse: 0.00958 |  0:01:34s\n",
      "epoch 28 | loss: 0.01251 | mse_mse: 0.01237 |  0:01:38s\n",
      "epoch 29 | loss: 0.01305 | mse_mse: 0.0124  |  0:01:41s\n",
      "epoch 30 | loss: 0.01176 | mse_mse: 0.00777 |  0:01:44s\n",
      "epoch 31 | loss: 0.01042 | mse_mse: 0.01028 |  0:01:48s\n",
      "epoch 32 | loss: 0.01197 | mse_mse: 0.01046 |  0:01:51s\n",
      "epoch 33 | loss: 0.01241 | mse_mse: 0.01088 |  0:01:54s\n",
      "epoch 34 | loss: 0.0129  | mse_mse: 0.00975 |  0:01:58s\n",
      "epoch 35 | loss: 0.01368 | mse_mse: 0.00888 |  0:02:01s\n",
      "epoch 36 | loss: 0.01195 | mse_mse: 0.00978 |  0:02:04s\n",
      "epoch 37 | loss: 0.01174 | mse_mse: 0.01711 |  0:02:08s\n",
      "epoch 38 | loss: 0.01282 | mse_mse: 0.0086  |  0:02:11s\n",
      "epoch 39 | loss: 0.01016 | mse_mse: 0.00781 |  0:02:15s\n",
      "epoch 40 | loss: 0.0099  | mse_mse: 0.00786 |  0:02:18s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_mse_mse = 0.00777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00826054459791774\n",
      "R2 Score: 0.9627342889563527\n",
      "\n",
      "Iteration 15/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.70828 | mse_mse: 0.58028 |  0:00:05s\n",
      "epoch 1  | loss: 0.24481 | mse_mse: 0.36629 |  0:00:10s\n",
      "epoch 2  | loss: 0.16449 | mse_mse: 0.15725 |  0:00:15s\n",
      "epoch 3  | loss: 0.13786 | mse_mse: 0.17461 |  0:00:20s\n",
      "epoch 4  | loss: 0.09318 | mse_mse: 0.13503 |  0:00:25s\n",
      "epoch 5  | loss: 0.07453 | mse_mse: 0.14512 |  0:00:30s\n",
      "epoch 6  | loss: 0.07624 | mse_mse: 0.12913 |  0:00:34s\n",
      "epoch 7  | loss: 0.08513 | mse_mse: 0.14311 |  0:00:39s\n",
      "epoch 8  | loss: 0.07305 | mse_mse: 0.09315 |  0:00:44s\n",
      "epoch 9  | loss: 0.06807 | mse_mse: 0.10356 |  0:00:50s\n",
      "epoch 10 | loss: 0.06649 | mse_mse: 0.09053 |  0:00:55s\n",
      "epoch 11 | loss: 0.06347 | mse_mse: 0.07677 |  0:01:00s\n",
      "epoch 12 | loss: 0.06041 | mse_mse: 0.05958 |  0:01:06s\n",
      "epoch 13 | loss: 0.05336 | mse_mse: 0.05044 |  0:01:11s\n",
      "epoch 14 | loss: 0.05517 | mse_mse: 0.05276 |  0:01:17s\n",
      "epoch 15 | loss: 0.05352 | mse_mse: 0.05413 |  0:01:22s\n",
      "epoch 16 | loss: 0.04677 | mse_mse: 0.03965 |  0:01:27s\n",
      "epoch 17 | loss: 0.05169 | mse_mse: 0.05133 |  0:01:33s\n",
      "epoch 18 | loss: 0.05529 | mse_mse: 0.04907 |  0:01:38s\n",
      "epoch 19 | loss: 0.04786 | mse_mse: 0.0377  |  0:01:43s\n",
      "epoch 20 | loss: 0.04315 | mse_mse: 0.04229 |  0:01:48s\n",
      "epoch 21 | loss: 0.04316 | mse_mse: 0.04979 |  0:01:54s\n",
      "epoch 22 | loss: 0.04248 | mse_mse: 0.04425 |  0:02:00s\n",
      "epoch 23 | loss: 0.04064 | mse_mse: 0.03865 |  0:02:05s\n",
      "epoch 24 | loss: 0.04245 | mse_mse: 0.04224 |  0:02:11s\n",
      "epoch 25 | loss: 0.04043 | mse_mse: 0.03713 |  0:02:16s\n",
      "epoch 26 | loss: 0.03879 | mse_mse: 0.0322  |  0:02:22s\n",
      "epoch 27 | loss: 0.04114 | mse_mse: 0.04507 |  0:02:27s\n",
      "epoch 28 | loss: 0.04315 | mse_mse: 0.05138 |  0:02:33s\n",
      "epoch 29 | loss: 0.03591 | mse_mse: 0.03066 |  0:02:38s\n",
      "epoch 30 | loss: 0.03607 | mse_mse: 0.03185 |  0:02:44s\n",
      "epoch 31 | loss: 0.03676 | mse_mse: 0.02326 |  0:02:49s\n",
      "epoch 32 | loss: 0.02905 | mse_mse: 0.02196 |  0:02:54s\n",
      "epoch 33 | loss: 0.03054 | mse_mse: 0.03282 |  0:03:00s\n",
      "epoch 34 | loss: 0.02771 | mse_mse: 0.02456 |  0:03:06s\n",
      "epoch 35 | loss: 0.0255  | mse_mse: 0.02249 |  0:03:13s\n",
      "epoch 36 | loss: 0.02518 | mse_mse: 0.02015 |  0:03:19s\n",
      "epoch 37 | loss: 0.02435 | mse_mse: 0.02518 |  0:03:25s\n",
      "epoch 38 | loss: 0.02489 | mse_mse: 0.02701 |  0:03:31s\n",
      "epoch 39 | loss: 0.02861 | mse_mse: 0.02935 |  0:03:37s\n",
      "epoch 40 | loss: 0.02177 | mse_mse: 0.01605 |  0:03:42s\n",
      "epoch 41 | loss: 0.02074 | mse_mse: 0.02416 |  0:03:48s\n",
      "epoch 42 | loss: 0.0286  | mse_mse: 0.03624 |  0:03:53s\n",
      "epoch 43 | loss: 0.02176 | mse_mse: 0.02175 |  0:03:59s\n",
      "epoch 44 | loss: 0.02113 | mse_mse: 0.0215  |  0:04:05s\n",
      "epoch 45 | loss: 0.01904 | mse_mse: 0.02144 |  0:04:11s\n",
      "epoch 46 | loss: 0.02187 | mse_mse: 0.02309 |  0:04:17s\n",
      "epoch 47 | loss: 0.02131 | mse_mse: 0.0155  |  0:04:22s\n",
      "epoch 48 | loss: 0.01866 | mse_mse: 0.0178  |  0:04:28s\n",
      "epoch 49 | loss: 0.01794 | mse_mse: 0.0165  |  0:04:34s\n",
      "epoch 50 | loss: 0.01689 | mse_mse: 0.01917 |  0:04:40s\n",
      "epoch 51 | loss: 0.01732 | mse_mse: 0.01172 |  0:04:46s\n",
      "epoch 52 | loss: 0.02047 | mse_mse: 0.03321 |  0:04:52s\n",
      "epoch 53 | loss: 0.01864 | mse_mse: 0.01243 |  0:04:58s\n",
      "epoch 54 | loss: 0.01654 | mse_mse: 0.01573 |  0:05:03s\n",
      "epoch 55 | loss: 0.0145  | mse_mse: 0.01593 |  0:05:09s\n",
      "epoch 56 | loss: 0.01781 | mse_mse: 0.01575 |  0:05:14s\n",
      "epoch 57 | loss: 0.01703 | mse_mse: 0.01174 |  0:05:19s\n",
      "epoch 58 | loss: 0.01406 | mse_mse: 0.00904 |  0:05:24s\n",
      "epoch 59 | loss: 0.01329 | mse_mse: 0.0096  |  0:05:30s\n",
      "epoch 60 | loss: 0.01647 | mse_mse: 0.01012 |  0:05:35s\n",
      "epoch 61 | loss: 0.01151 | mse_mse: 0.00849 |  0:05:41s\n",
      "epoch 62 | loss: 0.01229 | mse_mse: 0.01061 |  0:05:46s\n",
      "epoch 63 | loss: 0.01121 | mse_mse: 0.01044 |  0:05:52s\n",
      "epoch 64 | loss: 0.01471 | mse_mse: 0.01015 |  0:05:57s\n",
      "epoch 65 | loss: 0.01297 | mse_mse: 0.00963 |  0:06:02s\n",
      "epoch 66 | loss: 0.01034 | mse_mse: 0.01021 |  0:06:07s\n",
      "epoch 67 | loss: 0.01197 | mse_mse: 0.0226  |  0:06:12s\n",
      "epoch 68 | loss: 0.01126 | mse_mse: 0.00988 |  0:06:17s\n",
      "epoch 69 | loss: 0.01251 | mse_mse: 0.00999 |  0:06:22s\n",
      "epoch 70 | loss: 0.01372 | mse_mse: 0.01198 |  0:06:28s\n",
      "epoch 71 | loss: 0.01664 | mse_mse: 0.02898 |  0:06:34s\n",
      "\n",
      "Early stopping occurred at epoch 71 with best_epoch = 61 and best_mse_mse = 0.00849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008300509777727505\n",
      "R2 Score: 0.9625539944461126\n",
      "\n",
      "Iteration 16/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 9.60046 | mse_mse: 1.0094  |  0:00:05s\n",
      "epoch 1  | loss: 0.32533 | mse_mse: 0.35932 |  0:00:11s\n",
      "epoch 2  | loss: 0.17018 | mse_mse: 0.25089 |  0:00:16s\n",
      "epoch 3  | loss: 0.12468 | mse_mse: 0.20395 |  0:00:22s\n",
      "epoch 4  | loss: 0.12042 | mse_mse: 0.14022 |  0:00:28s\n",
      "epoch 5  | loss: 0.09716 | mse_mse: 0.11331 |  0:00:34s\n",
      "epoch 6  | loss: 0.08694 | mse_mse: 0.10957 |  0:00:39s\n",
      "epoch 7  | loss: 0.07407 | mse_mse: 0.10915 |  0:00:45s\n",
      "epoch 8  | loss: 0.07438 | mse_mse: 0.09209 |  0:00:50s\n",
      "epoch 9  | loss: 0.06746 | mse_mse: 0.08721 |  0:00:56s\n",
      "epoch 10 | loss: 0.05791 | mse_mse: 0.06031 |  0:01:01s\n",
      "epoch 11 | loss: 0.05206 | mse_mse: 0.05806 |  0:01:07s\n",
      "epoch 12 | loss: 0.04614 | mse_mse: 0.05738 |  0:01:13s\n",
      "epoch 13 | loss: 0.04177 | mse_mse: 0.04668 |  0:01:19s\n",
      "epoch 14 | loss: 0.04355 | mse_mse: 0.04939 |  0:01:25s\n",
      "epoch 15 | loss: 0.03422 | mse_mse: 0.02783 |  0:01:30s\n",
      "epoch 16 | loss: 0.02736 | mse_mse: 0.02297 |  0:01:36s\n",
      "epoch 17 | loss: 0.02556 | mse_mse: 0.02147 |  0:01:42s\n",
      "epoch 18 | loss: 0.02485 | mse_mse: 0.02006 |  0:01:48s\n",
      "epoch 19 | loss: 0.02425 | mse_mse: 0.02202 |  0:01:54s\n",
      "epoch 20 | loss: 0.02419 | mse_mse: 0.01902 |  0:02:00s\n",
      "epoch 21 | loss: 0.01915 | mse_mse: 0.0143  |  0:02:07s\n",
      "epoch 22 | loss: 0.01807 | mse_mse: 0.02695 |  0:02:12s\n",
      "epoch 23 | loss: 0.02421 | mse_mse: 0.02305 |  0:02:18s\n",
      "epoch 24 | loss: 0.01756 | mse_mse: 0.01979 |  0:02:24s\n",
      "epoch 25 | loss: 0.01668 | mse_mse: 0.01832 |  0:02:33s\n",
      "epoch 26 | loss: 0.01474 | mse_mse: 0.00962 |  0:02:42s\n",
      "epoch 27 | loss: 0.01607 | mse_mse: 0.01839 |  0:02:50s\n",
      "epoch 28 | loss: 0.01397 | mse_mse: 0.0099  |  0:02:59s\n",
      "epoch 29 | loss: 0.01503 | mse_mse: 0.03411 |  0:03:06s\n",
      "epoch 30 | loss: 0.01496 | mse_mse: 0.01188 |  0:03:13s\n",
      "epoch 31 | loss: 0.01362 | mse_mse: 0.01702 |  0:03:18s\n",
      "epoch 32 | loss: 0.01288 | mse_mse: 0.01186 |  0:03:24s\n",
      "epoch 33 | loss: 0.01484 | mse_mse: 0.01236 |  0:03:30s\n",
      "epoch 34 | loss: 0.01282 | mse_mse: 0.00866 |  0:03:36s\n",
      "epoch 35 | loss: 0.01076 | mse_mse: 0.00757 |  0:03:42s\n",
      "epoch 36 | loss: 0.01161 | mse_mse: 0.01126 |  0:03:48s\n",
      "epoch 37 | loss: 0.01186 | mse_mse: 0.01406 |  0:03:54s\n",
      "epoch 38 | loss: 0.0138  | mse_mse: 0.00982 |  0:04:00s\n",
      "epoch 39 | loss: 0.01367 | mse_mse: 0.00821 |  0:04:06s\n",
      "epoch 40 | loss: 0.01304 | mse_mse: 0.00819 |  0:04:12s\n",
      "epoch 41 | loss: 0.0104  | mse_mse: 0.00861 |  0:04:17s\n",
      "epoch 42 | loss: 0.01367 | mse_mse: 0.01448 |  0:04:23s\n",
      "epoch 43 | loss: 0.01484 | mse_mse: 0.02206 |  0:04:28s\n",
      "epoch 44 | loss: 0.01113 | mse_mse: 0.02915 |  0:04:34s\n",
      "epoch 45 | loss: 0.01989 | mse_mse: 0.0134  |  0:04:40s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_mse_mse = 0.00757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007189970923107396\n",
      "R2 Score: 0.967563957114851\n",
      "\n",
      "Iteration 17/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 9.39421 | mse_mse: 3.17711 |  0:00:06s\n",
      "epoch 1  | loss: 0.68888 | mse_mse: 0.2711  |  0:00:14s\n",
      "epoch 2  | loss: 0.22994 | mse_mse: 0.23021 |  0:00:21s\n",
      "epoch 3  | loss: 0.18263 | mse_mse: 0.12306 |  0:00:29s\n",
      "epoch 4  | loss: 0.14621 | mse_mse: 0.16747 |  0:00:37s\n",
      "epoch 5  | loss: 0.12223 | mse_mse: 0.13352 |  0:00:45s\n",
      "epoch 6  | loss: 0.11961 | mse_mse: 0.18778 |  0:00:53s\n",
      "epoch 7  | loss: 0.11888 | mse_mse: 0.10828 |  0:01:00s\n",
      "epoch 8  | loss: 0.10626 | mse_mse: 0.09842 |  0:01:08s\n",
      "epoch 9  | loss: 0.1181  | mse_mse: 0.13676 |  0:01:17s\n",
      "epoch 10 | loss: 0.12274 | mse_mse: 0.10115 |  0:01:25s\n",
      "epoch 11 | loss: 0.09534 | mse_mse: 0.07865 |  0:01:32s\n",
      "epoch 12 | loss: 0.09516 | mse_mse: 0.07377 |  0:01:40s\n",
      "epoch 13 | loss: 0.08961 | mse_mse: 0.06957 |  0:01:48s\n",
      "epoch 14 | loss: 0.08888 | mse_mse: 0.07209 |  0:01:55s\n",
      "epoch 15 | loss: 0.08142 | mse_mse: 0.08479 |  0:02:03s\n",
      "epoch 16 | loss: 0.07743 | mse_mse: 0.10273 |  0:02:10s\n",
      "epoch 17 | loss: 0.07124 | mse_mse: 0.04894 |  0:02:18s\n",
      "epoch 18 | loss: 0.05709 | mse_mse: 0.04908 |  0:02:26s\n",
      "epoch 19 | loss: 0.0534  | mse_mse: 0.0411  |  0:02:33s\n",
      "epoch 20 | loss: 0.05139 | mse_mse: 0.03797 |  0:02:41s\n",
      "epoch 21 | loss: 0.04862 | mse_mse: 0.03903 |  0:02:48s\n",
      "epoch 22 | loss: 0.04481 | mse_mse: 0.04418 |  0:02:55s\n",
      "epoch 23 | loss: 0.0443  | mse_mse: 0.03165 |  0:03:03s\n",
      "epoch 24 | loss: 0.04031 | mse_mse: 0.0337  |  0:03:11s\n",
      "epoch 25 | loss: 0.03985 | mse_mse: 0.03836 |  0:03:20s\n",
      "epoch 26 | loss: 0.03338 | mse_mse: 0.03554 |  0:03:28s\n",
      "epoch 27 | loss: 0.03721 | mse_mse: 0.0243  |  0:03:36s\n",
      "epoch 28 | loss: 0.03098 | mse_mse: 0.02353 |  0:03:44s\n",
      "epoch 29 | loss: 0.04041 | mse_mse: 0.07003 |  0:03:52s\n",
      "epoch 30 | loss: 0.03771 | mse_mse: 0.04416 |  0:04:00s\n",
      "epoch 31 | loss: 0.03432 | mse_mse: 0.03029 |  0:04:08s\n",
      "epoch 32 | loss: 0.03581 | mse_mse: 0.035   |  0:04:16s\n",
      "epoch 33 | loss: 0.02843 | mse_mse: 0.02436 |  0:04:23s\n",
      "epoch 34 | loss: 0.02631 | mse_mse: 0.04271 |  0:04:31s\n",
      "epoch 35 | loss: 0.02911 | mse_mse: 0.02283 |  0:04:39s\n",
      "epoch 36 | loss: 0.02477 | mse_mse: 0.01817 |  0:04:47s\n",
      "epoch 37 | loss: 0.0205  | mse_mse: 0.01673 |  0:04:55s\n",
      "epoch 38 | loss: 0.01971 | mse_mse: 0.02116 |  0:05:02s\n",
      "epoch 39 | loss: 0.02223 | mse_mse: 0.01747 |  0:05:10s\n",
      "epoch 40 | loss: 0.02079 | mse_mse: 0.02332 |  0:05:17s\n",
      "epoch 41 | loss: 0.02474 | mse_mse: 0.0416  |  0:05:25s\n",
      "epoch 42 | loss: 0.03008 | mse_mse: 0.02072 |  0:05:33s\n",
      "epoch 43 | loss: 0.04318 | mse_mse: 0.0328  |  0:05:41s\n",
      "epoch 44 | loss: 0.02348 | mse_mse: 0.02086 |  0:05:48s\n",
      "epoch 45 | loss: 0.02394 | mse_mse: 0.01807 |  0:05:56s\n",
      "epoch 46 | loss: 0.02189 | mse_mse: 0.03858 |  0:06:03s\n",
      "epoch 47 | loss: 0.02345 | mse_mse: 0.01516 |  0:06:10s\n",
      "epoch 48 | loss: 0.01697 | mse_mse: 0.01197 |  0:06:18s\n",
      "epoch 49 | loss: 0.02212 | mse_mse: 0.02379 |  0:06:26s\n",
      "epoch 50 | loss: 0.01699 | mse_mse: 0.01203 |  0:06:33s\n",
      "epoch 51 | loss: 0.01602 | mse_mse: 0.01167 |  0:06:40s\n",
      "epoch 52 | loss: 0.0234  | mse_mse: 0.02868 |  0:06:48s\n",
      "epoch 53 | loss: 0.01482 | mse_mse: 0.01143 |  0:06:55s\n",
      "epoch 54 | loss: 0.01254 | mse_mse: 0.01562 |  0:07:03s\n",
      "epoch 55 | loss: 0.01706 | mse_mse: 0.0092  |  0:07:10s\n",
      "epoch 56 | loss: 0.01298 | mse_mse: 0.00884 |  0:07:18s\n",
      "epoch 57 | loss: 0.01169 | mse_mse: 0.00879 |  0:07:25s\n",
      "epoch 58 | loss: 0.01322 | mse_mse: 0.0087  |  0:07:32s\n",
      "epoch 59 | loss: 0.01353 | mse_mse: 0.00779 |  0:07:39s\n",
      "epoch 60 | loss: 0.01227 | mse_mse: 0.01654 |  0:07:47s\n",
      "epoch 61 | loss: 0.02447 | mse_mse: 0.08085 |  0:07:54s\n",
      "epoch 62 | loss: 0.05669 | mse_mse: 0.05837 |  0:08:01s\n",
      "epoch 63 | loss: 0.0467  | mse_mse: 0.08373 |  0:08:09s\n",
      "epoch 64 | loss: 0.04536 | mse_mse: 0.04113 |  0:08:17s\n",
      "epoch 65 | loss: 0.04322 | mse_mse: 0.03258 |  0:08:24s\n",
      "epoch 66 | loss: 0.03726 | mse_mse: 0.06352 |  0:08:33s\n",
      "epoch 67 | loss: 0.03505 | mse_mse: 0.0313  |  0:08:42s\n",
      "epoch 68 | loss: 0.0375  | mse_mse: 0.04676 |  0:08:50s\n",
      "epoch 69 | loss: 0.03822 | mse_mse: 0.0271  |  0:08:58s\n",
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 59 and best_mse_mse = 0.00779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008147093244920703\n",
      "R2 Score: 0.9632461008941957\n",
      "\n",
      "Iteration 18/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 8 - n_a: 32 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.32309 | mse_mse: 0.41788 |  0:00:07s\n",
      "epoch 1  | loss: 0.30282 | mse_mse: 0.20086 |  0:00:15s\n",
      "epoch 2  | loss: 0.15583 | mse_mse: 0.20219 |  0:00:23s\n",
      "epoch 3  | loss: 0.14585 | mse_mse: 0.19721 |  0:00:32s\n",
      "epoch 4  | loss: 0.11804 | mse_mse: 0.15259 |  0:00:40s\n",
      "epoch 5  | loss: 0.08851 | mse_mse: 0.18085 |  0:00:51s\n",
      "epoch 6  | loss: 0.08037 | mse_mse: 0.10742 |  0:01:01s\n",
      "epoch 7  | loss: 0.0741  | mse_mse: 0.13506 |  0:01:10s\n",
      "epoch 8  | loss: 0.065   | mse_mse: 0.10014 |  0:01:19s\n",
      "epoch 9  | loss: 0.06609 | mse_mse: 0.07557 |  0:01:27s\n",
      "epoch 10 | loss: 0.05868 | mse_mse: 0.06614 |  0:01:36s\n",
      "epoch 11 | loss: 0.05788 | mse_mse: 0.05813 |  0:01:45s\n",
      "epoch 12 | loss: 0.06479 | mse_mse: 0.0554  |  0:01:53s\n",
      "epoch 13 | loss: 0.06628 | mse_mse: 0.06445 |  0:02:01s\n",
      "epoch 14 | loss: 0.06957 | mse_mse: 0.0848  |  0:02:09s\n",
      "epoch 15 | loss: 0.07304 | mse_mse: 0.06329 |  0:02:17s\n",
      "epoch 16 | loss: 0.05859 | mse_mse: 0.05869 |  0:02:26s\n",
      "epoch 17 | loss: 0.05422 | mse_mse: 0.07707 |  0:02:34s\n",
      "epoch 18 | loss: 0.05836 | mse_mse: 0.06149 |  0:02:43s\n",
      "epoch 19 | loss: 0.05507 | mse_mse: 0.05283 |  0:02:52s\n",
      "epoch 20 | loss: 0.05671 | mse_mse: 0.06219 |  0:03:01s\n",
      "epoch 21 | loss: 0.06122 | mse_mse: 0.06642 |  0:03:09s\n",
      "epoch 22 | loss: 0.06027 | mse_mse: 0.05325 |  0:03:17s\n",
      "epoch 23 | loss: 0.05507 | mse_mse: 0.04732 |  0:03:24s\n",
      "epoch 24 | loss: 0.0588  | mse_mse: 0.06183 |  0:03:32s\n",
      "epoch 25 | loss: 0.0519  | mse_mse: 0.04806 |  0:03:40s\n",
      "epoch 26 | loss: 0.04877 | mse_mse: 0.04768 |  0:03:48s\n",
      "epoch 27 | loss: 0.05019 | mse_mse: 0.05131 |  0:03:55s\n",
      "epoch 28 | loss: 0.04831 | mse_mse: 0.03919 |  0:04:03s\n",
      "epoch 29 | loss: 0.04007 | mse_mse: 0.04394 |  0:04:11s\n",
      "epoch 30 | loss: 0.0398  | mse_mse: 0.03665 |  0:04:19s\n",
      "epoch 31 | loss: 0.03807 | mse_mse: 0.05273 |  0:04:26s\n",
      "epoch 32 | loss: 0.0367  | mse_mse: 0.02929 |  0:04:34s\n",
      "epoch 33 | loss: 0.03225 | mse_mse: 0.03795 |  0:04:43s\n",
      "epoch 34 | loss: 0.03114 | mse_mse: 0.02711 |  0:04:51s\n",
      "epoch 35 | loss: 0.02957 | mse_mse: 0.02465 |  0:05:00s\n",
      "epoch 36 | loss: 0.02784 | mse_mse: 0.02517 |  0:05:07s\n",
      "epoch 37 | loss: 0.02845 | mse_mse: 0.0246  |  0:05:15s\n",
      "epoch 38 | loss: 0.02908 | mse_mse: 0.02575 |  0:05:24s\n",
      "epoch 39 | loss: 0.0249  | mse_mse: 0.01994 |  0:05:32s\n",
      "epoch 40 | loss: 0.02326 | mse_mse: 0.01773 |  0:05:41s\n",
      "epoch 41 | loss: 0.02536 | mse_mse: 0.0225  |  0:05:50s\n",
      "epoch 42 | loss: 0.03151 | mse_mse: 0.02967 |  0:05:58s\n",
      "epoch 43 | loss: 0.02207 | mse_mse: 0.01802 |  0:06:06s\n",
      "epoch 44 | loss: 0.03119 | mse_mse: 0.02181 |  0:06:14s\n",
      "epoch 45 | loss: 0.02469 | mse_mse: 0.05481 |  0:06:23s\n",
      "epoch 46 | loss: 0.02429 | mse_mse: 0.01946 |  0:06:31s\n",
      "epoch 47 | loss: 0.02381 | mse_mse: 0.01969 |  0:06:39s\n",
      "epoch 48 | loss: 0.02645 | mse_mse: 0.02517 |  0:06:47s\n",
      "epoch 49 | loss: 0.03113 | mse_mse: 0.03636 |  0:06:55s\n",
      "epoch 50 | loss: 0.02912 | mse_mse: 0.0307  |  0:07:04s\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_mse_mse = 0.01773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.017613362738478418\n",
      "R2 Score: 0.9205410153605932\n",
      "\n",
      "Iteration 19/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.9271  | mse_mse: 0.8728  |  0:00:02s\n",
      "epoch 1  | loss: 0.16999 | mse_mse: 0.26566 |  0:00:05s\n",
      "epoch 2  | loss: 0.09167 | mse_mse: 0.1603  |  0:00:08s\n",
      "epoch 3  | loss: 0.06646 | mse_mse: 0.11074 |  0:00:10s\n",
      "epoch 4  | loss: 0.05346 | mse_mse: 0.09526 |  0:00:13s\n",
      "epoch 5  | loss: 0.04876 | mse_mse: 0.07788 |  0:00:16s\n",
      "epoch 6  | loss: 0.04559 | mse_mse: 0.077   |  0:00:19s\n",
      "epoch 7  | loss: 0.0409  | mse_mse: 0.05352 |  0:00:22s\n",
      "epoch 8  | loss: 0.04203 | mse_mse: 0.04963 |  0:00:25s\n",
      "epoch 9  | loss: 0.03707 | mse_mse: 0.0398  |  0:00:28s\n",
      "epoch 10 | loss: 0.03874 | mse_mse: 0.04572 |  0:00:31s\n",
      "epoch 11 | loss: 0.03518 | mse_mse: 0.02972 |  0:00:34s\n",
      "epoch 12 | loss: 0.03411 | mse_mse: 0.0325  |  0:00:37s\n",
      "epoch 13 | loss: 0.03024 | mse_mse: 0.02688 |  0:00:40s\n",
      "epoch 14 | loss: 0.02896 | mse_mse: 0.02102 |  0:00:43s\n",
      "epoch 15 | loss: 0.02663 | mse_mse: 0.03269 |  0:00:47s\n",
      "epoch 16 | loss: 0.02683 | mse_mse: 0.0278  |  0:00:50s\n",
      "epoch 17 | loss: 0.02959 | mse_mse: 0.0187  |  0:00:53s\n",
      "epoch 18 | loss: 0.02663 | mse_mse: 0.01709 |  0:00:56s\n",
      "epoch 19 | loss: 0.02105 | mse_mse: 0.0156  |  0:00:59s\n",
      "epoch 20 | loss: 0.01855 | mse_mse: 0.01608 |  0:01:02s\n",
      "epoch 21 | loss: 0.01688 | mse_mse: 0.01543 |  0:01:05s\n",
      "epoch 22 | loss: 0.01741 | mse_mse: 0.01458 |  0:01:08s\n",
      "epoch 23 | loss: 0.01765 | mse_mse: 0.01192 |  0:01:11s\n",
      "epoch 24 | loss: 0.0157  | mse_mse: 0.01556 |  0:01:14s\n",
      "epoch 25 | loss: 0.01776 | mse_mse: 0.01536 |  0:01:17s\n",
      "epoch 26 | loss: 0.0141  | mse_mse: 0.01478 |  0:01:20s\n",
      "epoch 27 | loss: 0.01547 | mse_mse: 0.01236 |  0:01:23s\n",
      "epoch 28 | loss: 0.01559 | mse_mse: 0.01302 |  0:01:26s\n",
      "epoch 29 | loss: 0.01616 | mse_mse: 0.01667 |  0:01:30s\n",
      "epoch 30 | loss: 0.0147  | mse_mse: 0.01648 |  0:01:33s\n",
      "epoch 31 | loss: 0.01651 | mse_mse: 0.01398 |  0:01:36s\n",
      "epoch 32 | loss: 0.01453 | mse_mse: 0.01124 |  0:01:39s\n",
      "epoch 33 | loss: 0.01513 | mse_mse: 0.01684 |  0:01:42s\n",
      "epoch 34 | loss: 0.01437 | mse_mse: 0.01052 |  0:01:45s\n",
      "epoch 35 | loss: 0.01171 | mse_mse: 0.00821 |  0:01:48s\n",
      "epoch 36 | loss: 0.01437 | mse_mse: 0.01503 |  0:01:51s\n",
      "epoch 37 | loss: 0.01625 | mse_mse: 0.01521 |  0:01:54s\n",
      "epoch 38 | loss: 0.01529 | mse_mse: 0.01327 |  0:01:57s\n",
      "epoch 39 | loss: 0.01175 | mse_mse: 0.01036 |  0:02:00s\n",
      "epoch 40 | loss: 0.01108 | mse_mse: 0.01605 |  0:02:03s\n",
      "epoch 41 | loss: 0.01943 | mse_mse: 0.00829 |  0:02:06s\n",
      "epoch 42 | loss: 0.01382 | mse_mse: 0.00792 |  0:02:09s\n",
      "epoch 43 | loss: 0.01021 | mse_mse: 0.00863 |  0:02:12s\n",
      "epoch 44 | loss: 0.01124 | mse_mse: 0.0111  |  0:02:15s\n",
      "epoch 45 | loss: 0.01199 | mse_mse: 0.01153 |  0:02:18s\n",
      "epoch 46 | loss: 0.01211 | mse_mse: 0.00893 |  0:02:21s\n",
      "epoch 47 | loss: 0.01026 | mse_mse: 0.01014 |  0:02:24s\n",
      "epoch 48 | loss: 0.00945 | mse_mse: 0.00852 |  0:02:27s\n",
      "epoch 49 | loss: 0.00998 | mse_mse: 0.00924 |  0:02:30s\n",
      "epoch 50 | loss: 0.01026 | mse_mse: 0.00925 |  0:02:33s\n",
      "epoch 51 | loss: 0.01073 | mse_mse: 0.00805 |  0:02:36s\n",
      "epoch 52 | loss: 0.00906 | mse_mse: 0.00669 |  0:02:39s\n",
      "epoch 53 | loss: 0.01352 | mse_mse: 0.01342 |  0:02:42s\n",
      "epoch 54 | loss: 0.0139  | mse_mse: 0.01253 |  0:02:45s\n",
      "epoch 55 | loss: 0.01022 | mse_mse: 0.00837 |  0:02:48s\n",
      "epoch 56 | loss: 0.0131  | mse_mse: 0.00778 |  0:02:52s\n",
      "epoch 57 | loss: 0.01175 | mse_mse: 0.02465 |  0:02:55s\n",
      "epoch 58 | loss: 0.01145 | mse_mse: 0.00932 |  0:02:58s\n",
      "epoch 59 | loss: 0.01412 | mse_mse: 0.00965 |  0:03:01s\n",
      "epoch 60 | loss: 0.01255 | mse_mse: 0.01248 |  0:03:04s\n",
      "epoch 61 | loss: 0.01207 | mse_mse: 0.01395 |  0:03:07s\n",
      "epoch 62 | loss: 0.01614 | mse_mse: 0.19193 |  0:03:10s\n",
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 52 and best_mse_mse = 0.00669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.006883958463239461\n",
      "R2 Score: 0.9689444680206414\n",
      "\n",
      "Iteration 20/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.76559 | mse_mse: 0.84133 |  0:00:03s\n",
      "epoch 1  | loss: 0.20319 | mse_mse: 0.35595 |  0:00:06s\n",
      "epoch 2  | loss: 0.09954 | mse_mse: 0.17442 |  0:00:09s\n",
      "epoch 3  | loss: 0.0724  | mse_mse: 0.14524 |  0:00:12s\n",
      "epoch 4  | loss: 0.06394 | mse_mse: 0.13789 |  0:00:16s\n",
      "epoch 5  | loss: 0.05422 | mse_mse: 0.10506 |  0:00:19s\n",
      "epoch 6  | loss: 0.05498 | mse_mse: 0.10734 |  0:00:22s\n",
      "epoch 7  | loss: 0.05914 | mse_mse: 0.08524 |  0:00:25s\n",
      "epoch 8  | loss: 0.05522 | mse_mse: 0.08909 |  0:00:28s\n",
      "epoch 9  | loss: 0.05061 | mse_mse: 0.06456 |  0:00:31s\n",
      "epoch 10 | loss: 0.04427 | mse_mse: 0.05019 |  0:00:34s\n",
      "epoch 11 | loss: 0.04427 | mse_mse: 0.05597 |  0:00:37s\n",
      "epoch 12 | loss: 0.04134 | mse_mse: 0.03342 |  0:00:40s\n",
      "epoch 13 | loss: 0.03801 | mse_mse: 0.03931 |  0:00:44s\n",
      "epoch 14 | loss: 0.03615 | mse_mse: 0.03236 |  0:00:47s\n",
      "epoch 15 | loss: 0.03421 | mse_mse: 0.03818 |  0:00:50s\n",
      "epoch 16 | loss: 0.03017 | mse_mse: 0.02339 |  0:00:53s\n",
      "epoch 17 | loss: 0.02858 | mse_mse: 0.02154 |  0:00:56s\n",
      "epoch 18 | loss: 0.02571 | mse_mse: 0.0289  |  0:00:59s\n",
      "epoch 19 | loss: 0.02665 | mse_mse: 0.02728 |  0:01:03s\n",
      "epoch 20 | loss: 0.02916 | mse_mse: 0.02057 |  0:01:06s\n",
      "epoch 21 | loss: 0.02266 | mse_mse: 0.02143 |  0:01:09s\n",
      "epoch 22 | loss: 0.02718 | mse_mse: 0.01996 |  0:01:12s\n",
      "epoch 23 | loss: 0.02234 | mse_mse: 0.03037 |  0:01:15s\n",
      "epoch 24 | loss: 0.02248 | mse_mse: 0.01408 |  0:01:18s\n",
      "epoch 25 | loss: 0.02203 | mse_mse: 0.01511 |  0:01:21s\n",
      "epoch 26 | loss: 0.02152 | mse_mse: 0.02003 |  0:01:24s\n",
      "epoch 27 | loss: 0.02746 | mse_mse: 0.02337 |  0:01:27s\n",
      "epoch 28 | loss: 0.01933 | mse_mse: 0.0147  |  0:01:30s\n",
      "epoch 29 | loss: 0.01705 | mse_mse: 0.01313 |  0:01:33s\n",
      "epoch 30 | loss: 0.01769 | mse_mse: 0.01277 |  0:01:37s\n",
      "epoch 31 | loss: 0.02072 | mse_mse: 0.01365 |  0:01:40s\n",
      "epoch 32 | loss: 0.01628 | mse_mse: 0.01106 |  0:01:43s\n",
      "epoch 33 | loss: 0.01462 | mse_mse: 0.01448 |  0:01:46s\n",
      "epoch 34 | loss: 0.01591 | mse_mse: 0.01154 |  0:01:50s\n",
      "epoch 35 | loss: 0.01429 | mse_mse: 0.01169 |  0:01:53s\n",
      "epoch 36 | loss: 0.01609 | mse_mse: 0.01849 |  0:01:57s\n",
      "epoch 37 | loss: 0.01612 | mse_mse: 0.01038 |  0:02:00s\n",
      "epoch 38 | loss: 0.01381 | mse_mse: 0.01143 |  0:02:04s\n",
      "epoch 39 | loss: 0.01641 | mse_mse: 0.01261 |  0:02:08s\n",
      "epoch 40 | loss: 0.01851 | mse_mse: 0.01508 |  0:02:12s\n",
      "epoch 41 | loss: 0.01647 | mse_mse: 0.0143  |  0:02:16s\n",
      "epoch 42 | loss: 0.01792 | mse_mse: 0.022   |  0:02:20s\n",
      "epoch 43 | loss: 0.01921 | mse_mse: 0.01304 |  0:02:24s\n",
      "epoch 44 | loss: 0.01697 | mse_mse: 0.01158 |  0:02:27s\n",
      "epoch 45 | loss: 0.01244 | mse_mse: 0.0088  |  0:02:31s\n",
      "epoch 46 | loss: 0.012   | mse_mse: 0.00843 |  0:02:35s\n",
      "epoch 47 | loss: 0.0136  | mse_mse: 0.01921 |  0:02:38s\n",
      "epoch 48 | loss: 0.01162 | mse_mse: 0.00766 |  0:02:42s\n",
      "epoch 49 | loss: 0.01043 | mse_mse: 0.00765 |  0:02:45s\n",
      "epoch 50 | loss: 0.01078 | mse_mse: 0.00905 |  0:02:48s\n",
      "epoch 51 | loss: 0.01511 | mse_mse: 0.00962 |  0:02:52s\n",
      "epoch 52 | loss: 0.00993 | mse_mse: 0.00792 |  0:02:55s\n",
      "epoch 53 | loss: 0.01361 | mse_mse: 0.01571 |  0:02:58s\n",
      "epoch 54 | loss: 0.0117  | mse_mse: 0.00872 |  0:03:01s\n",
      "epoch 55 | loss: 0.01026 | mse_mse: 0.01267 |  0:03:05s\n",
      "epoch 56 | loss: 0.0202  | mse_mse: 0.00961 |  0:03:08s\n",
      "epoch 57 | loss: 0.01442 | mse_mse: 0.0096  |  0:03:11s\n",
      "epoch 58 | loss: 0.00944 | mse_mse: 0.00637 |  0:03:15s\n",
      "epoch 59 | loss: 0.01034 | mse_mse: 0.00614 |  0:03:18s\n",
      "epoch 60 | loss: 0.01249 | mse_mse: 0.00923 |  0:03:22s\n",
      "epoch 61 | loss: 0.01015 | mse_mse: 0.00703 |  0:03:26s\n",
      "epoch 62 | loss: 0.01009 | mse_mse: 0.01086 |  0:03:29s\n",
      "epoch 63 | loss: 0.01063 | mse_mse: 0.01242 |  0:03:32s\n",
      "epoch 64 | loss: 0.01337 | mse_mse: 0.00906 |  0:03:35s\n",
      "epoch 65 | loss: 0.01308 | mse_mse: 0.00828 |  0:03:38s\n",
      "epoch 66 | loss: 0.01015 | mse_mse: 0.0062  |  0:03:42s\n",
      "epoch 67 | loss: 0.01293 | mse_mse: 0.00681 |  0:03:45s\n",
      "epoch 68 | loss: 0.0114  | mse_mse: 0.00575 |  0:03:48s\n",
      "epoch 69 | loss: 0.00819 | mse_mse: 0.0067  |  0:03:51s\n",
      "epoch 70 | loss: 0.01119 | mse_mse: 0.0089  |  0:03:55s\n",
      "epoch 71 | loss: 0.00964 | mse_mse: 0.00751 |  0:03:58s\n",
      "epoch 72 | loss: 0.0094  | mse_mse: 0.00585 |  0:04:01s\n",
      "epoch 73 | loss: 0.00882 | mse_mse: 0.00702 |  0:04:04s\n",
      "epoch 74 | loss: 0.00898 | mse_mse: 0.00808 |  0:04:08s\n",
      "epoch 75 | loss: 0.01247 | mse_mse: 0.00573 |  0:04:11s\n",
      "epoch 76 | loss: 0.00977 | mse_mse: 0.02067 |  0:04:14s\n",
      "epoch 77 | loss: 0.01209 | mse_mse: 0.01259 |  0:04:17s\n",
      "epoch 78 | loss: 0.01191 | mse_mse: 0.00617 |  0:04:20s\n",
      "epoch 79 | loss: 0.01084 | mse_mse: 0.00852 |  0:04:24s\n",
      "epoch 80 | loss: 0.01037 | mse_mse: 0.01791 |  0:04:27s\n",
      "epoch 81 | loss: 0.00855 | mse_mse: 0.00588 |  0:04:30s\n",
      "epoch 82 | loss: 0.00867 | mse_mse: 0.00803 |  0:04:33s\n",
      "epoch 83 | loss: 0.00933 | mse_mse: 0.00608 |  0:04:37s\n",
      "epoch 84 | loss: 0.00948 | mse_mse: 0.01195 |  0:04:40s\n",
      "epoch 85 | loss: 0.01117 | mse_mse: 0.01064 |  0:04:43s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 75 and best_mse_mse = 0.00573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007525561442820867\n",
      "R2 Score: 0.9660500110077406\n",
      "\n",
      "Iteration 21/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.72727 | mse_mse: 0.85335 |  0:00:04s\n",
      "epoch 1  | loss: 0.35056 | mse_mse: 0.26075 |  0:00:09s\n",
      "epoch 2  | loss: 0.20087 | mse_mse: 0.15094 |  0:00:14s\n",
      "epoch 3  | loss: 0.14401 | mse_mse: 0.22299 |  0:00:19s\n",
      "epoch 4  | loss: 0.12228 | mse_mse: 0.168   |  0:00:23s\n",
      "epoch 5  | loss: 0.11044 | mse_mse: 0.11964 |  0:00:28s\n",
      "epoch 6  | loss: 0.09692 | mse_mse: 0.13791 |  0:00:32s\n",
      "epoch 7  | loss: 0.09164 | mse_mse: 0.09285 |  0:00:37s\n",
      "epoch 8  | loss: 0.07804 | mse_mse: 0.08628 |  0:00:41s\n",
      "epoch 9  | loss: 0.07559 | mse_mse: 0.1077  |  0:00:46s\n",
      "epoch 10 | loss: 0.08354 | mse_mse: 0.08146 |  0:00:50s\n",
      "epoch 11 | loss: 0.07857 | mse_mse: 0.06662 |  0:00:55s\n",
      "epoch 12 | loss: 0.06868 | mse_mse: 0.07277 |  0:01:01s\n",
      "epoch 13 | loss: 0.07494 | mse_mse: 0.05522 |  0:01:06s\n",
      "epoch 14 | loss: 0.06405 | mse_mse: 0.06025 |  0:01:11s\n",
      "epoch 15 | loss: 0.06257 | mse_mse: 0.05075 |  0:01:16s\n",
      "epoch 16 | loss: 0.05512 | mse_mse: 0.04795 |  0:01:22s\n",
      "epoch 17 | loss: 0.0529  | mse_mse: 0.03683 |  0:01:28s\n",
      "epoch 18 | loss: 0.04501 | mse_mse: 0.03612 |  0:01:33s\n",
      "epoch 19 | loss: 0.04625 | mse_mse: 0.03325 |  0:01:38s\n",
      "epoch 20 | loss: 0.04169 | mse_mse: 0.04298 |  0:01:43s\n",
      "epoch 21 | loss: 0.04389 | mse_mse: 0.0325  |  0:01:48s\n",
      "epoch 22 | loss: 0.03641 | mse_mse: 0.0286  |  0:01:53s\n",
      "epoch 23 | loss: 0.03227 | mse_mse: 0.02539 |  0:01:58s\n",
      "epoch 24 | loss: 0.03096 | mse_mse: 0.03134 |  0:02:03s\n",
      "epoch 25 | loss: 0.02967 | mse_mse: 0.0334  |  0:02:08s\n",
      "epoch 26 | loss: 0.03443 | mse_mse: 0.03523 |  0:02:12s\n",
      "epoch 27 | loss: 0.02745 | mse_mse: 0.0248  |  0:02:17s\n",
      "epoch 28 | loss: 0.02363 | mse_mse: 0.02039 |  0:02:22s\n",
      "epoch 29 | loss: 0.02424 | mse_mse: 0.02267 |  0:02:27s\n",
      "epoch 30 | loss: 0.0277  | mse_mse: 0.01851 |  0:02:31s\n",
      "epoch 31 | loss: 0.0272  | mse_mse: 0.05795 |  0:02:36s\n",
      "epoch 32 | loss: 0.02709 | mse_mse: 0.0183  |  0:02:41s\n",
      "epoch 33 | loss: 0.02341 | mse_mse: 0.02333 |  0:02:46s\n",
      "epoch 34 | loss: 0.02033 | mse_mse: 0.01816 |  0:02:51s\n",
      "epoch 35 | loss: 0.02176 | mse_mse: 0.01836 |  0:02:56s\n",
      "epoch 36 | loss: 0.02036 | mse_mse: 0.01451 |  0:03:01s\n",
      "epoch 37 | loss: 0.01875 | mse_mse: 0.017   |  0:03:05s\n",
      "epoch 38 | loss: 0.02076 | mse_mse: 0.01733 |  0:03:10s\n",
      "epoch 39 | loss: 0.01611 | mse_mse: 0.01545 |  0:03:15s\n",
      "epoch 40 | loss: 0.01697 | mse_mse: 0.01408 |  0:03:20s\n",
      "epoch 41 | loss: 0.01506 | mse_mse: 0.01183 |  0:03:25s\n",
      "epoch 42 | loss: 0.01509 | mse_mse: 0.01077 |  0:03:30s\n",
      "epoch 43 | loss: 0.01687 | mse_mse: 0.01705 |  0:03:35s\n",
      "epoch 44 | loss: 0.01581 | mse_mse: 0.02866 |  0:03:40s\n",
      "epoch 45 | loss: 0.01777 | mse_mse: 0.02262 |  0:03:45s\n",
      "epoch 46 | loss: 0.01544 | mse_mse: 0.01057 |  0:03:50s\n",
      "epoch 47 | loss: 0.01456 | mse_mse: 0.01147 |  0:03:54s\n",
      "epoch 48 | loss: 0.01762 | mse_mse: 0.02693 |  0:04:00s\n",
      "epoch 49 | loss: 0.01449 | mse_mse: 0.01262 |  0:04:04s\n",
      "epoch 50 | loss: 0.01716 | mse_mse: 0.01319 |  0:04:09s\n",
      "epoch 51 | loss: 0.01577 | mse_mse: 0.00972 |  0:04:14s\n",
      "epoch 52 | loss: 0.01197 | mse_mse: 0.00973 |  0:04:19s\n",
      "epoch 53 | loss: 0.01199 | mse_mse: 0.01198 |  0:04:23s\n",
      "epoch 54 | loss: 0.01115 | mse_mse: 0.00959 |  0:04:28s\n",
      "epoch 55 | loss: 0.01296 | mse_mse: 0.00892 |  0:04:33s\n",
      "epoch 56 | loss: 0.01195 | mse_mse: 0.01173 |  0:04:38s\n",
      "epoch 57 | loss: 0.0152  | mse_mse: 0.0112  |  0:04:42s\n",
      "epoch 58 | loss: 0.01018 | mse_mse: 0.00754 |  0:04:47s\n",
      "epoch 59 | loss: 0.01294 | mse_mse: 0.00728 |  0:04:52s\n",
      "epoch 60 | loss: 0.01189 | mse_mse: 0.01774 |  0:04:57s\n",
      "epoch 61 | loss: 0.01119 | mse_mse: 0.00907 |  0:05:02s\n",
      "epoch 62 | loss: 0.01317 | mse_mse: 0.0606  |  0:05:07s\n",
      "epoch 63 | loss: 0.01316 | mse_mse: 0.01069 |  0:05:12s\n",
      "epoch 64 | loss: 0.01298 | mse_mse: 0.02043 |  0:05:17s\n",
      "epoch 65 | loss: 0.01062 | mse_mse: 0.01205 |  0:05:22s\n",
      "epoch 66 | loss: 0.01175 | mse_mse: 0.01981 |  0:05:27s\n",
      "epoch 67 | loss: 0.0098  | mse_mse: 0.00952 |  0:05:32s\n",
      "epoch 68 | loss: 0.00911 | mse_mse: 0.01148 |  0:05:37s\n",
      "epoch 69 | loss: 0.01003 | mse_mse: 0.00697 |  0:05:41s\n",
      "epoch 70 | loss: 0.00991 | mse_mse: 0.00782 |  0:05:46s\n",
      "epoch 71 | loss: 0.0105  | mse_mse: 0.00745 |  0:05:51s\n",
      "epoch 72 | loss: 0.01091 | mse_mse: 0.01605 |  0:05:56s\n",
      "epoch 73 | loss: 0.0114  | mse_mse: 0.01    |  0:06:00s\n",
      "epoch 74 | loss: 0.01114 | mse_mse: 0.0087  |  0:06:05s\n",
      "epoch 75 | loss: 0.01021 | mse_mse: 0.00664 |  0:06:10s\n",
      "epoch 76 | loss: 0.00817 | mse_mse: 0.01429 |  0:06:14s\n",
      "epoch 77 | loss: 0.01018 | mse_mse: 0.00832 |  0:06:19s\n",
      "epoch 78 | loss: 0.00941 | mse_mse: 0.00542 |  0:06:24s\n",
      "epoch 79 | loss: 0.00934 | mse_mse: 0.00622 |  0:06:29s\n",
      "epoch 80 | loss: 0.01018 | mse_mse: 0.02423 |  0:06:34s\n",
      "epoch 81 | loss: 0.00798 | mse_mse: 0.01557 |  0:06:39s\n",
      "epoch 82 | loss: 0.00937 | mse_mse: 0.00631 |  0:06:43s\n",
      "epoch 83 | loss: 0.00828 | mse_mse: 0.00646 |  0:06:48s\n",
      "epoch 84 | loss: 0.01108 | mse_mse: 0.00916 |  0:06:53s\n",
      "epoch 85 | loss: 0.01219 | mse_mse: 0.0077  |  0:06:58s\n",
      "epoch 86 | loss: 0.00992 | mse_mse: 0.00684 |  0:07:03s\n",
      "epoch 87 | loss: 0.01083 | mse_mse: 0.00757 |  0:07:08s\n",
      "epoch 88 | loss: 0.00907 | mse_mse: 0.00678 |  0:07:13s\n",
      "\n",
      "Early stopping occurred at epoch 88 with best_epoch = 78 and best_mse_mse = 0.00542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.005357398783822059\n",
      "R2 Score: 0.9758312212158716\n",
      "Best model updated\n",
      "\n",
      "Iteration 22/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.6369  | mse_mse: 0.63097 |  0:00:04s\n",
      "epoch 1  | loss: 0.27844 | mse_mse: 0.21939 |  0:00:09s\n",
      "epoch 2  | loss: 0.15396 | mse_mse: 0.17025 |  0:00:14s\n",
      "epoch 3  | loss: 0.11703 | mse_mse: 0.17989 |  0:00:18s\n",
      "epoch 4  | loss: 0.12172 | mse_mse: 0.158   |  0:00:23s\n",
      "epoch 5  | loss: 0.09763 | mse_mse: 0.14287 |  0:00:28s\n",
      "epoch 6  | loss: 0.08943 | mse_mse: 0.17046 |  0:00:34s\n",
      "epoch 7  | loss: 0.08725 | mse_mse: 0.11347 |  0:00:39s\n",
      "epoch 8  | loss: 0.09337 | mse_mse: 0.13618 |  0:00:44s\n",
      "epoch 9  | loss: 0.08499 | mse_mse: 0.07651 |  0:00:50s\n",
      "epoch 10 | loss: 0.07641 | mse_mse: 0.10217 |  0:00:55s\n",
      "epoch 11 | loss: 0.07511 | mse_mse: 0.06657 |  0:01:00s\n",
      "epoch 12 | loss: 0.07845 | mse_mse: 0.07975 |  0:01:05s\n",
      "epoch 13 | loss: 0.0685  | mse_mse: 0.07055 |  0:01:10s\n",
      "epoch 14 | loss: 0.06606 | mse_mse: 0.05934 |  0:01:15s\n",
      "epoch 15 | loss: 0.06425 | mse_mse: 0.06112 |  0:01:21s\n",
      "epoch 16 | loss: 0.05891 | mse_mse: 0.04297 |  0:01:26s\n",
      "epoch 17 | loss: 0.0497  | mse_mse: 0.03914 |  0:01:30s\n",
      "epoch 18 | loss: 0.05691 | mse_mse: 0.04613 |  0:01:36s\n",
      "epoch 19 | loss: 0.0592  | mse_mse: 0.03873 |  0:01:41s\n",
      "epoch 20 | loss: 0.04476 | mse_mse: 0.04482 |  0:01:46s\n",
      "epoch 21 | loss: 0.05009 | mse_mse: 0.03283 |  0:01:51s\n",
      "epoch 22 | loss: 0.03631 | mse_mse: 0.03146 |  0:01:56s\n",
      "epoch 23 | loss: 0.03433 | mse_mse: 0.02734 |  0:02:01s\n",
      "epoch 24 | loss: 0.03054 | mse_mse: 0.02331 |  0:02:06s\n",
      "epoch 25 | loss: 0.02733 | mse_mse: 0.03188 |  0:02:11s\n",
      "epoch 26 | loss: 0.02966 | mse_mse: 0.03382 |  0:02:16s\n",
      "epoch 27 | loss: 0.02688 | mse_mse: 0.0252  |  0:02:21s\n",
      "epoch 28 | loss: 0.02725 | mse_mse: 0.01993 |  0:02:26s\n",
      "epoch 29 | loss: 0.0228  | mse_mse: 0.0225  |  0:02:31s\n",
      "epoch 30 | loss: 0.02161 | mse_mse: 0.02657 |  0:02:36s\n",
      "epoch 31 | loss: 0.04258 | mse_mse: 0.02586 |  0:02:41s\n",
      "epoch 32 | loss: 0.02368 | mse_mse: 0.01915 |  0:02:46s\n",
      "epoch 33 | loss: 0.02157 | mse_mse: 0.0128  |  0:02:51s\n",
      "epoch 34 | loss: 0.02026 | mse_mse: 0.03112 |  0:02:56s\n",
      "epoch 35 | loss: 0.02603 | mse_mse: 0.01256 |  0:03:01s\n",
      "epoch 36 | loss: 0.01824 | mse_mse: 0.01465 |  0:03:06s\n",
      "epoch 37 | loss: 0.01638 | mse_mse: 0.01445 |  0:03:10s\n",
      "epoch 38 | loss: 0.01492 | mse_mse: 0.01265 |  0:03:15s\n",
      "epoch 39 | loss: 0.01817 | mse_mse: 0.01557 |  0:03:20s\n",
      "epoch 40 | loss: 0.01707 | mse_mse: 0.01216 |  0:03:24s\n",
      "epoch 41 | loss: 0.01528 | mse_mse: 0.01032 |  0:03:29s\n",
      "epoch 42 | loss: 0.0158  | mse_mse: 0.01041 |  0:03:34s\n",
      "epoch 43 | loss: 0.01887 | mse_mse: 0.01081 |  0:03:40s\n",
      "epoch 44 | loss: 0.01588 | mse_mse: 0.01865 |  0:03:44s\n",
      "epoch 45 | loss: 0.01537 | mse_mse: 0.00983 |  0:03:50s\n",
      "epoch 46 | loss: 0.01979 | mse_mse: 0.0193  |  0:03:55s\n",
      "epoch 47 | loss: 0.02449 | mse_mse: 0.01548 |  0:04:01s\n",
      "epoch 48 | loss: 0.01515 | mse_mse: 0.01414 |  0:04:07s\n",
      "epoch 49 | loss: 0.01699 | mse_mse: 0.01166 |  0:04:12s\n",
      "epoch 50 | loss: 0.02272 | mse_mse: 0.01291 |  0:04:18s\n",
      "epoch 51 | loss: 0.01797 | mse_mse: 0.01162 |  0:04:23s\n",
      "epoch 52 | loss: 0.01241 | mse_mse: 0.01742 |  0:04:28s\n",
      "epoch 53 | loss: 0.01627 | mse_mse: 0.01137 |  0:04:33s\n",
      "epoch 54 | loss: 0.01669 | mse_mse: 0.02741 |  0:04:38s\n",
      "epoch 55 | loss: 0.01392 | mse_mse: 0.01548 |  0:04:44s\n",
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 45 and best_mse_mse = 0.00983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009457026005205508\n",
      "R2 Score: 0.9573366145216282\n",
      "\n",
      "Iteration 23/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.51929 | mse_mse: 1.16724 |  0:00:06s\n",
      "epoch 1  | loss: 0.51494 | mse_mse: 0.77836 |  0:00:12s\n",
      "epoch 2  | loss: 0.20754 | mse_mse: 0.25612 |  0:00:18s\n",
      "epoch 3  | loss: 0.12996 | mse_mse: 0.25653 |  0:00:25s\n",
      "epoch 4  | loss: 0.34903 | mse_mse: 0.15338 |  0:00:32s\n",
      "epoch 5  | loss: 0.09573 | mse_mse: 0.13754 |  0:00:38s\n",
      "epoch 6  | loss: 0.06778 | mse_mse: 0.10321 |  0:00:45s\n",
      "epoch 7  | loss: 0.06355 | mse_mse: 0.11277 |  0:00:52s\n",
      "epoch 8  | loss: 0.06722 | mse_mse: 0.08476 |  0:00:59s\n",
      "epoch 9  | loss: 0.06134 | mse_mse: 0.08661 |  0:01:06s\n",
      "epoch 10 | loss: 0.08119 | mse_mse: 0.0663  |  0:01:13s\n",
      "epoch 11 | loss: 0.06116 | mse_mse: 0.06404 |  0:01:19s\n",
      "epoch 12 | loss: 0.06217 | mse_mse: 0.06037 |  0:01:25s\n",
      "epoch 13 | loss: 0.06451 | mse_mse: 0.06765 |  0:01:32s\n",
      "epoch 14 | loss: 0.06197 | mse_mse: 0.05598 |  0:01:38s\n",
      "epoch 15 | loss: 0.05998 | mse_mse: 0.04959 |  0:01:45s\n",
      "epoch 16 | loss: 0.05826 | mse_mse: 0.06358 |  0:01:52s\n",
      "epoch 17 | loss: 0.06225 | mse_mse: 0.05278 |  0:01:59s\n",
      "epoch 18 | loss: 0.05639 | mse_mse: 0.05774 |  0:02:06s\n",
      "epoch 19 | loss: 0.05367 | mse_mse: 0.05263 |  0:02:13s\n",
      "epoch 20 | loss: 0.05329 | mse_mse: 0.05005 |  0:02:20s\n",
      "epoch 21 | loss: 0.05399 | mse_mse: 0.04757 |  0:02:27s\n",
      "epoch 22 | loss: 0.05049 | mse_mse: 0.06037 |  0:02:34s\n",
      "epoch 23 | loss: 0.06225 | mse_mse: 0.04765 |  0:02:41s\n",
      "epoch 24 | loss: 0.05295 | mse_mse: 0.05399 |  0:02:48s\n",
      "epoch 25 | loss: 0.05006 | mse_mse: 0.04671 |  0:02:55s\n",
      "epoch 26 | loss: 0.05296 | mse_mse: 0.04469 |  0:03:02s\n",
      "epoch 27 | loss: 0.05296 | mse_mse: 0.053   |  0:03:09s\n",
      "epoch 28 | loss: 0.0508  | mse_mse: 0.05021 |  0:03:15s\n",
      "epoch 29 | loss: 0.04879 | mse_mse: 0.04648 |  0:03:22s\n",
      "epoch 30 | loss: 0.05109 | mse_mse: 0.04786 |  0:03:28s\n",
      "epoch 31 | loss: 0.04772 | mse_mse: 0.04609 |  0:03:35s\n",
      "epoch 32 | loss: 0.0503  | mse_mse: 0.05752 |  0:03:42s\n",
      "epoch 33 | loss: 0.05007 | mse_mse: 0.04753 |  0:03:48s\n",
      "epoch 34 | loss: 0.04747 | mse_mse: 0.04329 |  0:03:55s\n",
      "epoch 35 | loss: 0.05311 | mse_mse: 0.05068 |  0:04:01s\n",
      "epoch 36 | loss: 0.04736 | mse_mse: 0.04385 |  0:04:08s\n",
      "epoch 37 | loss: 0.04498 | mse_mse: 0.04536 |  0:04:15s\n",
      "epoch 38 | loss: 0.0484  | mse_mse: 0.0426  |  0:04:21s\n",
      "epoch 39 | loss: 0.04774 | mse_mse: 0.03947 |  0:04:28s\n",
      "epoch 40 | loss: 0.04464 | mse_mse: 0.03823 |  0:04:34s\n",
      "epoch 41 | loss: 0.04058 | mse_mse: 0.04277 |  0:04:41s\n",
      "epoch 42 | loss: 0.04056 | mse_mse: 0.03852 |  0:04:48s\n",
      "epoch 43 | loss: 0.03962 | mse_mse: 0.04059 |  0:04:54s\n",
      "epoch 44 | loss: 0.03872 | mse_mse: 0.0349  |  0:05:01s\n",
      "epoch 45 | loss: 0.03762 | mse_mse: 0.03544 |  0:05:08s\n",
      "epoch 46 | loss: 0.03813 | mse_mse: 0.03046 |  0:05:15s\n",
      "epoch 47 | loss: 0.0358  | mse_mse: 0.04522 |  0:05:21s\n",
      "epoch 48 | loss: 0.03414 | mse_mse: 0.03126 |  0:05:29s\n",
      "epoch 49 | loss: 0.03288 | mse_mse: 0.03727 |  0:05:36s\n",
      "epoch 50 | loss: 0.0331  | mse_mse: 0.0266  |  0:05:43s\n",
      "epoch 51 | loss: 0.02859 | mse_mse: 0.0279  |  0:05:49s\n",
      "epoch 52 | loss: 0.02579 | mse_mse: 0.02242 |  0:05:57s\n",
      "epoch 53 | loss: 0.02912 | mse_mse: 0.02187 |  0:06:06s\n",
      "epoch 54 | loss: 0.02421 | mse_mse: 0.02056 |  0:06:13s\n",
      "epoch 55 | loss: 0.02228 | mse_mse: 0.0176  |  0:06:20s\n",
      "epoch 56 | loss: 0.02215 | mse_mse: 0.01605 |  0:06:27s\n",
      "epoch 57 | loss: 0.02086 | mse_mse: 0.02169 |  0:06:33s\n",
      "epoch 58 | loss: 0.02075 | mse_mse: 0.02157 |  0:06:40s\n",
      "epoch 59 | loss: 0.02339 | mse_mse: 0.02932 |  0:06:47s\n",
      "epoch 60 | loss: 0.02057 | mse_mse: 0.0193  |  0:06:53s\n",
      "epoch 61 | loss: 0.0203  | mse_mse: 0.01967 |  0:07:00s\n",
      "epoch 62 | loss: 0.0192  | mse_mse: 0.01917 |  0:07:07s\n",
      "epoch 63 | loss: 0.02284 | mse_mse: 0.01773 |  0:07:13s\n",
      "epoch 64 | loss: 0.02486 | mse_mse: 0.01344 |  0:07:19s\n",
      "epoch 65 | loss: 0.01465 | mse_mse: 0.01495 |  0:07:26s\n",
      "epoch 66 | loss: 0.0145  | mse_mse: 0.01067 |  0:07:33s\n",
      "epoch 67 | loss: 0.01589 | mse_mse: 0.01229 |  0:07:39s\n",
      "epoch 68 | loss: 0.01363 | mse_mse: 0.00951 |  0:07:45s\n",
      "epoch 69 | loss: 0.01422 | mse_mse: 0.01615 |  0:07:52s\n",
      "epoch 70 | loss: 0.01447 | mse_mse: 0.01098 |  0:07:58s\n",
      "epoch 71 | loss: 0.01294 | mse_mse: 0.01834 |  0:08:05s\n",
      "epoch 72 | loss: 0.01713 | mse_mse: 0.01228 |  0:08:11s\n",
      "epoch 73 | loss: 0.01507 | mse_mse: 0.01199 |  0:08:18s\n",
      "epoch 74 | loss: 0.01127 | mse_mse: 0.01038 |  0:08:24s\n",
      "epoch 75 | loss: 0.0156  | mse_mse: 0.0158  |  0:08:31s\n",
      "epoch 76 | loss: 0.0142  | mse_mse: 0.01074 |  0:08:39s\n",
      "epoch 77 | loss: 0.01292 | mse_mse: 0.00977 |  0:08:46s\n",
      "epoch 78 | loss: 0.0132  | mse_mse: 0.01062 |  0:08:53s\n",
      "\n",
      "Early stopping occurred at epoch 78 with best_epoch = 68 and best_mse_mse = 0.00951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00986585409265263\n",
      "R2 Score: 0.9554922725181758\n",
      "\n",
      "Iteration 24/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 8 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.60828 | mse_mse: 0.89327 |  0:00:06s\n",
      "epoch 1  | loss: 0.46853 | mse_mse: 0.2645  |  0:00:13s\n",
      "epoch 2  | loss: 0.40602 | mse_mse: 0.79289 |  0:00:19s\n",
      "epoch 3  | loss: 0.62184 | mse_mse: 0.18901 |  0:00:27s\n",
      "epoch 4  | loss: 0.23449 | mse_mse: 0.16683 |  0:00:34s\n",
      "epoch 5  | loss: 0.22507 | mse_mse: 0.14969 |  0:00:41s\n",
      "epoch 6  | loss: 0.12373 | mse_mse: 0.13077 |  0:00:48s\n",
      "epoch 7  | loss: 0.1274  | mse_mse: 0.12708 |  0:00:56s\n",
      "epoch 8  | loss: 0.11084 | mse_mse: 0.10613 |  0:01:03s\n",
      "epoch 9  | loss: 0.09739 | mse_mse: 0.12782 |  0:01:10s\n",
      "epoch 10 | loss: 0.09723 | mse_mse: 0.09516 |  0:01:18s\n",
      "epoch 11 | loss: 0.09613 | mse_mse: 0.08172 |  0:01:24s\n",
      "epoch 12 | loss: 0.07992 | mse_mse: 0.06578 |  0:01:31s\n",
      "epoch 13 | loss: 0.08487 | mse_mse: 0.06566 |  0:01:38s\n",
      "epoch 14 | loss: 0.07272 | mse_mse: 0.05982 |  0:01:44s\n",
      "epoch 15 | loss: 0.0774  | mse_mse: 0.05804 |  0:01:51s\n",
      "epoch 16 | loss: 0.07159 | mse_mse: 0.06157 |  0:01:58s\n",
      "epoch 17 | loss: 0.0751  | mse_mse: 0.05862 |  0:02:06s\n",
      "epoch 18 | loss: 0.06718 | mse_mse: 0.05529 |  0:02:13s\n",
      "epoch 19 | loss: 0.06041 | mse_mse: 0.04695 |  0:02:20s\n",
      "epoch 20 | loss: 0.05679 | mse_mse: 0.05953 |  0:02:27s\n",
      "epoch 21 | loss: 0.05656 | mse_mse: 0.0618  |  0:02:34s\n",
      "epoch 22 | loss: 0.05635 | mse_mse: 0.04549 |  0:02:41s\n",
      "epoch 23 | loss: 0.04939 | mse_mse: 0.04198 |  0:02:48s\n",
      "epoch 24 | loss: 0.04875 | mse_mse: 0.05161 |  0:02:55s\n",
      "epoch 25 | loss: 0.03981 | mse_mse: 0.02791 |  0:03:02s\n",
      "epoch 26 | loss: 0.04265 | mse_mse: 0.04852 |  0:03:09s\n",
      "epoch 27 | loss: 0.04446 | mse_mse: 0.02908 |  0:03:15s\n",
      "epoch 28 | loss: 0.0377  | mse_mse: 0.03093 |  0:03:22s\n",
      "epoch 29 | loss: 0.03473 | mse_mse: 0.02951 |  0:03:29s\n",
      "epoch 30 | loss: 0.03515 | mse_mse: 0.02315 |  0:03:36s\n",
      "epoch 31 | loss: 0.02956 | mse_mse: 0.02205 |  0:03:43s\n",
      "epoch 32 | loss: 0.02897 | mse_mse: 0.02196 |  0:03:50s\n",
      "epoch 33 | loss: 0.0234  | mse_mse: 0.01849 |  0:03:57s\n",
      "epoch 34 | loss: 0.02293 | mse_mse: 0.02612 |  0:04:04s\n",
      "epoch 35 | loss: 0.02437 | mse_mse: 0.02685 |  0:04:11s\n",
      "epoch 36 | loss: 0.02083 | mse_mse: 0.01705 |  0:04:19s\n",
      "epoch 37 | loss: 0.02515 | mse_mse: 0.01391 |  0:04:27s\n",
      "epoch 38 | loss: 0.01803 | mse_mse: 0.01311 |  0:04:34s\n",
      "epoch 39 | loss: 0.02199 | mse_mse: 0.01748 |  0:04:41s\n",
      "epoch 40 | loss: 0.02117 | mse_mse: 0.0227  |  0:04:48s\n",
      "epoch 41 | loss: 0.01861 | mse_mse: 0.01446 |  0:04:55s\n",
      "epoch 42 | loss: 0.0188  | mse_mse: 0.01258 |  0:05:02s\n",
      "epoch 43 | loss: 0.01654 | mse_mse: 0.02992 |  0:05:09s\n",
      "epoch 44 | loss: 0.02104 | mse_mse: 0.0204  |  0:05:16s\n",
      "epoch 45 | loss: 0.01823 | mse_mse: 0.01172 |  0:05:23s\n",
      "epoch 46 | loss: 0.02264 | mse_mse: 0.02153 |  0:05:29s\n",
      "epoch 47 | loss: 0.02393 | mse_mse: 0.02917 |  0:05:36s\n",
      "epoch 48 | loss: 0.02398 | mse_mse: 0.01    |  0:05:43s\n",
      "epoch 49 | loss: 0.01203 | mse_mse: 0.01111 |  0:05:50s\n",
      "epoch 50 | loss: 0.02004 | mse_mse: 0.01774 |  0:05:57s\n",
      "epoch 51 | loss: 0.01438 | mse_mse: 0.01098 |  0:06:04s\n",
      "epoch 52 | loss: 0.01642 | mse_mse: 0.02105 |  0:06:11s\n",
      "epoch 53 | loss: 0.0154  | mse_mse: 0.01639 |  0:06:18s\n",
      "epoch 54 | loss: 0.01897 | mse_mse: 0.02019 |  0:06:24s\n",
      "epoch 55 | loss: 0.01308 | mse_mse: 0.00852 |  0:06:32s\n",
      "epoch 56 | loss: 0.01211 | mse_mse: 0.01449 |  0:06:39s\n",
      "epoch 57 | loss: 0.01328 | mse_mse: 0.00909 |  0:06:46s\n",
      "epoch 58 | loss: 0.01065 | mse_mse: 0.00778 |  0:06:53s\n",
      "epoch 59 | loss: 0.01275 | mse_mse: 0.00808 |  0:07:00s\n",
      "epoch 60 | loss: 0.01194 | mse_mse: 0.00838 |  0:07:06s\n",
      "epoch 61 | loss: 0.01117 | mse_mse: 0.01011 |  0:07:13s\n",
      "epoch 62 | loss: 0.0108  | mse_mse: 0.01036 |  0:07:20s\n",
      "epoch 63 | loss: 0.01537 | mse_mse: 0.00769 |  0:07:27s\n",
      "epoch 64 | loss: 0.01023 | mse_mse: 0.01026 |  0:07:36s\n",
      "epoch 65 | loss: 0.01107 | mse_mse: 0.00885 |  0:07:43s\n",
      "epoch 66 | loss: 0.01744 | mse_mse: 0.03584 |  0:07:51s\n",
      "epoch 67 | loss: 0.01786 | mse_mse: 0.04576 |  0:07:59s\n",
      "epoch 68 | loss: 0.01768 | mse_mse: 0.00951 |  0:08:06s\n",
      "epoch 69 | loss: 0.01739 | mse_mse: 0.0114  |  0:08:13s\n",
      "epoch 70 | loss: 0.01449 | mse_mse: 0.16382 |  0:08:20s\n",
      "epoch 71 | loss: 0.01525 | mse_mse: 0.01074 |  0:08:27s\n",
      "epoch 72 | loss: 0.013   | mse_mse: 0.01086 |  0:08:34s\n",
      "epoch 73 | loss: 0.01356 | mse_mse: 0.01072 |  0:08:41s\n",
      "\n",
      "Early stopping occurred at epoch 73 with best_epoch = 63 and best_mse_mse = 0.00769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007671638162274176\n",
      "R2 Score: 0.9653910165851787\n",
      "\n",
      "Iteration 25/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.45903 | mse_mse: 0.78749 |  0:00:02s\n",
      "epoch 1  | loss: 0.23112 | mse_mse: 0.2416  |  0:00:05s\n",
      "epoch 2  | loss: 0.11086 | mse_mse: 0.15482 |  0:00:08s\n",
      "epoch 3  | loss: 0.08877 | mse_mse: 0.11387 |  0:00:11s\n",
      "epoch 4  | loss: 0.06351 | mse_mse: 0.09663 |  0:00:13s\n",
      "epoch 5  | loss: 0.04619 | mse_mse: 0.12006 |  0:00:16s\n",
      "epoch 6  | loss: 0.04254 | mse_mse: 0.08466 |  0:00:19s\n",
      "epoch 7  | loss: 0.03787 | mse_mse: 0.05863 |  0:00:22s\n",
      "epoch 8  | loss: 0.03227 | mse_mse: 0.04528 |  0:00:25s\n",
      "epoch 9  | loss: 0.03426 | mse_mse: 0.04608 |  0:00:28s\n",
      "epoch 10 | loss: 0.03226 | mse_mse: 0.03041 |  0:00:31s\n",
      "epoch 11 | loss: 0.03225 | mse_mse: 0.03172 |  0:00:34s\n",
      "epoch 12 | loss: 0.02513 | mse_mse: 0.01782 |  0:00:37s\n",
      "epoch 13 | loss: 0.02652 | mse_mse: 0.02766 |  0:00:40s\n",
      "epoch 14 | loss: 0.0235  | mse_mse: 0.0178  |  0:00:43s\n",
      "epoch 15 | loss: 0.02297 | mse_mse: 0.0168  |  0:00:46s\n",
      "epoch 16 | loss: 0.0222  | mse_mse: 0.02758 |  0:00:49s\n",
      "epoch 17 | loss: 0.02299 | mse_mse: 0.01673 |  0:00:52s\n",
      "epoch 18 | loss: 0.02081 | mse_mse: 0.03023 |  0:00:55s\n",
      "epoch 19 | loss: 0.02142 | mse_mse: 0.02173 |  0:00:58s\n",
      "epoch 20 | loss: 0.01935 | mse_mse: 0.01778 |  0:01:02s\n",
      "epoch 21 | loss: 0.01842 | mse_mse: 0.01226 |  0:01:05s\n",
      "epoch 22 | loss: 0.02068 | mse_mse: 0.01726 |  0:01:08s\n",
      "epoch 23 | loss: 0.01844 | mse_mse: 0.01476 |  0:01:11s\n",
      "epoch 24 | loss: 0.01548 | mse_mse: 0.00958 |  0:01:14s\n",
      "epoch 25 | loss: 0.01511 | mse_mse: 0.01009 |  0:01:17s\n",
      "epoch 26 | loss: 0.01224 | mse_mse: 0.00822 |  0:01:20s\n",
      "epoch 27 | loss: 0.01595 | mse_mse: 0.0106  |  0:01:23s\n",
      "epoch 28 | loss: 0.01232 | mse_mse: 0.00898 |  0:01:26s\n",
      "epoch 29 | loss: 0.0127  | mse_mse: 0.01117 |  0:01:29s\n",
      "epoch 30 | loss: 0.01252 | mse_mse: 0.00874 |  0:01:33s\n",
      "epoch 31 | loss: 0.0144  | mse_mse: 0.00774 |  0:01:36s\n",
      "epoch 32 | loss: 0.01206 | mse_mse: 0.01165 |  0:01:39s\n",
      "epoch 33 | loss: 0.01293 | mse_mse: 0.00662 |  0:01:42s\n",
      "epoch 34 | loss: 0.01521 | mse_mse: 0.00776 |  0:01:45s\n",
      "epoch 35 | loss: 0.01143 | mse_mse: 0.0081  |  0:01:49s\n",
      "epoch 36 | loss: 0.01148 | mse_mse: 0.00869 |  0:01:57s\n",
      "epoch 37 | loss: 0.01355 | mse_mse: 0.00862 |  0:02:03s\n",
      "epoch 38 | loss: 0.01286 | mse_mse: 0.00703 |  0:02:07s\n",
      "epoch 39 | loss: 0.0117  | mse_mse: 0.00882 |  0:02:10s\n",
      "epoch 40 | loss: 0.01245 | mse_mse: 0.00831 |  0:02:14s\n",
      "epoch 41 | loss: 0.01342 | mse_mse: 0.01243 |  0:02:18s\n",
      "epoch 42 | loss: 0.01402 | mse_mse: 0.01454 |  0:02:21s\n",
      "epoch 43 | loss: 0.01437 | mse_mse: 0.00944 |  0:02:25s\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_mse_mse = 0.00662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.006935480201286723\n",
      "R2 Score: 0.9687120385264626\n",
      "\n",
      "Iteration 26/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.71727 | mse_mse: 0.4853  |  0:00:03s\n",
      "epoch 1  | loss: 0.1735  | mse_mse: 0.21878 |  0:00:06s\n",
      "epoch 2  | loss: 0.09239 | mse_mse: 0.16614 |  0:00:09s\n",
      "epoch 3  | loss: 0.06996 | mse_mse: 0.15019 |  0:00:13s\n",
      "epoch 4  | loss: 0.05847 | mse_mse: 0.14102 |  0:00:16s\n",
      "epoch 5  | loss: 0.0531  | mse_mse: 0.11031 |  0:00:20s\n",
      "epoch 6  | loss: 0.05122 | mse_mse: 0.09325 |  0:00:24s\n",
      "epoch 7  | loss: 0.05236 | mse_mse: 0.07765 |  0:00:28s\n",
      "epoch 8  | loss: 0.04225 | mse_mse: 0.05724 |  0:00:31s\n",
      "epoch 9  | loss: 0.04079 | mse_mse: 0.04455 |  0:00:35s\n",
      "epoch 10 | loss: 0.03786 | mse_mse: 0.03857 |  0:00:38s\n",
      "epoch 11 | loss: 0.03663 | mse_mse: 0.04111 |  0:00:41s\n",
      "epoch 12 | loss: 0.03309 | mse_mse: 0.03171 |  0:00:44s\n",
      "epoch 13 | loss: 0.03505 | mse_mse: 0.03064 |  0:00:47s\n",
      "epoch 14 | loss: 0.0287  | mse_mse: 0.02567 |  0:00:51s\n",
      "epoch 15 | loss: 0.02806 | mse_mse: 0.02156 |  0:00:54s\n",
      "epoch 16 | loss: 0.02742 | mse_mse: 0.02187 |  0:00:57s\n",
      "epoch 17 | loss: 0.02501 | mse_mse: 0.02474 |  0:01:01s\n",
      "epoch 18 | loss: 0.0245  | mse_mse: 0.0188  |  0:01:04s\n",
      "epoch 19 | loss: 0.02428 | mse_mse: 0.02688 |  0:01:08s\n",
      "epoch 20 | loss: 0.02268 | mse_mse: 0.02068 |  0:01:11s\n",
      "epoch 21 | loss: 0.02158 | mse_mse: 0.01967 |  0:01:14s\n",
      "epoch 22 | loss: 0.01916 | mse_mse: 0.01867 |  0:01:18s\n",
      "epoch 23 | loss: 0.02027 | mse_mse: 0.02679 |  0:01:21s\n",
      "epoch 24 | loss: 0.02129 | mse_mse: 0.01576 |  0:01:25s\n",
      "epoch 25 | loss: 0.02001 | mse_mse: 0.01859 |  0:01:28s\n",
      "epoch 26 | loss: 0.0157  | mse_mse: 0.01635 |  0:01:31s\n",
      "epoch 27 | loss: 0.01453 | mse_mse: 0.0134  |  0:01:35s\n",
      "epoch 28 | loss: 0.01321 | mse_mse: 0.01437 |  0:01:38s\n",
      "epoch 29 | loss: 0.01777 | mse_mse: 0.01449 |  0:01:41s\n",
      "epoch 30 | loss: 0.01383 | mse_mse: 0.01181 |  0:01:45s\n",
      "epoch 31 | loss: 0.01244 | mse_mse: 0.01176 |  0:01:48s\n",
      "epoch 32 | loss: 0.01518 | mse_mse: 0.01433 |  0:01:51s\n",
      "epoch 33 | loss: 0.01223 | mse_mse: 0.00849 |  0:01:55s\n",
      "epoch 34 | loss: 0.01476 | mse_mse: 0.01648 |  0:01:58s\n",
      "epoch 35 | loss: 0.01552 | mse_mse: 0.01222 |  0:02:01s\n",
      "epoch 36 | loss: 0.01143 | mse_mse: 0.00769 |  0:02:05s\n",
      "epoch 37 | loss: 0.01103 | mse_mse: 0.00819 |  0:02:08s\n",
      "epoch 38 | loss: 0.00991 | mse_mse: 0.00981 |  0:02:12s\n",
      "epoch 39 | loss: 0.01126 | mse_mse: 0.00814 |  0:02:16s\n",
      "epoch 40 | loss: 0.01124 | mse_mse: 0.01418 |  0:02:19s\n",
      "epoch 41 | loss: 0.01235 | mse_mse: 0.01193 |  0:02:23s\n",
      "epoch 42 | loss: 0.01059 | mse_mse: 0.00827 |  0:02:27s\n",
      "epoch 43 | loss: 0.01232 | mse_mse: 0.01308 |  0:02:31s\n",
      "epoch 44 | loss: 0.01084 | mse_mse: 0.00803 |  0:02:34s\n",
      "epoch 45 | loss: 0.01006 | mse_mse: 0.01671 |  0:02:38s\n",
      "epoch 46 | loss: 0.01097 | mse_mse: 0.00865 |  0:02:41s\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_mse_mse = 0.00769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00790116949093661\n",
      "R2 Score: 0.9643555342307156\n",
      "\n",
      "Iteration 27/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.46472 | mse_mse: 0.44623 |  0:00:04s\n",
      "epoch 1  | loss: 0.28872 | mse_mse: 0.18831 |  0:00:09s\n",
      "epoch 2  | loss: 0.14326 | mse_mse: 0.2103  |  0:00:13s\n",
      "epoch 3  | loss: 0.18    | mse_mse: 0.18077 |  0:00:18s\n",
      "epoch 4  | loss: 0.1106  | mse_mse: 0.15136 |  0:00:23s\n",
      "epoch 5  | loss: 0.07603 | mse_mse: 0.13706 |  0:00:28s\n",
      "epoch 6  | loss: 0.0741  | mse_mse: 0.1041  |  0:00:33s\n",
      "epoch 7  | loss: 0.06772 | mse_mse: 0.11501 |  0:00:38s\n",
      "epoch 8  | loss: 0.05981 | mse_mse: 0.07142 |  0:00:43s\n",
      "epoch 9  | loss: 0.05733 | mse_mse: 0.07705 |  0:00:47s\n",
      "epoch 10 | loss: 0.05943 | mse_mse: 0.04522 |  0:00:52s\n",
      "epoch 11 | loss: 0.05548 | mse_mse: 0.04378 |  0:00:57s\n",
      "epoch 12 | loss: 0.05152 | mse_mse: 0.052   |  0:01:02s\n",
      "epoch 13 | loss: 0.05091 | mse_mse: 0.04374 |  0:01:07s\n",
      "epoch 14 | loss: 0.04867 | mse_mse: 0.04531 |  0:01:12s\n",
      "epoch 15 | loss: 0.04431 | mse_mse: 0.04189 |  0:01:16s\n",
      "epoch 16 | loss: 0.04192 | mse_mse: 0.03658 |  0:01:21s\n",
      "epoch 17 | loss: 0.03533 | mse_mse: 0.03095 |  0:01:26s\n",
      "epoch 18 | loss: 0.04525 | mse_mse: 0.03832 |  0:01:31s\n",
      "epoch 19 | loss: 0.04147 | mse_mse: 0.05054 |  0:01:36s\n",
      "epoch 20 | loss: 0.04187 | mse_mse: 0.03948 |  0:01:41s\n",
      "epoch 21 | loss: 0.03373 | mse_mse: 0.02856 |  0:01:46s\n",
      "epoch 22 | loss: 0.03179 | mse_mse: 0.04316 |  0:01:52s\n",
      "epoch 23 | loss: 0.03016 | mse_mse: 0.03023 |  0:01:58s\n",
      "epoch 24 | loss: 0.03107 | mse_mse: 0.02457 |  0:02:04s\n",
      "epoch 25 | loss: 0.02812 | mse_mse: 0.02738 |  0:02:10s\n",
      "epoch 26 | loss: 0.02454 | mse_mse: 0.02838 |  0:02:15s\n",
      "epoch 27 | loss: 0.02883 | mse_mse: 0.02183 |  0:02:22s\n",
      "epoch 28 | loss: 0.02499 | mse_mse: 0.02326 |  0:02:28s\n",
      "epoch 29 | loss: 0.02398 | mse_mse: 0.01685 |  0:02:34s\n",
      "epoch 30 | loss: 0.02033 | mse_mse: 0.01943 |  0:02:40s\n",
      "epoch 31 | loss: 0.02014 | mse_mse: 0.02218 |  0:02:45s\n",
      "epoch 32 | loss: 0.0195  | mse_mse: 0.01569 |  0:02:50s\n",
      "epoch 33 | loss: 0.01861 | mse_mse: 0.01597 |  0:02:55s\n",
      "epoch 34 | loss: 0.01839 | mse_mse: 0.01611 |  0:03:00s\n",
      "epoch 35 | loss: 0.01972 | mse_mse: 0.01426 |  0:03:05s\n",
      "epoch 36 | loss: 0.01777 | mse_mse: 0.0137  |  0:03:11s\n",
      "epoch 37 | loss: 0.01482 | mse_mse: 0.01317 |  0:03:16s\n",
      "epoch 38 | loss: 0.0148  | mse_mse: 0.01139 |  0:03:22s\n",
      "epoch 39 | loss: 0.0169  | mse_mse: 0.02477 |  0:03:27s\n",
      "epoch 40 | loss: 0.01838 | mse_mse: 0.01152 |  0:03:32s\n",
      "epoch 41 | loss: 0.01424 | mse_mse: 0.01111 |  0:03:37s\n",
      "epoch 42 | loss: 0.01699 | mse_mse: 0.01334 |  0:03:42s\n",
      "epoch 43 | loss: 0.01434 | mse_mse: 0.01445 |  0:03:47s\n",
      "epoch 44 | loss: 0.01646 | mse_mse: 0.0125  |  0:03:54s\n",
      "epoch 45 | loss: 0.01379 | mse_mse: 0.01636 |  0:04:00s\n",
      "epoch 46 | loss: 0.01781 | mse_mse: 0.01108 |  0:04:06s\n",
      "epoch 47 | loss: 0.01622 | mse_mse: 0.02074 |  0:04:12s\n",
      "epoch 48 | loss: 0.01544 | mse_mse: 0.00993 |  0:04:18s\n",
      "epoch 49 | loss: 0.01189 | mse_mse: 0.0088  |  0:04:23s\n",
      "epoch 50 | loss: 0.01516 | mse_mse: 0.01167 |  0:04:29s\n",
      "epoch 51 | loss: 0.01265 | mse_mse: 0.00725 |  0:04:34s\n",
      "epoch 52 | loss: 0.01159 | mse_mse: 0.01375 |  0:04:39s\n",
      "epoch 53 | loss: 0.01221 | mse_mse: 0.02009 |  0:04:45s\n",
      "epoch 54 | loss: 0.02077 | mse_mse: 0.02421 |  0:04:50s\n",
      "epoch 55 | loss: 0.01661 | mse_mse: 0.02198 |  0:04:56s\n",
      "epoch 56 | loss: 0.01449 | mse_mse: 0.01654 |  0:05:02s\n",
      "epoch 57 | loss: 0.01085 | mse_mse: 0.01048 |  0:05:07s\n",
      "epoch 58 | loss: 0.01313 | mse_mse: 0.00822 |  0:05:13s\n",
      "epoch 59 | loss: 0.01564 | mse_mse: 0.00982 |  0:05:19s\n",
      "epoch 60 | loss: 0.01186 | mse_mse: 0.00707 |  0:05:25s\n",
      "epoch 61 | loss: 0.01524 | mse_mse: 0.01635 |  0:05:31s\n",
      "epoch 62 | loss: 0.01175 | mse_mse: 0.00899 |  0:05:36s\n",
      "epoch 63 | loss: 0.01043 | mse_mse: 0.01189 |  0:05:43s\n",
      "epoch 64 | loss: 0.01135 | mse_mse: 0.00635 |  0:05:48s\n",
      "epoch 65 | loss: 0.01178 | mse_mse: 0.01124 |  0:05:54s\n",
      "epoch 66 | loss: 0.0098  | mse_mse: 0.00786 |  0:06:00s\n",
      "epoch 67 | loss: 0.01176 | mse_mse: 0.00947 |  0:06:05s\n",
      "epoch 68 | loss: 0.01207 | mse_mse: 0.00796 |  0:06:11s\n",
      "epoch 69 | loss: 0.00912 | mse_mse: 0.00758 |  0:06:17s\n",
      "epoch 70 | loss: 0.00888 | mse_mse: 0.00614 |  0:06:22s\n",
      "epoch 71 | loss: 0.0111  | mse_mse: 0.00787 |  0:06:27s\n",
      "epoch 72 | loss: 0.00882 | mse_mse: 0.00642 |  0:06:33s\n",
      "epoch 73 | loss: 0.00987 | mse_mse: 0.01254 |  0:06:38s\n",
      "epoch 74 | loss: 0.0102  | mse_mse: 0.00936 |  0:06:43s\n",
      "epoch 75 | loss: 0.00804 | mse_mse: 0.00615 |  0:06:48s\n",
      "epoch 76 | loss: 0.00794 | mse_mse: 0.01187 |  0:06:53s\n",
      "epoch 77 | loss: 0.01263 | mse_mse: 0.01404 |  0:06:58s\n",
      "epoch 78 | loss: 0.01012 | mse_mse: 0.00587 |  0:07:03s\n",
      "epoch 79 | loss: 0.00947 | mse_mse: 0.00715 |  0:07:08s\n",
      "epoch 80 | loss: 0.00965 | mse_mse: 0.00908 |  0:07:13s\n",
      "epoch 81 | loss: 0.00981 | mse_mse: 0.00965 |  0:07:18s\n",
      "epoch 82 | loss: 0.01243 | mse_mse: 0.00725 |  0:07:22s\n",
      "epoch 83 | loss: 0.00841 | mse_mse: 0.00559 |  0:07:28s\n",
      "epoch 84 | loss: 0.00913 | mse_mse: 0.00687 |  0:07:33s\n",
      "epoch 85 | loss: 0.00903 | mse_mse: 0.00658 |  0:07:39s\n",
      "epoch 86 | loss: 0.01157 | mse_mse: 0.01233 |  0:07:45s\n",
      "epoch 87 | loss: 0.00821 | mse_mse: 0.013   |  0:07:51s\n",
      "epoch 88 | loss: 0.01305 | mse_mse: 0.02247 |  0:07:57s\n",
      "epoch 89 | loss: 0.01087 | mse_mse: 0.0084  |  0:08:03s\n",
      "epoch 90 | loss: 0.00904 | mse_mse: 0.0075  |  0:08:08s\n",
      "epoch 91 | loss: 0.00761 | mse_mse: 0.00556 |  0:08:14s\n",
      "epoch 92 | loss: 0.01272 | mse_mse: 0.00841 |  0:08:19s\n",
      "epoch 93 | loss: 0.00976 | mse_mse: 0.00527 |  0:08:24s\n",
      "epoch 94 | loss: 0.00887 | mse_mse: 0.00941 |  0:08:29s\n",
      "epoch 95 | loss: 0.00741 | mse_mse: 0.006   |  0:08:34s\n",
      "epoch 96 | loss: 0.01072 | mse_mse: 0.01037 |  0:08:39s\n",
      "epoch 97 | loss: 0.01362 | mse_mse: 0.01798 |  0:08:44s\n",
      "epoch 98 | loss: 0.00976 | mse_mse: 0.00548 |  0:08:48s\n",
      "epoch 99 | loss: 0.00613 | mse_mse: 0.0051  |  0:08:53s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_mse_mse = 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.005402025411214137\n",
      "R2 Score: 0.9756298975644425\n",
      "\n",
      "Iteration 28/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.57449 | mse_mse: 0.55792 |  0:00:04s\n",
      "epoch 1  | loss: 0.408   | mse_mse: 0.26085 |  0:00:09s\n",
      "epoch 2  | loss: 0.34878 | mse_mse: 0.28379 |  0:00:14s\n",
      "epoch 3  | loss: 0.20378 | mse_mse: 0.14638 |  0:00:18s\n",
      "epoch 4  | loss: 0.14053 | mse_mse: 0.14987 |  0:00:23s\n",
      "epoch 5  | loss: 0.11451 | mse_mse: 0.13679 |  0:00:27s\n",
      "epoch 6  | loss: 0.09647 | mse_mse: 0.11296 |  0:00:32s\n",
      "epoch 7  | loss: 0.08816 | mse_mse: 0.10468 |  0:00:37s\n",
      "epoch 8  | loss: 0.07704 | mse_mse: 0.07037 |  0:00:42s\n",
      "epoch 9  | loss: 0.06486 | mse_mse: 0.06481 |  0:00:47s\n",
      "epoch 10 | loss: 0.05636 | mse_mse: 0.04852 |  0:20:27s\n",
      "epoch 11 | loss: 0.05154 | mse_mse: 0.04368 |  0:20:36s\n",
      "epoch 12 | loss: 0.04644 | mse_mse: 0.04148 |  0:20:41s\n",
      "epoch 13 | loss: 0.05524 | mse_mse: 0.03376 |  0:20:47s\n",
      "epoch 14 | loss: 0.04137 | mse_mse: 0.03348 |  0:20:52s\n",
      "epoch 15 | loss: 0.04224 | mse_mse: 0.05033 |  0:20:58s\n",
      "epoch 16 | loss: 0.0407  | mse_mse: 0.0289  |  0:21:04s\n",
      "epoch 17 | loss: 0.03687 | mse_mse: 0.02627 |  0:21:10s\n",
      "epoch 18 | loss: 0.03564 | mse_mse: 0.02498 |  0:21:15s\n",
      "epoch 19 | loss: 0.02939 | mse_mse: 0.02615 |  0:21:21s\n",
      "epoch 20 | loss: 0.03044 | mse_mse: 0.02198 |  0:21:26s\n",
      "epoch 21 | loss: 0.02693 | mse_mse: 0.02625 |  0:21:32s\n",
      "epoch 22 | loss: 0.02628 | mse_mse: 0.01819 |  0:21:37s\n",
      "epoch 23 | loss: 0.02777 | mse_mse: 0.01589 |  0:21:41s\n",
      "epoch 24 | loss: 0.02418 | mse_mse: 0.01534 |  0:21:46s\n",
      "epoch 25 | loss: 0.0301  | mse_mse: 0.01638 |  0:21:52s\n",
      "epoch 26 | loss: 0.02328 | mse_mse: 0.03299 |  0:21:56s\n",
      "epoch 27 | loss: 0.03478 | mse_mse: 0.04159 |  0:22:01s\n",
      "epoch 28 | loss: 0.03568 | mse_mse: 0.02303 |  0:22:05s\n",
      "epoch 29 | loss: 0.02978 | mse_mse: 0.02341 |  0:22:11s\n",
      "epoch 30 | loss: 0.02715 | mse_mse: 0.02243 |  0:22:15s\n",
      "epoch 31 | loss: 0.02496 | mse_mse: 0.02197 |  0:22:20s\n",
      "epoch 32 | loss: 0.02307 | mse_mse: 0.03094 |  0:22:25s\n",
      "epoch 33 | loss: 0.0228  | mse_mse: 0.01589 |  0:22:30s\n",
      "epoch 34 | loss: 0.0211  | mse_mse: 0.01729 |  0:22:35s\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_mse_mse = 0.01534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.01596838421176831\n",
      "R2 Score: 0.9279619903002885\n",
      "\n",
      "Iteration 29/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.34412 | mse_mse: 0.43215 |  0:00:05s\n",
      "epoch 1  | loss: 0.37948 | mse_mse: 0.21612 |  0:00:12s\n",
      "epoch 2  | loss: 0.48738 | mse_mse: 0.24474 |  0:00:18s\n",
      "epoch 3  | loss: 0.22934 | mse_mse: 0.18686 |  0:00:24s\n",
      "epoch 4  | loss: 0.24621 | mse_mse: 0.14657 |  0:00:31s\n",
      "epoch 5  | loss: 0.13012 | mse_mse: 0.13409 |  0:00:38s\n",
      "epoch 6  | loss: 0.12775 | mse_mse: 0.13794 |  0:00:46s\n",
      "epoch 7  | loss: 0.11645 | mse_mse: 0.11671 |  0:00:52s\n",
      "epoch 8  | loss: 0.10816 | mse_mse: 0.09817 |  0:00:59s\n",
      "epoch 9  | loss: 0.09669 | mse_mse: 0.07927 |  0:01:06s\n",
      "epoch 10 | loss: 0.08326 | mse_mse: 0.08298 |  0:01:13s\n",
      "epoch 11 | loss: 0.07982 | mse_mse: 0.06843 |  0:01:19s\n",
      "epoch 12 | loss: 0.07244 | mse_mse: 0.06347 |  0:01:25s\n",
      "epoch 13 | loss: 0.07162 | mse_mse: 0.06234 |  0:01:31s\n",
      "epoch 14 | loss: 0.0676  | mse_mse: 0.06074 |  0:01:39s\n",
      "epoch 15 | loss: 0.06249 | mse_mse: 0.05063 |  0:01:47s\n",
      "epoch 16 | loss: 0.05917 | mse_mse: 0.05623 |  0:01:53s\n",
      "epoch 17 | loss: 0.05865 | mse_mse: 0.05902 |  0:01:59s\n",
      "epoch 18 | loss: 0.05104 | mse_mse: 0.0446  |  0:02:06s\n",
      "epoch 19 | loss: 0.04871 | mse_mse: 0.03969 |  0:02:12s\n",
      "epoch 20 | loss: 0.04461 | mse_mse: 0.03666 |  0:02:18s\n",
      "epoch 21 | loss: 0.04442 | mse_mse: 0.0397  |  0:02:25s\n",
      "epoch 22 | loss: 0.03776 | mse_mse: 0.03243 |  0:02:31s\n",
      "epoch 23 | loss: 0.03775 | mse_mse: 0.03188 |  0:02:38s\n",
      "epoch 24 | loss: 0.03543 | mse_mse: 0.03712 |  0:02:44s\n",
      "epoch 25 | loss: 0.03608 | mse_mse: 0.02959 |  0:02:50s\n",
      "epoch 26 | loss: 0.03445 | mse_mse: 0.03746 |  0:02:56s\n",
      "epoch 27 | loss: 0.03398 | mse_mse: 0.02665 |  0:03:02s\n",
      "epoch 28 | loss: 0.03073 | mse_mse: 0.02265 |  0:03:08s\n",
      "epoch 29 | loss: 0.02754 | mse_mse: 0.02088 |  0:03:13s\n",
      "epoch 30 | loss: 0.02353 | mse_mse: 0.02111 |  0:03:19s\n",
      "epoch 31 | loss: 0.02764 | mse_mse: 0.0263  |  0:03:25s\n",
      "epoch 32 | loss: 0.02752 | mse_mse: 0.02303 |  0:03:31s\n",
      "epoch 33 | loss: 0.02075 | mse_mse: 0.01719 |  0:03:37s\n",
      "epoch 34 | loss: 0.02194 | mse_mse: 0.01678 |  0:03:43s\n",
      "epoch 35 | loss: 0.01755 | mse_mse: 0.01911 |  0:03:50s\n",
      "epoch 36 | loss: 0.02369 | mse_mse: 0.02393 |  0:03:56s\n",
      "epoch 37 | loss: 0.02365 | mse_mse: 0.01396 |  0:04:03s\n",
      "epoch 38 | loss: 0.02518 | mse_mse: 0.02963 |  0:04:09s\n",
      "epoch 39 | loss: 0.03875 | mse_mse: 0.02959 |  0:04:15s\n",
      "epoch 40 | loss: 0.04511 | mse_mse: 0.0174  |  0:04:22s\n",
      "epoch 41 | loss: 0.02275 | mse_mse: 0.01845 |  0:04:28s\n",
      "epoch 42 | loss: 0.02636 | mse_mse: 0.04063 |  0:04:35s\n",
      "epoch 43 | loss: 0.03087 | mse_mse: 0.02067 |  0:04:42s\n",
      "epoch 44 | loss: 0.02659 | mse_mse: 0.0323  |  0:04:50s\n",
      "epoch 45 | loss: 0.02061 | mse_mse: 0.01592 |  0:04:58s\n",
      "epoch 46 | loss: 0.01894 | mse_mse: 0.03162 |  0:05:05s\n",
      "epoch 47 | loss: 0.01903 | mse_mse: 0.02028 |  0:05:12s\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 37 and best_mse_mse = 0.01396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0144636842768489\n",
      "R2 Score: 0.934750127851926\n",
      "\n",
      "Iteration 30/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 16 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.34072 | mse_mse: 0.53017 |  0:00:06s\n",
      "epoch 1  | loss: 0.38333 | mse_mse: 0.24494 |  0:00:13s\n",
      "epoch 2  | loss: 0.41996 | mse_mse: 0.18904 |  0:00:20s\n",
      "epoch 3  | loss: 0.16176 | mse_mse: 0.13143 |  0:00:27s\n",
      "epoch 4  | loss: 0.10929 | mse_mse: 0.16366 |  0:00:33s\n",
      "epoch 5  | loss: 0.08341 | mse_mse: 0.12722 |  0:00:40s\n",
      "epoch 6  | loss: 0.07513 | mse_mse: 0.12364 |  0:00:47s\n",
      "epoch 7  | loss: 0.07218 | mse_mse: 0.09622 |  0:00:55s\n",
      "epoch 8  | loss: 0.06485 | mse_mse: 0.07743 |  0:01:01s\n",
      "epoch 9  | loss: 0.0656  | mse_mse: 0.0903  |  0:01:08s\n",
      "epoch 10 | loss: 0.05763 | mse_mse: 0.05675 |  0:01:14s\n",
      "epoch 11 | loss: 0.04998 | mse_mse: 0.05156 |  0:01:22s\n",
      "epoch 12 | loss: 0.05324 | mse_mse: 0.05132 |  0:01:28s\n",
      "epoch 13 | loss: 0.05095 | mse_mse: 0.04312 |  0:01:35s\n",
      "epoch 14 | loss: 0.0479  | mse_mse: 0.04408 |  0:01:41s\n",
      "epoch 15 | loss: 0.04781 | mse_mse: 0.0577  |  0:01:48s\n",
      "epoch 16 | loss: 0.05111 | mse_mse: 0.0473  |  0:01:54s\n",
      "epoch 17 | loss: 0.04623 | mse_mse: 0.04702 |  0:02:00s\n",
      "epoch 18 | loss: 0.05031 | mse_mse: 0.04151 |  0:02:06s\n",
      "epoch 19 | loss: 0.0441  | mse_mse: 0.03723 |  0:02:12s\n",
      "epoch 20 | loss: 0.04491 | mse_mse: 0.03725 |  0:02:19s\n",
      "epoch 21 | loss: 0.04037 | mse_mse: 0.03225 |  0:02:25s\n",
      "epoch 22 | loss: 0.03862 | mse_mse: 0.03318 |  0:02:31s\n",
      "epoch 23 | loss: 0.03715 | mse_mse: 0.03757 |  0:02:38s\n",
      "epoch 24 | loss: 0.03655 | mse_mse: 0.03008 |  0:02:44s\n",
      "epoch 25 | loss: 0.03341 | mse_mse: 0.03073 |  0:02:50s\n",
      "epoch 26 | loss: 0.03715 | mse_mse: 0.02923 |  0:02:56s\n",
      "epoch 27 | loss: 0.0354  | mse_mse: 0.0329  |  0:03:03s\n",
      "epoch 28 | loss: 0.03145 | mse_mse: 0.02799 |  0:03:09s\n",
      "epoch 29 | loss: 0.03268 | mse_mse: 0.02783 |  0:03:15s\n",
      "epoch 30 | loss: 0.03371 | mse_mse: 0.02466 |  0:03:21s\n",
      "epoch 31 | loss: 0.02956 | mse_mse: 0.02422 |  0:03:28s\n",
      "epoch 32 | loss: 0.02853 | mse_mse: 0.02274 |  0:03:34s\n",
      "epoch 33 | loss: 0.02692 | mse_mse: 0.03731 |  0:03:40s\n",
      "epoch 34 | loss: 0.02692 | mse_mse: 0.02116 |  0:03:46s\n",
      "epoch 35 | loss: 0.02955 | mse_mse: 0.02581 |  0:03:53s\n",
      "epoch 36 | loss: 0.02665 | mse_mse: 0.02131 |  0:03:59s\n",
      "epoch 37 | loss: 0.02548 | mse_mse: 0.02038 |  0:04:05s\n",
      "epoch 38 | loss: 0.02882 | mse_mse: 0.02033 |  0:04:12s\n",
      "epoch 39 | loss: 0.02371 | mse_mse: 0.02349 |  0:04:18s\n",
      "epoch 40 | loss: 0.0214  | mse_mse: 0.01631 |  0:04:24s\n",
      "epoch 41 | loss: 0.02254 | mse_mse: 0.01631 |  0:04:31s\n",
      "epoch 42 | loss: 0.02214 | mse_mse: 0.03403 |  0:04:42s\n",
      "epoch 43 | loss: 0.02846 | mse_mse: 0.02516 |  0:04:49s\n",
      "epoch 44 | loss: 0.02376 | mse_mse: 0.01998 |  0:04:56s\n",
      "epoch 45 | loss: 0.02506 | mse_mse: 0.01615 |  0:05:04s\n",
      "epoch 46 | loss: 0.02077 | mse_mse: 0.01838 |  0:05:10s\n",
      "epoch 47 | loss: 0.0203  | mse_mse: 0.01329 |  0:05:17s\n",
      "epoch 48 | loss: 0.02018 | mse_mse: 0.02042 |  0:05:25s\n",
      "epoch 49 | loss: 0.01871 | mse_mse: 0.01679 |  0:05:31s\n",
      "epoch 50 | loss: 0.01679 | mse_mse: 0.01812 |  0:05:38s\n",
      "epoch 51 | loss: 0.01627 | mse_mse: 0.01228 |  0:05:45s\n",
      "epoch 52 | loss: 0.01498 | mse_mse: 0.00982 |  0:05:52s\n",
      "epoch 53 | loss: 0.01577 | mse_mse: 0.01284 |  0:05:58s\n",
      "epoch 54 | loss: 0.01664 | mse_mse: 0.01001 |  0:06:05s\n",
      "epoch 55 | loss: 0.01525 | mse_mse: 0.01756 |  0:06:12s\n",
      "epoch 56 | loss: 0.01334 | mse_mse: 0.01065 |  0:06:18s\n",
      "epoch 57 | loss: 0.01169 | mse_mse: 0.0096  |  0:06:25s\n",
      "epoch 58 | loss: 0.01429 | mse_mse: 0.01114 |  0:06:37s\n",
      "epoch 59 | loss: 0.01435 | mse_mse: 0.00943 |  0:06:45s\n",
      "epoch 60 | loss: 0.01365 | mse_mse: 0.00802 |  0:06:52s\n",
      "epoch 61 | loss: 0.01189 | mse_mse: 0.01039 |  0:07:00s\n",
      "epoch 62 | loss: 0.01126 | mse_mse: 0.01318 |  0:07:07s\n",
      "epoch 63 | loss: 0.01162 | mse_mse: 0.01032 |  0:07:14s\n",
      "epoch 64 | loss: 0.01282 | mse_mse: 0.00939 |  0:07:20s\n",
      "epoch 65 | loss: 0.00947 | mse_mse: 0.00789 |  0:07:27s\n",
      "epoch 66 | loss: 0.01133 | mse_mse: 0.00799 |  0:07:34s\n",
      "epoch 67 | loss: 0.01052 | mse_mse: 0.0068  |  0:07:41s\n",
      "epoch 68 | loss: 0.01067 | mse_mse: 0.00746 |  0:07:48s\n",
      "epoch 69 | loss: 0.01112 | mse_mse: 0.00845 |  0:07:56s\n",
      "epoch 70 | loss: 0.01054 | mse_mse: 0.0071  |  0:08:03s\n",
      "epoch 71 | loss: 0.01082 | mse_mse: 0.00975 |  0:08:10s\n",
      "epoch 72 | loss: 0.0083  | mse_mse: 0.00737 |  0:08:17s\n",
      "epoch 73 | loss: 0.01093 | mse_mse: 0.00704 |  0:08:25s\n",
      "epoch 74 | loss: 0.01103 | mse_mse: 0.00802 |  0:08:32s\n",
      "epoch 75 | loss: 0.01291 | mse_mse: 0.02555 |  0:08:39s\n",
      "epoch 76 | loss: 0.01329 | mse_mse: 0.00837 |  0:08:45s\n",
      "epoch 77 | loss: 0.01146 | mse_mse: 0.01509 |  0:08:53s\n",
      "\n",
      "Early stopping occurred at epoch 77 with best_epoch = 67 and best_mse_mse = 0.0068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0067657333177041515\n",
      "R2 Score: 0.9694778159203334\n",
      "\n",
      "Iteration 31/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.55859 | mse_mse: 0.5441  |  0:00:04s\n",
      "epoch 1  | loss: 0.2138  | mse_mse: 0.31002 |  0:00:08s\n",
      "epoch 2  | loss: 0.08964 | mse_mse: 0.12313 |  0:00:12s\n",
      "epoch 3  | loss: 0.07019 | mse_mse: 0.11644 |  0:00:15s\n",
      "epoch 4  | loss: 0.05574 | mse_mse: 0.10486 |  0:00:19s\n",
      "epoch 5  | loss: 0.05076 | mse_mse: 0.10134 |  0:00:22s\n",
      "epoch 6  | loss: 0.04519 | mse_mse: 0.08675 |  0:00:26s\n",
      "epoch 7  | loss: 0.03959 | mse_mse: 0.06945 |  0:00:29s\n",
      "epoch 8  | loss: 0.0373  | mse_mse: 0.04754 |  0:00:32s\n",
      "epoch 9  | loss: 0.0362  | mse_mse: 0.05793 |  0:00:36s\n",
      "epoch 10 | loss: 0.03281 | mse_mse: 0.04525 |  0:00:39s\n",
      "epoch 11 | loss: 0.03049 | mse_mse: 0.03613 |  0:00:42s\n",
      "epoch 12 | loss: 0.03136 | mse_mse: 0.02825 |  0:00:46s\n",
      "epoch 13 | loss: 0.02963 | mse_mse: 0.03084 |  0:00:49s\n",
      "epoch 14 | loss: 0.0277  | mse_mse: 0.02219 |  0:00:52s\n",
      "epoch 15 | loss: 0.0232  | mse_mse: 0.0191  |  0:00:56s\n",
      "epoch 16 | loss: 0.02455 | mse_mse: 0.02065 |  0:00:59s\n",
      "epoch 17 | loss: 0.02261 | mse_mse: 0.02166 |  0:01:02s\n",
      "epoch 18 | loss: 0.02882 | mse_mse: 0.03228 |  0:01:05s\n",
      "epoch 19 | loss: 0.02129 | mse_mse: 0.01772 |  0:01:08s\n",
      "epoch 20 | loss: 0.01946 | mse_mse: 0.01343 |  0:01:12s\n",
      "epoch 21 | loss: 0.01963 | mse_mse: 0.01682 |  0:01:15s\n",
      "epoch 22 | loss: 0.01851 | mse_mse: 0.01357 |  0:01:18s\n",
      "epoch 23 | loss: 0.01647 | mse_mse: 0.01306 |  0:01:22s\n",
      "epoch 24 | loss: 0.01681 | mse_mse: 0.01934 |  0:01:25s\n",
      "epoch 25 | loss: 0.016   | mse_mse: 0.01516 |  0:01:29s\n",
      "epoch 26 | loss: 0.01789 | mse_mse: 0.01701 |  0:01:32s\n",
      "epoch 27 | loss: 0.01579 | mse_mse: 0.01149 |  0:01:35s\n",
      "epoch 28 | loss: 0.0163  | mse_mse: 0.01423 |  0:01:38s\n",
      "epoch 29 | loss: 0.01703 | mse_mse: 0.00971 |  0:01:41s\n",
      "epoch 30 | loss: 0.01435 | mse_mse: 0.01047 |  0:01:45s\n",
      "epoch 31 | loss: 0.01307 | mse_mse: 0.01034 |  0:01:48s\n",
      "epoch 32 | loss: 0.01317 | mse_mse: 0.0113  |  0:01:51s\n",
      "epoch 33 | loss: 0.01228 | mse_mse: 0.00847 |  0:01:54s\n",
      "epoch 34 | loss: 0.01217 | mse_mse: 0.00814 |  0:01:57s\n",
      "epoch 35 | loss: 0.0126  | mse_mse: 0.00992 |  0:02:01s\n",
      "epoch 36 | loss: 0.01302 | mse_mse: 0.02518 |  0:02:04s\n",
      "epoch 37 | loss: 0.01262 | mse_mse: 0.01197 |  0:02:07s\n",
      "epoch 38 | loss: 0.01253 | mse_mse: 0.01814 |  0:02:10s\n",
      "epoch 39 | loss: 0.01343 | mse_mse: 0.02529 |  0:02:14s\n",
      "epoch 40 | loss: 0.01569 | mse_mse: 0.01308 |  0:02:17s\n",
      "epoch 41 | loss: 0.01223 | mse_mse: 0.00706 |  0:02:21s\n",
      "epoch 42 | loss: 0.00868 | mse_mse: 0.00822 |  0:02:24s\n",
      "epoch 43 | loss: 0.0136  | mse_mse: 0.01092 |  0:02:27s\n",
      "epoch 44 | loss: 0.01291 | mse_mse: 0.01189 |  0:02:30s\n",
      "epoch 45 | loss: 0.00962 | mse_mse: 0.00683 |  0:02:34s\n",
      "epoch 46 | loss: 0.01059 | mse_mse: 0.0209  |  0:02:37s\n",
      "epoch 47 | loss: 0.0203  | mse_mse: 0.01486 |  0:02:40s\n",
      "epoch 48 | loss: 0.01926 | mse_mse: 0.01509 |  0:02:44s\n",
      "epoch 49 | loss: 0.01574 | mse_mse: 0.01243 |  0:02:47s\n",
      "epoch 50 | loss: 0.01416 | mse_mse: 0.01534 |  0:02:50s\n",
      "epoch 51 | loss: 0.01281 | mse_mse: 0.01047 |  0:02:54s\n",
      "epoch 52 | loss: 0.01447 | mse_mse: 0.01288 |  0:02:58s\n",
      "epoch 53 | loss: 0.01278 | mse_mse: 0.01284 |  0:03:01s\n",
      "epoch 54 | loss: 0.01313 | mse_mse: 0.01185 |  0:03:05s\n",
      "epoch 55 | loss: 0.01539 | mse_mse: 0.01305 |  0:03:09s\n",
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 45 and best_mse_mse = 0.00683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007569145746394884\n",
      "R2 Score: 0.9658533895811777\n",
      "\n",
      "Iteration 32/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.03657 | mse_mse: 0.60518 |  0:00:03s\n",
      "epoch 1  | loss: 0.20047 | mse_mse: 0.21067 |  0:00:07s\n",
      "epoch 2  | loss: 0.09076 | mse_mse: 0.15138 |  0:00:10s\n",
      "epoch 3  | loss: 0.07553 | mse_mse: 0.12333 |  0:00:14s\n",
      "epoch 4  | loss: 0.06251 | mse_mse: 0.12762 |  0:00:18s\n",
      "epoch 5  | loss: 0.05482 | mse_mse: 0.10459 |  0:00:21s\n",
      "epoch 6  | loss: 0.0518  | mse_mse: 0.08011 |  0:00:24s\n",
      "epoch 7  | loss: 0.04729 | mse_mse: 0.06953 |  0:00:28s\n",
      "epoch 8  | loss: 0.04332 | mse_mse: 0.05524 |  0:00:32s\n",
      "epoch 9  | loss: 0.03781 | mse_mse: 0.04854 |  0:00:35s\n",
      "epoch 10 | loss: 0.03526 | mse_mse: 0.02896 |  0:00:39s\n",
      "epoch 11 | loss: 0.03007 | mse_mse: 0.02817 |  0:00:42s\n",
      "epoch 12 | loss: 0.02864 | mse_mse: 0.02866 |  0:00:46s\n",
      "epoch 13 | loss: 0.02746 | mse_mse: 0.02018 |  0:00:50s\n",
      "epoch 14 | loss: 0.02395 | mse_mse: 0.02182 |  0:00:53s\n",
      "epoch 15 | loss: 0.02387 | mse_mse: 0.01673 |  0:00:57s\n",
      "epoch 16 | loss: 0.02052 | mse_mse: 0.02377 |  0:01:00s\n",
      "epoch 17 | loss: 0.02345 | mse_mse: 0.01505 |  0:01:03s\n",
      "epoch 18 | loss: 0.02038 | mse_mse: 0.01913 |  0:01:07s\n",
      "epoch 19 | loss: 0.02193 | mse_mse: 0.01766 |  0:01:11s\n",
      "epoch 20 | loss: 0.01742 | mse_mse: 0.01277 |  0:01:14s\n",
      "epoch 21 | loss: 0.01838 | mse_mse: 0.01467 |  0:01:18s\n",
      "epoch 22 | loss: 0.02708 | mse_mse: 0.0224  |  0:01:22s\n",
      "epoch 23 | loss: 0.02025 | mse_mse: 0.01313 |  0:01:25s\n",
      "epoch 24 | loss: 0.01575 | mse_mse: 0.0119  |  0:01:29s\n",
      "epoch 25 | loss: 0.01797 | mse_mse: 0.02387 |  0:01:32s\n",
      "epoch 26 | loss: 0.01976 | mse_mse: 0.01809 |  0:01:36s\n",
      "epoch 27 | loss: 0.01698 | mse_mse: 0.02291 |  0:01:39s\n",
      "epoch 28 | loss: 0.01632 | mse_mse: 0.00933 |  0:01:43s\n",
      "epoch 29 | loss: 0.01459 | mse_mse: 0.01549 |  0:01:47s\n",
      "epoch 30 | loss: 0.01179 | mse_mse: 0.01081 |  0:01:50s\n",
      "epoch 31 | loss: 0.01071 | mse_mse: 0.0093  |  0:01:54s\n",
      "epoch 32 | loss: 0.01596 | mse_mse: 0.0105  |  0:01:58s\n",
      "epoch 33 | loss: 0.01368 | mse_mse: 0.01368 |  0:02:02s\n",
      "epoch 34 | loss: 0.01784 | mse_mse: 0.01217 |  0:02:05s\n",
      "epoch 35 | loss: 0.01206 | mse_mse: 0.00784 |  0:02:09s\n",
      "epoch 36 | loss: 0.01209 | mse_mse: 0.0115  |  0:02:13s\n",
      "epoch 37 | loss: 0.01192 | mse_mse: 0.01336 |  0:02:16s\n",
      "epoch 38 | loss: 0.01081 | mse_mse: 0.00869 |  0:02:20s\n",
      "epoch 39 | loss: 0.01242 | mse_mse: 0.02088 |  0:02:23s\n",
      "epoch 40 | loss: 0.01162 | mse_mse: 0.00744 |  0:02:27s\n",
      "epoch 41 | loss: 0.01136 | mse_mse: 0.00983 |  0:02:30s\n",
      "epoch 42 | loss: 0.01658 | mse_mse: 0.00891 |  0:02:34s\n",
      "epoch 43 | loss: 0.01173 | mse_mse: 0.00735 |  0:02:37s\n",
      "epoch 44 | loss: 0.00988 | mse_mse: 0.00979 |  0:02:41s\n",
      "epoch 45 | loss: 0.00975 | mse_mse: 0.00727 |  0:02:44s\n",
      "epoch 46 | loss: 0.01078 | mse_mse: 0.0065  |  0:02:48s\n",
      "epoch 47 | loss: 0.01595 | mse_mse: 0.01274 |  0:02:51s\n",
      "epoch 48 | loss: 0.01099 | mse_mse: 0.01471 |  0:02:55s\n",
      "epoch 49 | loss: 0.01082 | mse_mse: 0.00857 |  0:02:58s\n",
      "epoch 50 | loss: 0.00837 | mse_mse: 0.00633 |  0:03:02s\n",
      "epoch 51 | loss: 0.01187 | mse_mse: 0.02496 |  0:03:06s\n",
      "epoch 52 | loss: 0.01456 | mse_mse: 0.00993 |  0:03:09s\n",
      "epoch 53 | loss: 0.01186 | mse_mse: 0.00794 |  0:03:13s\n",
      "epoch 54 | loss: 0.01835 | mse_mse: 0.01877 |  0:03:17s\n",
      "epoch 55 | loss: 0.01555 | mse_mse: 0.01541 |  0:03:21s\n",
      "epoch 56 | loss: 0.01791 | mse_mse: 0.02585 |  0:03:24s\n",
      "epoch 57 | loss: 0.01409 | mse_mse: 0.01296 |  0:03:28s\n",
      "epoch 58 | loss: 0.01119 | mse_mse: 0.01231 |  0:03:32s\n",
      "epoch 59 | loss: 0.0099  | mse_mse: 0.00745 |  0:03:36s\n",
      "epoch 60 | loss: 0.0121  | mse_mse: 0.00722 |  0:03:39s\n",
      "\n",
      "Early stopping occurred at epoch 60 with best_epoch = 50 and best_mse_mse = 0.00633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.006306341144409187\n",
      "R2 Score: 0.9715502671713125\n",
      "\n",
      "Iteration 33/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.10455 | mse_mse: 1.00367 |  0:00:05s\n",
      "epoch 1  | loss: 0.29065 | mse_mse: 0.33545 |  0:00:10s\n",
      "epoch 2  | loss: 0.14924 | mse_mse: 0.20869 |  0:00:15s\n",
      "epoch 3  | loss: 0.09609 | mse_mse: 0.20514 |  0:00:20s\n",
      "epoch 4  | loss: 0.07929 | mse_mse: 0.14147 |  0:00:26s\n",
      "epoch 5  | loss: 0.07053 | mse_mse: 0.11854 |  0:00:31s\n",
      "epoch 6  | loss: 0.06325 | mse_mse: 0.08728 |  0:00:36s\n",
      "epoch 7  | loss: 0.06191 | mse_mse: 0.08414 |  0:00:41s\n",
      "epoch 8  | loss: 0.05232 | mse_mse: 0.0743  |  0:00:47s\n",
      "epoch 9  | loss: 0.05517 | mse_mse: 0.05959 |  0:00:53s\n",
      "epoch 10 | loss: 0.04631 | mse_mse: 0.06622 |  0:00:59s\n",
      "epoch 11 | loss: 0.04376 | mse_mse: 0.05243 |  0:01:05s\n",
      "epoch 12 | loss: 0.04591 | mse_mse: 0.04479 |  0:01:11s\n",
      "epoch 13 | loss: 0.05383 | mse_mse: 0.04457 |  0:01:18s\n",
      "epoch 14 | loss: 0.0437  | mse_mse: 0.04022 |  0:01:26s\n",
      "epoch 15 | loss: 0.03739 | mse_mse: 0.03258 |  0:01:32s\n",
      "epoch 16 | loss: 0.03327 | mse_mse: 0.02729 |  0:01:38s\n",
      "epoch 17 | loss: 0.03148 | mse_mse: 0.02675 |  0:01:44s\n",
      "epoch 18 | loss: 0.03154 | mse_mse: 0.02705 |  0:01:50s\n",
      "epoch 19 | loss: 0.03617 | mse_mse: 0.03122 |  0:01:55s\n",
      "epoch 20 | loss: 0.03011 | mse_mse: 0.03274 |  0:02:01s\n",
      "epoch 21 | loss: 0.03176 | mse_mse: 0.0233  |  0:02:06s\n",
      "epoch 22 | loss: 0.03067 | mse_mse: 0.02231 |  0:02:12s\n",
      "epoch 23 | loss: 0.02605 | mse_mse: 0.02365 |  0:02:18s\n",
      "epoch 24 | loss: 0.03247 | mse_mse: 0.0243  |  0:02:24s\n",
      "epoch 25 | loss: 0.03842 | mse_mse: 0.01948 |  0:02:30s\n",
      "epoch 26 | loss: 0.02683 | mse_mse: 0.01969 |  0:02:36s\n",
      "epoch 27 | loss: 0.02261 | mse_mse: 0.0199  |  0:02:42s\n",
      "epoch 28 | loss: 0.02277 | mse_mse: 0.02561 |  0:02:48s\n",
      "epoch 29 | loss: 0.02403 | mse_mse: 0.01522 |  0:02:54s\n",
      "epoch 30 | loss: 0.02541 | mse_mse: 0.03412 |  0:03:00s\n",
      "epoch 31 | loss: 0.02093 | mse_mse: 0.01997 |  0:03:06s\n",
      "epoch 32 | loss: 0.02132 | mse_mse: 0.02728 |  0:03:12s\n",
      "epoch 33 | loss: 0.01862 | mse_mse: 0.01531 |  0:03:18s\n",
      "epoch 34 | loss: 0.01928 | mse_mse: 0.0135  |  0:03:24s\n",
      "epoch 35 | loss: 0.0203  | mse_mse: 0.01537 |  0:03:30s\n",
      "epoch 36 | loss: 0.01999 | mse_mse: 0.02244 |  0:03:36s\n",
      "epoch 37 | loss: 0.01778 | mse_mse: 0.01273 |  0:03:42s\n",
      "epoch 38 | loss: 0.01693 | mse_mse: 0.01073 |  0:03:49s\n",
      "epoch 39 | loss: 0.01619 | mse_mse: 0.01706 |  0:03:55s\n",
      "epoch 40 | loss: 0.02281 | mse_mse: 0.07615 |  0:04:01s\n",
      "epoch 41 | loss: 0.01954 | mse_mse: 0.0145  |  0:04:07s\n",
      "epoch 42 | loss: 0.02003 | mse_mse: 0.01615 |  0:04:14s\n",
      "epoch 43 | loss: 0.01647 | mse_mse: 0.01055 |  0:04:19s\n",
      "epoch 44 | loss: 0.01522 | mse_mse: 0.01163 |  0:04:25s\n",
      "epoch 45 | loss: 0.02373 | mse_mse: 0.01551 |  0:04:31s\n",
      "epoch 46 | loss: 0.0205  | mse_mse: 0.02588 |  0:04:36s\n",
      "epoch 47 | loss: 0.02352 | mse_mse: 0.0201  |  0:04:42s\n",
      "epoch 48 | loss: 0.01724 | mse_mse: 0.01316 |  0:04:48s\n",
      "epoch 49 | loss: 0.01738 | mse_mse: 0.03174 |  0:04:54s\n",
      "epoch 50 | loss: 0.01847 | mse_mse: 0.02123 |  0:05:00s\n",
      "epoch 51 | loss: 0.01674 | mse_mse: 0.02297 |  0:05:06s\n",
      "epoch 52 | loss: 0.01663 | mse_mse: 0.02005 |  0:05:14s\n",
      "epoch 53 | loss: 0.01761 | mse_mse: 0.01503 |  0:05:20s\n",
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 43 and best_mse_mse = 0.01055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010513897768379984\n",
      "R2 Score: 0.9525687596580907\n",
      "\n",
      "Iteration 34/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.87349 | mse_mse: 0.56062 |  0:00:07s\n",
      "epoch 1  | loss: 0.35424 | mse_mse: 0.255   |  0:00:13s\n",
      "epoch 2  | loss: 0.14915 | mse_mse: 0.20091 |  0:00:19s\n",
      "epoch 3  | loss: 0.09871 | mse_mse: 0.12247 |  0:00:25s\n",
      "epoch 4  | loss: 0.08383 | mse_mse: 0.10214 |  0:00:31s\n",
      "epoch 5  | loss: 0.06878 | mse_mse: 0.08613 |  0:00:37s\n",
      "epoch 6  | loss: 0.06429 | mse_mse: 0.07781 |  0:00:43s\n",
      "epoch 7  | loss: 0.05462 | mse_mse: 0.06791 |  0:00:49s\n",
      "epoch 8  | loss: 0.05493 | mse_mse: 0.06684 |  0:00:55s\n",
      "epoch 9  | loss: 0.05343 | mse_mse: 0.07251 |  0:01:01s\n",
      "epoch 10 | loss: 0.04646 | mse_mse: 0.04106 |  0:01:08s\n",
      "epoch 11 | loss: 0.03935 | mse_mse: 0.04378 |  0:01:13s\n",
      "epoch 12 | loss: 0.04172 | mse_mse: 0.04279 |  0:01:20s\n",
      "epoch 13 | loss: 0.03869 | mse_mse: 0.03089 |  0:01:27s\n",
      "epoch 14 | loss: 0.04302 | mse_mse: 0.02954 |  0:01:33s\n",
      "epoch 15 | loss: 0.03737 | mse_mse: 0.02978 |  0:01:40s\n",
      "epoch 16 | loss: 0.03457 | mse_mse: 0.0274  |  0:01:46s\n",
      "epoch 17 | loss: 0.03043 | mse_mse: 0.02746 |  0:01:52s\n",
      "epoch 18 | loss: 0.02986 | mse_mse: 0.02641 |  0:01:58s\n",
      "epoch 19 | loss: 0.03616 | mse_mse: 0.02114 |  0:02:04s\n",
      "epoch 20 | loss: 0.02637 | mse_mse: 0.01985 |  0:02:10s\n",
      "epoch 21 | loss: 0.0242  | mse_mse: 0.01733 |  0:02:16s\n",
      "epoch 22 | loss: 0.02223 | mse_mse: 0.03552 |  0:02:21s\n",
      "epoch 23 | loss: 0.02335 | mse_mse: 0.01659 |  0:02:27s\n",
      "epoch 24 | loss: 0.02053 | mse_mse: 0.01522 |  0:02:32s\n",
      "epoch 25 | loss: 0.01765 | mse_mse: 0.01226 |  0:02:38s\n",
      "epoch 26 | loss: 0.02228 | mse_mse: 0.01778 |  0:02:43s\n",
      "epoch 27 | loss: 0.01777 | mse_mse: 0.01268 |  0:02:49s\n",
      "epoch 28 | loss: 0.02612 | mse_mse: 0.02404 |  0:02:54s\n",
      "epoch 29 | loss: 0.02383 | mse_mse: 0.0202  |  0:03:00s\n",
      "epoch 30 | loss: 0.02204 | mse_mse: 0.01899 |  0:03:05s\n",
      "epoch 31 | loss: 0.02592 | mse_mse: 0.02577 |  0:03:11s\n",
      "epoch 32 | loss: 0.02638 | mse_mse: 0.01569 |  0:03:17s\n",
      "epoch 33 | loss: 0.02318 | mse_mse: 0.02262 |  0:03:22s\n",
      "epoch 34 | loss: 0.02136 | mse_mse: 0.02319 |  0:03:28s\n",
      "epoch 35 | loss: 0.0147  | mse_mse: 0.01225 |  0:03:34s\n",
      "epoch 36 | loss: 0.01569 | mse_mse: 0.01226 |  0:03:40s\n",
      "epoch 37 | loss: 0.01273 | mse_mse: 0.0251  |  0:03:45s\n",
      "epoch 38 | loss: 0.0179  | mse_mse: 0.02428 |  0:03:51s\n",
      "epoch 39 | loss: 0.01598 | mse_mse: 0.01243 |  0:03:56s\n",
      "epoch 40 | loss: 0.02343 | mse_mse: 0.01864 |  0:04:02s\n",
      "epoch 41 | loss: 0.01839 | mse_mse: 0.02026 |  0:04:07s\n",
      "epoch 42 | loss: 0.01352 | mse_mse: 0.01014 |  0:04:13s\n",
      "epoch 43 | loss: 0.01165 | mse_mse: 0.00928 |  0:04:18s\n",
      "epoch 44 | loss: 0.01351 | mse_mse: 0.00928 |  0:04:24s\n",
      "epoch 45 | loss: 0.01185 | mse_mse: 0.01453 |  0:04:29s\n",
      "epoch 46 | loss: 0.01246 | mse_mse: 0.00637 |  0:04:35s\n",
      "epoch 47 | loss: 0.01115 | mse_mse: 0.0066  |  0:04:41s\n",
      "epoch 48 | loss: 0.01395 | mse_mse: 0.01883 |  0:04:46s\n",
      "epoch 49 | loss: 0.01594 | mse_mse: 0.0113  |  0:04:52s\n",
      "epoch 50 | loss: 0.01276 | mse_mse: 0.01397 |  0:04:58s\n",
      "epoch 51 | loss: 0.0113  | mse_mse: 0.01122 |  0:05:04s\n",
      "epoch 52 | loss: 0.01578 | mse_mse: 0.0184  |  0:05:10s\n",
      "epoch 53 | loss: 0.01504 | mse_mse: 0.01644 |  0:05:15s\n",
      "epoch 54 | loss: 0.01392 | mse_mse: 0.04508 |  0:05:21s\n",
      "epoch 55 | loss: 0.01406 | mse_mse: 0.01383 |  0:05:27s\n",
      "epoch 56 | loss: 0.01087 | mse_mse: 0.02975 |  0:05:33s\n",
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 46 and best_mse_mse = 0.00637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007117470792850449\n",
      "R2 Score: 0.9678910262169853\n",
      "\n",
      "Iteration 35/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.66996 | mse_mse: 0.78783 |  0:00:06s\n",
      "epoch 1  | loss: 0.34477 | mse_mse: 0.2571  |  0:00:13s\n",
      "epoch 2  | loss: 0.48411 | mse_mse: 0.13291 |  0:00:20s\n",
      "epoch 3  | loss: 0.18459 | mse_mse: 0.16103 |  0:00:27s\n",
      "epoch 4  | loss: 0.12288 | mse_mse: 0.14211 |  0:00:34s\n",
      "epoch 5  | loss: 0.09895 | mse_mse: 0.14147 |  0:00:41s\n",
      "epoch 6  | loss: 0.07924 | mse_mse: 0.10778 |  0:00:48s\n",
      "epoch 7  | loss: 0.07805 | mse_mse: 0.10854 |  0:00:55s\n",
      "epoch 8  | loss: 0.09026 | mse_mse: 0.15871 |  0:01:02s\n",
      "epoch 9  | loss: 0.07917 | mse_mse: 0.0849  |  0:01:10s\n",
      "epoch 10 | loss: 0.06954 | mse_mse: 0.07861 |  0:01:16s\n",
      "epoch 11 | loss: 0.06213 | mse_mse: 0.07797 |  0:01:24s\n",
      "epoch 12 | loss: 0.06425 | mse_mse: 0.05624 |  0:01:30s\n",
      "epoch 13 | loss: 0.06313 | mse_mse: 0.05639 |  0:01:37s\n",
      "epoch 14 | loss: 0.06139 | mse_mse: 0.05063 |  0:01:44s\n",
      "epoch 15 | loss: 0.05643 | mse_mse: 0.05506 |  0:01:51s\n",
      "epoch 16 | loss: 0.06274 | mse_mse: 0.0556  |  0:01:58s\n",
      "epoch 17 | loss: 0.05679 | mse_mse: 0.05076 |  0:02:05s\n",
      "epoch 18 | loss: 0.05797 | mse_mse: 0.0667  |  0:02:13s\n",
      "epoch 19 | loss: 0.0615  | mse_mse: 0.05847 |  0:02:20s\n",
      "epoch 20 | loss: 0.06289 | mse_mse: 0.06514 |  0:02:27s\n",
      "epoch 21 | loss: 0.05833 | mse_mse: 0.04992 |  0:02:35s\n",
      "epoch 22 | loss: 0.06239 | mse_mse: 0.06219 |  0:02:42s\n",
      "epoch 23 | loss: 0.06527 | mse_mse: 0.05379 |  0:02:49s\n",
      "epoch 24 | loss: 0.05838 | mse_mse: 0.05656 |  0:02:56s\n",
      "epoch 25 | loss: 0.05869 | mse_mse: 0.05201 |  0:03:03s\n",
      "epoch 26 | loss: 0.0556  | mse_mse: 0.04675 |  0:03:10s\n",
      "epoch 27 | loss: 0.05639 | mse_mse: 0.04644 |  0:03:18s\n",
      "epoch 28 | loss: 0.04987 | mse_mse: 0.04557 |  0:03:25s\n",
      "epoch 29 | loss: 0.04926 | mse_mse: 0.0449  |  0:03:32s\n",
      "epoch 30 | loss: 0.04633 | mse_mse: 0.0428  |  0:03:39s\n",
      "epoch 31 | loss: 0.04953 | mse_mse: 0.04135 |  0:03:46s\n",
      "epoch 32 | loss: 0.0474  | mse_mse: 0.05114 |  0:03:54s\n",
      "epoch 33 | loss: 0.04981 | mse_mse: 0.05734 |  0:04:01s\n",
      "epoch 34 | loss: 0.04885 | mse_mse: 0.0396  |  0:04:08s\n",
      "epoch 35 | loss: 0.04233 | mse_mse: 0.04018 |  0:04:16s\n",
      "epoch 36 | loss: 0.04788 | mse_mse: 0.04481 |  0:04:23s\n",
      "epoch 37 | loss: 0.04389 | mse_mse: 0.04937 |  0:04:30s\n",
      "epoch 38 | loss: 0.03865 | mse_mse: 0.05284 |  0:04:37s\n",
      "epoch 39 | loss: 0.04218 | mse_mse: 0.03528 |  0:04:45s\n",
      "epoch 40 | loss: 0.04198 | mse_mse: 0.03464 |  0:04:52s\n",
      "epoch 41 | loss: 0.03723 | mse_mse: 0.03129 |  0:04:59s\n",
      "epoch 42 | loss: 0.0359  | mse_mse: 0.03497 |  0:05:06s\n",
      "epoch 43 | loss: 0.03681 | mse_mse: 0.02989 |  0:05:13s\n",
      "epoch 44 | loss: 0.03196 | mse_mse: 0.02956 |  0:05:21s\n",
      "epoch 45 | loss: 0.03772 | mse_mse: 0.04292 |  0:05:28s\n",
      "epoch 46 | loss: 0.03978 | mse_mse: 0.02991 |  0:05:35s\n",
      "epoch 47 | loss: 0.03044 | mse_mse: 0.02931 |  0:05:42s\n",
      "epoch 48 | loss: 0.03225 | mse_mse: 0.02338 |  0:05:52s\n",
      "epoch 49 | loss: 0.02782 | mse_mse: 0.02164 |  0:06:00s\n",
      "epoch 50 | loss: 0.02548 | mse_mse: 0.02139 |  0:06:07s\n",
      "epoch 51 | loss: 0.0272  | mse_mse: 0.02088 |  0:06:15s\n",
      "epoch 52 | loss: 0.0321  | mse_mse: 0.03124 |  0:06:24s\n",
      "epoch 53 | loss: 0.02991 | mse_mse: 0.03012 |  0:06:32s\n",
      "epoch 54 | loss: 0.02815 | mse_mse: 0.03011 |  0:06:40s\n",
      "epoch 55 | loss: 0.02609 | mse_mse: 0.01869 |  0:06:48s\n",
      "epoch 56 | loss: 0.02502 | mse_mse: 0.02482 |  0:06:55s\n",
      "epoch 57 | loss: 0.02736 | mse_mse: 0.02308 |  0:07:03s\n",
      "epoch 58 | loss: 0.03108 | mse_mse: 0.03099 |  0:07:10s\n",
      "epoch 59 | loss: 0.025   | mse_mse: 0.01863 |  0:07:18s\n",
      "epoch 60 | loss: 0.02288 | mse_mse: 0.01587 |  0:07:26s\n",
      "epoch 61 | loss: 0.02533 | mse_mse: 0.03466 |  0:07:34s\n",
      "epoch 62 | loss: 0.02242 | mse_mse: 0.01317 |  0:07:41s\n",
      "epoch 63 | loss: 0.01975 | mse_mse: 0.03866 |  0:07:49s\n",
      "epoch 64 | loss: 0.0214  | mse_mse: 0.01502 |  0:07:56s\n",
      "epoch 65 | loss: 0.02092 | mse_mse: 0.02178 |  0:08:04s\n",
      "epoch 66 | loss: 0.01857 | mse_mse: 0.02103 |  0:08:14s\n",
      "epoch 67 | loss: 0.02029 | mse_mse: 0.01928 |  0:08:24s\n",
      "epoch 68 | loss: 0.02007 | mse_mse: 0.01843 |  0:08:33s\n",
      "epoch 69 | loss: 0.01946 | mse_mse: 0.01739 |  0:08:42s\n",
      "epoch 70 | loss: 0.02091 | mse_mse: 0.01487 |  0:08:50s\n",
      "epoch 71 | loss: 0.01718 | mse_mse: 0.01209 |  0:09:00s\n",
      "epoch 72 | loss: 0.01768 | mse_mse: 0.01499 |  0:09:11s\n",
      "epoch 73 | loss: 0.02434 | mse_mse: 0.01709 |  0:09:22s\n",
      "epoch 74 | loss: 0.01653 | mse_mse: 0.01504 |  0:09:33s\n",
      "epoch 75 | loss: 0.01733 | mse_mse: 0.01058 |  0:09:44s\n",
      "epoch 76 | loss: 0.01434 | mse_mse: 0.01551 |  0:09:54s\n",
      "epoch 77 | loss: 0.02439 | mse_mse: 0.03095 |  0:10:02s\n",
      "epoch 78 | loss: 0.02443 | mse_mse: 0.02087 |  0:10:11s\n",
      "epoch 79 | loss: 0.01727 | mse_mse: 0.02413 |  0:10:19s\n",
      "epoch 80 | loss: 0.01583 | mse_mse: 0.01483 |  0:10:27s\n",
      "epoch 81 | loss: 0.0155  | mse_mse: 0.01459 |  0:10:36s\n",
      "epoch 82 | loss: 0.01515 | mse_mse: 0.01137 |  0:10:44s\n",
      "epoch 83 | loss: 0.01977 | mse_mse: 0.01791 |  0:10:52s\n",
      "epoch 84 | loss: 0.01462 | mse_mse: 0.01668 |  0:11:01s\n",
      "epoch 85 | loss: 0.01323 | mse_mse: 0.00953 |  0:11:09s\n",
      "epoch 86 | loss: 0.01151 | mse_mse: 0.02137 |  0:11:18s\n",
      "epoch 87 | loss: 0.01462 | mse_mse: 0.00949 |  0:11:26s\n",
      "epoch 88 | loss: 0.01759 | mse_mse: 0.03361 |  0:11:35s\n",
      "epoch 89 | loss: 0.02614 | mse_mse: 0.01348 |  0:11:44s\n",
      "epoch 90 | loss: 0.01447 | mse_mse: 0.00839 |  0:11:53s\n",
      "epoch 91 | loss: 0.01303 | mse_mse: 0.00958 |  0:12:04s\n",
      "epoch 92 | loss: 0.01157 | mse_mse: 0.00859 |  0:12:13s\n",
      "epoch 93 | loss: 0.0108  | mse_mse: 0.01898 |  0:12:24s\n",
      "epoch 94 | loss: 0.01302 | mse_mse: 0.00873 |  0:12:37s\n",
      "epoch 95 | loss: 0.01791 | mse_mse: 0.07178 |  0:12:54s\n",
      "epoch 96 | loss: 0.01761 | mse_mse: 0.0168  |  0:13:06s\n",
      "epoch 97 | loss: 0.01388 | mse_mse: 0.01153 |  0:13:15s\n",
      "epoch 98 | loss: 0.0165  | mse_mse: 0.02184 |  0:13:22s\n",
      "epoch 99 | loss: 0.01277 | mse_mse: 0.01018 |  0:13:30s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 90 and best_mse_mse = 0.00839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008121179012365526\n",
      "R2 Score: 0.9633630075086291\n",
      "\n",
      "Iteration 36/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 16 - n_a: 32 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.91636 | mse_mse: 0.80066 |  0:00:07s\n",
      "epoch 1  | loss: 0.44194 | mse_mse: 0.25636 |  0:00:15s\n",
      "epoch 2  | loss: 0.30045 | mse_mse: 0.13852 |  0:00:23s\n",
      "epoch 3  | loss: 0.24962 | mse_mse: 0.13965 |  0:00:31s\n",
      "epoch 4  | loss: 0.10897 | mse_mse: 0.12819 |  0:00:40s\n",
      "epoch 5  | loss: 0.08314 | mse_mse: 0.1144  |  0:00:48s\n",
      "epoch 6  | loss: 0.07995 | mse_mse: 0.12609 |  0:00:57s\n",
      "epoch 7  | loss: 0.07286 | mse_mse: 0.1376  |  0:01:05s\n",
      "epoch 8  | loss: 0.07433 | mse_mse: 0.0854  |  0:01:12s\n",
      "epoch 9  | loss: 0.07487 | mse_mse: 0.07547 |  0:01:21s\n",
      "epoch 10 | loss: 0.07004 | mse_mse: 0.0706  |  0:01:29s\n",
      "epoch 11 | loss: 0.06814 | mse_mse: 0.07229 |  0:01:37s\n",
      "epoch 12 | loss: 0.07094 | mse_mse: 0.07651 |  0:01:45s\n",
      "epoch 13 | loss: 0.06526 | mse_mse: 0.06388 |  0:01:53s\n",
      "epoch 14 | loss: 0.07277 | mse_mse: 0.06859 |  0:02:01s\n",
      "epoch 15 | loss: 0.06104 | mse_mse: 0.05555 |  0:02:09s\n",
      "epoch 16 | loss: 0.05593 | mse_mse: 0.05191 |  0:02:17s\n",
      "epoch 17 | loss: 0.05243 | mse_mse: 0.05041 |  0:02:25s\n",
      "epoch 18 | loss: 0.053   | mse_mse: 0.05509 |  0:02:33s\n",
      "epoch 19 | loss: 0.05711 | mse_mse: 0.06487 |  0:02:41s\n",
      "epoch 20 | loss: 0.05958 | mse_mse: 0.05285 |  0:02:50s\n",
      "epoch 21 | loss: 0.05644 | mse_mse: 0.06149 |  0:02:57s\n",
      "epoch 22 | loss: 0.05844 | mse_mse: 0.07011 |  0:03:05s\n",
      "epoch 23 | loss: 0.06374 | mse_mse: 0.04989 |  0:03:13s\n",
      "epoch 24 | loss: 0.05508 | mse_mse: 0.05269 |  0:03:21s\n",
      "epoch 25 | loss: 0.05017 | mse_mse: 0.04491 |  0:03:29s\n",
      "epoch 26 | loss: 0.04894 | mse_mse: 0.04852 |  0:03:37s\n",
      "epoch 27 | loss: 0.05425 | mse_mse: 0.04906 |  0:03:47s\n",
      "epoch 28 | loss: 0.04514 | mse_mse: 0.04352 |  0:03:57s\n",
      "epoch 29 | loss: 0.04407 | mse_mse: 0.04577 |  0:04:08s\n",
      "epoch 30 | loss: 0.04466 | mse_mse: 0.04219 |  0:04:18s\n",
      "epoch 31 | loss: 0.0431  | mse_mse: 0.04717 |  0:04:27s\n",
      "epoch 32 | loss: 0.04681 | mse_mse: 0.04169 |  0:04:38s\n",
      "epoch 33 | loss: 0.04283 | mse_mse: 0.03777 |  0:04:47s\n",
      "epoch 34 | loss: 0.03855 | mse_mse: 0.04116 |  0:04:56s\n",
      "epoch 35 | loss: 0.03714 | mse_mse: 0.03719 |  0:05:03s\n",
      "epoch 36 | loss: 0.03882 | mse_mse: 0.04585 |  0:05:11s\n",
      "epoch 37 | loss: 0.03965 | mse_mse: 0.03559 |  0:05:19s\n",
      "epoch 38 | loss: 0.03815 | mse_mse: 0.03876 |  0:05:28s\n",
      "epoch 39 | loss: 0.03781 | mse_mse: 0.03209 |  0:05:36s\n",
      "epoch 40 | loss: 0.03263 | mse_mse: 0.03555 |  0:05:44s\n",
      "epoch 41 | loss: 0.034   | mse_mse: 0.03376 |  0:05:52s\n",
      "epoch 42 | loss: 0.03062 | mse_mse: 0.0264  |  0:06:01s\n",
      "epoch 43 | loss: 0.03249 | mse_mse: 0.02761 |  0:06:09s\n",
      "epoch 44 | loss: 0.02746 | mse_mse: 0.02838 |  0:06:18s\n",
      "epoch 45 | loss: 0.02824 | mse_mse: 0.02214 |  0:06:27s\n",
      "epoch 46 | loss: 0.02324 | mse_mse: 0.02035 |  0:06:37s\n",
      "epoch 47 | loss: 0.02468 | mse_mse: 0.01755 |  0:06:46s\n",
      "epoch 48 | loss: 0.02447 | mse_mse: 0.02055 |  0:06:55s\n",
      "epoch 49 | loss: 0.01974 | mse_mse: 0.01779 |  0:07:04s\n",
      "epoch 50 | loss: 0.02396 | mse_mse: 0.01517 |  0:07:12s\n",
      "epoch 51 | loss: 0.01905 | mse_mse: 0.01422 |  0:07:21s\n",
      "epoch 52 | loss: 0.02624 | mse_mse: 0.01854 |  0:07:30s\n",
      "epoch 53 | loss: 0.02004 | mse_mse: 0.01456 |  0:07:38s\n",
      "epoch 54 | loss: 0.01848 | mse_mse: 0.01751 |  0:07:47s\n",
      "epoch 55 | loss: 0.01692 | mse_mse: 0.01859 |  0:07:55s\n",
      "epoch 56 | loss: 0.02159 | mse_mse: 0.01348 |  0:08:03s\n",
      "epoch 57 | loss: 0.01838 | mse_mse: 0.03393 |  0:08:12s\n",
      "epoch 58 | loss: 0.01737 | mse_mse: 0.01117 |  0:08:20s\n",
      "epoch 59 | loss: 0.01504 | mse_mse: 0.01321 |  0:08:29s\n",
      "epoch 60 | loss: 0.01607 | mse_mse: 0.01088 |  0:08:39s\n",
      "epoch 61 | loss: 0.0156  | mse_mse: 0.01179 |  0:08:48s\n",
      "epoch 62 | loss: 0.01355 | mse_mse: 0.01086 |  0:08:57s\n",
      "epoch 63 | loss: 0.01238 | mse_mse: 0.00832 |  0:09:06s\n",
      "epoch 64 | loss: 0.01615 | mse_mse: 0.01559 |  0:09:15s\n",
      "epoch 65 | loss: 0.01587 | mse_mse: 0.00793 |  0:09:23s\n",
      "epoch 66 | loss: 0.01295 | mse_mse: 0.01804 |  0:09:31s\n",
      "epoch 67 | loss: 0.01122 | mse_mse: 0.01007 |  0:09:40s\n",
      "epoch 68 | loss: 0.01166 | mse_mse: 0.00914 |  0:09:49s\n",
      "epoch 69 | loss: 0.00983 | mse_mse: 0.00674 |  0:09:57s\n",
      "epoch 70 | loss: 0.01236 | mse_mse: 0.00774 |  0:10:05s\n",
      "epoch 71 | loss: 0.00949 | mse_mse: 0.01264 |  0:10:13s\n",
      "epoch 72 | loss: 0.00948 | mse_mse: 0.01066 |  0:10:22s\n",
      "epoch 73 | loss: 0.01189 | mse_mse: 0.00643 |  0:10:30s\n",
      "epoch 74 | loss: 0.01199 | mse_mse: 0.00646 |  0:10:39s\n",
      "epoch 75 | loss: 0.01024 | mse_mse: 0.00779 |  0:10:47s\n",
      "epoch 76 | loss: 0.01306 | mse_mse: 0.00849 |  0:10:56s\n",
      "epoch 77 | loss: 0.01073 | mse_mse: 0.01633 |  0:11:05s\n",
      "epoch 78 | loss: 0.0154  | mse_mse: 0.01118 |  0:11:13s\n",
      "epoch 79 | loss: 0.01047 | mse_mse: 0.01171 |  0:11:21s\n",
      "epoch 80 | loss: 0.01036 | mse_mse: 0.00651 |  0:11:29s\n",
      "epoch 81 | loss: 0.00846 | mse_mse: 0.00575 |  0:11:37s\n",
      "epoch 82 | loss: 0.00852 | mse_mse: 0.01083 |  0:11:46s\n",
      "epoch 83 | loss: 0.01065 | mse_mse: 0.00619 |  0:11:56s\n",
      "epoch 84 | loss: 0.00818 | mse_mse: 0.00615 |  0:12:05s\n",
      "epoch 85 | loss: 0.00947 | mse_mse: 0.00863 |  0:12:14s\n",
      "epoch 86 | loss: 0.01077 | mse_mse: 0.00764 |  0:12:23s\n",
      "epoch 87 | loss: 0.01198 | mse_mse: 0.01204 |  0:12:33s\n",
      "epoch 88 | loss: 0.01077 | mse_mse: 0.01452 |  0:12:43s\n",
      "epoch 89 | loss: 0.01035 | mse_mse: 0.02142 |  0:12:53s\n",
      "epoch 90 | loss: 0.00998 | mse_mse: 0.00741 |  0:13:05s\n",
      "epoch 91 | loss: 0.00986 | mse_mse: 0.00655 |  0:13:16s\n",
      "\n",
      "Early stopping occurred at epoch 91 with best_epoch = 81 and best_mse_mse = 0.00575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.005905684086096785\n",
      "R2 Score: 0.9733577472939223\n",
      "\n",
      "Iteration 37/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.29288 | mse_mse: 0.49532 |  0:00:03s\n",
      "epoch 1  | loss: 0.1832  | mse_mse: 0.28926 |  0:00:06s\n",
      "epoch 2  | loss: 0.10131 | mse_mse: 0.13584 |  0:00:10s\n",
      "epoch 3  | loss: 0.0694  | mse_mse: 0.10577 |  0:00:13s\n",
      "epoch 4  | loss: 0.05706 | mse_mse: 0.10942 |  0:00:17s\n",
      "epoch 5  | loss: 0.05212 | mse_mse: 0.10355 |  0:00:21s\n",
      "epoch 6  | loss: 0.05043 | mse_mse: 0.0776  |  0:00:24s\n",
      "epoch 7  | loss: 0.04225 | mse_mse: 0.06078 |  0:00:28s\n",
      "epoch 8  | loss: 0.03884 | mse_mse: 0.05149 |  0:00:33s\n",
      "epoch 9  | loss: 0.03833 | mse_mse: 0.04995 |  0:00:37s\n",
      "epoch 10 | loss: 0.03197 | mse_mse: 0.04509 |  0:00:41s\n",
      "epoch 11 | loss: 0.02568 | mse_mse: 0.0352  |  0:00:45s\n",
      "epoch 12 | loss: 0.02435 | mse_mse: 0.02292 |  0:00:50s\n",
      "epoch 13 | loss: 0.02432 | mse_mse: 0.02092 |  0:00:54s\n",
      "epoch 14 | loss: 0.02579 | mse_mse: 0.0182  |  0:00:59s\n",
      "epoch 15 | loss: 0.02243 | mse_mse: 0.01459 |  0:01:03s\n",
      "epoch 16 | loss: 0.02044 | mse_mse: 0.01433 |  0:01:07s\n",
      "epoch 17 | loss: 0.01886 | mse_mse: 0.0204  |  0:01:12s\n",
      "epoch 18 | loss: 0.02363 | mse_mse: 0.01388 |  0:01:16s\n",
      "epoch 19 | loss: 0.01992 | mse_mse: 0.01734 |  0:01:20s\n",
      "epoch 20 | loss: 0.01734 | mse_mse: 0.01387 |  0:01:24s\n",
      "epoch 21 | loss: 0.0155  | mse_mse: 0.01181 |  0:01:29s\n",
      "epoch 22 | loss: 0.0161  | mse_mse: 0.01233 |  0:01:33s\n",
      "epoch 23 | loss: 0.01466 | mse_mse: 0.01304 |  0:01:36s\n",
      "epoch 24 | loss: 0.01624 | mse_mse: 0.01154 |  0:01:40s\n",
      "epoch 25 | loss: 0.01894 | mse_mse: 0.0156  |  0:01:44s\n",
      "epoch 26 | loss: 0.01512 | mse_mse: 0.01235 |  0:01:48s\n",
      "epoch 27 | loss: 0.01246 | mse_mse: 0.00771 |  0:01:51s\n",
      "epoch 28 | loss: 0.01768 | mse_mse: 0.00828 |  0:01:55s\n",
      "epoch 29 | loss: 0.01787 | mse_mse: 0.01243 |  0:01:59s\n",
      "epoch 30 | loss: 0.01114 | mse_mse: 0.00937 |  0:02:03s\n",
      "epoch 31 | loss: 0.01729 | mse_mse: 0.00944 |  0:02:07s\n",
      "epoch 32 | loss: 0.01139 | mse_mse: 0.0102  |  0:02:11s\n",
      "epoch 33 | loss: 0.01185 | mse_mse: 0.00884 |  0:02:15s\n",
      "epoch 34 | loss: 0.0097  | mse_mse: 0.00761 |  0:02:18s\n",
      "epoch 35 | loss: 0.01022 | mse_mse: 0.0077  |  0:02:21s\n",
      "epoch 36 | loss: 0.01005 | mse_mse: 0.00972 |  0:02:25s\n",
      "epoch 37 | loss: 0.01295 | mse_mse: 0.01537 |  0:02:29s\n",
      "epoch 38 | loss: 0.01055 | mse_mse: 0.01343 |  0:02:32s\n",
      "epoch 39 | loss: 0.01244 | mse_mse: 0.01385 |  0:02:36s\n",
      "epoch 40 | loss: 0.01054 | mse_mse: 0.00697 |  0:02:39s\n",
      "epoch 41 | loss: 0.01154 | mse_mse: 0.0064  |  0:02:43s\n",
      "epoch 42 | loss: 0.01067 | mse_mse: 0.0073  |  0:02:46s\n",
      "epoch 43 | loss: 0.01207 | mse_mse: 0.00865 |  0:02:50s\n",
      "epoch 44 | loss: 0.01058 | mse_mse: 0.00899 |  0:02:53s\n",
      "epoch 45 | loss: 0.01328 | mse_mse: 0.01243 |  0:02:58s\n",
      "epoch 46 | loss: 0.0135  | mse_mse: 0.0107  |  0:03:02s\n",
      "epoch 47 | loss: 0.01407 | mse_mse: 0.00638 |  0:03:06s\n",
      "epoch 48 | loss: 0.01371 | mse_mse: 0.01665 |  0:03:10s\n",
      "epoch 49 | loss: 0.01727 | mse_mse: 0.01491 |  0:03:14s\n",
      "epoch 50 | loss: 0.01374 | mse_mse: 0.00676 |  0:03:17s\n",
      "epoch 51 | loss: 0.00905 | mse_mse: 0.02052 |  0:03:21s\n",
      "epoch 52 | loss: 0.01398 | mse_mse: 0.01214 |  0:03:25s\n",
      "epoch 53 | loss: 0.00896 | mse_mse: 0.00885 |  0:03:29s\n",
      "epoch 54 | loss: 0.01026 | mse_mse: 0.00797 |  0:03:32s\n",
      "epoch 55 | loss: 0.00994 | mse_mse: 0.00737 |  0:03:36s\n",
      "epoch 56 | loss: 0.00788 | mse_mse: 0.00743 |  0:03:39s\n",
      "epoch 57 | loss: 0.00845 | mse_mse: 0.00978 |  0:03:43s\n",
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 47 and best_mse_mse = 0.00638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.006379973604058571\n",
      "R2 Score: 0.9712180898030772\n",
      "\n",
      "Iteration 38/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.58242 | mse_mse: 0.49044 |  0:00:03s\n",
      "epoch 1  | loss: 0.1721  | mse_mse: 0.22427 |  0:00:07s\n",
      "epoch 2  | loss: 0.08149 | mse_mse: 0.14843 |  0:00:10s\n",
      "epoch 3  | loss: 0.07618 | mse_mse: 0.13095 |  0:00:14s\n",
      "epoch 4  | loss: 0.05978 | mse_mse: 0.11911 |  0:00:17s\n",
      "epoch 5  | loss: 0.05154 | mse_mse: 0.12395 |  0:00:21s\n",
      "epoch 6  | loss: 0.05334 | mse_mse: 0.10541 |  0:00:24s\n",
      "epoch 7  | loss: 0.04409 | mse_mse: 0.09505 |  0:00:28s\n",
      "epoch 8  | loss: 0.04143 | mse_mse: 0.06407 |  0:00:31s\n",
      "epoch 9  | loss: 0.04118 | mse_mse: 0.04946 |  0:00:35s\n",
      "epoch 10 | loss: 0.03599 | mse_mse: 0.04032 |  0:00:38s\n",
      "epoch 11 | loss: 0.03165 | mse_mse: 0.02973 |  0:00:42s\n",
      "epoch 12 | loss: 0.03136 | mse_mse: 0.03534 |  0:00:46s\n",
      "epoch 13 | loss: 0.03081 | mse_mse: 0.02474 |  0:00:49s\n",
      "epoch 14 | loss: 0.0242  | mse_mse: 0.02487 |  0:00:53s\n",
      "epoch 15 | loss: 0.02383 | mse_mse: 0.01862 |  0:00:57s\n",
      "epoch 16 | loss: 0.02395 | mse_mse: 0.01677 |  0:01:01s\n",
      "epoch 17 | loss: 0.02183 | mse_mse: 0.01574 |  0:01:05s\n",
      "epoch 18 | loss: 0.02742 | mse_mse: 0.02314 |  0:01:09s\n",
      "epoch 19 | loss: 0.01899 | mse_mse: 0.0153  |  0:01:13s\n",
      "epoch 20 | loss: 0.02151 | mse_mse: 0.01796 |  0:01:17s\n",
      "epoch 21 | loss: 0.01994 | mse_mse: 0.01523 |  0:01:21s\n",
      "epoch 22 | loss: 0.0168  | mse_mse: 0.01133 |  0:01:24s\n",
      "epoch 23 | loss: 0.02404 | mse_mse: 0.01705 |  0:01:28s\n",
      "epoch 24 | loss: 0.01663 | mse_mse: 0.01798 |  0:01:32s\n",
      "epoch 25 | loss: 0.01593 | mse_mse: 0.0114  |  0:01:36s\n",
      "epoch 26 | loss: 0.0149  | mse_mse: 0.01279 |  0:01:40s\n",
      "epoch 27 | loss: 0.01341 | mse_mse: 0.01164 |  0:01:44s\n",
      "epoch 28 | loss: 0.0146  | mse_mse: 0.01725 |  0:01:48s\n",
      "epoch 29 | loss: 0.01391 | mse_mse: 0.01247 |  0:01:51s\n",
      "epoch 30 | loss: 0.01307 | mse_mse: 0.00985 |  0:01:55s\n",
      "epoch 31 | loss: 0.01546 | mse_mse: 0.01156 |  0:01:59s\n",
      "epoch 32 | loss: 0.01325 | mse_mse: 0.03085 |  0:02:03s\n",
      "epoch 33 | loss: 0.01528 | mse_mse: 0.02565 |  0:02:06s\n",
      "epoch 34 | loss: 0.01982 | mse_mse: 0.01426 |  0:02:10s\n",
      "epoch 35 | loss: 0.01575 | mse_mse: 0.03593 |  0:02:13s\n",
      "epoch 36 | loss: 0.01592 | mse_mse: 0.01191 |  0:02:16s\n",
      "epoch 37 | loss: 0.01252 | mse_mse: 0.00911 |  0:02:20s\n",
      "epoch 38 | loss: 0.01367 | mse_mse: 0.00917 |  0:02:23s\n",
      "epoch 39 | loss: 0.01157 | mse_mse: 0.01104 |  0:02:28s\n",
      "epoch 40 | loss: 0.01232 | mse_mse: 0.00945 |  0:02:32s\n",
      "epoch 41 | loss: 0.01293 | mse_mse: 0.0192  |  0:02:37s\n",
      "epoch 42 | loss: 0.01597 | mse_mse: 0.00959 |  0:02:41s\n",
      "epoch 43 | loss: 0.01342 | mse_mse: 0.00861 |  0:02:47s\n",
      "epoch 44 | loss: 0.01199 | mse_mse: 0.00843 |  0:02:51s\n",
      "epoch 45 | loss: 0.01146 | mse_mse: 0.00825 |  0:02:55s\n",
      "epoch 46 | loss: 0.01566 | mse_mse: 0.02973 |  0:02:59s\n",
      "epoch 47 | loss: 0.02604 | mse_mse: 0.019   |  0:03:03s\n",
      "epoch 48 | loss: 0.01735 | mse_mse: 0.02672 |  0:03:07s\n",
      "epoch 49 | loss: 0.01368 | mse_mse: 0.01144 |  0:03:11s\n",
      "epoch 50 | loss: 0.01113 | mse_mse: 0.00828 |  0:03:15s\n",
      "epoch 51 | loss: 0.01034 | mse_mse: 0.00777 |  0:03:19s\n",
      "epoch 52 | loss: 0.01061 | mse_mse: 0.01487 |  0:03:22s\n",
      "epoch 53 | loss: 0.01865 | mse_mse: 0.01023 |  0:03:26s\n",
      "epoch 54 | loss: 0.01343 | mse_mse: 0.00842 |  0:03:30s\n",
      "epoch 55 | loss: 0.01305 | mse_mse: 0.00968 |  0:03:34s\n",
      "epoch 56 | loss: 0.0133  | mse_mse: 0.02891 |  0:03:37s\n",
      "epoch 57 | loss: 0.02377 | mse_mse: 0.01447 |  0:03:41s\n",
      "epoch 58 | loss: 0.01277 | mse_mse: 0.0157  |  0:03:45s\n",
      "epoch 59 | loss: 0.01393 | mse_mse: 0.00984 |  0:03:48s\n",
      "epoch 60 | loss: 0.00974 | mse_mse: 0.01193 |  0:03:52s\n",
      "epoch 61 | loss: 0.01009 | mse_mse: 0.00626 |  0:03:55s\n",
      "epoch 62 | loss: 0.01014 | mse_mse: 0.00775 |  0:03:58s\n",
      "epoch 63 | loss: 0.01429 | mse_mse: 0.00877 |  0:04:02s\n",
      "epoch 64 | loss: 0.01291 | mse_mse: 0.00974 |  0:04:05s\n",
      "epoch 65 | loss: 0.00919 | mse_mse: 0.01152 |  0:04:09s\n",
      "epoch 66 | loss: 0.01421 | mse_mse: 0.00927 |  0:04:12s\n",
      "epoch 67 | loss: 0.00904 | mse_mse: 0.0116  |  0:04:16s\n",
      "epoch 68 | loss: 0.01306 | mse_mse: 0.00865 |  0:04:19s\n",
      "epoch 69 | loss: 0.01498 | mse_mse: 0.00906 |  0:04:23s\n",
      "epoch 70 | loss: 0.00896 | mse_mse: 0.00609 |  0:04:26s\n",
      "epoch 71 | loss: 0.00999 | mse_mse: 0.00683 |  0:04:30s\n",
      "epoch 72 | loss: 0.01151 | mse_mse: 0.00567 |  0:04:34s\n",
      "epoch 73 | loss: 0.01153 | mse_mse: 0.00832 |  0:04:37s\n",
      "epoch 74 | loss: 0.00886 | mse_mse: 0.00914 |  0:04:41s\n",
      "epoch 75 | loss: 0.00981 | mse_mse: 0.00602 |  0:04:44s\n",
      "epoch 76 | loss: 0.01012 | mse_mse: 0.00657 |  0:04:48s\n",
      "epoch 77 | loss: 0.0084  | mse_mse: 0.00871 |  0:04:52s\n",
      "epoch 78 | loss: 0.01424 | mse_mse: 0.0111  |  0:04:56s\n",
      "epoch 79 | loss: 0.01369 | mse_mse: 0.02547 |  0:05:00s\n",
      "epoch 80 | loss: 0.01129 | mse_mse: 0.01306 |  0:05:03s\n",
      "epoch 81 | loss: 0.01042 | mse_mse: 0.00806 |  0:05:07s\n",
      "epoch 82 | loss: 0.01079 | mse_mse: 0.00687 |  0:05:11s\n",
      "\n",
      "Early stopping occurred at epoch 82 with best_epoch = 72 and best_mse_mse = 0.00567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.006059153718829681\n",
      "R2 Score: 0.9726654012966814\n",
      "\n",
      "Iteration 39/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.55479 | mse_mse: 0.45408 |  0:00:05s\n",
      "epoch 1  | loss: 0.41388 | mse_mse: 0.40747 |  0:00:10s\n",
      "epoch 2  | loss: 0.22854 | mse_mse: 0.21491 |  0:00:16s\n",
      "epoch 3  | loss: 0.13086 | mse_mse: 0.19766 |  0:00:21s\n",
      "epoch 4  | loss: 0.10111 | mse_mse: 0.1885  |  0:00:27s\n",
      "epoch 5  | loss: 0.09484 | mse_mse: 0.11417 |  0:00:33s\n",
      "epoch 6  | loss: 0.07959 | mse_mse: 0.12698 |  0:00:39s\n",
      "epoch 7  | loss: 0.08137 | mse_mse: 0.11002 |  0:00:45s\n",
      "epoch 8  | loss: 0.0802  | mse_mse: 0.08836 |  0:00:52s\n",
      "epoch 9  | loss: 0.07522 | mse_mse: 0.12001 |  0:00:59s\n",
      "epoch 10 | loss: 0.07647 | mse_mse: 0.11902 |  0:01:07s\n",
      "epoch 11 | loss: 0.07451 | mse_mse: 0.05961 |  0:01:13s\n",
      "epoch 12 | loss: 0.06539 | mse_mse: 0.05582 |  0:01:19s\n",
      "epoch 13 | loss: 0.06114 | mse_mse: 0.06935 |  0:01:25s\n",
      "epoch 14 | loss: 0.06989 | mse_mse: 0.05887 |  0:01:31s\n",
      "epoch 15 | loss: 0.05565 | mse_mse: 0.0467  |  0:01:36s\n",
      "epoch 16 | loss: 0.05205 | mse_mse: 0.05096 |  0:01:42s\n",
      "epoch 17 | loss: 0.06219 | mse_mse: 0.05038 |  0:01:48s\n",
      "epoch 18 | loss: 0.05705 | mse_mse: 0.04648 |  0:01:53s\n",
      "epoch 19 | loss: 0.04978 | mse_mse: 0.04297 |  0:01:58s\n",
      "epoch 20 | loss: 0.05485 | mse_mse: 0.08624 |  0:02:05s\n",
      "epoch 21 | loss: 0.05136 | mse_mse: 0.04033 |  0:02:11s\n",
      "epoch 22 | loss: 0.0446  | mse_mse: 0.03838 |  0:02:17s\n",
      "epoch 23 | loss: 0.05328 | mse_mse: 0.04093 |  0:02:23s\n",
      "epoch 24 | loss: 0.04324 | mse_mse: 0.03675 |  0:02:30s\n",
      "epoch 25 | loss: 0.04184 | mse_mse: 0.03364 |  0:02:36s\n",
      "epoch 26 | loss: 0.04244 | mse_mse: 0.03867 |  0:02:41s\n",
      "epoch 27 | loss: 0.0405  | mse_mse: 0.03497 |  0:02:47s\n",
      "epoch 28 | loss: 0.03641 | mse_mse: 0.02993 |  0:02:52s\n",
      "epoch 29 | loss: 0.03764 | mse_mse: 0.02685 |  0:02:58s\n",
      "epoch 30 | loss: 0.03296 | mse_mse: 0.02786 |  0:03:05s\n",
      "epoch 31 | loss: 0.0345  | mse_mse: 0.02551 |  0:03:12s\n",
      "epoch 32 | loss: 0.03296 | mse_mse: 0.02733 |  0:03:19s\n",
      "epoch 33 | loss: 0.03156 | mse_mse: 0.02563 |  0:03:25s\n",
      "epoch 34 | loss: 0.02606 | mse_mse: 0.02063 |  0:03:32s\n",
      "epoch 35 | loss: 0.02979 | mse_mse: 0.02632 |  0:03:38s\n",
      "epoch 36 | loss: 0.0258  | mse_mse: 0.02129 |  0:03:44s\n",
      "epoch 37 | loss: 0.02622 | mse_mse: 0.01805 |  0:03:50s\n",
      "epoch 38 | loss: 0.02886 | mse_mse: 0.02276 |  0:03:55s\n",
      "epoch 39 | loss: 0.02588 | mse_mse: 0.02279 |  0:04:02s\n",
      "epoch 40 | loss: 0.02303 | mse_mse: 0.02193 |  0:04:08s\n",
      "epoch 41 | loss: 0.02013 | mse_mse: 0.01647 |  0:04:15s\n",
      "epoch 42 | loss: 0.01942 | mse_mse: 0.01288 |  0:04:21s\n",
      "epoch 43 | loss: 0.01655 | mse_mse: 0.01365 |  0:04:27s\n",
      "epoch 44 | loss: 0.02038 | mse_mse: 0.01307 |  0:04:34s\n",
      "epoch 45 | loss: 0.01762 | mse_mse: 0.0142  |  0:04:40s\n",
      "epoch 46 | loss: 0.01882 | mse_mse: 0.01159 |  0:04:46s\n",
      "epoch 47 | loss: 0.01808 | mse_mse: 0.01081 |  0:04:52s\n",
      "epoch 48 | loss: 0.01689 | mse_mse: 0.01151 |  0:04:57s\n",
      "epoch 49 | loss: 0.01348 | mse_mse: 0.01311 |  0:05:04s\n",
      "epoch 50 | loss: 0.01452 | mse_mse: 0.01026 |  0:05:11s\n",
      "epoch 51 | loss: 0.01423 | mse_mse: 0.01109 |  0:05:17s\n",
      "epoch 52 | loss: 0.01471 | mse_mse: 0.0094  |  0:05:24s\n",
      "epoch 53 | loss: 0.01342 | mse_mse: 0.01376 |  0:05:30s\n",
      "epoch 54 | loss: 0.01442 | mse_mse: 0.00995 |  0:05:36s\n",
      "epoch 55 | loss: 0.01192 | mse_mse: 0.01389 |  0:05:44s\n",
      "epoch 56 | loss: 0.01155 | mse_mse: 0.02163 |  0:05:50s\n",
      "epoch 57 | loss: 0.01339 | mse_mse: 0.00933 |  0:05:56s\n",
      "epoch 58 | loss: 0.01367 | mse_mse: 0.00854 |  0:06:03s\n",
      "epoch 59 | loss: 0.01374 | mse_mse: 0.01651 |  0:06:09s\n",
      "epoch 60 | loss: 0.0134  | mse_mse: 0.00817 |  0:06:15s\n",
      "epoch 61 | loss: 0.01082 | mse_mse: 0.0076  |  0:06:21s\n",
      "epoch 62 | loss: 0.01119 | mse_mse: 0.01038 |  0:06:27s\n",
      "epoch 63 | loss: 0.01084 | mse_mse: 0.01196 |  0:06:33s\n",
      "epoch 64 | loss: 0.01246 | mse_mse: 0.00927 |  0:06:39s\n",
      "epoch 65 | loss: 0.01547 | mse_mse: 0.01378 |  0:06:46s\n",
      "epoch 66 | loss: 0.01099 | mse_mse: 0.00789 |  0:06:54s\n",
      "epoch 67 | loss: 0.01227 | mse_mse: 0.0107  |  0:07:00s\n",
      "epoch 68 | loss: 0.01355 | mse_mse: 0.01068 |  0:07:06s\n",
      "epoch 69 | loss: 0.0124  | mse_mse: 0.00778 |  0:07:12s\n",
      "epoch 70 | loss: 0.01056 | mse_mse: 0.00788 |  0:07:18s\n",
      "epoch 71 | loss: 0.01076 | mse_mse: 0.01277 |  0:07:24s\n",
      "\n",
      "Early stopping occurred at epoch 71 with best_epoch = 61 and best_mse_mse = 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0072897525114764454\n",
      "R2 Score: 0.9671138134474982\n",
      "\n",
      "Iteration 40/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.69412 | mse_mse: 0.52905 |  0:00:05s\n",
      "epoch 1  | loss: 0.40038 | mse_mse: 0.45933 |  0:00:11s\n",
      "epoch 2  | loss: 0.21819 | mse_mse: 0.22682 |  0:00:17s\n",
      "epoch 3  | loss: 0.12539 | mse_mse: 0.20452 |  0:00:24s\n",
      "epoch 4  | loss: 0.11583 | mse_mse: 0.14065 |  0:00:30s\n",
      "epoch 5  | loss: 0.0924  | mse_mse: 0.13434 |  0:00:37s\n",
      "epoch 6  | loss: 0.08714 | mse_mse: 0.09942 |  0:00:44s\n",
      "epoch 7  | loss: 0.09316 | mse_mse: 0.09449 |  0:00:54s\n",
      "epoch 8  | loss: 0.09207 | mse_mse: 0.1046  |  0:01:06s\n",
      "epoch 9  | loss: 0.08198 | mse_mse: 0.08691 |  0:01:15s\n",
      "epoch 10 | loss: 0.07761 | mse_mse: 0.07387 |  0:01:23s\n",
      "epoch 11 | loss: 0.07527 | mse_mse: 0.07708 |  0:01:30s\n",
      "epoch 12 | loss: 0.06882 | mse_mse: 0.06656 |  0:01:37s\n",
      "epoch 13 | loss: 0.06924 | mse_mse: 0.07057 |  0:01:44s\n",
      "epoch 14 | loss: 0.07924 | mse_mse: 0.06939 |  0:01:50s\n",
      "epoch 15 | loss: 0.06416 | mse_mse: 0.06075 |  0:01:57s\n",
      "epoch 16 | loss: 0.05955 | mse_mse: 0.06376 |  0:02:03s\n",
      "epoch 17 | loss: 0.05711 | mse_mse: 0.05287 |  0:02:09s\n",
      "epoch 18 | loss: 0.05409 | mse_mse: 0.04702 |  0:02:15s\n",
      "epoch 19 | loss: 0.05434 | mse_mse: 0.0684  |  0:02:21s\n",
      "epoch 20 | loss: 0.05986 | mse_mse: 0.0489  |  0:02:27s\n",
      "epoch 21 | loss: 0.04778 | mse_mse: 0.04405 |  0:02:33s\n",
      "epoch 22 | loss: 0.04514 | mse_mse: 0.03805 |  0:02:39s\n",
      "epoch 23 | loss: 0.04061 | mse_mse: 0.04547 |  0:02:45s\n",
      "epoch 24 | loss: 0.04392 | mse_mse: 0.04083 |  0:02:50s\n",
      "epoch 25 | loss: 0.03835 | mse_mse: 0.03408 |  0:02:57s\n",
      "epoch 26 | loss: 0.03623 | mse_mse: 0.03837 |  0:03:03s\n",
      "epoch 27 | loss: 0.0376  | mse_mse: 0.03159 |  0:03:09s\n",
      "epoch 28 | loss: 0.03515 | mse_mse: 0.02923 |  0:03:17s\n",
      "epoch 29 | loss: 0.02968 | mse_mse: 0.03005 |  0:03:26s\n",
      "epoch 30 | loss: 0.03429 | mse_mse: 0.04011 |  0:03:38s\n",
      "epoch 31 | loss: 0.03134 | mse_mse: 0.04137 |  0:03:46s\n",
      "epoch 32 | loss: 0.029   | mse_mse: 0.03242 |  0:03:54s\n",
      "epoch 33 | loss: 0.03572 | mse_mse: 0.04032 |  0:04:01s\n",
      "epoch 34 | loss: 0.02891 | mse_mse: 0.02727 |  0:04:09s\n",
      "epoch 35 | loss: 0.02676 | mse_mse: 0.02378 |  0:04:16s\n",
      "epoch 36 | loss: 0.02115 | mse_mse: 0.01848 |  0:04:22s\n",
      "epoch 37 | loss: 0.02352 | mse_mse: 0.01764 |  0:04:27s\n",
      "epoch 38 | loss: 0.01998 | mse_mse: 0.01819 |  0:04:32s\n",
      "epoch 39 | loss: 0.01961 | mse_mse: 0.01617 |  0:04:37s\n",
      "epoch 40 | loss: 0.02178 | mse_mse: 0.01341 |  0:04:45s\n",
      "epoch 41 | loss: 0.01855 | mse_mse: 0.01225 |  0:04:51s\n",
      "epoch 42 | loss: 0.01968 | mse_mse: 0.01212 |  0:05:03s\n",
      "epoch 43 | loss: 0.01729 | mse_mse: 0.01407 |  0:05:10s\n",
      "epoch 44 | loss: 0.02073 | mse_mse: 0.01515 |  0:05:17s\n",
      "epoch 45 | loss: 0.01716 | mse_mse: 0.01373 |  0:05:22s\n",
      "epoch 46 | loss: 0.01643 | mse_mse: 0.02093 |  0:05:28s\n",
      "epoch 47 | loss: 0.01708 | mse_mse: 0.01845 |  0:05:33s\n",
      "epoch 48 | loss: 0.01895 | mse_mse: 0.01505 |  0:05:39s\n",
      "epoch 49 | loss: 0.01423 | mse_mse: 0.01049 |  0:05:44s\n",
      "epoch 50 | loss: 0.01397 | mse_mse: 0.0143  |  0:05:50s\n",
      "epoch 51 | loss: 0.01582 | mse_mse: 0.01473 |  0:05:57s\n",
      "epoch 52 | loss: 0.01725 | mse_mse: 0.01441 |  0:06:03s\n",
      "epoch 53 | loss: 0.01698 | mse_mse: 0.01535 |  0:06:09s\n",
      "epoch 54 | loss: 0.01402 | mse_mse: 0.02739 |  0:06:15s\n",
      "epoch 55 | loss: 0.01742 | mse_mse: 0.01259 |  0:06:20s\n",
      "epoch 56 | loss: 0.01435 | mse_mse: 0.01104 |  0:06:26s\n",
      "epoch 57 | loss: 0.01316 | mse_mse: 0.00927 |  0:06:32s\n",
      "epoch 58 | loss: 0.01293 | mse_mse: 0.01202 |  0:06:39s\n",
      "epoch 59 | loss: 0.01463 | mse_mse: 0.01256 |  0:06:45s\n",
      "epoch 60 | loss: 0.01161 | mse_mse: 0.01135 |  0:06:51s\n",
      "epoch 61 | loss: 0.01446 | mse_mse: 0.01093 |  0:06:58s\n",
      "epoch 62 | loss: 0.01408 | mse_mse: 0.01182 |  0:07:05s\n",
      "epoch 63 | loss: 0.01194 | mse_mse: 0.01059 |  0:07:13s\n",
      "epoch 64 | loss: 0.01254 | mse_mse: 0.00976 |  0:07:18s\n",
      "epoch 65 | loss: 0.01062 | mse_mse: 0.0086  |  0:07:25s\n",
      "epoch 66 | loss: 0.01294 | mse_mse: 0.00896 |  0:07:32s\n",
      "epoch 67 | loss: 0.01267 | mse_mse: 0.00743 |  0:07:39s\n",
      "epoch 68 | loss: 0.01165 | mse_mse: 0.00676 |  0:07:45s\n",
      "epoch 69 | loss: 0.01229 | mse_mse: 0.01817 |  0:07:50s\n",
      "epoch 70 | loss: 0.01479 | mse_mse: 0.00872 |  0:07:56s\n",
      "epoch 71 | loss: 0.01    | mse_mse: 0.00721 |  0:08:01s\n",
      "epoch 72 | loss: 0.01172 | mse_mse: 0.0089  |  0:08:07s\n",
      "epoch 73 | loss: 0.01078 | mse_mse: 0.00899 |  0:08:12s\n",
      "epoch 74 | loss: 0.01183 | mse_mse: 0.00993 |  0:08:20s\n",
      "epoch 75 | loss: 0.01191 | mse_mse: 0.00804 |  0:08:25s\n",
      "epoch 76 | loss: 0.01057 | mse_mse: 0.01052 |  0:08:31s\n",
      "epoch 77 | loss: 0.01317 | mse_mse: 0.00795 |  0:08:36s\n",
      "epoch 78 | loss: 0.01253 | mse_mse: 0.01027 |  0:08:42s\n",
      "\n",
      "Early stopping occurred at epoch 78 with best_epoch = 68 and best_mse_mse = 0.00676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0065353801693378\n",
      "R2 Score: 0.9705170057416896\n",
      "\n",
      "Iteration 41/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.5745  | mse_mse: 0.60607 |  0:00:07s\n",
      "epoch 1  | loss: 0.4124  | mse_mse: 0.76155 |  0:00:16s\n",
      "epoch 2  | loss: 0.40527 | mse_mse: 0.16654 |  0:00:25s\n",
      "epoch 3  | loss: 0.25022 | mse_mse: 0.13971 |  0:00:34s\n",
      "epoch 4  | loss: 0.13791 | mse_mse: 0.15376 |  0:00:45s\n",
      "epoch 5  | loss: 0.10644 | mse_mse: 0.1196  |  0:00:55s\n",
      "epoch 6  | loss: 0.08934 | mse_mse: 0.16799 |  0:01:04s\n",
      "epoch 7  | loss: 0.11395 | mse_mse: 0.15571 |  0:01:14s\n",
      "epoch 8  | loss: 0.12176 | mse_mse: 0.1039  |  0:01:22s\n",
      "epoch 9  | loss: 0.08936 | mse_mse: 0.08746 |  0:01:30s\n",
      "epoch 10 | loss: 0.09278 | mse_mse: 0.08224 |  0:01:38s\n",
      "epoch 11 | loss: 0.08196 | mse_mse: 0.09648 |  0:01:46s\n",
      "epoch 12 | loss: 0.07621 | mse_mse: 0.0722  |  0:01:56s\n",
      "epoch 13 | loss: 0.07191 | mse_mse: 0.06546 |  0:02:04s\n",
      "epoch 14 | loss: 0.07085 | mse_mse: 0.06416 |  0:02:12s\n",
      "epoch 15 | loss: 0.0662  | mse_mse: 0.06323 |  0:02:19s\n",
      "epoch 16 | loss: 0.07083 | mse_mse: 0.06614 |  0:02:27s\n",
      "epoch 17 | loss: 0.0652  | mse_mse: 0.06937 |  0:02:34s\n",
      "epoch 18 | loss: 0.0697  | mse_mse: 0.061   |  0:02:43s\n",
      "epoch 19 | loss: 0.06235 | mse_mse: 0.06194 |  0:02:51s\n",
      "epoch 20 | loss: 0.06354 | mse_mse: 0.06613 |  0:02:59s\n",
      "epoch 21 | loss: 0.07504 | mse_mse: 0.07824 |  0:03:09s\n",
      "epoch 22 | loss: 0.06474 | mse_mse: 0.05448 |  0:03:18s\n",
      "epoch 23 | loss: 0.05825 | mse_mse: 0.05306 |  0:03:27s\n",
      "epoch 24 | loss: 0.05889 | mse_mse: 0.04796 |  0:03:35s\n",
      "epoch 25 | loss: 0.0514  | mse_mse: 0.04796 |  0:03:42s\n",
      "epoch 26 | loss: 0.06625 | mse_mse: 0.05063 |  0:03:50s\n",
      "epoch 27 | loss: 0.05273 | mse_mse: 0.04916 |  0:03:57s\n",
      "epoch 28 | loss: 0.04914 | mse_mse: 0.04695 |  0:04:05s\n",
      "epoch 29 | loss: 0.05069 | mse_mse: 0.04996 |  0:04:13s\n",
      "epoch 30 | loss: 0.05002 | mse_mse: 0.04566 |  0:04:20s\n",
      "epoch 31 | loss: 0.04481 | mse_mse: 0.04443 |  0:04:29s\n",
      "epoch 32 | loss: 0.0498  | mse_mse: 0.08799 |  0:04:38s\n",
      "epoch 33 | loss: 0.04752 | mse_mse: 0.0419  |  0:04:48s\n",
      "epoch 34 | loss: 0.04265 | mse_mse: 0.04785 |  0:04:57s\n",
      "epoch 35 | loss: 0.05391 | mse_mse: 0.05602 |  0:05:07s\n",
      "epoch 36 | loss: 0.04713 | mse_mse: 0.04499 |  0:05:16s\n",
      "epoch 37 | loss: 0.04325 | mse_mse: 0.04012 |  0:05:25s\n",
      "epoch 38 | loss: 0.04163 | mse_mse: 0.05131 |  0:05:33s\n",
      "epoch 39 | loss: 0.04312 | mse_mse: 0.04063 |  0:05:41s\n",
      "epoch 40 | loss: 0.04182 | mse_mse: 0.03684 |  0:05:50s\n",
      "epoch 41 | loss: 0.03781 | mse_mse: 0.03483 |  0:05:59s\n",
      "epoch 42 | loss: 0.03866 | mse_mse: 0.05289 |  0:06:08s\n",
      "epoch 43 | loss: 0.04241 | mse_mse: 0.04478 |  0:06:18s\n",
      "epoch 44 | loss: 0.03709 | mse_mse: 0.03508 |  0:06:26s\n",
      "epoch 45 | loss: 0.03491 | mse_mse: 0.04134 |  0:06:33s\n",
      "epoch 46 | loss: 0.0351  | mse_mse: 0.03173 |  0:06:41s\n",
      "epoch 47 | loss: 0.03191 | mse_mse: 0.02962 |  0:06:49s\n",
      "epoch 48 | loss: 0.0399  | mse_mse: 0.0321  |  0:06:57s\n",
      "epoch 49 | loss: 0.02984 | mse_mse: 0.02802 |  0:07:05s\n",
      "epoch 50 | loss: 0.02809 | mse_mse: 0.02465 |  0:07:13s\n",
      "epoch 51 | loss: 0.03014 | mse_mse: 0.0299  |  0:07:22s\n",
      "epoch 52 | loss: 0.02753 | mse_mse: 0.04058 |  0:07:31s\n",
      "epoch 53 | loss: 0.02992 | mse_mse: 0.02839 |  0:07:40s\n",
      "epoch 54 | loss: 0.02888 | mse_mse: 0.02235 |  0:07:48s\n",
      "epoch 55 | loss: 0.02606 | mse_mse: 0.03084 |  0:07:56s\n",
      "epoch 56 | loss: 0.02714 | mse_mse: 0.02804 |  0:08:03s\n",
      "epoch 57 | loss: 0.02661 | mse_mse: 0.03013 |  0:08:11s\n",
      "epoch 58 | loss: 0.03364 | mse_mse: 0.03577 |  0:08:19s\n",
      "epoch 59 | loss: 0.02748 | mse_mse: 0.02518 |  0:08:26s\n",
      "epoch 60 | loss: 0.02452 | mse_mse: 0.03497 |  0:08:34s\n",
      "epoch 61 | loss: 0.02547 | mse_mse: 0.02473 |  0:08:41s\n",
      "epoch 62 | loss: 0.03018 | mse_mse: 0.02007 |  0:08:48s\n",
      "epoch 63 | loss: 0.02536 | mse_mse: 0.02166 |  0:08:56s\n",
      "epoch 64 | loss: 0.02383 | mse_mse: 0.01913 |  0:09:03s\n",
      "epoch 65 | loss: 0.02637 | mse_mse: 0.01658 |  0:09:11s\n",
      "epoch 66 | loss: 0.02039 | mse_mse: 0.02033 |  0:09:19s\n",
      "epoch 67 | loss: 0.01926 | mse_mse: 0.02005 |  0:09:27s\n",
      "epoch 68 | loss: 0.0182  | mse_mse: 0.02307 |  0:09:34s\n",
      "epoch 69 | loss: 0.0188  | mse_mse: 0.01403 |  0:09:42s\n",
      "epoch 70 | loss: 0.01675 | mse_mse: 0.01932 |  0:09:49s\n",
      "epoch 71 | loss: 0.01767 | mse_mse: 0.01362 |  0:09:57s\n",
      "epoch 72 | loss: 0.01932 | mse_mse: 0.02075 |  0:10:04s\n",
      "epoch 73 | loss: 0.02548 | mse_mse: 0.01151 |  0:10:11s\n",
      "epoch 74 | loss: 0.01395 | mse_mse: 0.01643 |  0:10:19s\n",
      "epoch 75 | loss: 0.01451 | mse_mse: 0.01054 |  0:10:26s\n",
      "epoch 76 | loss: 0.01902 | mse_mse: 0.02276 |  0:10:33s\n",
      "epoch 77 | loss: 0.02335 | mse_mse: 0.01726 |  0:10:41s\n",
      "epoch 78 | loss: 0.02289 | mse_mse: 0.04808 |  0:10:49s\n",
      "epoch 79 | loss: 0.01771 | mse_mse: 0.01206 |  0:10:56s\n",
      "epoch 80 | loss: 0.01469 | mse_mse: 0.00983 |  0:11:04s\n",
      "epoch 81 | loss: 0.01365 | mse_mse: 0.01058 |  0:11:12s\n",
      "epoch 82 | loss: 0.01687 | mse_mse: 0.02155 |  0:11:19s\n",
      "epoch 83 | loss: 0.01981 | mse_mse: 0.01269 |  0:11:27s\n",
      "epoch 84 | loss: 0.01652 | mse_mse: 0.01108 |  0:11:36s\n",
      "epoch 85 | loss: 0.01597 | mse_mse: 0.01206 |  0:11:43s\n",
      "epoch 86 | loss: 0.01566 | mse_mse: 0.0317  |  0:11:51s\n",
      "epoch 87 | loss: 0.01371 | mse_mse: 0.01511 |  0:11:58s\n",
      "epoch 88 | loss: 0.01282 | mse_mse: 0.01395 |  0:12:05s\n",
      "epoch 89 | loss: 0.01764 | mse_mse: 0.02081 |  0:12:12s\n",
      "epoch 90 | loss: 0.01358 | mse_mse: 0.01137 |  0:12:19s\n",
      "\n",
      "Early stopping occurred at epoch 90 with best_epoch = 80 and best_mse_mse = 0.00983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.01033096416211384\n",
      "R2 Score: 0.9533940261802284\n",
      "\n",
      "Iteration 42/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 8 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.4053  | mse_mse: 0.83137 |  0:00:06s\n",
      "epoch 1  | loss: 0.98258 | mse_mse: 0.61963 |  0:00:13s\n",
      "epoch 2  | loss: 0.31583 | mse_mse: 0.37948 |  0:00:21s\n",
      "epoch 3  | loss: 0.33487 | mse_mse: 0.33603 |  0:00:29s\n",
      "epoch 4  | loss: 0.19311 | mse_mse: 0.13719 |  0:00:37s\n",
      "epoch 5  | loss: 0.13361 | mse_mse: 0.14568 |  0:00:45s\n",
      "epoch 6  | loss: 0.16147 | mse_mse: 0.18405 |  0:00:55s\n",
      "epoch 7  | loss: 0.12946 | mse_mse: 0.11098 |  0:01:05s\n",
      "epoch 8  | loss: 0.10643 | mse_mse: 0.14396 |  0:01:15s\n",
      "epoch 9  | loss: 0.10134 | mse_mse: 0.09613 |  0:01:24s\n",
      "epoch 10 | loss: 0.08968 | mse_mse: 0.09913 |  0:01:33s\n",
      "epoch 11 | loss: 0.08224 | mse_mse: 0.07912 |  0:01:42s\n",
      "epoch 12 | loss: 0.08249 | mse_mse: 0.09681 |  0:01:51s\n",
      "epoch 13 | loss: 0.0777  | mse_mse: 0.07132 |  0:02:00s\n",
      "epoch 14 | loss: 0.0842  | mse_mse: 0.07149 |  0:02:09s\n",
      "epoch 15 | loss: 0.07701 | mse_mse: 0.06664 |  0:02:19s\n",
      "epoch 16 | loss: 0.07392 | mse_mse: 0.05809 |  0:02:29s\n",
      "epoch 17 | loss: 0.07449 | mse_mse: 0.06588 |  0:02:41s\n",
      "epoch 18 | loss: 0.07592 | mse_mse: 0.06585 |  0:02:52s\n",
      "epoch 19 | loss: 0.07803 | mse_mse: 0.06558 |  0:03:06s\n",
      "epoch 20 | loss: 0.06795 | mse_mse: 0.07923 |  0:03:17s\n",
      "epoch 21 | loss: 0.07013 | mse_mse: 0.05498 |  0:03:27s\n",
      "epoch 22 | loss: 0.06049 | mse_mse: 0.06033 |  0:03:36s\n",
      "epoch 23 | loss: 0.05736 | mse_mse: 0.06087 |  0:03:44s\n",
      "epoch 24 | loss: 0.05625 | mse_mse: 0.05259 |  0:03:52s\n",
      "epoch 25 | loss: 0.05084 | mse_mse: 0.04317 |  0:03:59s\n",
      "epoch 26 | loss: 0.04933 | mse_mse: 0.05266 |  0:04:08s\n",
      "epoch 27 | loss: 0.05442 | mse_mse: 0.04261 |  0:04:16s\n",
      "epoch 28 | loss: 0.04055 | mse_mse: 0.04251 |  0:04:24s\n",
      "epoch 29 | loss: 0.04213 | mse_mse: 0.03336 |  0:04:32s\n",
      "epoch 30 | loss: 0.03549 | mse_mse: 0.03109 |  0:04:40s\n",
      "epoch 31 | loss: 0.03237 | mse_mse: 0.04091 |  0:04:48s\n",
      "epoch 32 | loss: 0.033   | mse_mse: 0.0289  |  0:04:56s\n",
      "epoch 33 | loss: 0.0339  | mse_mse: 0.02299 |  0:05:04s\n",
      "epoch 34 | loss: 0.02705 | mse_mse: 0.03184 |  0:05:12s\n",
      "epoch 35 | loss: 0.02771 | mse_mse: 0.01965 |  0:05:22s\n",
      "epoch 36 | loss: 0.03099 | mse_mse: 0.02051 |  0:05:32s\n",
      "epoch 37 | loss: 0.02084 | mse_mse: 0.02113 |  0:05:41s\n",
      "epoch 38 | loss: 0.02652 | mse_mse: 0.03201 |  0:05:51s\n",
      "epoch 39 | loss: 0.03161 | mse_mse: 0.02147 |  0:06:02s\n",
      "epoch 40 | loss: 0.02385 | mse_mse: 0.02084 |  0:06:14s\n",
      "epoch 41 | loss: 0.02368 | mse_mse: 0.01796 |  0:06:25s\n",
      "epoch 42 | loss: 0.01813 | mse_mse: 0.01918 |  0:06:36s\n",
      "epoch 43 | loss: 0.02042 | mse_mse: 0.02662 |  0:06:48s\n",
      "epoch 44 | loss: 0.02121 | mse_mse: 0.01433 |  0:07:02s\n",
      "epoch 45 | loss: 0.01747 | mse_mse: 0.01181 |  0:07:17s\n",
      "epoch 46 | loss: 0.01598 | mse_mse: 0.01701 |  0:07:30s\n",
      "epoch 47 | loss: 0.01619 | mse_mse: 0.01151 |  0:07:41s\n",
      "epoch 48 | loss: 0.01459 | mse_mse: 0.01107 |  0:07:50s\n",
      "epoch 49 | loss: 0.01537 | mse_mse: 0.01354 |  0:08:00s\n",
      "epoch 50 | loss: 0.01683 | mse_mse: 0.02937 |  0:08:09s\n",
      "epoch 51 | loss: 0.01556 | mse_mse: 0.01433 |  0:08:18s\n",
      "epoch 52 | loss: 0.01315 | mse_mse: 0.01521 |  0:08:28s\n",
      "epoch 53 | loss: 0.0129  | mse_mse: 0.0139  |  0:08:40s\n",
      "epoch 54 | loss: 0.01614 | mse_mse: 0.0134  |  0:08:52s\n",
      "epoch 55 | loss: 0.01303 | mse_mse: 0.02009 |  0:09:02s\n",
      "epoch 56 | loss: 0.0142  | mse_mse: 0.01901 |  0:09:12s\n",
      "epoch 57 | loss: 0.0163  | mse_mse: 0.01841 |  0:09:19s\n",
      "epoch 58 | loss: 0.01829 | mse_mse: 0.02388 |  0:09:27s\n",
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 48 and best_mse_mse = 0.01107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010537318146255793\n",
      "R2 Score: 0.9524631035449729\n",
      "\n",
      "Iteration 43/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.8741  | mse_mse: 0.56985 |  0:00:03s\n",
      "epoch 1  | loss: 0.20229 | mse_mse: 0.31853 |  0:00:06s\n",
      "epoch 2  | loss: 0.10546 | mse_mse: 0.19127 |  0:00:09s\n",
      "epoch 3  | loss: 0.07726 | mse_mse: 0.15592 |  0:00:13s\n",
      "epoch 4  | loss: 0.07213 | mse_mse: 0.11735 |  0:00:17s\n",
      "epoch 5  | loss: 0.0607  | mse_mse: 0.08779 |  0:00:21s\n",
      "epoch 6  | loss: 0.05891 | mse_mse: 0.08694 |  0:00:25s\n",
      "epoch 7  | loss: 0.06535 | mse_mse: 0.07319 |  0:00:30s\n",
      "epoch 8  | loss: 0.06237 | mse_mse: 0.06673 |  0:00:35s\n",
      "epoch 9  | loss: 0.0472  | mse_mse: 0.04447 |  0:00:40s\n",
      "epoch 10 | loss: 0.04377 | mse_mse: 0.04774 |  0:00:46s\n",
      "epoch 11 | loss: 0.04403 | mse_mse: 0.03649 |  0:00:52s\n",
      "epoch 12 | loss: 0.04556 | mse_mse: 0.04607 |  0:01:02s\n",
      "epoch 13 | loss: 0.03713 | mse_mse: 0.02816 |  0:01:16s\n",
      "epoch 14 | loss: 0.03571 | mse_mse: 0.03078 |  0:01:30s\n",
      "epoch 15 | loss: 0.03755 | mse_mse: 0.02523 |  0:01:39s\n",
      "epoch 16 | loss: 0.03165 | mse_mse: 0.02217 |  0:01:46s\n",
      "epoch 17 | loss: 0.02502 | mse_mse: 0.03321 |  0:01:51s\n",
      "epoch 18 | loss: 0.02249 | mse_mse: 0.01565 |  0:01:56s\n",
      "epoch 19 | loss: 0.02352 | mse_mse: 0.01782 |  0:02:01s\n",
      "epoch 20 | loss: 0.01865 | mse_mse: 0.01316 |  0:02:06s\n",
      "epoch 21 | loss: 0.0223  | mse_mse: 0.01547 |  0:02:11s\n",
      "epoch 22 | loss: 0.01925 | mse_mse: 0.01387 |  0:02:16s\n",
      "epoch 23 | loss: 0.01926 | mse_mse: 0.02003 |  0:02:21s\n",
      "epoch 24 | loss: 0.01994 | mse_mse: 0.01265 |  0:02:25s\n",
      "epoch 25 | loss: 0.0154  | mse_mse: 0.01035 |  0:02:30s\n",
      "epoch 26 | loss: 0.01289 | mse_mse: 0.00875 |  0:02:34s\n",
      "epoch 27 | loss: 0.01506 | mse_mse: 0.00944 |  0:02:39s\n",
      "epoch 28 | loss: 0.01412 | mse_mse: 0.00987 |  0:02:43s\n",
      "epoch 29 | loss: 0.01142 | mse_mse: 0.01374 |  0:02:47s\n",
      "epoch 30 | loss: 0.01461 | mse_mse: 0.01847 |  0:02:50s\n",
      "epoch 31 | loss: 0.01597 | mse_mse: 0.01384 |  0:02:55s\n",
      "epoch 32 | loss: 0.01293 | mse_mse: 0.01719 |  0:03:00s\n",
      "epoch 33 | loss: 0.0133  | mse_mse: 0.0077  |  0:03:05s\n",
      "epoch 34 | loss: 0.01209 | mse_mse: 0.00758 |  0:03:10s\n",
      "epoch 35 | loss: 0.01466 | mse_mse: 0.0221  |  0:03:15s\n",
      "epoch 36 | loss: 0.01904 | mse_mse: 0.0249  |  0:03:19s\n",
      "epoch 37 | loss: 0.01422 | mse_mse: 0.01107 |  0:03:24s\n",
      "epoch 38 | loss: 0.00955 | mse_mse: 0.00775 |  0:03:29s\n",
      "epoch 39 | loss: 0.01199 | mse_mse: 0.00767 |  0:03:35s\n",
      "epoch 40 | loss: 0.0126  | mse_mse: 0.01188 |  0:03:40s\n",
      "epoch 41 | loss: 0.01241 | mse_mse: 0.0076  |  0:03:45s\n",
      "epoch 42 | loss: 0.01365 | mse_mse: 0.00774 |  0:03:50s\n",
      "epoch 43 | loss: 0.01019 | mse_mse: 0.00688 |  0:04:00s\n",
      "epoch 44 | loss: 0.01205 | mse_mse: 0.01071 |  0:04:10s\n",
      "epoch 45 | loss: 0.0111  | mse_mse: 0.00903 |  0:04:22s\n",
      "epoch 46 | loss: 0.01441 | mse_mse: 0.00782 |  0:04:34s\n",
      "epoch 47 | loss: 0.01097 | mse_mse: 0.0056  |  0:04:41s\n",
      "epoch 48 | loss: 0.01027 | mse_mse: 0.00603 |  0:04:46s\n",
      "epoch 49 | loss: 0.01089 | mse_mse: 0.00584 |  0:04:50s\n",
      "epoch 50 | loss: 0.0104  | mse_mse: 0.00672 |  0:04:54s\n",
      "epoch 51 | loss: 0.00957 | mse_mse: 0.00601 |  0:04:58s\n",
      "epoch 52 | loss: 0.01796 | mse_mse: 0.00576 |  0:05:02s\n",
      "epoch 53 | loss: 0.01279 | mse_mse: 0.00614 |  0:05:06s\n",
      "epoch 54 | loss: 0.01237 | mse_mse: 0.00893 |  0:05:09s\n",
      "epoch 55 | loss: 0.00962 | mse_mse: 0.00569 |  0:05:13s\n",
      "epoch 56 | loss: 0.01301 | mse_mse: 0.01018 |  0:05:17s\n",
      "epoch 57 | loss: 0.01078 | mse_mse: 0.00618 |  0:05:21s\n",
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 47 and best_mse_mse = 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00606246182265908\n",
      "R2 Score: 0.9726504774814356\n",
      "\n",
      "Iteration 44/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.78288 | mse_mse: 1.12635 |  0:00:03s\n",
      "epoch 1  | loss: 0.27214 | mse_mse: 0.56495 |  0:00:07s\n",
      "epoch 2  | loss: 0.10588 | mse_mse: 0.21622 |  0:00:11s\n",
      "epoch 3  | loss: 0.08267 | mse_mse: 0.12001 |  0:00:15s\n",
      "epoch 4  | loss: 0.06897 | mse_mse: 0.13507 |  0:00:18s\n",
      "epoch 5  | loss: 0.06078 | mse_mse: 0.07813 |  0:00:23s\n",
      "epoch 6  | loss: 0.05078 | mse_mse: 0.07497 |  0:00:27s\n",
      "epoch 7  | loss: 0.0475  | mse_mse: 0.05239 |  0:00:31s\n",
      "epoch 8  | loss: 0.04244 | mse_mse: 0.04419 |  0:00:35s\n",
      "epoch 9  | loss: 0.04138 | mse_mse: 0.03607 |  0:00:39s\n",
      "epoch 10 | loss: 0.03324 | mse_mse: 0.03096 |  0:00:43s\n",
      "epoch 11 | loss: 0.0307  | mse_mse: 0.02364 |  0:00:46s\n",
      "epoch 12 | loss: 0.02748 | mse_mse: 0.02186 |  0:00:50s\n",
      "epoch 13 | loss: 0.02796 | mse_mse: 0.01773 |  0:00:54s\n",
      "epoch 14 | loss: 0.02683 | mse_mse: 0.0288  |  0:00:59s\n",
      "epoch 15 | loss: 0.02164 | mse_mse: 0.01715 |  0:01:03s\n",
      "epoch 16 | loss: 0.02501 | mse_mse: 0.01949 |  0:01:07s\n",
      "epoch 17 | loss: 0.02367 | mse_mse: 0.01923 |  0:01:12s\n",
      "epoch 18 | loss: 0.01992 | mse_mse: 0.02488 |  0:01:16s\n",
      "epoch 19 | loss: 0.01791 | mse_mse: 0.01534 |  0:01:20s\n",
      "epoch 20 | loss: 0.01816 | mse_mse: 0.01818 |  0:01:24s\n",
      "epoch 21 | loss: 0.01705 | mse_mse: 0.01427 |  0:01:29s\n",
      "epoch 22 | loss: 0.01517 | mse_mse: 0.0137  |  0:01:33s\n",
      "epoch 23 | loss: 0.01532 | mse_mse: 0.01198 |  0:01:38s\n",
      "epoch 24 | loss: 0.01469 | mse_mse: 0.01721 |  0:01:42s\n",
      "epoch 25 | loss: 0.01413 | mse_mse: 0.01053 |  0:01:46s\n",
      "epoch 26 | loss: 0.01215 | mse_mse: 0.01202 |  0:01:50s\n",
      "epoch 27 | loss: 0.01235 | mse_mse: 0.01141 |  0:01:54s\n",
      "epoch 28 | loss: 0.01267 | mse_mse: 0.01158 |  0:01:58s\n",
      "epoch 29 | loss: 0.01205 | mse_mse: 0.0122  |  0:02:01s\n",
      "epoch 30 | loss: 0.01529 | mse_mse: 0.01768 |  0:02:05s\n",
      "epoch 31 | loss: 0.01628 | mse_mse: 0.01063 |  0:02:09s\n",
      "epoch 32 | loss: 0.01088 | mse_mse: 0.0106  |  0:02:13s\n",
      "epoch 33 | loss: 0.01111 | mse_mse: 0.01375 |  0:02:17s\n",
      "epoch 34 | loss: 0.01406 | mse_mse: 0.0117  |  0:02:21s\n",
      "epoch 35 | loss: 0.01238 | mse_mse: 0.0076  |  0:02:26s\n",
      "epoch 36 | loss: 0.01158 | mse_mse: 0.01418 |  0:02:30s\n",
      "epoch 37 | loss: 0.0104  | mse_mse: 0.02049 |  0:02:34s\n",
      "epoch 38 | loss: 0.0116  | mse_mse: 0.01382 |  0:02:38s\n",
      "epoch 39 | loss: 0.00904 | mse_mse: 0.01004 |  0:02:42s\n",
      "epoch 40 | loss: 0.00862 | mse_mse: 0.01497 |  0:02:46s\n",
      "epoch 41 | loss: 0.01123 | mse_mse: 0.01231 |  0:02:50s\n",
      "epoch 42 | loss: 0.01282 | mse_mse: 0.00715 |  0:02:53s\n",
      "epoch 43 | loss: 0.00908 | mse_mse: 0.00771 |  0:02:57s\n",
      "epoch 44 | loss: 0.01068 | mse_mse: 0.00578 |  0:03:01s\n",
      "epoch 45 | loss: 0.00798 | mse_mse: 0.02346 |  0:03:05s\n",
      "epoch 46 | loss: 0.01012 | mse_mse: 0.01092 |  0:03:08s\n",
      "epoch 47 | loss: 0.0102  | mse_mse: 0.00699 |  0:03:12s\n",
      "epoch 48 | loss: 0.00903 | mse_mse: 0.01027 |  0:03:16s\n",
      "epoch 49 | loss: 0.01239 | mse_mse: 0.01156 |  0:03:19s\n",
      "epoch 50 | loss: 0.01111 | mse_mse: 0.00601 |  0:03:23s\n",
      "epoch 51 | loss: 0.01244 | mse_mse: 0.01454 |  0:03:27s\n",
      "epoch 52 | loss: 0.01147 | mse_mse: 0.01679 |  0:03:31s\n",
      "epoch 53 | loss: 0.0116  | mse_mse: 0.01141 |  0:03:35s\n",
      "epoch 54 | loss: 0.00986 | mse_mse: 0.00678 |  0:03:38s\n",
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 44 and best_mse_mse = 0.00578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0059293561148828595\n",
      "R2 Score: 0.973250955910606\n",
      "\n",
      "Iteration 45/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.96467 | mse_mse: 0.88146 |  0:00:05s\n",
      "epoch 1  | loss: 0.44446 | mse_mse: 0.55347 |  0:00:11s\n",
      "epoch 2  | loss: 0.25759 | mse_mse: 0.19984 |  0:00:16s\n",
      "epoch 3  | loss: 0.11869 | mse_mse: 0.17974 |  0:00:22s\n",
      "epoch 4  | loss: 0.11031 | mse_mse: 0.12803 |  0:00:28s\n",
      "epoch 5  | loss: 0.08021 | mse_mse: 0.11317 |  0:00:33s\n",
      "epoch 6  | loss: 0.09568 | mse_mse: 0.17427 |  0:00:39s\n",
      "epoch 7  | loss: 0.09326 | mse_mse: 0.09116 |  0:00:44s\n",
      "epoch 8  | loss: 0.06771 | mse_mse: 0.06201 |  0:00:50s\n",
      "epoch 9  | loss: 0.05905 | mse_mse: 0.09028 |  0:00:56s\n",
      "epoch 10 | loss: 0.05263 | mse_mse: 0.0684  |  0:01:01s\n",
      "epoch 11 | loss: 0.04992 | mse_mse: 0.0376  |  0:01:07s\n",
      "epoch 12 | loss: 0.05104 | mse_mse: 0.04749 |  0:01:12s\n",
      "epoch 13 | loss: 0.04123 | mse_mse: 0.0339  |  0:01:18s\n",
      "epoch 14 | loss: 0.04144 | mse_mse: 0.03526 |  0:01:23s\n",
      "epoch 15 | loss: 0.03471 | mse_mse: 0.02833 |  0:01:29s\n",
      "epoch 16 | loss: 0.03475 | mse_mse: 0.03793 |  0:01:34s\n",
      "epoch 17 | loss: 0.04328 | mse_mse: 0.03471 |  0:01:40s\n",
      "epoch 18 | loss: 0.03505 | mse_mse: 0.02315 |  0:01:46s\n",
      "epoch 19 | loss: 0.03099 | mse_mse: 0.02967 |  0:01:52s\n",
      "epoch 20 | loss: 0.02632 | mse_mse: 0.02312 |  0:01:57s\n",
      "epoch 21 | loss: 0.02606 | mse_mse: 0.02011 |  0:02:03s\n",
      "epoch 22 | loss: 0.02425 | mse_mse: 0.01781 |  0:02:09s\n",
      "epoch 23 | loss: 0.02255 | mse_mse: 0.01714 |  0:02:15s\n",
      "epoch 24 | loss: 0.01983 | mse_mse: 0.01519 |  0:02:20s\n",
      "epoch 25 | loss: 0.02024 | mse_mse: 0.01586 |  0:02:26s\n",
      "epoch 26 | loss: 0.01985 | mse_mse: 0.03121 |  0:02:32s\n",
      "epoch 27 | loss: 0.01896 | mse_mse: 0.01654 |  0:02:38s\n",
      "epoch 28 | loss: 0.01819 | mse_mse: 0.01638 |  0:02:43s\n",
      "epoch 29 | loss: 0.02059 | mse_mse: 0.01932 |  0:02:49s\n",
      "epoch 30 | loss: 0.0206  | mse_mse: 0.01823 |  0:02:55s\n",
      "epoch 31 | loss: 0.01485 | mse_mse: 0.01205 |  0:03:00s\n",
      "epoch 32 | loss: 0.01419 | mse_mse: 0.01942 |  0:03:05s\n",
      "epoch 33 | loss: 0.01621 | mse_mse: 0.01896 |  0:03:11s\n",
      "epoch 34 | loss: 0.01528 | mse_mse: 0.01587 |  0:03:16s\n",
      "epoch 35 | loss: 0.01496 | mse_mse: 0.01778 |  0:03:21s\n",
      "epoch 36 | loss: 0.01453 | mse_mse: 0.01411 |  0:03:27s\n",
      "epoch 37 | loss: 0.01641 | mse_mse: 0.01654 |  0:03:33s\n",
      "epoch 38 | loss: 0.0144  | mse_mse: 0.01001 |  0:03:38s\n",
      "epoch 39 | loss: 0.01592 | mse_mse: 0.0178  |  0:03:45s\n",
      "epoch 40 | loss: 0.01687 | mse_mse: 0.01369 |  0:03:50s\n",
      "epoch 41 | loss: 0.01604 | mse_mse: 0.01442 |  0:03:56s\n",
      "epoch 42 | loss: 0.01445 | mse_mse: 0.01592 |  0:04:03s\n",
      "epoch 43 | loss: 0.02307 | mse_mse: 0.01242 |  0:04:09s\n",
      "epoch 44 | loss: 0.01249 | mse_mse: 0.01169 |  0:04:15s\n",
      "epoch 45 | loss: 0.01731 | mse_mse: 0.01123 |  0:04:21s\n",
      "epoch 46 | loss: 0.0114  | mse_mse: 0.01655 |  0:04:27s\n",
      "epoch 47 | loss: 0.01146 | mse_mse: 0.00982 |  0:04:33s\n",
      "epoch 48 | loss: 0.01268 | mse_mse: 0.01332 |  0:04:39s\n",
      "epoch 49 | loss: 0.01529 | mse_mse: 0.00901 |  0:04:45s\n",
      "epoch 50 | loss: 0.01288 | mse_mse: 0.0106  |  0:04:51s\n",
      "epoch 51 | loss: 0.01733 | mse_mse: 0.01844 |  0:04:57s\n",
      "epoch 52 | loss: 0.01098 | mse_mse: 0.00832 |  0:05:03s\n",
      "epoch 53 | loss: 0.01201 | mse_mse: 0.00984 |  0:05:09s\n",
      "epoch 54 | loss: 0.01016 | mse_mse: 0.0144  |  0:05:16s\n",
      "epoch 55 | loss: 0.01137 | mse_mse: 0.00806 |  0:05:23s\n",
      "epoch 56 | loss: 0.01155 | mse_mse: 0.00934 |  0:05:29s\n",
      "epoch 57 | loss: 0.01239 | mse_mse: 0.01355 |  0:05:35s\n",
      "epoch 58 | loss: 0.01227 | mse_mse: 0.014   |  0:05:42s\n",
      "epoch 59 | loss: 0.0105  | mse_mse: 0.02063 |  0:05:48s\n",
      "epoch 60 | loss: 0.01173 | mse_mse: 0.00872 |  0:05:54s\n",
      "epoch 61 | loss: 0.01135 | mse_mse: 0.01152 |  0:06:00s\n",
      "epoch 62 | loss: 0.01183 | mse_mse: 0.01298 |  0:06:06s\n",
      "epoch 63 | loss: 0.01182 | mse_mse: 0.01477 |  0:06:13s\n",
      "epoch 64 | loss: 0.01422 | mse_mse: 0.00691 |  0:06:20s\n",
      "epoch 65 | loss: 0.01188 | mse_mse: 0.00677 |  0:06:28s\n",
      "epoch 66 | loss: 0.00797 | mse_mse: 0.00911 |  0:06:34s\n",
      "epoch 67 | loss: 0.01324 | mse_mse: 0.01089 |  0:06:41s\n",
      "epoch 68 | loss: 0.00965 | mse_mse: 0.00607 |  0:06:48s\n",
      "epoch 69 | loss: 0.00912 | mse_mse: 0.00805 |  0:06:54s\n",
      "epoch 70 | loss: 0.01199 | mse_mse: 0.01506 |  0:07:00s\n",
      "epoch 71 | loss: 0.00953 | mse_mse: 0.01524 |  0:07:06s\n",
      "epoch 72 | loss: 0.01606 | mse_mse: 0.01051 |  0:07:12s\n",
      "epoch 73 | loss: 0.01089 | mse_mse: 0.01012 |  0:07:19s\n",
      "epoch 74 | loss: 0.01187 | mse_mse: 0.01278 |  0:07:26s\n",
      "epoch 75 | loss: 0.01017 | mse_mse: 0.00973 |  0:07:32s\n",
      "epoch 76 | loss: 0.00934 | mse_mse: 0.00825 |  0:07:38s\n",
      "epoch 77 | loss: 0.01052 | mse_mse: 0.00657 |  0:07:44s\n",
      "epoch 78 | loss: 0.0092  | mse_mse: 0.00754 |  0:07:52s\n",
      "\n",
      "Early stopping occurred at epoch 78 with best_epoch = 68 and best_mse_mse = 0.00607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.005991321070783788\n",
      "R2 Score: 0.9729714140336674\n",
      "\n",
      "Iteration 46/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.21166 | mse_mse: 0.84971 |  0:00:05s\n",
      "epoch 1  | loss: 0.36575 | mse_mse: 0.69428 |  0:00:11s\n",
      "epoch 2  | loss: 0.17762 | mse_mse: 0.24443 |  0:00:17s\n",
      "epoch 3  | loss: 0.13999 | mse_mse: 0.31359 |  0:00:24s\n",
      "epoch 4  | loss: 0.11545 | mse_mse: 0.13827 |  0:00:33s\n",
      "epoch 5  | loss: 0.09261 | mse_mse: 0.14455 |  0:00:40s\n",
      "epoch 6  | loss: 0.10928 | mse_mse: 0.12269 |  0:00:47s\n",
      "epoch 7  | loss: 0.09924 | mse_mse: 0.15129 |  0:00:55s\n",
      "epoch 8  | loss: 0.1056  | mse_mse: 0.08624 |  0:01:01s\n",
      "epoch 9  | loss: 0.07753 | mse_mse: 0.11403 |  0:01:07s\n",
      "epoch 10 | loss: 0.08288 | mse_mse: 0.07361 |  0:01:12s\n",
      "epoch 11 | loss: 0.06984 | mse_mse: 0.07233 |  0:01:18s\n",
      "epoch 12 | loss: 0.06693 | mse_mse: 0.05732 |  0:01:24s\n",
      "epoch 13 | loss: 0.07044 | mse_mse: 0.05969 |  0:01:30s\n",
      "epoch 14 | loss: 0.06763 | mse_mse: 0.05694 |  0:01:39s\n",
      "epoch 15 | loss: 0.06083 | mse_mse: 0.06457 |  0:01:46s\n",
      "epoch 16 | loss: 0.05875 | mse_mse: 0.05953 |  0:01:53s\n",
      "epoch 17 | loss: 0.06165 | mse_mse: 0.05256 |  0:02:00s\n",
      "epoch 18 | loss: 0.06901 | mse_mse: 0.05769 |  0:02:08s\n",
      "epoch 19 | loss: 0.05154 | mse_mse: 0.046   |  0:02:16s\n",
      "epoch 20 | loss: 0.04963 | mse_mse: 0.04983 |  0:02:24s\n",
      "epoch 21 | loss: 0.04785 | mse_mse: 0.058   |  0:02:32s\n",
      "epoch 22 | loss: 0.06465 | mse_mse: 0.09775 |  0:02:38s\n",
      "epoch 23 | loss: 0.06286 | mse_mse: 0.06298 |  0:02:45s\n",
      "epoch 24 | loss: 0.05935 | mse_mse: 0.05132 |  0:02:53s\n",
      "epoch 25 | loss: 0.05577 | mse_mse: 0.0521  |  0:03:00s\n",
      "epoch 26 | loss: 0.04928 | mse_mse: 0.0644  |  0:03:07s\n",
      "epoch 27 | loss: 0.05323 | mse_mse: 0.03337 |  0:03:13s\n",
      "epoch 28 | loss: 0.03656 | mse_mse: 0.02995 |  0:03:20s\n",
      "epoch 29 | loss: 0.03697 | mse_mse: 0.02824 |  0:03:26s\n",
      "epoch 30 | loss: 0.03463 | mse_mse: 0.03789 |  0:03:40s\n",
      "epoch 31 | loss: 0.03257 | mse_mse: 0.02912 |  0:03:55s\n",
      "epoch 32 | loss: 0.02767 | mse_mse: 0.02906 |  0:04:07s\n",
      "epoch 33 | loss: 0.031   | mse_mse: 0.03482 |  0:04:17s\n",
      "epoch 34 | loss: 0.02997 | mse_mse: 0.02789 |  0:04:24s\n",
      "epoch 35 | loss: 0.0341  | mse_mse: 0.02311 |  0:04:31s\n",
      "epoch 36 | loss: 0.03454 | mse_mse: 0.02642 |  0:04:38s\n",
      "epoch 37 | loss: 0.02543 | mse_mse: 0.02242 |  0:04:47s\n",
      "epoch 38 | loss: 0.02412 | mse_mse: 0.03149 |  0:04:54s\n",
      "epoch 39 | loss: 0.03438 | mse_mse: 0.02495 |  0:05:01s\n",
      "epoch 40 | loss: 0.02928 | mse_mse: 0.02053 |  0:05:07s\n",
      "epoch 41 | loss: 0.02358 | mse_mse: 0.02164 |  0:05:15s\n",
      "epoch 42 | loss: 0.0269  | mse_mse: 0.02575 |  0:05:22s\n",
      "epoch 43 | loss: 0.02279 | mse_mse: 0.0192  |  0:05:28s\n",
      "epoch 44 | loss: 0.02438 | mse_mse: 0.01772 |  0:05:35s\n",
      "epoch 45 | loss: 0.0242  | mse_mse: 0.0183  |  0:05:41s\n",
      "epoch 46 | loss: 0.02288 | mse_mse: 0.01513 |  0:05:47s\n",
      "epoch 47 | loss: 0.02025 | mse_mse: 0.01737 |  0:05:53s\n",
      "epoch 48 | loss: 0.01882 | mse_mse: 0.01443 |  0:05:59s\n",
      "epoch 49 | loss: 0.01876 | mse_mse: 0.01577 |  0:06:05s\n",
      "epoch 50 | loss: 0.01811 | mse_mse: 0.01759 |  0:06:11s\n",
      "epoch 51 | loss: 0.0182  | mse_mse: 0.02869 |  0:06:18s\n",
      "epoch 52 | loss: 0.0188  | mse_mse: 0.01708 |  0:06:25s\n",
      "epoch 53 | loss: 0.01551 | mse_mse: 0.01274 |  0:06:32s\n",
      "epoch 54 | loss: 0.01489 | mse_mse: 0.01008 |  0:06:39s\n",
      "epoch 55 | loss: 0.01466 | mse_mse: 0.01332 |  0:06:46s\n",
      "epoch 56 | loss: 0.01515 | mse_mse: 0.0107  |  0:06:53s\n",
      "epoch 57 | loss: 0.01289 | mse_mse: 0.02144 |  0:07:00s\n",
      "epoch 58 | loss: 0.01416 | mse_mse: 0.01256 |  0:07:08s\n",
      "epoch 59 | loss: 0.01294 | mse_mse: 0.00874 |  0:07:15s\n",
      "epoch 60 | loss: 0.01169 | mse_mse: 0.00854 |  0:07:22s\n",
      "epoch 61 | loss: 0.01414 | mse_mse: 0.00852 |  0:07:28s\n",
      "epoch 62 | loss: 0.0125  | mse_mse: 0.01323 |  0:07:35s\n",
      "epoch 63 | loss: 0.01283 | mse_mse: 0.00978 |  0:07:41s\n",
      "epoch 64 | loss: 0.01708 | mse_mse: 0.00861 |  0:07:48s\n",
      "epoch 65 | loss: 0.01481 | mse_mse: 0.00818 |  0:07:57s\n",
      "epoch 66 | loss: 0.01458 | mse_mse: 0.00957 |  0:08:04s\n",
      "epoch 67 | loss: 0.0098  | mse_mse: 0.00745 |  0:08:11s\n",
      "epoch 68 | loss: 0.0129  | mse_mse: 0.01033 |  0:08:19s\n",
      "epoch 69 | loss: 0.01107 | mse_mse: 0.00836 |  0:08:26s\n",
      "epoch 70 | loss: 0.01366 | mse_mse: 0.0141  |  0:08:31s\n",
      "epoch 71 | loss: 0.01098 | mse_mse: 0.00875 |  0:08:41s\n",
      "epoch 72 | loss: 0.01067 | mse_mse: 0.00697 |  0:08:48s\n",
      "epoch 73 | loss: 0.01206 | mse_mse: 0.00894 |  0:08:56s\n",
      "epoch 74 | loss: 0.0109  | mse_mse: 0.00941 |  0:09:04s\n",
      "epoch 75 | loss: 0.01057 | mse_mse: 0.0125  |  0:09:10s\n",
      "epoch 76 | loss: 0.00952 | mse_mse: 0.00696 |  0:09:17s\n",
      "epoch 77 | loss: 0.01078 | mse_mse: 0.00804 |  0:09:23s\n",
      "epoch 78 | loss: 0.01538 | mse_mse: 0.01079 |  0:09:29s\n",
      "epoch 79 | loss: 0.01263 | mse_mse: 0.00994 |  0:09:36s\n",
      "epoch 80 | loss: 0.01309 | mse_mse: 0.00952 |  0:09:43s\n",
      "epoch 81 | loss: 0.01098 | mse_mse: 0.01169 |  0:09:49s\n",
      "epoch 82 | loss: 0.0142  | mse_mse: 0.00661 |  0:09:55s\n",
      "epoch 83 | loss: 0.01249 | mse_mse: 0.01388 |  0:10:01s\n",
      "epoch 84 | loss: 0.01341 | mse_mse: 0.00936 |  0:10:07s\n",
      "epoch 85 | loss: 0.01193 | mse_mse: 0.01371 |  0:10:14s\n",
      "epoch 86 | loss: 0.01611 | mse_mse: 0.01072 |  0:10:20s\n",
      "epoch 87 | loss: 0.01115 | mse_mse: 0.00836 |  0:10:27s\n",
      "epoch 88 | loss: 0.01092 | mse_mse: 0.01253 |  0:10:38s\n",
      "epoch 89 | loss: 0.01063 | mse_mse: 0.00818 |  0:10:46s\n",
      "epoch 90 | loss: 0.01167 | mse_mse: 0.01162 |  0:10:54s\n",
      "epoch 91 | loss: 0.01416 | mse_mse: 0.0233  |  0:11:01s\n",
      "epoch 92 | loss: 0.01054 | mse_mse: 0.00642 |  0:11:07s\n",
      "epoch 93 | loss: 0.00763 | mse_mse: 0.00705 |  0:11:13s\n",
      "epoch 94 | loss: 0.00961 | mse_mse: 0.01158 |  0:11:20s\n",
      "epoch 95 | loss: 0.00933 | mse_mse: 0.00628 |  0:11:26s\n",
      "epoch 96 | loss: 0.00927 | mse_mse: 0.0197  |  0:11:33s\n",
      "epoch 97 | loss: 0.01843 | mse_mse: 0.01498 |  0:11:41s\n",
      "epoch 98 | loss: 0.01212 | mse_mse: 0.00678 |  0:11:50s\n",
      "epoch 99 | loss: 0.00936 | mse_mse: 0.00703 |  0:11:58s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 95 and best_mse_mse = 0.00628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.006172263300300378\n",
      "R2 Score: 0.972155131189258\n",
      "\n",
      "Iteration 47/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.15809 | mse_mse: 2.20167 |  0:00:08s\n",
      "epoch 1  | loss: 0.82588 | mse_mse: 0.66495 |  0:00:19s\n",
      "epoch 2  | loss: 0.5315  | mse_mse: 0.25306 |  0:00:28s\n",
      "epoch 3  | loss: 0.21709 | mse_mse: 0.36547 |  0:00:36s\n",
      "epoch 4  | loss: 0.12447 | mse_mse: 0.17573 |  0:00:45s\n",
      "epoch 5  | loss: 0.10588 | mse_mse: 0.29292 |  0:00:54s\n",
      "epoch 6  | loss: 0.08202 | mse_mse: 0.18084 |  0:01:03s\n",
      "epoch 7  | loss: 0.07354 | mse_mse: 0.15697 |  0:01:12s\n",
      "epoch 8  | loss: 0.07997 | mse_mse: 0.07623 |  0:01:20s\n",
      "epoch 9  | loss: 0.06181 | mse_mse: 0.085   |  0:01:29s\n",
      "epoch 10 | loss: 0.05596 | mse_mse: 0.05894 |  0:01:37s\n",
      "epoch 11 | loss: 0.05682 | mse_mse: 0.08213 |  0:01:45s\n",
      "epoch 12 | loss: 0.06343 | mse_mse: 0.05201 |  0:01:53s\n",
      "epoch 13 | loss: 0.06038 | mse_mse: 0.04825 |  0:02:01s\n",
      "epoch 14 | loss: 0.06509 | mse_mse: 0.07097 |  0:02:09s\n",
      "epoch 15 | loss: 0.06308 | mse_mse: 0.04709 |  0:02:17s\n",
      "epoch 16 | loss: 0.04835 | mse_mse: 0.04348 |  0:02:26s\n",
      "epoch 17 | loss: 0.0519  | mse_mse: 0.03585 |  0:02:34s\n",
      "epoch 18 | loss: 0.04718 | mse_mse: 0.03982 |  0:02:42s\n",
      "epoch 19 | loss: 0.04514 | mse_mse: 0.03657 |  0:02:50s\n",
      "epoch 20 | loss: 0.04203 | mse_mse: 0.03509 |  0:02:59s\n",
      "epoch 21 | loss: 0.04597 | mse_mse: 0.03537 |  0:03:07s\n",
      "epoch 22 | loss: 0.03815 | mse_mse: 0.04033 |  0:03:15s\n",
      "epoch 23 | loss: 0.04562 | mse_mse: 0.03803 |  0:03:24s\n",
      "epoch 24 | loss: 0.04365 | mse_mse: 0.05186 |  0:03:32s\n",
      "epoch 25 | loss: 0.0464  | mse_mse: 0.03705 |  0:03:40s\n",
      "epoch 26 | loss: 0.03979 | mse_mse: 0.03744 |  0:03:48s\n",
      "epoch 27 | loss: 0.03911 | mse_mse: 0.03093 |  0:03:56s\n",
      "epoch 28 | loss: 0.04166 | mse_mse: 0.03171 |  0:04:05s\n",
      "epoch 29 | loss: 0.03518 | mse_mse: 0.029   |  0:04:12s\n",
      "epoch 30 | loss: 0.03505 | mse_mse: 0.02559 |  0:04:20s\n",
      "epoch 31 | loss: 0.03257 | mse_mse: 0.02791 |  0:04:29s\n",
      "epoch 32 | loss: 0.03221 | mse_mse: 0.03042 |  0:04:37s\n",
      "epoch 33 | loss: 0.03133 | mse_mse: 0.03621 |  0:04:45s\n",
      "epoch 34 | loss: 0.02805 | mse_mse: 0.02805 |  0:04:56s\n",
      "epoch 35 | loss: 0.02554 | mse_mse: 0.02221 |  0:05:05s\n",
      "epoch 36 | loss: 0.02483 | mse_mse: 0.02477 |  0:05:13s\n",
      "epoch 37 | loss: 0.02216 | mse_mse: 0.01707 |  0:05:22s\n",
      "epoch 38 | loss: 0.02318 | mse_mse: 0.02608 |  0:05:30s\n",
      "epoch 39 | loss: 0.02436 | mse_mse: 0.02248 |  0:05:38s\n",
      "epoch 40 | loss: 0.02597 | mse_mse: 0.02586 |  0:05:46s\n",
      "epoch 41 | loss: 0.02185 | mse_mse: 0.01568 |  0:05:54s\n",
      "epoch 42 | loss: 0.01975 | mse_mse: 0.01598 |  0:06:02s\n",
      "epoch 43 | loss: 0.02224 | mse_mse: 0.02919 |  0:06:11s\n",
      "epoch 44 | loss: 0.02644 | mse_mse: 0.01849 |  0:06:19s\n",
      "epoch 45 | loss: 0.02836 | mse_mse: 0.06027 |  0:06:27s\n",
      "epoch 46 | loss: 0.02323 | mse_mse: 0.0163  |  0:06:36s\n",
      "epoch 47 | loss: 0.02185 | mse_mse: 0.01394 |  0:06:44s\n",
      "epoch 48 | loss: 0.01851 | mse_mse: 0.02329 |  0:06:52s\n",
      "epoch 49 | loss: 0.0196  | mse_mse: 0.01403 |  0:07:01s\n",
      "epoch 50 | loss: 0.0186  | mse_mse: 0.0218  |  0:07:09s\n",
      "epoch 51 | loss: 0.01601 | mse_mse: 0.02682 |  0:07:17s\n",
      "epoch 52 | loss: 0.01708 | mse_mse: 0.02215 |  0:07:26s\n",
      "epoch 53 | loss: 0.01529 | mse_mse: 0.03748 |  0:07:35s\n",
      "epoch 54 | loss: 0.01646 | mse_mse: 0.01598 |  0:07:43s\n",
      "epoch 55 | loss: 0.01285 | mse_mse: 0.01173 |  0:07:52s\n",
      "epoch 56 | loss: 0.01208 | mse_mse: 0.00927 |  0:08:01s\n",
      "epoch 57 | loss: 0.01346 | mse_mse: 0.01653 |  0:08:09s\n",
      "epoch 58 | loss: 0.01508 | mse_mse: 0.01297 |  0:08:17s\n",
      "epoch 59 | loss: 0.01339 | mse_mse: 0.01796 |  0:08:25s\n",
      "epoch 60 | loss: 0.01678 | mse_mse: 0.00864 |  0:08:33s\n",
      "epoch 61 | loss: 0.01089 | mse_mse: 0.00951 |  0:08:41s\n",
      "epoch 62 | loss: 0.00982 | mse_mse: 0.01552 |  0:08:50s\n",
      "epoch 63 | loss: 0.01539 | mse_mse: 0.0184  |  0:09:00s\n",
      "epoch 64 | loss: 0.01589 | mse_mse: 0.00937 |  0:09:08s\n",
      "epoch 65 | loss: 0.01209 | mse_mse: 0.01033 |  0:09:17s\n",
      "epoch 66 | loss: 0.01037 | mse_mse: 0.0103  |  0:09:25s\n",
      "epoch 67 | loss: 0.00942 | mse_mse: 0.00717 |  0:09:34s\n",
      "epoch 68 | loss: 0.01106 | mse_mse: 0.00932 |  0:09:42s\n",
      "epoch 69 | loss: 0.01007 | mse_mse: 0.00649 |  0:09:50s\n",
      "epoch 70 | loss: 0.01298 | mse_mse: 0.0119  |  0:09:58s\n",
      "epoch 71 | loss: 0.01156 | mse_mse: 0.01394 |  0:10:06s\n",
      "epoch 72 | loss: 0.0126  | mse_mse: 0.00791 |  0:10:14s\n",
      "epoch 73 | loss: 0.02683 | mse_mse: 0.0281  |  0:10:22s\n",
      "epoch 74 | loss: 0.02099 | mse_mse: 0.02356 |  0:10:30s\n",
      "epoch 75 | loss: 0.01848 | mse_mse: 0.02119 |  0:10:39s\n",
      "epoch 76 | loss: 0.01354 | mse_mse: 0.00949 |  0:10:47s\n",
      "epoch 77 | loss: 0.0164  | mse_mse: 0.04124 |  0:10:55s\n",
      "epoch 78 | loss: 0.01813 | mse_mse: 0.01429 |  0:11:04s\n",
      "epoch 79 | loss: 0.01893 | mse_mse: 0.02359 |  0:11:12s\n",
      "\n",
      "Early stopping occurred at epoch 79 with best_epoch = 69 and best_mse_mse = 0.00649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.006641918042807992\n",
      "R2 Score: 0.9700363825139008\n",
      "\n",
      "Iteration 48/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 16 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.23731 | mse_mse: 0.56212 |  0:00:08s\n",
      "epoch 1  | loss: 0.42118 | mse_mse: 0.23669 |  0:00:15s\n",
      "epoch 2  | loss: 0.43935 | mse_mse: 0.14952 |  0:00:24s\n",
      "epoch 3  | loss: 0.45087 | mse_mse: 0.15489 |  0:00:33s\n",
      "epoch 4  | loss: 0.13529 | mse_mse: 0.11874 |  0:00:43s\n",
      "epoch 5  | loss: 0.12538 | mse_mse: 0.13938 |  0:00:52s\n",
      "epoch 6  | loss: 0.08372 | mse_mse: 0.11799 |  0:01:01s\n",
      "epoch 7  | loss: 0.07784 | mse_mse: 0.09689 |  0:01:12s\n",
      "epoch 8  | loss: 0.08225 | mse_mse: 0.11832 |  0:01:22s\n",
      "epoch 9  | loss: 0.07025 | mse_mse: 0.08823 |  0:01:33s\n",
      "epoch 10 | loss: 0.07176 | mse_mse: 0.10019 |  0:01:43s\n",
      "epoch 11 | loss: 0.07054 | mse_mse: 0.15298 |  0:01:52s\n",
      "epoch 12 | loss: 0.09304 | mse_mse: 0.12682 |  0:02:01s\n",
      "epoch 13 | loss: 0.08632 | mse_mse: 0.06221 |  0:02:09s\n",
      "epoch 14 | loss: 0.065   | mse_mse: 0.06147 |  0:02:18s\n",
      "epoch 15 | loss: 0.06897 | mse_mse: 0.05638 |  0:02:27s\n",
      "epoch 16 | loss: 0.07702 | mse_mse: 0.08612 |  0:02:38s\n",
      "epoch 17 | loss: 0.0754  | mse_mse: 0.05631 |  0:02:48s\n",
      "epoch 18 | loss: 0.0559  | mse_mse: 0.04856 |  0:02:58s\n",
      "epoch 19 | loss: 0.05727 | mse_mse: 0.04492 |  0:03:09s\n",
      "epoch 20 | loss: 0.05307 | mse_mse: 0.05145 |  0:03:19s\n",
      "epoch 21 | loss: 0.05402 | mse_mse: 0.05074 |  0:03:28s\n",
      "epoch 22 | loss: 0.05228 | mse_mse: 0.05087 |  0:03:38s\n",
      "epoch 23 | loss: 0.05353 | mse_mse: 0.04111 |  0:03:47s\n",
      "epoch 24 | loss: 0.04629 | mse_mse: 0.03814 |  0:03:55s\n",
      "epoch 25 | loss: 0.04725 | mse_mse: 0.03804 |  0:04:03s\n",
      "epoch 26 | loss: 0.04607 | mse_mse: 0.04255 |  0:04:11s\n",
      "epoch 27 | loss: 0.05185 | mse_mse: 0.07343 |  0:04:19s\n",
      "epoch 28 | loss: 0.04529 | mse_mse: 0.03641 |  0:04:27s\n",
      "epoch 29 | loss: 0.04602 | mse_mse: 0.04268 |  0:04:37s\n",
      "epoch 30 | loss: 0.04685 | mse_mse: 0.03761 |  0:04:48s\n",
      "epoch 31 | loss: 0.04722 | mse_mse: 0.0386  |  0:05:00s\n",
      "epoch 32 | loss: 0.04445 | mse_mse: 0.03783 |  0:05:13s\n",
      "epoch 33 | loss: 0.04665 | mse_mse: 0.04687 |  0:05:23s\n",
      "epoch 34 | loss: 0.04481 | mse_mse: 0.03829 |  0:05:34s\n",
      "epoch 35 | loss: 0.0361  | mse_mse: 0.05166 |  0:05:47s\n",
      "epoch 36 | loss: 0.03873 | mse_mse: 0.05731 |  0:05:57s\n",
      "epoch 37 | loss: 0.04524 | mse_mse: 0.04227 |  0:06:07s\n",
      "epoch 38 | loss: 0.0347  | mse_mse: 0.03338 |  0:06:17s\n",
      "epoch 39 | loss: 0.03267 | mse_mse: 0.02661 |  0:06:27s\n",
      "epoch 40 | loss: 0.0299  | mse_mse: 0.0283  |  0:06:37s\n",
      "epoch 41 | loss: 0.02593 | mse_mse: 0.02307 |  0:06:47s\n",
      "epoch 42 | loss: 0.02774 | mse_mse: 0.02123 |  0:06:58s\n",
      "epoch 43 | loss: 0.03496 | mse_mse: 0.04492 |  0:07:08s\n",
      "epoch 44 | loss: 0.02831 | mse_mse: 0.02331 |  0:07:18s\n",
      "epoch 45 | loss: 0.02435 | mse_mse: 0.01777 |  0:07:27s\n",
      "epoch 46 | loss: 0.02885 | mse_mse: 0.01655 |  0:07:38s\n",
      "epoch 47 | loss: 0.02443 | mse_mse: 0.02263 |  0:07:49s\n",
      "epoch 48 | loss: 0.02056 | mse_mse: 0.02981 |  0:08:00s\n",
      "epoch 49 | loss: 0.03416 | mse_mse: 0.02909 |  0:08:09s\n",
      "epoch 50 | loss: 0.02597 | mse_mse: 0.03176 |  0:08:18s\n",
      "epoch 51 | loss: 0.02999 | mse_mse: 0.02625 |  0:08:27s\n",
      "epoch 52 | loss: 0.02729 | mse_mse: 0.02    |  0:08:37s\n",
      "epoch 53 | loss: 0.02465 | mse_mse: 0.01716 |  0:08:48s\n",
      "epoch 54 | loss: 0.02529 | mse_mse: 0.02563 |  0:08:57s\n",
      "epoch 55 | loss: 0.03032 | mse_mse: 0.01957 |  0:09:07s\n",
      "epoch 56 | loss: 0.02757 | mse_mse: 0.01837 |  0:09:17s\n",
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 46 and best_mse_mse = 0.01655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.01724429505529756\n",
      "R2 Score: 0.9222059866556375\n",
      "\n",
      "Iteration 49/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 3 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.98239 | mse_mse: 0.55842 |  0:00:03s\n",
      "epoch 1  | loss: 0.23626 | mse_mse: 0.25675 |  0:00:07s\n",
      "epoch 2  | loss: 0.10191 | mse_mse: 0.14698 |  0:00:11s\n",
      "epoch 3  | loss: 0.07236 | mse_mse: 0.13613 |  0:00:15s\n",
      "epoch 4  | loss: 0.06258 | mse_mse: 0.10339 |  0:00:19s\n",
      "epoch 5  | loss: 0.05533 | mse_mse: 0.07525 |  0:00:24s\n",
      "epoch 6  | loss: 0.05144 | mse_mse: 0.09162 |  0:00:28s\n",
      "epoch 7  | loss: 0.04655 | mse_mse: 0.05012 |  0:00:33s\n",
      "epoch 8  | loss: 0.04044 | mse_mse: 0.05455 |  0:00:37s\n",
      "epoch 9  | loss: 0.03845 | mse_mse: 0.05108 |  0:00:41s\n",
      "epoch 10 | loss: 0.03582 | mse_mse: 0.05104 |  0:00:45s\n",
      "epoch 11 | loss: 0.03512 | mse_mse: 0.03649 |  0:00:49s\n",
      "epoch 12 | loss: 0.03421 | mse_mse: 0.03395 |  0:00:53s\n",
      "epoch 13 | loss: 0.0328  | mse_mse: 0.03387 |  0:00:57s\n",
      "epoch 14 | loss: 0.03801 | mse_mse: 0.02533 |  0:01:01s\n",
      "epoch 15 | loss: 0.03255 | mse_mse: 0.02081 |  0:01:05s\n",
      "epoch 16 | loss: 0.02358 | mse_mse: 0.02387 |  0:01:08s\n",
      "epoch 17 | loss: 0.02825 | mse_mse: 0.04621 |  0:01:12s\n",
      "epoch 18 | loss: 0.02261 | mse_mse: 0.01571 |  0:01:16s\n",
      "epoch 19 | loss: 0.02422 | mse_mse: 0.01617 |  0:01:20s\n",
      "epoch 20 | loss: 0.02148 | mse_mse: 0.02411 |  0:01:23s\n",
      "epoch 21 | loss: 0.02009 | mse_mse: 0.01602 |  0:01:27s\n",
      "epoch 22 | loss: 0.0192  | mse_mse: 0.01192 |  0:01:31s\n",
      "epoch 23 | loss: 0.0163  | mse_mse: 0.0125  |  0:01:35s\n",
      "epoch 24 | loss: 0.01503 | mse_mse: 0.01181 |  0:01:39s\n",
      "epoch 25 | loss: 0.01649 | mse_mse: 0.02398 |  0:01:43s\n",
      "epoch 26 | loss: 0.01595 | mse_mse: 0.0098  |  0:01:46s\n",
      "epoch 27 | loss: 0.01617 | mse_mse: 0.01871 |  0:01:50s\n",
      "epoch 28 | loss: 0.01569 | mse_mse: 0.00887 |  0:01:54s\n",
      "epoch 29 | loss: 0.01762 | mse_mse: 0.0096  |  0:01:58s\n",
      "epoch 30 | loss: 0.01609 | mse_mse: 0.01042 |  0:02:01s\n",
      "epoch 31 | loss: 0.01603 | mse_mse: 0.00907 |  0:02:05s\n",
      "epoch 32 | loss: 0.01133 | mse_mse: 0.00905 |  0:02:09s\n",
      "epoch 33 | loss: 0.01444 | mse_mse: 0.01141 |  0:02:13s\n",
      "epoch 34 | loss: 0.01571 | mse_mse: 0.02707 |  0:02:17s\n",
      "epoch 35 | loss: 0.03203 | mse_mse: 0.00969 |  0:02:22s\n",
      "epoch 36 | loss: 0.01318 | mse_mse: 0.01328 |  0:02:25s\n",
      "epoch 37 | loss: 0.01664 | mse_mse: 0.01081 |  0:02:29s\n",
      "epoch 38 | loss: 0.01353 | mse_mse: 0.00861 |  0:02:33s\n",
      "epoch 39 | loss: 0.01239 | mse_mse: 0.01182 |  0:02:38s\n",
      "epoch 40 | loss: 0.01834 | mse_mse: 0.01149 |  0:02:41s\n",
      "epoch 41 | loss: 0.01628 | mse_mse: 0.00975 |  0:02:46s\n",
      "epoch 42 | loss: 0.01224 | mse_mse: 0.00814 |  0:02:50s\n",
      "epoch 43 | loss: 0.01468 | mse_mse: 0.01025 |  0:02:54s\n",
      "epoch 44 | loss: 0.01251 | mse_mse: 0.00741 |  0:02:58s\n",
      "epoch 45 | loss: 0.01178 | mse_mse: 0.00794 |  0:03:02s\n",
      "epoch 46 | loss: 0.01306 | mse_mse: 0.02178 |  0:03:06s\n",
      "epoch 47 | loss: 0.01234 | mse_mse: 0.01449 |  0:03:10s\n",
      "epoch 48 | loss: 0.01616 | mse_mse: 0.00864 |  0:03:15s\n",
      "epoch 49 | loss: 0.01654 | mse_mse: 0.01569 |  0:03:19s\n",
      "epoch 50 | loss: 0.01474 | mse_mse: 0.0149  |  0:03:23s\n",
      "epoch 51 | loss: 0.01285 | mse_mse: 0.01401 |  0:03:27s\n",
      "epoch 52 | loss: 0.00969 | mse_mse: 0.00874 |  0:03:31s\n",
      "epoch 53 | loss: 0.00979 | mse_mse: 0.00631 |  0:03:37s\n",
      "epoch 54 | loss: 0.01303 | mse_mse: 0.00616 |  0:03:42s\n",
      "epoch 55 | loss: 0.01033 | mse_mse: 0.00705 |  0:03:46s\n",
      "epoch 56 | loss: 0.01412 | mse_mse: 0.00992 |  0:03:51s\n",
      "epoch 57 | loss: 0.01419 | mse_mse: 0.01033 |  0:03:56s\n",
      "epoch 58 | loss: 0.01669 | mse_mse: 0.00816 |  0:04:00s\n",
      "epoch 59 | loss: 0.00922 | mse_mse: 0.00588 |  0:04:04s\n",
      "epoch 60 | loss: 0.01191 | mse_mse: 0.00962 |  0:04:08s\n",
      "epoch 61 | loss: 0.01156 | mse_mse: 0.00942 |  0:04:12s\n",
      "epoch 62 | loss: 0.00959 | mse_mse: 0.00612 |  0:04:15s\n",
      "epoch 63 | loss: 0.01276 | mse_mse: 0.00611 |  0:04:19s\n",
      "epoch 64 | loss: 0.01185 | mse_mse: 0.00663 |  0:04:23s\n",
      "epoch 65 | loss: 0.00863 | mse_mse: 0.0071  |  0:04:27s\n",
      "epoch 66 | loss: 0.00903 | mse_mse: 0.00662 |  0:04:31s\n",
      "epoch 67 | loss: 0.00986 | mse_mse: 0.01328 |  0:04:35s\n",
      "epoch 68 | loss: 0.01151 | mse_mse: 0.01673 |  0:04:39s\n",
      "epoch 69 | loss: 0.01048 | mse_mse: 0.00781 |  0:04:43s\n",
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 59 and best_mse_mse = 0.00588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00593369949360281\n",
      "R2 Score: 0.9732313616702489\n",
      "\n",
      "Iteration 50/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 3 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.44752 | mse_mse: 0.92025 |  0:00:04s\n",
      "epoch 1  | loss: 0.16571 | mse_mse: 0.25306 |  0:00:08s\n",
      "epoch 2  | loss: 0.0928  | mse_mse: 0.11294 |  0:00:13s\n",
      "epoch 3  | loss: 0.06695 | mse_mse: 0.11719 |  0:00:17s\n",
      "epoch 4  | loss: 0.05722 | mse_mse: 0.08946 |  0:00:21s\n",
      "epoch 5  | loss: 0.05238 | mse_mse: 0.07711 |  0:00:25s\n",
      "epoch 6  | loss: 0.04716 | mse_mse: 0.081   |  0:00:30s\n",
      "epoch 7  | loss: 0.04124 | mse_mse: 0.05199 |  0:00:34s\n",
      "epoch 8  | loss: 0.03976 | mse_mse: 0.06025 |  0:00:38s\n",
      "epoch 9  | loss: 0.03977 | mse_mse: 0.05713 |  0:00:43s\n",
      "epoch 10 | loss: 0.03515 | mse_mse: 0.04274 |  0:00:47s\n",
      "epoch 11 | loss: 0.02762 | mse_mse: 0.02849 |  0:00:53s\n",
      "epoch 12 | loss: 0.02722 | mse_mse: 0.02652 |  0:00:58s\n",
      "epoch 13 | loss: 0.02255 | mse_mse: 0.01625 |  0:01:03s\n",
      "epoch 14 | loss: 0.01846 | mse_mse: 0.02363 |  0:01:07s\n",
      "epoch 15 | loss: 0.02094 | mse_mse: 0.03383 |  0:01:11s\n",
      "epoch 16 | loss: 0.0199  | mse_mse: 0.01626 |  0:01:15s\n",
      "epoch 17 | loss: 0.01791 | mse_mse: 0.0232  |  0:01:19s\n",
      "epoch 18 | loss: 0.01504 | mse_mse: 0.01125 |  0:01:24s\n",
      "epoch 19 | loss: 0.01851 | mse_mse: 0.01451 |  0:01:28s\n",
      "epoch 20 | loss: 0.01655 | mse_mse: 0.01218 |  0:01:32s\n",
      "epoch 21 | loss: 0.01522 | mse_mse: 0.00921 |  0:01:36s\n",
      "epoch 22 | loss: 0.01561 | mse_mse: 0.00896 |  0:01:40s\n",
      "epoch 23 | loss: 0.01373 | mse_mse: 0.01456 |  0:01:45s\n",
      "epoch 24 | loss: 0.01446 | mse_mse: 0.01047 |  0:01:50s\n",
      "epoch 25 | loss: 0.01535 | mse_mse: 0.0164  |  0:01:55s\n",
      "epoch 26 | loss: 0.0169  | mse_mse: 0.03083 |  0:01:59s\n",
      "epoch 27 | loss: 0.02357 | mse_mse: 0.0192  |  0:02:04s\n",
      "epoch 28 | loss: 0.01601 | mse_mse: 0.00979 |  0:02:08s\n",
      "epoch 29 | loss: 0.01244 | mse_mse: 0.01472 |  0:02:13s\n",
      "epoch 30 | loss: 0.01255 | mse_mse: 0.00792 |  0:02:17s\n",
      "epoch 31 | loss: 0.01154 | mse_mse: 0.01214 |  0:02:22s\n",
      "epoch 32 | loss: 0.0175  | mse_mse: 0.01351 |  0:02:26s\n",
      "epoch 33 | loss: 0.01596 | mse_mse: 0.00925 |  0:02:30s\n",
      "epoch 34 | loss: 0.015   | mse_mse: 0.01099 |  0:02:34s\n",
      "epoch 35 | loss: 0.01541 | mse_mse: 0.01262 |  0:02:38s\n",
      "epoch 36 | loss: 0.0112  | mse_mse: 0.01695 |  0:02:43s\n",
      "epoch 37 | loss: 0.01381 | mse_mse: 0.03903 |  0:02:47s\n",
      "epoch 38 | loss: 0.0217  | mse_mse: 0.01075 |  0:02:51s\n",
      "epoch 39 | loss: 0.0127  | mse_mse: 0.01675 |  0:02:56s\n",
      "epoch 40 | loss: 0.01228 | mse_mse: 0.00931 |  0:03:00s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_mse_mse = 0.00792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.007419645024571107\n",
      "R2 Score: 0.9665278306708979\n",
      "\n",
      "Iteration 51/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 5 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.28833 | mse_mse: 0.22213 |  0:00:06s\n",
      "epoch 1  | loss: 0.53211 | mse_mse: 0.2524  |  0:00:13s\n",
      "epoch 2  | loss: 0.17522 | mse_mse: 0.20343 |  0:00:19s\n",
      "epoch 3  | loss: 0.15765 | mse_mse: 0.1863  |  0:00:25s\n",
      "epoch 4  | loss: 0.15047 | mse_mse: 0.15988 |  0:00:32s\n",
      "epoch 5  | loss: 0.10022 | mse_mse: 0.14996 |  0:00:39s\n",
      "epoch 6  | loss: 0.09504 | mse_mse: 0.17037 |  0:00:45s\n",
      "epoch 7  | loss: 0.08485 | mse_mse: 0.11612 |  0:00:51s\n",
      "epoch 8  | loss: 0.09914 | mse_mse: 0.08407 |  0:00:58s\n",
      "epoch 9  | loss: 0.08938 | mse_mse: 0.07391 |  0:01:04s\n",
      "epoch 10 | loss: 0.07568 | mse_mse: 0.07273 |  0:01:10s\n",
      "epoch 11 | loss: 0.06838 | mse_mse: 0.05994 |  0:01:16s\n",
      "epoch 12 | loss: 0.06364 | mse_mse: 0.07091 |  0:01:22s\n",
      "epoch 13 | loss: 0.06093 | mse_mse: 0.05423 |  0:01:28s\n",
      "epoch 14 | loss: 0.05264 | mse_mse: 0.04264 |  0:01:34s\n",
      "epoch 15 | loss: 0.04972 | mse_mse: 0.03856 |  0:01:40s\n",
      "epoch 16 | loss: 0.0493  | mse_mse: 0.03848 |  0:01:46s\n",
      "epoch 17 | loss: 0.04193 | mse_mse: 0.03627 |  0:01:52s\n",
      "epoch 18 | loss: 0.03706 | mse_mse: 0.03463 |  0:01:59s\n",
      "epoch 19 | loss: 0.0427  | mse_mse: 0.03782 |  0:02:06s\n",
      "epoch 20 | loss: 0.036   | mse_mse: 0.02938 |  0:02:12s\n",
      "epoch 21 | loss: 0.0306  | mse_mse: 0.02742 |  0:02:20s\n",
      "epoch 22 | loss: 0.02759 | mse_mse: 0.02327 |  0:02:26s\n",
      "epoch 23 | loss: 0.03175 | mse_mse: 0.03075 |  0:02:33s\n",
      "epoch 24 | loss: 0.03414 | mse_mse: 0.03595 |  0:02:40s\n",
      "epoch 25 | loss: 0.02867 | mse_mse: 0.02216 |  0:02:47s\n",
      "epoch 26 | loss: 0.02579 | mse_mse: 0.02482 |  0:02:55s\n",
      "epoch 27 | loss: 0.02378 | mse_mse: 0.01941 |  0:03:01s\n",
      "epoch 28 | loss: 0.02299 | mse_mse: 0.01548 |  0:03:08s\n",
      "epoch 29 | loss: 0.02063 | mse_mse: 0.01955 |  0:03:14s\n",
      "epoch 30 | loss: 0.02179 | mse_mse: 0.02628 |  0:03:21s\n",
      "epoch 31 | loss: 0.02097 | mse_mse: 0.01379 |  0:03:27s\n",
      "epoch 32 | loss: 0.02047 | mse_mse: 0.01327 |  0:03:33s\n",
      "epoch 33 | loss: 0.02381 | mse_mse: 0.01155 |  0:03:39s\n",
      "epoch 34 | loss: 0.02328 | mse_mse: 0.0265  |  0:03:45s\n",
      "epoch 35 | loss: 0.02087 | mse_mse: 0.01655 |  0:03:51s\n",
      "epoch 36 | loss: 0.01897 | mse_mse: 0.01413 |  0:03:57s\n",
      "epoch 37 | loss: 0.01716 | mse_mse: 0.01669 |  0:04:03s\n",
      "epoch 38 | loss: 0.0151  | mse_mse: 0.01747 |  0:04:09s\n",
      "epoch 39 | loss: 0.01477 | mse_mse: 0.01195 |  0:04:16s\n",
      "epoch 40 | loss: 0.01276 | mse_mse: 0.00897 |  0:04:22s\n",
      "epoch 41 | loss: 0.01387 | mse_mse: 0.01284 |  0:04:28s\n",
      "epoch 42 | loss: 0.01651 | mse_mse: 0.00913 |  0:04:34s\n",
      "epoch 43 | loss: 0.01217 | mse_mse: 0.00995 |  0:04:40s\n",
      "epoch 44 | loss: 0.01315 | mse_mse: 0.0088  |  0:04:46s\n",
      "epoch 45 | loss: 0.01478 | mse_mse: 0.01294 |  0:04:52s\n",
      "epoch 46 | loss: 0.01209 | mse_mse: 0.00724 |  0:04:58s\n",
      "epoch 47 | loss: 0.01626 | mse_mse: 0.02085 |  0:05:04s\n",
      "epoch 48 | loss: 0.01214 | mse_mse: 0.00692 |  0:05:10s\n",
      "epoch 49 | loss: 0.01229 | mse_mse: 0.00834 |  0:05:17s\n",
      "epoch 50 | loss: 0.01317 | mse_mse: 0.01886 |  0:05:24s\n",
      "epoch 51 | loss: 0.01555 | mse_mse: 0.00938 |  0:05:31s\n",
      "epoch 52 | loss: 0.00986 | mse_mse: 0.00672 |  0:05:38s\n",
      "epoch 53 | loss: 0.01095 | mse_mse: 0.00747 |  0:05:44s\n",
      "epoch 54 | loss: 0.01229 | mse_mse: 0.01113 |  0:05:51s\n",
      "epoch 55 | loss: 0.01216 | mse_mse: 0.01114 |  0:05:57s\n",
      "epoch 56 | loss: 0.01108 | mse_mse: 0.01088 |  0:06:03s\n",
      "epoch 57 | loss: 0.01431 | mse_mse: 0.02254 |  0:06:09s\n",
      "epoch 58 | loss: 0.01492 | mse_mse: 0.01028 |  0:06:16s\n",
      "epoch 59 | loss: 0.01036 | mse_mse: 0.00745 |  0:06:21s\n",
      "epoch 60 | loss: 0.01014 | mse_mse: 0.00798 |  0:06:27s\n",
      "epoch 61 | loss: 0.0097  | mse_mse: 0.00597 |  0:06:33s\n",
      "epoch 62 | loss: 0.01254 | mse_mse: 0.00809 |  0:06:39s\n",
      "epoch 63 | loss: 0.0094  | mse_mse: 0.00612 |  0:06:45s\n",
      "epoch 64 | loss: 0.00943 | mse_mse: 0.00576 |  0:06:51s\n",
      "epoch 65 | loss: 0.00823 | mse_mse: 0.0127  |  0:06:57s\n",
      "epoch 66 | loss: 0.00898 | mse_mse: 0.00889 |  0:07:04s\n",
      "epoch 67 | loss: 0.00911 | mse_mse: 0.00809 |  0:07:10s\n",
      "epoch 68 | loss: 0.00968 | mse_mse: 0.01794 |  0:07:16s\n",
      "epoch 69 | loss: 0.00984 | mse_mse: 0.00889 |  0:07:22s\n",
      "epoch 70 | loss: 0.00882 | mse_mse: 0.01566 |  0:07:28s\n",
      "epoch 71 | loss: 0.00909 | mse_mse: 0.00687 |  0:07:34s\n",
      "epoch 72 | loss: 0.0088  | mse_mse: 0.0085  |  0:07:39s\n",
      "epoch 73 | loss: 0.01047 | mse_mse: 0.0087  |  0:07:45s\n",
      "epoch 74 | loss: 0.01002 | mse_mse: 0.00729 |  0:07:51s\n",
      "\n",
      "Early stopping occurred at epoch 74 with best_epoch = 64 and best_mse_mse = 0.00576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.006229401953938397\n",
      "R2 Score: 0.9718973621607567\n",
      "\n",
      "Iteration 52/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 5 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.53037 | mse_mse: 0.22962 |  0:00:06s\n",
      "epoch 1  | loss: 0.33352 | mse_mse: 0.19161 |  0:00:12s\n",
      "epoch 2  | loss: 0.24432 | mse_mse: 0.22106 |  0:00:18s\n",
      "epoch 3  | loss: 0.14847 | mse_mse: 0.18773 |  0:00:25s\n",
      "epoch 4  | loss: 0.10608 | mse_mse: 0.11464 |  0:00:31s\n",
      "epoch 5  | loss: 0.08821 | mse_mse: 0.08165 |  0:00:37s\n",
      "epoch 6  | loss: 0.11904 | mse_mse: 0.07626 |  0:00:43s\n",
      "epoch 7  | loss: 0.07937 | mse_mse: 0.06758 |  0:00:50s\n",
      "epoch 8  | loss: 0.07643 | mse_mse: 0.05995 |  0:00:57s\n",
      "epoch 9  | loss: 0.0822  | mse_mse: 0.0537  |  0:01:04s\n",
      "epoch 10 | loss: 0.06625 | mse_mse: 0.04587 |  0:01:11s\n",
      "epoch 11 | loss: 0.06065 | mse_mse: 0.04798 |  0:01:18s\n",
      "epoch 12 | loss: 0.05481 | mse_mse: 0.05598 |  0:01:24s\n",
      "epoch 13 | loss: 0.05597 | mse_mse: 0.04628 |  0:01:30s\n",
      "epoch 14 | loss: 0.05225 | mse_mse: 0.04255 |  0:01:37s\n",
      "epoch 15 | loss: 0.05092 | mse_mse: 0.04814 |  0:01:45s\n",
      "epoch 16 | loss: 0.0403  | mse_mse: 0.03668 |  0:01:51s\n",
      "epoch 17 | loss: 0.03932 | mse_mse: 0.04707 |  0:01:58s\n",
      "epoch 18 | loss: 0.04139 | mse_mse: 0.03112 |  0:02:04s\n",
      "epoch 19 | loss: 0.03457 | mse_mse: 0.03364 |  0:02:11s\n",
      "epoch 20 | loss: 0.0369  | mse_mse: 0.03713 |  0:02:18s\n",
      "epoch 21 | loss: 0.03297 | mse_mse: 0.03428 |  0:02:25s\n",
      "epoch 22 | loss: 0.03567 | mse_mse: 0.0276  |  0:02:31s\n",
      "epoch 23 | loss: 0.0313  | mse_mse: 0.02642 |  0:02:38s\n",
      "epoch 24 | loss: 0.03046 | mse_mse: 0.02237 |  0:02:44s\n",
      "epoch 25 | loss: 0.02617 | mse_mse: 0.03136 |  0:02:50s\n",
      "epoch 26 | loss: 0.02491 | mse_mse: 0.02204 |  0:02:57s\n",
      "epoch 27 | loss: 0.03165 | mse_mse: 0.02895 |  0:03:03s\n",
      "epoch 28 | loss: 0.04003 | mse_mse: 0.03442 |  0:03:11s\n",
      "epoch 29 | loss: 0.03221 | mse_mse: 0.02905 |  0:03:18s\n",
      "epoch 30 | loss: 0.03624 | mse_mse: 0.03784 |  0:03:26s\n",
      "epoch 31 | loss: 0.03738 | mse_mse: 0.02704 |  0:03:33s\n",
      "epoch 32 | loss: 0.02997 | mse_mse: 0.02204 |  0:03:40s\n",
      "epoch 33 | loss: 0.02893 | mse_mse: 0.01921 |  0:03:48s\n",
      "epoch 34 | loss: 0.02284 | mse_mse: 0.0161  |  0:03:55s\n",
      "epoch 35 | loss: 0.02492 | mse_mse: 0.01981 |  0:04:03s\n",
      "epoch 36 | loss: 0.01944 | mse_mse: 0.01957 |  0:04:11s\n",
      "epoch 37 | loss: 0.02225 | mse_mse: 0.01313 |  0:04:18s\n",
      "epoch 38 | loss: 0.01776 | mse_mse: 0.01596 |  0:04:26s\n",
      "epoch 39 | loss: 0.02151 | mse_mse: 0.01247 |  0:04:33s\n",
      "epoch 40 | loss: 0.01815 | mse_mse: 0.01599 |  0:04:40s\n",
      "epoch 41 | loss: 0.02325 | mse_mse: 0.01783 |  0:04:47s\n",
      "epoch 42 | loss: 0.02464 | mse_mse: 0.02112 |  0:04:55s\n",
      "epoch 43 | loss: 0.02178 | mse_mse: 0.01567 |  0:05:01s\n",
      "epoch 44 | loss: 0.01802 | mse_mse: 0.016   |  0:05:08s\n",
      "epoch 45 | loss: 0.01873 | mse_mse: 0.01101 |  0:05:16s\n",
      "epoch 46 | loss: 0.01719 | mse_mse: 0.01256 |  0:05:30s\n",
      "epoch 47 | loss: 0.01891 | mse_mse: 0.02746 |  0:05:46s\n",
      "epoch 48 | loss: 0.01792 | mse_mse: 0.01411 |  0:05:55s\n",
      "epoch 49 | loss: 0.01654 | mse_mse: 0.00967 |  0:06:05s\n",
      "epoch 50 | loss: 0.01515 | mse_mse: 0.01463 |  0:06:13s\n",
      "epoch 51 | loss: 0.01716 | mse_mse: 0.0122  |  0:06:21s\n",
      "epoch 52 | loss: 0.01963 | mse_mse: 0.01849 |  0:06:29s\n",
      "epoch 53 | loss: 0.01514 | mse_mse: 0.01002 |  0:06:36s\n",
      "epoch 54 | loss: 0.01394 | mse_mse: 0.01196 |  0:06:44s\n",
      "epoch 55 | loss: 0.01364 | mse_mse: 0.01148 |  0:06:52s\n",
      "epoch 56 | loss: 0.01402 | mse_mse: 0.01663 |  0:07:00s\n",
      "epoch 57 | loss: 0.02353 | mse_mse: 0.01898 |  0:07:07s\n",
      "epoch 58 | loss: 0.01842 | mse_mse: 0.02229 |  0:07:14s\n",
      "epoch 59 | loss: 0.02113 | mse_mse: 0.0139  |  0:07:22s\n",
      "\n",
      "Early stopping occurred at epoch 59 with best_epoch = 49 and best_mse_mse = 0.00967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.01168487251596444\n",
      "R2 Score: 0.9472861531585277\n",
      "\n",
      "Iteration 53/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 7 - n_indipendent: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.66822 | mse_mse: 0.82016 |  0:00:08s\n",
      "epoch 1  | loss: 0.50862 | mse_mse: 0.8457  |  0:00:18s\n",
      "epoch 2  | loss: 0.41279 | mse_mse: 0.53908 |  0:00:27s\n",
      "epoch 3  | loss: 0.64985 | mse_mse: 0.18535 |  0:00:38s\n",
      "epoch 4  | loss: 0.14369 | mse_mse: 0.14467 |  0:00:47s\n",
      "epoch 5  | loss: 0.16641 | mse_mse: 0.14531 |  0:00:57s\n",
      "epoch 6  | loss: 0.10278 | mse_mse: 0.12983 |  0:01:07s\n",
      "epoch 7  | loss: 0.1147  | mse_mse: 0.11481 |  0:01:16s\n",
      "epoch 8  | loss: 0.08354 | mse_mse: 0.08424 |  0:01:26s\n",
      "epoch 9  | loss: 0.06639 | mse_mse: 0.07618 |  0:01:35s\n",
      "epoch 10 | loss: 0.06896 | mse_mse: 0.09093 |  0:01:44s\n",
      "epoch 11 | loss: 0.06818 | mse_mse: 0.06726 |  0:01:52s\n",
      "epoch 12 | loss: 0.06719 | mse_mse: 0.07311 |  0:02:00s\n",
      "epoch 13 | loss: 0.06513 | mse_mse: 0.058   |  0:02:08s\n",
      "epoch 14 | loss: 0.05945 | mse_mse: 0.0559  |  0:02:16s\n",
      "epoch 15 | loss: 0.05574 | mse_mse: 0.04887 |  0:02:24s\n",
      "epoch 16 | loss: 0.06423 | mse_mse: 0.05857 |  0:02:33s\n",
      "epoch 17 | loss: 0.05213 | mse_mse: 0.04674 |  0:02:42s\n",
      "epoch 18 | loss: 0.0496  | mse_mse: 0.04146 |  0:02:51s\n",
      "epoch 19 | loss: 0.04654 | mse_mse: 0.03745 |  0:03:00s\n",
      "epoch 20 | loss: 0.04368 | mse_mse: 0.04901 |  0:03:09s\n",
      "epoch 21 | loss: 0.0524  | mse_mse: 0.07977 |  0:03:18s\n",
      "epoch 22 | loss: 0.04939 | mse_mse: 0.03524 |  0:03:26s\n",
      "epoch 23 | loss: 0.03977 | mse_mse: 0.03704 |  0:03:35s\n",
      "epoch 24 | loss: 0.03611 | mse_mse: 0.03634 |  0:03:43s\n",
      "epoch 25 | loss: 0.0339  | mse_mse: 0.03548 |  0:03:53s\n",
      "epoch 26 | loss: 0.03314 | mse_mse: 0.02899 |  0:04:01s\n",
      "epoch 27 | loss: 0.02939 | mse_mse: 0.02544 |  0:04:09s\n",
      "epoch 28 | loss: 0.03052 | mse_mse: 0.02841 |  0:04:17s\n",
      "epoch 29 | loss: 0.03083 | mse_mse: 0.02626 |  0:04:25s\n",
      "epoch 30 | loss: 0.02805 | mse_mse: 0.02705 |  0:04:33s\n",
      "epoch 31 | loss: 0.02895 | mse_mse: 0.02063 |  0:04:41s\n",
      "epoch 32 | loss: 0.02572 | mse_mse: 0.02077 |  0:04:48s\n",
      "epoch 33 | loss: 0.03658 | mse_mse: 0.04986 |  0:04:56s\n",
      "epoch 34 | loss: 0.02513 | mse_mse: 0.01945 |  0:05:04s\n",
      "epoch 35 | loss: 0.02429 | mse_mse: 0.02221 |  0:05:12s\n",
      "epoch 36 | loss: 0.02431 | mse_mse: 0.02619 |  0:05:20s\n",
      "epoch 37 | loss: 0.0222  | mse_mse: 0.01894 |  0:05:29s\n",
      "epoch 38 | loss: 0.02173 | mse_mse: 0.0217  |  0:05:40s\n",
      "epoch 39 | loss: 0.02388 | mse_mse: 0.02216 |  0:05:48s\n",
      "epoch 40 | loss: 0.0225  | mse_mse: 0.01621 |  0:05:57s\n",
      "epoch 41 | loss: 0.01979 | mse_mse: 0.01785 |  0:06:05s\n",
      "epoch 42 | loss: 0.01815 | mse_mse: 0.0151  |  0:06:13s\n",
      "epoch 43 | loss: 0.01681 | mse_mse: 0.01389 |  0:06:23s\n",
      "epoch 44 | loss: 0.02041 | mse_mse: 0.0207  |  0:06:32s\n",
      "epoch 45 | loss: 0.01726 | mse_mse: 0.01197 |  0:06:41s\n",
      "epoch 46 | loss: 0.01766 | mse_mse: 0.01298 |  0:06:50s\n",
      "epoch 47 | loss: 0.01886 | mse_mse: 0.01417 |  0:07:00s\n",
      "epoch 48 | loss: 0.01303 | mse_mse: 0.01543 |  0:07:09s\n",
      "epoch 49 | loss: 0.01622 | mse_mse: 0.01514 |  0:07:18s\n",
      "epoch 50 | loss: 0.01556 | mse_mse: 0.01104 |  0:07:28s\n",
      "epoch 51 | loss: 0.01488 | mse_mse: 0.01282 |  0:07:37s\n",
      "epoch 52 | loss: 0.0144  | mse_mse: 0.01198 |  0:07:47s\n",
      "epoch 53 | loss: 0.01293 | mse_mse: 0.01698 |  0:07:56s\n",
      "epoch 54 | loss: 0.01128 | mse_mse: 0.012   |  0:08:05s\n",
      "epoch 55 | loss: 0.01249 | mse_mse: 0.02049 |  0:08:13s\n",
      "epoch 56 | loss: 0.01286 | mse_mse: 0.0111  |  0:08:21s\n",
      "epoch 57 | loss: 0.0118  | mse_mse: 0.00915 |  0:08:30s\n",
      "epoch 58 | loss: 0.01265 | mse_mse: 0.0218  |  0:08:39s\n",
      "epoch 59 | loss: 0.014   | mse_mse: 0.02262 |  0:08:47s\n",
      "epoch 60 | loss: 0.01621 | mse_mse: 0.02303 |  0:08:55s\n",
      "epoch 61 | loss: 0.01674 | mse_mse: 0.0137  |  0:09:04s\n",
      "epoch 62 | loss: 0.0131  | mse_mse: 0.0116  |  0:09:13s\n",
      "epoch 63 | loss: 0.01193 | mse_mse: 0.00942 |  0:09:23s\n",
      "epoch 64 | loss: 0.01248 | mse_mse: 0.00977 |  0:09:33s\n",
      "epoch 65 | loss: 0.01187 | mse_mse: 0.00995 |  0:09:43s\n",
      "epoch 66 | loss: 0.01305 | mse_mse: 0.00977 |  0:09:51s\n",
      "epoch 67 | loss: 0.01604 | mse_mse: 0.0084  |  0:09:59s\n",
      "epoch 68 | loss: 0.01135 | mse_mse: 0.0111  |  0:10:07s\n",
      "epoch 69 | loss: 0.01005 | mse_mse: 0.00862 |  0:10:15s\n",
      "epoch 70 | loss: 0.01186 | mse_mse: 0.00766 |  0:10:23s\n",
      "epoch 71 | loss: 0.01708 | mse_mse: 0.0326  |  0:10:31s\n",
      "epoch 72 | loss: 0.01129 | mse_mse: 0.00684 |  0:10:41s\n",
      "epoch 73 | loss: 0.01094 | mse_mse: 0.01693 |  0:10:49s\n",
      "epoch 74 | loss: 0.0111  | mse_mse: 0.01087 |  0:10:57s\n",
      "epoch 75 | loss: 0.0171  | mse_mse: 0.01174 |  0:11:05s\n",
      "epoch 76 | loss: 0.01766 | mse_mse: 0.01052 |  0:11:14s\n",
      "epoch 77 | loss: 0.00888 | mse_mse: 0.0079  |  0:11:23s\n",
      "epoch 78 | loss: 0.01472 | mse_mse: 0.01095 |  0:11:31s\n",
      "epoch 79 | loss: 0.01185 | mse_mse: 0.01011 |  0:11:40s\n",
      "epoch 80 | loss: 0.01334 | mse_mse: 0.00802 |  0:11:49s\n",
      "epoch 81 | loss: 0.00836 | mse_mse: 0.01314 |  0:11:58s\n",
      "epoch 82 | loss: 0.01109 | mse_mse: 0.00979 |  0:12:07s\n",
      "\n",
      "Early stopping occurred at epoch 82 with best_epoch = 72 and best_mse_mse = 0.00684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0072603892620705665\n",
      "R2 Score: 0.967246279576661\n",
      "\n",
      "Iteration 54/54\n",
      "Configuration batch size: 256 - epochs: 200 - n_d: 32 - n_a: 32 - steps: 7 - n_indipendent: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.45549 | mse_mse: 0.71874 |  0:00:08s\n",
      "epoch 1  | loss: 0.65631 | mse_mse: 0.41291 |  0:00:16s\n",
      "epoch 2  | loss: 0.78668 | mse_mse: 0.16181 |  0:00:25s\n",
      "epoch 3  | loss: 0.26863 | mse_mse: 0.10532 |  0:00:34s\n",
      "epoch 4  | loss: 0.15552 | mse_mse: 0.19355 |  0:00:42s\n",
      "epoch 5  | loss: 0.10522 | mse_mse: 0.15253 |  0:00:51s\n",
      "epoch 6  | loss: 0.08631 | mse_mse: 0.10203 |  0:01:01s\n",
      "epoch 7  | loss: 0.06631 | mse_mse: 0.1097  |  0:01:11s\n",
      "epoch 8  | loss: 0.07118 | mse_mse: 0.07913 |  0:01:20s\n",
      "epoch 9  | loss: 0.06991 | mse_mse: 0.06485 |  0:01:29s\n",
      "epoch 10 | loss: 0.05877 | mse_mse: 0.06092 |  0:01:39s\n",
      "epoch 11 | loss: 0.05573 | mse_mse: 0.06056 |  0:01:48s\n",
      "epoch 12 | loss: 0.04904 | mse_mse: 0.04847 |  0:01:56s\n",
      "epoch 13 | loss: 0.05202 | mse_mse: 0.04104 |  0:02:06s\n",
      "epoch 14 | loss: 0.05476 | mse_mse: 0.03847 |  0:02:17s\n",
      "epoch 15 | loss: 0.04874 | mse_mse: 0.03785 |  0:02:26s\n",
      "epoch 16 | loss: 0.04528 | mse_mse: 0.03895 |  0:02:36s\n",
      "epoch 17 | loss: 0.04502 | mse_mse: 0.03779 |  0:02:45s\n",
      "epoch 18 | loss: 0.04381 | mse_mse: 0.04182 |  0:02:54s\n",
      "epoch 19 | loss: 0.0454  | mse_mse: 0.0365  |  0:03:03s\n",
      "epoch 20 | loss: 0.04641 | mse_mse: 0.04416 |  0:03:12s\n",
      "epoch 21 | loss: 0.04233 | mse_mse: 0.03602 |  0:03:23s\n",
      "epoch 22 | loss: 0.03988 | mse_mse: 0.03279 |  0:03:33s\n",
      "epoch 23 | loss: 0.0433  | mse_mse: 0.03022 |  0:03:43s\n",
      "epoch 24 | loss: 0.04054 | mse_mse: 0.04727 |  0:03:53s\n",
      "epoch 25 | loss: 0.04053 | mse_mse: 0.02935 |  0:04:03s\n",
      "epoch 26 | loss: 0.03618 | mse_mse: 0.02951 |  0:04:12s\n",
      "epoch 27 | loss: 0.03731 | mse_mse: 0.04293 |  0:04:21s\n",
      "epoch 28 | loss: 0.03685 | mse_mse: 0.03802 |  0:04:29s\n",
      "epoch 29 | loss: 0.04603 | mse_mse: 0.02962 |  0:04:40s\n",
      "epoch 30 | loss: 0.03412 | mse_mse: 0.02995 |  0:04:49s\n",
      "epoch 31 | loss: 0.03549 | mse_mse: 0.02811 |  0:04:58s\n",
      "epoch 32 | loss: 0.03341 | mse_mse: 0.02615 |  0:05:06s\n",
      "epoch 33 | loss: 0.03328 | mse_mse: 0.02302 |  0:05:16s\n",
      "epoch 34 | loss: 0.02906 | mse_mse: 0.0281  |  0:05:25s\n",
      "epoch 35 | loss: 0.03193 | mse_mse: 0.02542 |  0:05:34s\n",
      "epoch 36 | loss: 0.02704 | mse_mse: 0.02302 |  0:05:43s\n",
      "epoch 37 | loss: 0.02513 | mse_mse: 0.02069 |  0:05:51s\n",
      "epoch 38 | loss: 0.02558 | mse_mse: 0.02242 |  0:06:00s\n",
      "epoch 39 | loss: 0.02753 | mse_mse: 0.02312 |  0:06:09s\n",
      "epoch 40 | loss: 0.02398 | mse_mse: 0.02135 |  0:06:17s\n",
      "epoch 41 | loss: 0.02544 | mse_mse: 0.02672 |  0:06:26s\n",
      "epoch 42 | loss: 0.02897 | mse_mse: 0.02307 |  0:06:35s\n",
      "epoch 43 | loss: 0.02868 | mse_mse: 0.02767 |  0:06:45s\n",
      "epoch 44 | loss: 0.02639 | mse_mse: 0.02371 |  0:06:56s\n",
      "epoch 45 | loss: 0.0266  | mse_mse: 0.02303 |  0:07:07s\n",
      "epoch 46 | loss: 0.02813 | mse_mse: 0.03201 |  0:07:20s\n",
      "epoch 47 | loss: 0.02702 | mse_mse: 0.0212  |  0:07:32s\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 37 and best_mse_mse = 0.02069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.02091376308632036\n",
      "R2 Score: 0.905651952753022\n"
     ]
    }
   ],
   "source": [
    "best_mse = float('inf')\n",
    "best_model = None\n",
    "best_params = None\n",
    "iter = 0\n",
    "for b, n_e, n_d, n_a, n_s, n_i in params:\n",
    "    iter += 1\n",
    "    print(f'\\nIteration {iter}/{comb}')\n",
    "    print(f\"Configuration batch size: {b} - epochs: {n_e} - n_d: {n_d} - n_a: {n_a} - steps: {n_s} - n_indipendent: {n_i}\")\n",
    "    \n",
    "    model = get_model(b, n_e, n_d, n_a, n_s, n_i)\n",
    "    #save results for each iteration with tensorboard\n",
    "    log = f'bach_size_{b}_nEpochs_{n_e}_nd_{n_d}_na_{n_a}_nSteps_{n_s}_nIndipendent_{n_i}'\n",
    "\n",
    "    if pca_t == True:\n",
    "        if os.path.exists(\"./results/TabNet/pca/\"+log):\n",
    "            print(\"Model already trained. Skipping...\")\n",
    "            continue\n",
    "        writer = SummaryWriter(f'results/TabNet/pca/bach_size_{b}_nEpochs_{n_e}_nd_{n_d}_na_{n_a}_nSteps_{n_s}_nIndipendent_{n_i}')\n",
    "    else:\n",
    "        if os.path.exists(\"./results/TabNet/no_pca/\"+log):\n",
    "            print(\"Model already trained. Skipping...\")\n",
    "            continue\n",
    "        writer = SummaryWriter(f'results/TabNet/no_pca/bach_size_{b}_nEpochs_{n_e}_nd_{n_d}_na_{n_a}_nSteps_{n_s}_nIndipendent_{n_i}')\n",
    "\n",
    "    #fit model\n",
    "    model.fit(\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_name=['mse'],\n",
    "        patience=10,\n",
    "        batch_size=b,\n",
    "        virtual_batch_size=128\n",
    "    )\n",
    "\n",
    "    # evaluate model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "   #save hparams for each iteration with tensorboard\n",
    "    writer.add_hparams(\n",
    "        {'batch_size': b, 'n_epochs': n_e, 'n_d': n_d, 'n_a': n_a, 'n_steps': n_s, 'n_indipendent': n_i},\n",
    "        {'hparam/mse': mse, 'hparam/r2': r2}\n",
    "    )\n",
    "    print('MSE:', mse)\n",
    "    print('R2 Score:', r2)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_params = (b, n_e, n_d, n_a, n_s, n_i)\n",
    "        print('Best model updated')\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabNetRegressor(n_d=16, n_a=8, n_steps=5, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=0, clip_value=1, verbose=1, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=1128, output_dim=1, device_name='auto', n_shared_decoder=1, n_indep_decoder=1)\n",
      "Best MSE:  0.005357398783822059\n",
      "R2 score 0.9758312212158716\n"
     ]
    }
   ],
   "source": [
    "#pint the best model\n",
    "print(best_model)\n",
    "print(\"Best MSE: \", best_mse)\n",
    "print(\"R2 score\", r2_score(y_test, best_model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at best_model_tabnet_nopca_256.csv.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'best_model_tabnet_nopca_256.csv.zip'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the best model in a file csv\n",
    "best_model.save_model('best_model_tabnet_nopca_256.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
