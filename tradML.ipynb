{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "pca_t=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "df = pd.read_csv('dataset-ml-25m/dataset.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train set:  9946\n",
      "Number of validation set:  1106\n",
      "Numebr of test set:  2764\n"
     ]
    }
   ],
   "source": [
    "#split data and labels \n",
    "X = df.drop(['rating'], axis=1)\n",
    "y = df['rating']\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1, random_state=42)\n",
    "\n",
    "#count the numebr of x_train x_val and x_test\n",
    "print(\"Number of train set: \", X_train.shape[0])\n",
    "print(\"Number of validation set: \", X_val.shape[0])\n",
    "print(\"Numebr of test set: \", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA is not applied\n"
     ]
    }
   ],
   "source": [
    "if pca_t == True:\n",
    "    pca = PCA(n_components=0.95)\n",
    "    pca.fit(X_train)\n",
    "    X_train = pca.transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "else:\n",
    "    print (\"PCA is not applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-SNE\n",
    "#tsne = TSNE(n_components=2, random_state=0, perplexity=50, n_iter=500)\n",
    "#X_train_tsne = tsne.fit_transform(X_train)\n",
    "\n",
    "#plt.figure(figsize=(12, 8))\n",
    "#plt.scatter(X_train_tsne[:, 0], X_train_tsne[:, 1], c=y_train, cmap=\"jet\", s=7)\n",
    "#plt.colorbar()\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regressor\n",
    "Con PCA:\n",
    "- Mean Square Error: 0.00643\n",
    "- R-square: 0.97096\n",
    "\n",
    "Senza PCA:\n",
    "- mse: 0.00544\n",
    "- R2-square: 0.97543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error: 0.005445406919048585\n",
      "R2-square: 0.9754341910082424\n"
     ]
    }
   ],
   "source": [
    "log_name = f\"linear_regression\"\n",
    "if pca_t == True:\n",
    "    writer = SummaryWriter(f\"results/tradML/pca/LinearRegression/{log_name}\")\n",
    "else:\n",
    "    writer = SummaryWriter(f\"results/tradML/no_pca/LinearRegression/{log_name}\")\n",
    "\n",
    "lin_regr = linear_model.LinearRegression()\n",
    "lin_regr.fit(X_train, y_train)\n",
    "y_pred = lin_regr.predict(X_test)\n",
    "\n",
    "# Compute the RSS\n",
    "mse = mean_squared_error(y_test, y_pred) \n",
    "print('Mean Square Error:', mse)\n",
    "writer.add_scalar('Loss', mse)\n",
    "writer.flush()\n",
    "\n",
    "# Compute the R-square index\n",
    "rsquare = r2_score(y_test, y_pred) \n",
    "print('R2-square:', rsquare)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor\n",
    "Con PCA:\n",
    "- Mean Squared Error:  0.03735\n",
    "- R2 Score:  0.83150\n",
    "\n",
    "Senza PCA:\n",
    "- mse:  0.01255\n",
    "- R2 Score:  0.94334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper:  {'criterion': 'friedman_mse', 'n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "                \"n_estimators\": [10, 15, 20, 25, 30],\n",
    "                \"criterion\": [\"squared_error\", \"friedman_mse\"]\n",
    "              }\n",
    "rf = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_hyper= grid_search.best_params_\n",
    "print(\"Best hyper: \", best_hyper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#display(grid_search.cv_results_)\n",
    "## con pca\n",
    "print(pca_t)\n",
    "if pca_t == True:\n",
    "    pd.DataFrame(grid_search.cv_results_).to_csv(\"cv_results/pca/RandomForestRegressor.csv\")\n",
    "else:\n",
    "    pd.DataFrame(grid_search.cv_results_).to_csv(\"cv_results/no_pca/RandomForestRegressor.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take only neg_mean_squared_error and convert to positive\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results = results[['param_n_estimators', 'param_criterion', 'mean_test_score']]\n",
    "results['mean_test_score'] = results['mean_test_score'] * -1\n",
    "\n",
    "#save mse to tensorboard\n",
    "if pca_t == True:\n",
    "    writer = SummaryWriter(f\"results/tradML/pca/RandomForest/\")\n",
    "else:\n",
    "    writer = SummaryWriter(f\"results/tradML/no_pca/RandomForest/\")\n",
    "for index, row in results.iterrows():\n",
    "    mse = row['mean_test_score']\n",
    "    n_estimators = row['param_n_estimators']\n",
    "    criterion = row['param_criterion']\n",
    "    writer.add_hparams({\"n_estimators\": n_estimators, \"criterion\": criterion},{\"hparam/mse\": mse})\n",
    "    writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = pd.DataFrame.from_dict(grid_search.best_params_, orient='index', columns=['value'])\n",
    "rf = rf.T\n",
    "if pca_t == True:\n",
    "    rf.to_csv('best_params/pca/random_forest.csv', index=False)\n",
    "else:\n",
    "    rf.to_csv('best_params/no_pca/random_forest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  0.01255852775271672\n",
      "R2 Score:  0.9433448411519578\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(**best_hyper)\n",
    "rf= rf.fit(X_train,y_train)\n",
    "y_pred= rf.predict(X_test)\n",
    "\n",
    "print(\"Mean Squared Error: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 Score: \", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regressor\n",
    "Con PCA:\n",
    "- Mean Squared Error:  0.00639\n",
    "- R2 Score:  0.97113\n",
    "\n",
    "Senza PCA:\n",
    "- mse: 0.00532\n",
    "- R2 Score:  0.97598"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper:  {'alpha': 5}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "                \"alpha\":[0.0001, 0.001, 0.1, 0.5, 1, 5, 10, 20]\n",
    "              }\n",
    "ridge = Ridge()\n",
    "grid_search = GridSearchCV(ridge, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_train,y_train)\n",
    "best_hyper= grid_search.best_params_\n",
    "print(\"Best hyper: \", best_hyper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(grid_search.cv_results_)\n",
    "if pca_t == True:\n",
    "    writer = SummaryWriter(f\"cv_results/pca/Ridge/\")\n",
    "else:\n",
    "    writer = SummaryWriter(f\"cv_results/no_pca/Ridge/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take only neg_mean_squared_error and convert to positive\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results = results[['param_alpha','mean_test_score']]\n",
    "results['mean_test_score'] = results['mean_test_score'] * -1\n",
    "\n",
    "#save mse to tensorboard\n",
    "if pca_t == True:\n",
    "    writer = SummaryWriter(f\"results/tradML/pca/Ridge\")\n",
    "else:\n",
    "    writer = SummaryWriter(f\"results/tradML/no_pca/Ridge\")\n",
    "for index, row in results.iterrows():\n",
    "    mse = row['mean_test_score']\n",
    "    alpha = row['param_alpha']\n",
    "    writer.add_hparams({\"alpha\": alpha},{\"/hparam/mse\": mse})\n",
    "    writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = pd.DataFrame.from_dict(grid_search.best_params_, orient='index', columns=['value'])\n",
    "ridge = ridge.T\n",
    "if pca_t == True:\n",
    "    ridge.to_csv('best_params/pca/ridge.csv', index=False)\n",
    "else:\n",
    "    ridge.to_csv('best_params/no_pca/ridge.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  0.005323110704793611\n",
      "R2 Score:  0.9759859046789496\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(**best_hyper)\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred= ridge.predict(X_test)\n",
    "\n",
    "print(\"Mean Squared Error: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 Score: \", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Regressor\n",
    "Con PCA:\n",
    "- Mean Squared Error:  0.04028\n",
    "- R2 Score:  0.81828\n",
    "\n",
    "Senza PCA:\n",
    "- mse: 0.04050\n",
    "- R2 Score:  0.81727"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper:  {'n_neighbors': 10, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "                'n_neighbors': [3, 4, 5, 7, 8, 9, 10],\n",
    "                'weights': ['uniform', 'distance']\n",
    "              }\n",
    "knn = KNeighborsRegressor()\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_train,y_train)\n",
    "best_hyper= grid_search.best_params_\n",
    "print(\"Best hyper: \", best_hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(grid_search.cv_results_)\n",
    "if pca_t == True:\n",
    "    pd.DataFrame(grid_search.cv_results_).to_csv(\"cv_results/pca/KNN.csv\")\n",
    "else:\n",
    "    pd.DataFrame(grid_search.cv_results_).to_csv(\"cv_results/no_pca/KNN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take only neg_mean_squared_error and convert to positive\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results = results[['param_n_neighbors', 'param_weights', 'mean_test_score']]\n",
    "results['mean_test_score'] = results['mean_test_score'] * -1\n",
    "\n",
    "#save mse to tensorboard\n",
    "if pca_t == True:\n",
    "    writer = SummaryWriter(f\"results/tradML/pca/KNN/\")\n",
    "else:\n",
    "    writer = SummaryWriter(f\"results/tradML/no_pca/KNN/\")\n",
    "writer = SummaryWriter(f\"results/tradML/pca/KNN/\")\n",
    "for index, row in results.iterrows():\n",
    "    mse = row['mean_test_score']\n",
    "    n_neighbors = row['param_n_neighbors']\n",
    "    weights = row['param_weights']\n",
    "    writer.add_hparams({\"n_neighbors\": n_neighbors, \"weights\":weights},{\"hparam/mse\": mse})\n",
    "    writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = pd.DataFrame.from_dict(grid_search.best_params_, orient='index', columns=['value'])\n",
    "knn = knn.T\n",
    "if pca_t == True:\n",
    "    knn.to_csv('best_params/pca/knn.csv', index=False)\n",
    "else:\n",
    "    knn.to_csv('best_params/no_pca/knn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  0.040503488522491256\n",
      "R2 Score:  0.8172770231251678\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(**best_hyper)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred= knn.predict(X_test)\n",
    "\n",
    "print(\"Mean Squared Error: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 Score: \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regressor\n",
    "Con PCA:\n",
    "- Mean Squared Error:  0.00641\n",
    "- R2 Score:  0.97106\n",
    "\n",
    "Senza PCA:\n",
    "- 0.00542\n",
    "- R2 Score:  0.97553\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.527e+00, tolerance: 1.880e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.996e+00, tolerance: 1.910e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.742e+00, tolerance: 1.920e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.814e+00, tolerance: 1.897e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.194e+00, tolerance: 1.885e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.590e+01, tolerance: 1.880e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.585e+01, tolerance: 1.910e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+01, tolerance: 1.920e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e+01, tolerance: 1.897e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.543e+01, tolerance: 1.885e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper:  {'alpha': 1e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.046e+01, tolerance: 2.373e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "                'alpha':[1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "              }\n",
    "lasso = Lasso()\n",
    "grid_search = GridSearchCV(lasso, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_train,y_train)\n",
    "best_hyper= grid_search.best_params_\n",
    "print(\"Best hyper: \", best_hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(grid_search.cv_results_)\n",
    "if pca_t == True:\n",
    "    pd.DataFrame(grid_search.cv_results_).to_csv(\"cv_results/pca/Lasso.csv\")\n",
    "else:\n",
    "    pd.DataFrame(grid_search.cv_results_).to_csv(\"cv_results/no_pca/Lasso.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take only neg_mean_squared_error and convert to positive\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results = results[['param_alpha','mean_test_score']]\n",
    "results['mean_test_score'] = results['mean_test_score'] * -1\n",
    "\n",
    "#save mse to tensorboard\n",
    "if pca_t == True:\n",
    "    writer = SummaryWriter(f\"results/tradML/pca/Lasso/\")\n",
    "else:\n",
    "    writer = SummaryWriter(f\"results/tradML/no_pca/Lasso/\")\n",
    "for index, row in results.iterrows():\n",
    "    mse = row['mean_test_score']\n",
    "    alpha = row['param_alpha']\n",
    "    writer.add_hparams({\"alpha\": alpha},{\"hparam/mse\": mse})\n",
    "    writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = pd.DataFrame.from_dict(grid_search.best_params_, orient='index', columns=['value'])\n",
    "lasso= lasso.T\n",
    "if pca_t == True:\n",
    "    lasso.to_csv('best_params/pca/lasso.csv', index=False)\n",
    "else:\n",
    "    lasso.to_csv('best_params/no_pca/lasso.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  0.005423553353396875\n",
      "R2 Score:  0.9755327787772686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.046e+01, tolerance: 2.373e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(**best_hyper)\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred= lasso.predict(X_test)\n",
    "\n",
    "print(\"Mean Squared Error: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 Score: \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR\n",
    "Con PCA:\n",
    "- Mean Squared Error: 0.00645\n",
    "- R2 Score: 0.97086"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper  {'epsilon': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "                'kernel': ['linear', 'poly', 'rbf'],\n",
    "                'epsilon': [0.001, 0.01, 0.1, 1]\n",
    "              }\n",
    "svr = SVR()\n",
    "grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_train,y_train)\n",
    "best_hyper = grid_search.best_params_\n",
    "print(\"Best hyper \", best_hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(grid_search.cv_results_)\n",
    "if pca_t == True:\n",
    "    pd.DataFrame(grid_search.cv_results_).to_csv(\"cv_results/pca/SVR.csv\")\n",
    "else:\n",
    "    pd.DataFrame(grid_search.cv_results_).to_csv(\"cv_results/no_pca/SVR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take only neg_mean_squared_error and convert to positive\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results = results[['param_kernel','param_epsilon' ,'mean_test_score']]\n",
    "results['mean_test_score'] = results['mean_test_score'] * -1\n",
    "\n",
    "\n",
    "#save mse to tensorboard\n",
    "if pca_t == True:\n",
    "    writer = SummaryWriter(f\"results/tradML/pca/SVR/\")\n",
    "else:\n",
    "    writer = SummaryWriter(f\"results/tradML/no_pca/SVR/\")\n",
    "for index, row in results.iterrows():\n",
    "    mse = row['mean_test_score']\n",
    "    kernel = row['param_kernel']\n",
    "    epsilon = row['param_epsilon']\n",
    "    writer.add_hparams({\"kernel\": kernel, \"epsilon\":epsilon},{\"hparam/mse\": mse})\n",
    "    writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = pd.DataFrame.from_dict(grid_search.best_params_, orient='index', columns=['value'])\n",
    "svr = svr.T\n",
    "if pca_t == True:   \n",
    "    svr.to_csv('best_params/pca/svr.csv', index=False)\n",
    "else:\n",
    "    svr.to_csv('best_params/no_pca/svr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  0.005214488613478723\n",
      "R2 Score:  0.9764759304175574\n"
     ]
    }
   ],
   "source": [
    "svr = SVR(**best_hyper)\n",
    "svr.fit(X_train, y_train)\n",
    "y_pred= svr.predict(X_test)\n",
    "\n",
    "print(\"Mean Squared Error: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 Score: \", r2_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
